% $Id: projets.tex,v 1.7 2008/02/05 22:53:15 cappe Exp $
\documentclass[11pt]{article}

\usepackage{a4wide,amsmath,amssymb,graphicx,url}
\usepackage[french]{babel}
\usepackage[applemac]{inputenc}

% Definitions (pas trop!)
\newcommand{\btheta}{{\mathbf \theta}}
\newcommand{\bx}{{\mathbf x}}
\newcommand{\by}{{\mathbf y}}
\newcommand{\R}{\mathbb R}
\newcommand \com[1]{\noindent \fbox{\sf  #1}}
\newtheorem{definition}{D\'efinition}
% Projets O. Cappé
\newcommand{\rset}{\ensuremath{\mathbb{R}}}
\renewcommand{\P}{\ensuremath{\operatorname{P}}}
\newcommand{\E}{\ensuremath{\operatorname{E}}}
\newcommand{\eqdef}{\ensuremath{\stackrel{\mathrm{def}}{=}}}
% Projets G. Lang
\def\1{{\bf 1}}

%Projets C. Giraud
\newcommand{\mois}{\textrm{\scriptsize mois}}
\newcommand{\mai}{\textrm{\scriptsize mai}}
\newcommand{\juin}{\textrm{\scriptsize juin}}

%Projets M. Rosenbaum
\newcommand{\PP}{\mathbb{P}}

%Projets A. Dalalyan
\newcommand{\PPhi}{\boldsymbol{\Phi}}
\newcommand{\bY}{\boldsymbol{Y}}
\newcommand{\bA}{\boldsymbol{A}}

\def\myvarlimsup{\mathop{\varlimsup}}
\def\myvarliminf{\mathop{\varliminf}}
\def\diff{d}
\def\supp{\mathop{\rm supp}\nolimits}
\def\arg{\mathop{\rm arg}}
\def\argmax{\mathop{\rm arg\max}}
\def\infl{\mathop{\rm inf\hskip-5pt\phantom{p}}}
\def\Re{\mathop{\rm Re}\nolimits}
\def\betam{\bar{\beta}}
\def\Im{\mathop{\rm Im}\nolimits}
\def\cc#1{\mathcal{#1}}
\newcommand{\B}{\cc{B}^{*}}
\def\T{\top}
\def\tr{\mathop{\rm tr}}
\def\Span{\mathop{\rm span}}
\def\rank{\mathop{\rm rank}}
\def\arginf{\mathop{\rm arg\,inf}}
\def\esp{{\bf E}}
\def\Pb{{\bf P}}
\def\var{{\bf Var}}
\def\sign{\mathop{\rm sgn}}
\def\ZZ{\mathbb Z}
\def\RR{\mathbb R}
\def\BB{\mathbb B}
\def\EE{\mathbb E}
\def\CC{\mathbb C}
\def\NN{\mathbb N}

\def \1{{\rm 1}\mskip -4,5mu{\rm l} } % application identique

\def\eps{\varepsilon}
\def\Aeps{\mathcal A_\eps}
\def\theta{\vartheta}
\def\wdhat{\widehat}

\def\ds{\displaystyle}
%\def \1{{\rm 1}\mskip -4,5mu{\rm l}}
\newcommand{\onev}[1] {\biggl(\begin{matrix} 1 \\[-3pt] #1
\end{matrix}\biggr)}
\newcommand{\zerov}[1] {\biggl(\begin{matrix} 0 \\[-3pt] #1
\end{matrix}\biggr)}
\newcommand{\blockr}[1] {\biggl(\begin{matrix} 0 & 0 \\[-3pt] 0 & #1
\end{matrix}\biggr)}

\def\bb#1{\boldsymbol{#1}}

\def\diag{\operatorname{diag}}

\newcommand{\M}{\mathscr M}
\newcommand{\tM}{\ \ \tilde{\!\!\!\!\!\mathscr M}}
\newcommand{\s}[1]{#1^{*}}

\newcommand{\nablaf}{\nabla \! f}
\newcommand{\nablaG}{\nabla \! g}

\def\V{\tilde{V}}
\def\e{\boldsymbol{e}}

% Projets F. Roueff
\newcommand \N {\mathbb N}
%\newcommand \PP {\mathbb P}


\def\prob{\mathbb{P}}
\def\esp{\mathbb{E}}
\newcommand{\cl}{{\:\stackrel{\cal L}{\longrightarrow}\:}}
\def\calN{\mathcal{N}}

%Projets S. Gaiffas
%\newcommand{\eps}{\varepsilon}

\newcommand{\ind}[1]{\mathbf 1{\{#1\}}}
\newcommand{\abs}[1]{\lv #1\rv}

\newcommand{\goes}{\rightarrow}
\newcommand{\goesproba}{\overset{\P}{\rightarrow}}
\newcommand{\goesltwo}{\overset{L^2}{\rightarrow}}
\newcommand{\goesps}{\overset{\text{p.s}}{\rightarrow}}

\newcommand{\norm}[1]{\|#1\|}

\DeclareMathOperator{\cov}{cov}%
%\DeclareMathOperator{\var}{Var}

\newtheorem{theorem}{Théoréme}


\newcounter{qst} % POUR NE PAS QUE LES EXOS SOIENT RENUMEROTE A PARTIR DE 1
                 % DANS CHAQUE SECTION

%\newcommand{\Question}{\bigskip \question}

\newcommand{\bp}{\mathbf p}

\newcommand{\cH}{\mathcal H}%
\newcommand{\cP}{\mathcal P}%
\newcommand{\cX}{\mathcal X}%
\newcommand{\cT}{\mathcal T}%

\DeclareMathOperator{\fdr}{FDR}

%Projets G Lécué

\DeclareMathOperator{\limInf}{liminf}
\DeclareMathOperator{\limSup}{limsup}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\pen}{pen}
\DeclareMathOperator{\conv}{conv}


%\setlength{\footrulewidth}{0pt}
%\setlength{\headrulewidth}{1pt}



% Retaille la largeur
%\setlength{\hoffset}{-1.5cm} \setlength{\marginparsep}{0pt}
%\setlength{\marginparwidth}{0pt} \addtolength{\textwidth}{2.5cm}

% Retaille la longueur
%\setlength{\voffset}{-1cm} \setlength{\headsep}{20pt}

%\setlength{\footskip}{10pt} \addtolength{\textheight}{5cm}


%\newcounter{cexo}
%\setcounter{cexo}{1}
%\newenvironment{exo}{\noindent \textbf{Exercice \thecexo~:}}{\medskip
%\par \addtocounter{cexo}{1}}

\pagestyle{plain}

\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi )}

\newcommand{\Pro}{\mathbb{P}}
\newcommand{\cD}{{\mathcal{D}}}
\newcommand{\coF}{{\rm conv}(F)}

\newcommand{\inr}[1]{\bigl< #1 \bigr>}

\newcommand{\cU}{\ensuremath{\mathcal{U}}}

\newcommand{\D}{\ensuremath{\mathbb{D}}}
\newcommand{\X}{\ensuremath{\mathbb{X}}}
%\newcommand{\R}{\ensuremath{\mathbb{R}}}
%\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
%\newcommand{\E}{\ensuremath{\mathbb{E}}}
\newcommand \cB{{\mathcal B}}
\newcommand \cL{{\mathcal L}}
\newcommand{\cA}{\mathcal A}
%\newcommand{\M}{\ensuremath{\mathbb{M}}}
\newcommand{\cN}{{\mathcal N}}
%\newcommand{\eps}{\varepsilon}
\newcommand \cM{{\mathcal M}}
\newcommand{\ERM}{\hat f_n^{ERM}}

\newcommand{\cC}{\mathcal{C}}

\let\leq\leqslant

\let\geq\geqslant

\let\vec\overrightarrow

\newtheorem{Theorem}{Theorem}[section]
\newtheorem{Question}[Theorem]{Question}
\newtheorem{Lemma}[Theorem]{Lemma}
\newtheorem{Sublemma}{Sublemma}
\newtheorem{Definition}[Theorem]{Definition}
\newtheorem{Problem}[Theorem]{Problem}
\newtheorem{Proposition}[Theorem]{Proposition}
\newtheorem{Corollary}[Theorem]{Corollary}
\newtheorem{Remark}[Theorem]{Remark}
\newtheorem{Example}[Theorem]{Example}
\newtheorem{Assumption}{Assumption}[section]









\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vskip 5truecm {\Large \centerline{\'Ecole Polytechnique} \centerline{Année 2013-2014}
  \centerline{MAP433 Introduction aux méthodes statistiques} \bigskip \centerline{\bf Enoncés des projets} \centerline{\bf
    (par binôme)} \bigskip }

\bigskip

\begin{itemize}
%\item Ces travaux personnels sont facultatifs et s'effectuent en binôme.
\item Les choix de projet doivent être déclarés auprès de la scolarité, avant
  le {\bf vendredi 7 mars 2014}.
\item Les rapports doivent être rendus à la scolarité au plus tard le jour de la pâle.
%\item Il est impératif de respecter les délais ci-dessus.
%\item La notation tiendra compte du travail effectué ainsi que de la qualité du
  %rapport.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} {\tt \noindent \'Ecole
  Polytechnique}
\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 1 : Modéles PROBIT et TOBIT} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Mathieu Rosenbaum {\sf (mathieu.rosenbaum@polytechnique.edu)}}
\end{center}

\bigskip

Dans de nombreux domaines, les variables que nous devons modéliser sont des variables discrétes qui
correspondent par exemple à des choix faits par des agents: se marier avec quelqu'un de sa
communauté religieuse, acheter un objet, voter pour un parti politique, faire une demande de prêt.
Il est aussi parfois possible d'observer l'intensité de ce choix lorsque celui-ci correspond à une
demande : montant de la dépense, montant du prêt. Cela peut mener à une modélisation plus riche du
phénoméne étudié.  Dans l'exemple oô un individu décide d'acheter un objet, la connaissance du
montant de sa dépense peut éventuellement permettre d'affiner la compréhension des déterminants de
son choix. Ainsi, supposons que la décision d'acheter $\left( y_{i}=1\right) $ ou non $\left(
  y_{i}=0\right) $ une voiture puisse être décrite par une variable continue $\left( y_{i}^{\ast
  }\right) $ qui mesure la dépense nécessaire pour répondre au besoin de locomotion compte-tenu des
caractéristiques socio-démographiques et des ressources financiéres de la personne.  Nous pouvons
écrire le modéle suivant:
\begin{equation}
  \left\{
    \begin{array}
      [c]{cc}%
y_{i}=1 & \text{si }y_{i}^{\ast}>0\\
y_{i}=0 & \text{si }y_{i}^{\ast}\leq0
\end{array}
\right.
\end{equation}
oô un modéle pour $y_{i}^{\ast}$ peut être postulé sur la base d'une théorie du comportement
microéconomique. Nous supposons par la suite que $y_{i}^{\ast}$ correspond au montant que peut
consacrer l'individu $i$ à la dépense étudiée. Supposons que nous pouvons écrire $y_{i}^{\ast}$
sous la forme d'une fonction linéaire de plusieurs caractéristiques des individus $X_{i}$ (revenu,
âge, statut marital, nombre d'enfant, distance domicile-lieu de travail, propriétaire d'un garage
ou non,....)
\begin{equation}
y_{i}^{\ast}=X_{i}\beta+u_{i}
\end{equation}
oô $u_{i}$ capture l'hétérogénéité des individus conditionnellement à l'information présente dans
le modéle $\left( X_{i}\right) .$ Pour mener à bien l'estimation d'un tel modéle, il faut faire
quelques hypothéses. Une hypothése de loi sur la distribution de $u_{i}$ peut suffire. Dans la
suite de cette étude, nous supposerons que $\left( u_{i}\right) _{i=1,...,N}\sim\mathcal{N}\left(
  0,\sigma^{2}I_{N}\right) $. On notera $\phi\left( u\right) $ la densité de probabilité de la loi
normale standard et $\Phi\left( u\right) $ sa fonction de répartition.\bigskip

\textbf{Objet du travail personnel} : modéliser la décision d'achat d'un produit et étudier par
simulation le gain de précision sur les estimateurs déduit de l'emploi de l'information sur
l'ampleur de la dépense.

\section{Ecriture de la vraisemblance et équations de vraisemblance }\label{seq:deb}
\begin{enumerate}
\renewcommand{\theenumi}{{\bf \ref{seq:deb}.\arabic{enumi}}}
\item Dans un premier temps, nous supposons que nous n'observons que les variables $\left(
    y_{i},X_{i}\right) $. Un tel modéle est appelé modéle \textbf{Probit.} Ecrire la vraisemblance
  d'un ensemble de $N$ observations dans le modéle d'échantillonnage ci-dessus. Est-ce que tous les
  paramétres du modéle sont identifiables ?
\item Donner les équations de vraisemblance qui caractérisent les estimateurs des paramétres.
\item Montrer que s'il existe une coordonnée $x_{i,j}$ de $X_{i}$ parfaitement corrélée (ou
  anti-corrélée) avec la variable de choix $y_{i}$ alors le coefficient qui lui est associé dans la
  forme linéaire $X_{i}\beta$ tend vers $+\infty$. Comment interprétez-vous ce résultat? On
  supposera par la suite que cette situation n'est pas rencontrée.
\item Montrer que la log-vraisemblance d'une observation est strictement concave en les paramétres
  identifiables.
\item Donner l'équation qui donne la matrice de variance-covariance des estimateurs. En pratique,
  comment estimez-vous cette quantité ?
\item Nous supposons que nous observons en plus le montant de la dépense $y_{i}^{\ast}$ lorsque
  l'individu $i$ décide d'acheter le bien. Un tel modéle est appelé un modéle \textbf{Tobit}.
  Ecrire la vraisemblance de vos $N$ observations. Est-ce que tous les paramétres sont
  identifiables ?
\item Donner les équations de vraisemblance qui caractérisent les estimateurs des paramétres.
\item En remarquant que
  \begin{equation}
    \frac{d^{2}\log\Phi\left(  u\right)  }{du^{2}}=-\frac{\phi\left(
        u\right) }{\Phi\left(  u\right)  ^{2}}\left(  \phi\left(
        u\right)  +u\Phi\left( u\right)  \right)
  \end{equation}
  montrer que la log-vraisemblance d'une observation est strictement concave en
  $\frac{\beta}{\sigma}$ et $\frac{1}{\sigma}$.
\item Donner l'équation qui donne la matrice de variance-covariance des estimateurs. En pratique,
  comment estimez-vous cette quantité ?
\item D'aprés vous, comment sont ordonnées les matrices de variance-covariance obtenues en
  ${{1.5}})$ et ${{1.9}})$ pour les paramétres communs?
\end{enumerate}

\section{Simulations}\label{sec:simul}
Nous allons illustrer les propriétés de la comparaison des matrices de variance-covariance des
estimateurs dans un cadre simple oô $X_{i} =\left(
  \begin{array} [c]{cc} 1 & x_{i}
  \end{array}
\right) $.

\begin{enumerate}
  \renewcommand{\theenumi}{{\bf \ref{sec:simul}.\arabic{enumi}}}
\item Simuler pour $N$ grand et un choix de valeurs de paramétres $\beta_{0}$ et $\beta_{1}$,
  $\sigma^{2}$ étant fixé à la valeur $1,$ un grand nombre de fois $\left( S\right) $ des données
  selon le modéle Tobit introduit ci-dessus.
\item Estimer les modéles Probit et Tobit associés à chacun des jeux d'obser\-vations, ainsi que
  les écarts-type des estimateurs.
\item Représenter graphiquement la distribution des estimateurs de $\beta _{0}$ et de $\beta_{1}$
  dans les deux situations.
\item Représenter graphiquement la distribution des estimateurs des variances des estimateurs de
  $\beta_{0}$ et de $\beta_{1}$ dans les deux situations.
\item Conclure.
\end{enumerate}

(Texte proposé par Stéphane Grégoir.)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} {\tt \noindent \'Ecole
%  Polytechnique}
%\hfill{\tt Ann\'ee 2011-2012}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 2 : Modéles Vectoriels AutoRégressifs} }
%\bigskip \hrule height .5pt \bigskip
%\begin{center} {responsable: Stéphane Gregoir \sf{(stephane.gregoir@edhec.edu)}}
%\end{center}
%
%\bigskip
%
%Lorsque l'on travaille sur plusieurs variables endogénes placées dans un vecteur $y_{t}$, un de nos
%premiers travaux est d'analyser les relations qui existent en moyenne entre les composantes du
%vecteur et ce pour différentes dates. Cette analyse se fait à l'aide de l'étude de la moyenne
%$Ey_{t}=m_{t}$ et de la fonction d'autocovariance $\Gamma\left( t,s\right) =Cov\left(
%  y_{t},y_{s}\right) $. Lorsque ces fonctions dépendent de la date à laquelle nous les calculons,
%il n'est possible de les estimer que lorsque l'on dispose de l'observation de plusieurs chroniques
%de valeurs de $\left\{ y_{t}^{\left( i\right) }\right\} _{t=1,...,T}$, pour $i=1,..$.$.,N$. En
%revanche, lorsque ces fonctions ne présentent pas une dépendance aussi forte, il est parfois
%possible de les estimer en utilisant des moyennes empiriques temporelles. C'est le cas lorsque la
%suite des vecteurs aléatoires $\left( y_{t}\right)_{t\in\mathbb{Z}}$ satisfait les conditions
%suivantes :
%\begin{enumerate}
%\item $\forall t\in\mathbb{Z},Vy_{t}<+\infty$
%\item $\forall t\in\mathbb{Z},Ey_{t}=m$
%\item $\forall\left(  t,s\right)  \in\mathbb{Z}^{2},cov\left(  y_{t}%
%,y_{s}\right)  =\gamma_{y}\left(  t-s\right)  $
%\item lim$_{h\longrightarrow+\infty}\gamma_{y}\left( h\right) =0$
%\end{enumerate}
%
%Si la suite des $\left( y_{t}\right) _{t\in\mathbb{Z}}$ satisfait les trois premiéres propriétés,
%nous disons que la suite est stationnaire du second ordre. Un exemple particulier de suite de
%vecteurs aléatoires qui satisfait ces propriétés est celui de la suite composée de vecteurs
%centrés, de matrice de variance-covariance constante et non corrélés deux à deux, c'est-à-dire tels
%que $\forall\left( t,s\right) \in\mathbb{Z}^{2},Ey_{t}=0$ et si $t=s,cov\left( y_{t}%
%  ,y_{s}\right) =\Sigma$ et si $t\neq s,cov\left( y_{t},y_{s}\right) =0.$ Une telle suite est
%appelée un \textbf{bruit blanc} (de matrice de variance-covariance $\Sigma$).
%
%Pour analyser les relations qui existent entre différentes variables stationnaires du second ordre,
%il est possible de faire appel à la modélisation Vectorielle AutoRégressive (VAR) qui permet de
%paramétrer à l'aide de peu de paramétres les autocovariances entre les variables.
%
%\begin{definition}
%  Une suite de vecteurs aléatoires $\left( y_{t}\right) _{t\in\mathbb{Z}}$ stationnaires du second
%  ordre de dimension $n$ satisfait une représentation VAR d'ordre $p$ stable s'il satisfait une
%  équation de la forme%
%  \begin{equation}
%    y_{t}=\phi_{1}y_{t-1}+\phi_{2}y_{t-2}+...+\phi_{p}y_{t-p}+\varepsilon_{t}%
%  \end{equation}
%  oô $\left( \phi_{j}\right) _{j=1,...p}$ sont des matrices de taille $n\times n$,
%  $\varepsilon_{t}$ est un bruit blanc de matrice de variance covariance $\Sigma$ et le polynôme
%  $\det\left( I_{n}-\phi_{1}u-\phi _{2}u^{2}...-\phi_{p}u^{p}\right) $ a des racines de module
%  strictement supérieur à 1.
%\end{definition}
%
%Le vecteur $\varepsilon_{t}$ s'interpréte comme les chocs nouveaux à
%chaque date qui viennent modifier l'évolution de nos variables en
%perturbant la trajectoire décrite par la partie autorégressive du
%modéle résultant de la persistance des liens entre les valeurs prises
%par les variables contemporaines et passées. En pratique, la lecture d'une
%suite de matrice de variance-covariance n'est pas aisée. Afin d'en
%simplifier la lecture, nous avons recours à une procédure graphique
%qui permet d'illustrer comment un choc correspondant à une composante du
%vecteur $\varepsilon_{t}$ se propage au cours du temps entre les
%différentes variables du vecteur $y_{t}$. On appelle ces graphiques des
%fonctions de réponse.
%
%\textbf{Objet du travail personnel : }calculer la réponse au cours du
%temps d'une variable $y_{1,t}$ à une modification d'une variable $y_{2,t}$
%et en donner une mesure de la variabilité.
%
%\section{Simulation d'un modéle VAR(1) bivarié gaussien} \label{sec:simvar} Dans ce qui suit, nous
%supposons que $y_{t}$ est un vecteur de dimension 2 et satisfait un modéle VAR(1) dans lequel
%$\varepsilon_{t}$ est normalement distribué de moyenne 0 et de matrice de variance $\Sigma$. Nous
%nous proposons de simuler un tel processus puis de procéder à un exercice d'estimation et de calcul
%de fonction de réponse pour ce systéme. La simulation d'un tel processus se fait à l'aide de
%l'équation autorégressive de génération des données. Néanmoins, elle demande une condition
%d'initialisation $y_{0}$. Ce vecteur ne peut être quelconque mais est contraint par le processus de
%génération des données.
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:simvar}.\arabic{enumi}}}
%\item Faites choix des valeurs des quatre coefficients de la matrice $\phi =\phi_{1}$ (de façon à
%  assurer la condition sur la position des racines du polynôme $\det\left( I_{2}-\phi u\right) $)
%  et des coefficients de la matrice de variance-covariance $\Sigma$.
%\item Montrer que
%  \begin{equation}
%    \lim_{k\rightarrow+\infty}V\left(  y_{t}-\sum_{j=0}^{k}\phi^{j}\varepsilon
%      _{t-j}\right)  =0
%  \end{equation}
%  En déduire qu'au sens de $L^{2}$, $y_{t}=\sum_{j=0}^{+\infty}\phi ^{j}\varepsilon_{t-j}$ et que
%  $$y_{t}\sim\mathcal{N}\left( 0,\sum _{j=0}^{+\infty}\phi^{j}\Sigma\left( \phi^{^{\prime}}\right)
%    ^{j}\right)$$
%\item Simuler le processus en tirant le premier vecteur $y_{0}$ dans sa loi inconditionnelle, puis
%  en itérant l'équation autorégressive sur $T$ périodes.
%\end{enumerate}
%\section{Estimation d'un modéle VAR(1) bivarié} \label{sec:estimVar}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:estimVar}.\arabic{enumi}}}
%\item Montrer en réécrivant sous forme vectorielle l'ensemble des équations satisfaites par les
%  observations que les estimateurs des Moindres Carrés Généralisés des paramétres $\phi_{11}%
%  ,\phi_{12,}\phi_{21}$ et $\phi_{22}$ sont égaux respectivement aux estimateurs des Moindres
%  Carrés Ordinaires de $\phi_{11}$ et $\phi_{12}$ obtenus dans la régression de $\left(
%    y_{1,t}\right) $ sur $\left(
%    \begin{array} [c]{cc} y_{1,t-1} & y_{2,t-1}
%    \end{array}
%  \right) $ et à ceux des Moindres Carrés Ordinaires de $\phi_{21}$ et $\phi_{22}$ obtenus dans la
%  régression de $\left( y_{2,t}\right) $ sur $\left(
%    \begin{array} [c]{cc} y_{1,t-1} & y_{2,t-1}
%    \end{array}
%  \right)$
%\item Construire ces estimateurs et construire un estimateur des moindres carrés de la matrice de
%  variance-covariance des $\left( \varepsilon _{t}\right) _{t\in\mathbb{Z}}$.  Les estimateurs de
%  $\phi_{11},\phi_{12,}\phi_{21}$ et $\phi_{22}$ correspondent à l'estimateur du maximum de
%  vraisemblance pour les paramétres du premier ordre du fait des hypothéses de loi faites.
%\item Construire un estimateur du maximum de vraisemblance de la matrice de variance-covariance des
%  termes $\varepsilon_{t}$
%\end{enumerate}
%
%\section{Test de la spécification du modéle }\label{sec:testSpec}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:testSpec}.\arabic{enumi}}}
%\item Tester que $\phi$ est significativement non nulle
%par un test du rapport du maximum de vraisemblance.
%
%Dans le cas d'un modéle VAR(p), un test pour s'assurer que
%l'ordre $p$ a bien été sélectionné pourrait
%être effectué sur la derniére matrice $\phi_{p}$
%\end{enumerate}
%
%\section{Calcul d'une fonction de réponse }\label{sec:calFoncRep}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:calFoncRep}.\arabic{enumi}}}
%\item Nous pouvons, munis de l'estimation des paramétres $\phi$ et $\Sigma$, procéder à des
%  simulations du modéle et étudier comment les variables $y_{1}$ et $y_{2}$ se déforment au cours
%  du temps lorsqu'un choc $\varepsilon_{1,t}$ ou $\varepsilon_{2,t}$ se réalise.  Afin de respecter
%  la structure d'autocorrélation qui existe entre les variables $\varepsilon_{1}$ et
%  $\varepsilon_{2}$, simuler la réponse sur un horizon de $H$ dates de chacune des variables aux
%  chocs $\left(
%    \begin{array} [c]{cc} 1 & \frac{\sigma_{12}}{\sigma_{11}}
%    \end{array}
%  \right)^{\prime}$ et $\left(
%    \begin{array} [c]{cc} \frac{\sigma_{21}}{\sigma_{22}} & 1
%    \end{array}
%  \right)^{\prime}$. Du fait de la structure linéaire du modéle, il suffit d'itérer $H$ fois
%  l'équation autorégressive avec comme vecteur initial un des deux vecteurs ci-dessus pour simuler
%  la réponse de chaque variable.
%\end{enumerate}
%
%\section{Calcul d'un intervalle de confiance par Monte Carlo} \label{sec:icMC}
%
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:icMC}.\arabic{enumi}}}
%\item Nous souhaitons construire un intervalle de confiance à 90\% pour chaque valeur des deux
%  fonctions de réponse simulées précédemment. Ces valeurs sont des fonctions compliquées des
%  paramétres estimés $\phi$ et $\Sigma$. Leur expression exacte nous permettrait de
%  calculer un intervalle de confiance asymptotique suivant les résultats du cours. Nous vous
%  proposons plutôt de procéder par simulation pour construire à distance finie ( $T$ donné) ces
%  intervalles de confiance. Pour ce faire, répétez un trés grand nombre de fois pour la valeur de $\phi$ et $\Sigma$ estimée sur les données, les étapes 1.3, 2.2 et 4.1. Vous obtenez pour chaque simulation une fonction de réponse différente, ce qui illustre la
%  dépendance de votre résultat aux tirages aléatoires des valeurs de $\left(
%    \varepsilon_{t}\right)_{t=1,...,T}$ et donne une mesure de son incertitude. Pour chaque date de
%  l'horizon de simulation, vous pouvez donc calculer les valeurs qui correspondent aux centiles de
%  5\% et de 95\% qui définissent l'intervalle des valeurs qui concentrent 90\% des réalisations
%  possibles.
%\item Est-ce que l'ensemble des intervalles que vous construisez pour chaque date correspond à la
%  zone de confiance à 95\% de la distribution des courbes ?
%\end{enumerate}
%
%
%
%
%
%
%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
%  \noindent \'Ecole Polytechnique}\hfill{\tt Année 2008-2009}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 1 : Modéles PROBIT et TOBIT} } \bigskip
%\hrule height .5pt \bigskip
%\begin{center} {responsable: Stéphane Gregoir {\sf (stephane.gregoir@ensae.fr)}}
%\end{center}

%\bigskip

%Dans de nombreux domaines, les variables que nous devons modéliser sont des variables discrétes qui
%correspondent par exemple à des choix faits par des agents: se marier avec quelqu'un de sa
%communauté religieuse, acheter un objet, voter pour un parti politique, faire une demande de prêt.
%Il est aussi parfois possible d'observer l'intensité de ce choix lorsque celui-ci correspond à une
%demande : montant de la dépense, montant du prêt. Cela peut mener à une modélisation plus riche du
%phénoméne étudié.  Dans l'exemple oô un individu décide d'acheter un objet, la connaissance du
%montant de sa dépense peut éventuellement permettre d'affiner la compréhension des déterminants de
%son choix. Ainsi, supposons que la décision d'acheter $\left( y_{i}=1\right) $ ou non $\left(
%  y_{i}=0\right) $ une voiture puisse être décrite par une variable continue $\left( y_{i}^{\ast
%  }\right) $ qui mesure la dépense nécessaire pour répondre au besoin de locomotion compte-tenu des
%caractéristiques socio-démographiques et des ressources financiéres de la personne.  Nous pouvons
%écrire le modéle suivant:
%\begin{equation}
%  \left\{
%    \begin{array}
%      [c]{cc}%
%y_{i}=1 & \text{si }y_{i}^{\ast}>0\\
%y_{i}=0 & \text{si }y_{i}^{\ast}\leq0
%\end{array}
%\right.
%\end{equation}
%oô un modéle pour $y_{i}^{\ast}$ peut être postulé sur la base d'une théorie du comportement
%microéconomique. Nous supposons par la suite que $y_{i}^{\ast}$ correspond au montant que peut
%consacrer l'individu $i$ à la dépense étudiée. Supposons que nous pouvons écrire $y_{i}^{\ast}$
%sous la forme d'une fonction linéaire de plusieurs caractéristiques des individus $X_{i}$ (revenu,
%‚ge, statut marital, nombre d'enfant, distance domicile-lieu de travail, propriétaire d'un garage
%ou non,....)
%\begin{equation}
%y_{i}^{\ast}=X_{i}\beta+u_{i}
%\end{equation}
%oô $u_{i}$ capture l'hétérogénéité des individus conditionnellement à l'information présente dans
%le modéle $\left( X_{i}\right) .$ Pour mener à bien l'estimation d'un tel modéle, il faut faire
%quelques hypothéses. Une hypothése de loi sur la distribution de $u_{i}$ peut suffire. Dans la
%suite de cette étude, nous supposerons que $\left( u_{i}\right) _{i=1,...,N}\sim\mathcal{N}\left(
%  0,\sigma^{2}I_{N}\right) $. On notera $\phi\left( u\right) $ la densité de probabilité de la loi
%normale standard et $\Phi\left( u\right) $ sa fonction de répartition.\bigskip

%\textbf{Objet du travail personnel} : modéliser la décision d'achat d'un produit et étudier par
%simulation le gain de précision sur les estimateurs déduit de l'emploi de l'information sur
%l'ampleur de la dépense.

%\section{Ecriture de la vraisemblance et équations de vraisemblance }\label{seq:deb}
%\begin{enumerate}
%\renewcommand{\theenumi}{{\bf \ref{seq:deb}.\arabic{enumi}}}
%\item Dans un premier temps, nous supposons que nous n'observons que les variables $\left(
%    y_{i},X_{i}\right) $. Un tel modéle est appelé modéle \textbf{Probit.} Ecrire la vraisemblance
%  d'un ensemble de $N$ observations dans le modéle d'échantillonnage ci-dessus. Est-ce que tous les
%  paramétres du modéle sont identifiables ?
%\item Donner les équations de vraisemblance qui caractérisent les estimateurs des paramétres.
%\item Montrer que s'il existe une coordonnée $x_{i,j}$ de $X_{i}$ parfaitement corrélée (ou
%  anti-corrélée) avec la variable de choix $y_{i}$ alors le coefficient qui lui est associé dans la
%  forme linéaire $X_{i}\beta$ tend vers $+\infty$. Comment interprétez-vous ce résultat? On
%  supposera par la suite que cette situation n'est pas rencontrée.
%\item Montrer que la log-vraisemblance d'une observation est strictement concave en les paramétres
%  identifiables.
%\item Donner l'équation qui donne la matrice de variance-covariance des estimateurs. En pratique,
%  comment estimez-vous cette quantité ?
%\item Nous supposons que nous observons en plus le montant de la dépense $y_{i}^{\ast}$ lorsque
%  l'individu $i$ décide d'acheter le bien. Un tel modéle est appelé un modéle \textbf{Tobit}.
%  Ecrire la vraisemblance de vos $N$ observations. Est-ce que tous les paramétres sont
%  identifiables ?
%\item Donner les équations de vraisemblance qui caractérisent les estimateurs des paramétres.
%\item En remarquant que
%  \begin{equation}
%    \frac{d^{2}\log\Phi\left(  u\right)  }{du^{2}}=\frac{\phi\left(
%        u\right) }{\Phi\left(  u\right)  ^{2}}\left(  \phi\left(
%        u\right)  +u\Phi\left( u\right)  \right)
%  \end{equation}
%  montrer que la log-vraisemblance d'une observation est strictement concave en
%  $\frac{\beta}{\sigma}$ et $\frac{1}{\sigma}$.
%\item Donner l'équation qui donne la matrice de variance-covariance des estimateurs. En pratique,
%  comment estimez-vous cette quantité ?
%\item D'aprés vous, comment sont ordonnées les matrices de variance-covariance obtenues en
%  ${{1.5}})$ et ${{1.9}})$ pour les paramétres communs?
%\end{enumerate}

%\section{Simulations}\label{sec:simul}
%Nous allons illustrer les propriétés de la comparaison des matrices de variance-covariance des
%estimateurs dans un cadre simple oô $X_{i} =\left(
%  \begin{array} [c]{cc} 1 & x_{i}
%  \end{array}
%\right) $.

%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:simul}.\arabic{enumi}}}
%\item Simuler pour $N$ grand et un choix de valeurs de paramétres $\beta_{0}$ et $\beta_{1}$,
%  $\sigma^{2}$ étant fixé à la valeur $1,$ un grand nombre de fois $\left( S\right) $ des données
%  selon le modéle Tobit introduit ci-dessus.
%\item Estimer les modéles Probit et Tobit associés à chacun des jeux d'obser\-vations, ainsi que
%  les écarts-type des estimateurs.
%\item Représenter graphiquement la distribution des estimateurs de $\beta _{0}$ et de $\beta_{1}$
%  dans les deux situations.
%\item Représenter graphiquement la distribution des estimateurs des variances des estimateurs de
%  $\beta_{0}$ et de $\beta_{1}$ dans les deux situations.
%\item Conclure.
%\end{enumerate}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} {\tt \noindent \'Ecole
%  Polytechnique}\hfill{\tt Année 2007-2008}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 2 : Modéles Vectoriels AutoRégressifs} }
%\bigskip \hrule height .5pt \bigskip
%\begin{center} {responsable: Stéphane Gregoir \sf{(stephane.gregoir@ensae.fr)}}
%\end{center}

%\bigskip

%Lorsque l'on travaille sur plusieurs variables endogénes placées dans un vecteur $y_{t}$, un de nos
%premiers travaux est d'analyser les relations qui existent en moyenne entre les composantes du
%vecteur et ce pour différentes dates. Cette analyse se fait à l'aide de l'étude de la moyenne
%$Ey_{t}=m_{t}$ et de la fonction d'autocovariance $\Gamma\left( t,s\right) =Cov\left(
%  y_{t},y_{s}\right) $. Lorsque ces fonctions dépendent de la date à laquelle nous les calculons,
%il n'est possible de les estimer que lorsque l'on dispose de l'observation de plusieurs chroniques
%de valeurs de $\left\{ y_{t}^{\left( i\right) }\right\} _{t=1,...,T}$, pour $i=1,..$.$.,N$. En
%revanche, lorsque ces fonctions ne présentent pas une dépendance aussi forte, il est parfois
%possible de les estimer en utilisant des moyennes empiriques temporelles. C'est le cas lorsque la
%suite des vecteurs aléatoires $\left( y_{t}\right)_{t\in\mathbb{Z}}$ satisfait les conditions
%suivantes :
%\begin{enumerate}
%\item $\forall t\in\mathbb{Z},Vy_{t}<+\infty$
%\item $\forall t\in\mathbb{Z},Ey_{t}=m$
%\item $\forall\left(  t,s\right)  \in\mathbb{Z}^{2},cov\left(  y_{t}%
%,y_{s}\right)  =\gamma_{y}\left(  t-s\right)  $
%\item lim$_{h\longrightarrow+\infty}\gamma_{y}\left( h\right) =0$
%\end{enumerate}

%Si la suite des $\left( y_{t}\right) _{t\in\mathbb{Z}}$ satisfait les trois premiéres propriétés,
%nous disons que la suite est stationnaire du second ordre. Un exemple particulier de suite de
%vecteurs aléatoires qui satisfait ces propriétés est celui de la suite composée de vecteurs
%centrés, de matrice de variance-covariance constante et non corrélés deux à deux, c'est-à-dire tels
%que $\forall\left( t,s\right) \in\mathbb{Z}^{2},Ey_{t}=0$ et si $t=s,cov\left( y_{t}%
%  ,y_{s}\right) =\Sigma$ et si $t\neq s,cov\left( y_{t},y_{s}\right) =0.$ Une telle suite est
%appelée un \textbf{bruit blanc} (de matrice de variance-covariance $\Sigma$).

%Pour analyser les relations qui existent entre différentes variables stationnaires du second ordre,
%il est possible de faire appel à la modélisation Vectorielle AutoRégressive (VAR) qui permet de
%paramétrer à l'aide de peu de paramétres les autocovariances entre les variables.

%\begin{definition}
%  Une suite de vecteurs aléatoires $\left( y_{t}\right) _{t\in\mathbb{Z}}$ stationnaires du second
%  ordre de dimension $n$ satisfait une représentation VAR d'ordre $p$ stable s'il satisfait une
%  équation de la forme%
%  \begin{equation}
%    y_{t}=\phi_{1}y_{t-1}+\phi_{2}y_{t-2}+...+\phi_{p}y_{t-p}+\varepsilon_{t}%
%  \end{equation}
%  oô $\left( \phi_{j}\right) _{j=1,...p}$ sont des matrices de taille $n\times n$,
%  $\varepsilon_{t}$ est un bruit blanc de matrice de variance covariance $\Sigma$ et le polynôme
%  $\det\left( I_{n}-\phi_{1}u-\phi _{2}u^{2}...-\phi_{p}u^{p}\right) $ a des racines de module
%  strictement supérieur à 1.
%\end{definition}

%Le vecteur $\varepsilon_{t}$ s'interpréte comme les chocs nouveaux à
%chaque date qui viennent modifier l'évolution de nos variables en
%perturbant la trajectoire décrite par la partie autorégressive du
%modéle résultant de la persistance des liens entre les valeurs prises
%par les variables contemporaines et passées. En pratique, la lecture d'une
%suite de matrice de variance-covariance n'est pas aisée. Afin d'en
%simplifier la lecture, nous avons recours à une procédure graphique
%qui permet d'illustrer comment un choc correspondant à une composante du
%vecteur $\varepsilon_{t}$ se propage au cours du temps entre les
%différentes variables du vecteur $y_{t}$. On appelle ces graphiques des
%fonctions de réponse.

%\textbf{Objet du travail personnel : }calculer la réponse au cours du
%temps d'une variable $y_{1,t}$ à une modification d'une variable $y_{2,t}$
%et en donner une mesure de la variabilité.

%\section{Simulation d'un modéle VAR(1) bivarié gaussien} \label{sec:simvar} Dans ce qui suit, nous
%supposons que $y_{t}$ est un vecteur de dimension 2 et satisfait un modéle VAR(1) dans lequel
%$\varepsilon_{t}$ est normalement distribué de moyenne 0 et de matrice de variance $\Sigma$. Nous
%nous proposons de simuler un tel processus puis de procéder à un exercice d'estimation et de calcul
%de fonction de réponse pour ce systéme. La simulation d'un tel processus se fait à l'aide de
%l'équation autorégressive de génération des données. Néanmoins, elle demande une condition
%d'initialisation $y_{0}$. Ce vecteur ne peut être quelconque mais est contraint par le processus de
%génération des données.
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:simvar}.\arabic{enumi}}}
%\item Faites choix des valeurs des quatre coefficients de la matrice $\phi =\phi_{1}$ (de façon à
%  assurer la condition sur la position des racines du polynôme $\det\left( I_{2}-\phi u\right) $)
%  et des coefficients de la matrice de variance-covariance $\Sigma$.
%\item Montrer que
%  \begin{equation}
%    \lim_{k\rightarrow+\infty}V\left(  y_{t}-\sum_{j=0}^{k}\phi^{j}\varepsilon
%      _{t-j}\right)  =0
%  \end{equation}
%  En déduire qu'au sens de $L^{2}$, $y_{t}=\sum_{j=0}^{+\infty}\phi ^{j}\varepsilon_{t-j}$ et que
%  $$y_{t}\sim\mathcal{N}\left( 0,\sum _{j=0}^{+\infty}\phi^{j}\Sigma\left( \phi^{^{\prime}}\right)
%    ^{j}\right)$$
%\item Simuler le processus en tirant le premier vecteur $y_{0}$ dans sa loi inconditionnelle, puis
%  en itérant l'équation autorégressive sur $T$ périodes.
%\end{enumerate}
%\section{Estimation d'un modéle VAR(1) bivarié} \label{sec:estimVar}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:estimVar}.\arabic{enumi}}}
%\item Montrer en réécrivant sous forme vectorielle l'ensemble des équations satisfaites par les
%  observations que les estimateurs des Moindres Carrés Généralisés des paramétres $\phi_{11}%
%  ,\phi_{12,}\phi_{21}$ et $\phi_{22}$ sont égaux respectivement aux estimateurs des Moindres
%  Carrés Ordinaires de $\phi_{11}$ et $\phi_{12}$ obtenus dans la régression de $\left(
%    y_{1,t}\right) $ sur $\left(
%    \begin{array} [c]{cc} y_{1,t-1} & y_{2,t-1}
%    \end{array}
%  \right) $ et à ceux des Moindres Carrés Ordinaires de $\phi_{21}$ et $\phi_{22}$ obtenus dans la
%  régression de $\left( y_{2,t}\right) $ sur $\left(
%    \begin{array} [c]{cc} y_{1,t-1} & y_{2,t-1}
%    \end{array}
%  \right)$
%\item Construire ces estimateurs et construire un estimateur des moindres carrés de la matrice de
%  variance-covariance des $\left( \varepsilon _{t}\right) _{t\in\mathbb{Z}}$.  Les estimateurs de
%  $\phi_{11},\phi_{12,}\phi_{21}$ et $\phi_{22}$ correspondent à l'estimateur du maximum de
%  vraisemblance pour les paramétres du premier ordre du fait des hypothéses de loi faites.
%\item Construire un estimateur du maximum de vraisemblance de la matrice de variance-covariance des
%  termes $\varepsilon_{t}$
%\end{enumerate}

%\section{Test de la spécification du modéle }\label{sec:testSpec}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:testSpec}.\arabic{enumi}}}
%\item Tester que $\phi$ est significativement non nulle
%par un test du rapport du maximum de vraisemblance.

%Dans le cas d'un modéle VAR(p), un test pour s'assurer que
%l'ordre $p$ a bien été sélectionné pourrait
%être effectué sur la derniére matrice $\phi_{p}$
%\end{enumerate}

%\section{Calcul d'une fonction de réponse }\label{sec:calFoncRep}
%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:calFoncRep}.\arabic{enumi}}}
%\item Nous pouvons, munis de l'estimation des paramétres $\phi$ et $\Sigma$, procéder à des
%  simulations du modéle et étudier comment les variables $y_{1}$ et $y_{2}$ se déforment au cours
%  du temps lorsqu'un choc $\varepsilon_{1,t}$ ou $\varepsilon_{2,t}$ se réalise.  Afin de respecter
%  la structure d'autocorrélation qui existe entre les variables $\varepsilon_{1}$ et
%  $\varepsilon_{2}$, simuler la réponse sur un horizon de $H$ dates de chacune des variables aux
%  chocs $\left(
%    \begin{array} [c]{cc} 1 & \frac{\sigma_{12}}{\sigma_{11}}
%    \end{array}
%  \right)^{\prime}$ et $\left(
%    \begin{array} [c]{cc} \frac{\sigma_{21}}{\sigma_{22}} & 1
%    \end{array}
%  \right)^{\prime}$. Du fait de la structure linéaire du modéle, il suffit d'itérer $H$ fois
%  l'équation autorégressive avec comme vecteur initial un des deux vecteurs ci-dessus pour simuler
%  la réponse de chaque variable.
%\end{enumerate}

%\section{Calcul d'un intervalle de confiance par Monte Carlo} \label{sec:icMC}

%\begin{enumerate}\renewcommand{\theenumi}{{\bf \ref{sec:icMC}.\arabic{enumi}}}
%\item Nous souhaitons construire un intervalle de confiance à 90\% pour chaque valeur des deux
%  fonctions de réponse simulées précédemment. Ces valeurs sont des fonctions compliquées des
%  paramétres estimés $\phi$ et $\Sigma$. Leur expression exacte nous permettrait de
%  calculer un intervalle de confiance asymptotique suivant les résultats du cours. Nous vous
%  proposons plutôt de procéder par simulation pour construire à distance finie ( $T$ donné) ces
%  intervalles de confiance. Pour ce faire, répétez un trés grand nombre de fois les étapes 3, 5 et
%  8. Vous obtenez pour chaque simulation une fonction de réponse différente, ce qui illustre la
%  dépendance de votre résultat aux tirages aléatoires des valeurs de $\left(
%    \varepsilon_{t}\right)_{t=1,...,T}$ et donne une mesure de son incertitude. Pour chaque date de
%  l'horizon de simulation, vous pouvez donc calculer les valeurs qui correspondent aux centiles de
%  5\% et de 95\% qui définissent l'intervalle des valeurs qui concentrent 90\% des réalisations
%  possibles.
%\item Est-ce que l'ensemble des intervalles que vous construisez pour chaque date correspond à la
%  zone de confiance à 95\% de la distribution des courbes ?
%\end{enumerate}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} {\tt \noindent \'Ecole
%  Polytechnique}\hfill{\tt Année 2007-2008}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 3 : Reconnaissance du locuteur par
%    l'algorithme EM} } \bigskip \hrule height .5pt \bigskip \centerline{responsable: Randal
%  Douc {\sf (douc@cmapx.polytechnique.fr)}}
%
%\bigskip
%
%\section{Préliminaires}
%
%Le but de ce projet consistera à identifier un locuteur à partir d'un échantillon de parole en
%utilisant une méthode liée à l'algorithme EM. Commencez par récupérer
%les échantillons disponibles à l'adresse: \\
%\url{http://www.cmap.polytechnique.fr/~douc/Page/Teaching/Stat/locuteur.html}
%
%La démarche générale de ce projet est la suivante:
%\begin{itemize}
%\item Les signaux audio ``.wav'' sont prétraités de maniére à associer à des intervalles de temps
%  (de l'ordre de quelques dizaines de millisecondes) du signal un petit nombre $p$ de paramétres
%  significatifs (de l'ordre de la dizaine). On associe donc à un signal ``x.wav'' un ensemble de
%  vecteurs $x_1^n=(x_1,...,x_n)$, chaque $x_i$ étant élément de $\R^p$ (ces notations seront
%  utilisées systématiquement, c'est à dire que $a_1^N$ désigne le vecteur $(a_1,...,a_N)$). Les
%  $(x_i)$ sont appelés coefficients cepstraux du signal audio.
%\item On considére les $x_1^n$ comme des observations i.i.d. dont la densité est modélisée par un
%  mélange de gaussiennes.
%\item L'algorithme EM est utilisé pour obtenir une approximation des para-\- métres du mélange qui
%  maximisent la vraisemblance pour une observation $x_1^n$. Ceci constitue la phase
%  d'apprentissage.
%\item Les paramétres du mélange obtenus pour chaque locuteur sont utilisés pour reconnaître un
%  locuteur à partir d'un nouvel échantillon. C'est la phase de test.
%\end{itemize}
%
%Les échantillons audio que vous récupérez sont constitués de deux échantil\-lons par locuteur, un
%pour la phase d'apprentissage, un pour la phase de test. Les échantillons fournis sont de même
%taille, bien que généralement l'échantillon pour l'apprentissage soit nettement plus long que celui
%utilisé pour le test.
%
%\section{Prétraitement}
%La premiére étape consiste à extraire les coefficients cepstraux du signal. Cette étape est déjà
%traitée et il vous suffit dans un premier temps d'aller dans le répertoire \textbf{DataCeps} pour
%récupérer les coefficients cepstraux de chaque locuteur (à l'aide de la commande scilab {\sf
%  read}). Pour la suite du projet, nous ne retiendrons pas la premiére coordonnée des vecteurs des
%cepstres $x_i$. Cette coordonnée est reliée à la puissance du signal sonore étudié et n'est pas
%pertinente pour l'identification du locuteur. Il vous faut ainsi supprimer la premiére colonne de
%la matrice obtenue. On obtient alors une série de vecteurs $x_1^n$, chaque vecteur étant de taille
%$p$ ($p=12$ dans les échantillons obtenus à partir de la page web).
%
%\section{Modéle et notations}
%Les $x_1^n$ sont donc vus comme $n$ observations i.i.d. de variables $X_1^n$ de densité $g_\theta$,
%définie par:
%$$
%\forall x \in {\mathbb R}^p, \quad g_\theta(x)=\sum_{k=1}^K\alpha_k \phi_{\mu_k,A_k}(x),
%$$
%oô l'on a introduit les notations suivantes:
%\begin{itemize}
%\item Le paramétre $\theta=(\alpha_1^K,\mu_1^K, A_1^K)$ avec $\alpha_1^K \in [0,1]^K$,
%  $\sum_{k=1}^K \alpha_k=1$, $\mu_1^K \in ({\mathbb R}^p)^K$ et les $A_k$ sont des matrices
%  symétriques positives.
%\item $\phi_{\mu, A}$ est la densité associée à la loi d'un vecteur normal de dimension $p$ de
%  moyenne $\mu$ et de matrice de variance-covariance $A$:
%$$
%\forall x \in {\mathbb R}^p, \quad \phi_{\mu,A}(x)=\frac{1}{(2 \pi)^{p/2} \sqrt{\mathrm{det}
%    A}}\exp\left(-\frac{1}{2}(x -\mu)^T(A)^{-1}(x -\mu)\right)
%$$
%\end{itemize}
%Les $\alpha_1^K$ seront appelés poids du mélange. Un locuteur sera identifié par une valeur
%particuliére de $\theta$.
%
%\section{Algorithme EM}
%\label{sec:algoEm}
%On remarque que la fonction $f_\theta: {\mathbb R}^p \times \{1,\ldots, K\} \to {\mathbb R}$
%définie par:
%$$
%f_\theta(x,y)=\alpha_y \phi_{\mu_y,A_y}(x)
%$$
%est une densité jointe par rapport à la mesure produit naturelle sur ${\mathbb R}^p \times
%\{1,\ldots, K\}$, c'est à dire la mesure produite de la mesure de Lebesgue sur ${\mathbb R}^p$ et
%de la mesure ponctuelle sur $\{1,\ldots, K\}$. On peut donc joindre les variables $Y_1^n$ aux
%$X_1^n$ telles que la suite de variables $(X_i,Y_i)$, $i=1, \ldots, n$ soient des variables i.i.d
%de densité jointe $f_\theta(x,y)$.
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:algoEm}.\arabic{enumi}}}
%\item Quelle est la loi de $Y_1^n$? Montrer que la loi marginale pour $X_1^n$ est bien la loi
%  associée à un échantillon i.i.d. de variables ayant pour densité $g_\theta$. Ecrire la
%  vraisemblance jointe $f_\theta(X_1^n,Y_1^n)$ et la vraisemblance marginale $f_\theta(X_1^n)$.
%\end{enumerate}
%L'estimateur du maximum de vraisemblance $\theta_{MV}$ pour ce modéle associé aux observations
%$x_1^n$ est défini par
%$$
%\theta_{MV}=\mathrm{argmax}_{\theta} \log \left(f_\theta(X_1^n)\right)
%$$
%Comme il n'y a pas de formule explicite pour $\theta_{MV}$, nous vous proposons d'utiliser une
%procédure itérative appelé algorithme EM (en Anglais: Expectation Maximisation, parce qu'il y a une
%partie oô l'on prend une espérance et une autre oô l'on maximise):
%\begin{equation}\label{eq:iteration}
%  \theta[t+1]=\mathrm{argmax}_\theta \quad \E_{\theta[t]} (\log f_\theta(X_1^n, Y_1^n)| X_1^n=x_1^n)
%\end{equation}
%L'itération de cet algorithme produit, sous de bonnes hypothéses, une convergence de $\theta[t]$
%(lorsque $t \to \infty$) vers l'estimateur du maximum de vraisemblance $\theta_{MV}$. Nous
%n'étudierons pas les propriétés théoriques de cet estimateur (qui sont plus détaillées dans le
%Projet 5) mais nous nous contenterons de l'appliquer dans notre situation.
%\section{Relation de récurrence sur les coefficients pour une itération}
%\label{sec:recur}
%Nous supposerons dans toute la suite que les matrices $A_1^K$ sont diagonales. La matrice $A_i$ est
%ainsi entiérement caractérisée par les coefficients de sa diagonale que nous noterons $\sigma_i$.
%Ainsi, $\sigma_i$ est un vecteur de $({\mathbb R}^+)^p$.
%
%Nous notons maintenant $\theta=(\alpha_1^K, \mu_1^K, \sigma_1^K)$ et $\theta[t]$ les paramétres
%obtenus par $t$ itérations de la relation (\ref{eq:iteration}).
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:recur}.\arabic{enumi}}}
%\item Montrer que pour tout $i = 1, \ldots, n$,
%$$
%\E_{\theta[t]}(\mathbf{1}_k(Y_i)|
%X_1^n=x_1^n)=\frac{\alpha_k[t]\phi_{\mu_k,\sigma_k}(x_i)}{\sum_{l=1}^K\alpha_l[t]\phi_{\mu_l,\sigma_l}(x_i)}.
%$$
%
%Nous noterons cette valeur $p_{\theta[t]}(k\vert x_i)$.
%\item En notant que la maximisation en $\alpha$ peut se faire indépendamment des autres paramétres,
%  montrer que
%$$\alpha_k[t+1]=\frac 1 n \sum_{i=1}^n p_{\theta[t]}(k\vert x_i)$$
%\item Montrer ensuite que
%$$\mu_k[t+1]=\frac{\sum_{i=1}^n x_i p_{\theta[t]}(k\vert x_i)}
%{\sum_{i=1}^np_{\theta[t]}(k\vert x_i)}.
%$$
%\item Rappelons que $\sigma_k[t+1] \in ({\mathbb R}^+)^p$ et notons $\sigma_k[t+1](j)$ son $j$-éme
%  coefficient. De même, notons $x_i(j)$ ( et $\mu_k[t+1](j)$) le $j$-éme coefficient de $x_i$ ( et
%  $\mu_k[t+1]$). Montrer alors que pour tout $j=1, \ldots, p$,
%$$
%\sigma_k[t+1](j)=\frac{\sum_{i=1}^np_{\theta[t]}(k\vert x_i)(x_i(j)-\mu_k[t+1](j))^2}
%{\sum_{i=1}^np_{\theta[t]}(k\vert x_i)},
%$$
%Puis que:
%$$
%\sigma_k[t+1](j)=\frac{\sum_{i=1}^np_{\theta[t]}(k\vert x_i)(x_i(j))^2}
%{\sum_{i=1}^np_{\theta[t]}(k\vert x_i)}-(\mu_k[t+1](j))^2.
%$$
%
%\end{enumerate}
%
%\section{Programmation d'une itération}
%On écrira les fonctions demandées en laissant la possibilité de changer le nombre $K$ de classe du
%mélange. On pourra commencer à tester le modéle avec $K=5$.  En reprenant les formules de la
%section précédente, programmez une fonction Scilab qui, à partir des observations $x_1^n$ et de
%paramétre initial $\theta_0$, calcule le paramétre $\theta_1$ obtenu aprés une itération de
%l'algorithme EM.
%
%Afin de simplifier l'écriture de ce programme, vous commencerez par programmer une fonction
%\com{gauseval} permettant l'évaluation de densités gaussiennes. La syntaxe de cette fonction est:
%
%\noindent \com{dens=gauseval(X,mu,sigma);}
%
%oô
%\begin{itemize}
%\item $X$ est le vecteur des observations; la ligne $i_0$ contient le vecteur $x_{i_0}$. Cette
%  matrice est donc de taille $n \times p$.
%\item $mu$ est la matrice des moyennes du mélange; la ligne $k_0$ contient le vecteur $\mu_{k_0}$.
%  Cette matrice est donc de taille $K \times p$.
%\item $sigma$ est la matrice des diagonales des covariances du modéle; la ligne $i_0$ contient le
%  vecteur des éléments diagonaux de la matrice $A_{k_0}$. Cette matrice est donc de taille $K
%  \times p$.
%\item $dens$ est une matrice dont la ligne $i_0$ contient le vecteur $(dens(i_0,1),...,$
%  $dens(i_0,K))$, oô $dens(i,k)=\phi_{\eta_k}(x_i)$, avec $\eta_k=(\mu_k,A_k)$. Cette matrice est
%  donc de taille $n\times K$.
%
%\end{itemize}
%
%Cette fonction ``gauseval''doit vous permettre de calculer facilement les termes dont vous avez
%besoin lors d'une itération de l'algorithme EM.
%
%\section{Le probléme de l'initialisation}
%Vous êtes maintenant en mesure de calculer les coefficients de votre mélange en partant d'un choix
%initial de coefficients et en effectuant plusieurs itérations de l'algorithme EM. Ce choix initial
%est délicat, et nous adopterons une approche simple: les moyennes initiales seront prises égales à
%certains des vecteurs d'observation choisis aléatoirement uniformément sur l'ensemble des vecteurs
%correspondant à un locuteur. Les éléments des diagonales des matrices de covariance seront choisis
%égaux (et valant par exemple 0.5).
%
%\section{Application}
%\label{sec:Application}
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:Application}.\arabic{enumi}}}
%\item Programmez une procédure qui, étant donné un paramétre $\theta$ et un vecteur d'observations
%  $x_1^n$, calcule la vraisemblance correspondant à $g_\theta$.
%
%\item Choisissez un locuteur particulier, et appliquez lui l'algorithme EM.
%\item Vérifiez (numériquement) la convergence de la vraisemblance lors de l'application de EM.
%
%\item Vérifiez que, pour un vecteur $x_1^n$ correspondant au locuteur ``a'', la vraisemblance
%  associée à $g_{\theta}$ est supérieure avec les paramétres de ce locuteur qu'avec les paramétres
%  des autres locuteurs.
%\end{enumerate}
%
%\section{Phases d'apprentissage et de test}
%
%Pour chacun des locuteurs dont vous disposez d'un échantillon de voix, calculez les paramétres du
%mélange correspondant. Vous disposez maintenant de M échantillons de voix, auxquels vous avez
%associé les paramétres d'un mélange de gaussienne $(g_{\theta_1},...,g_{\theta_M})$. Sélectionnez
%un échantillon test au hasard et choisissez le modéle ayant la vraisemblance la plus forte.
%Conclusions ? Etudiez l'effet des différents paramétres ($K$, initialisation, nombre d'itérations
%de EM) sur les résultats d'identification. Vous pouvez aussi construire vos propres échantillons
%une dizaine de secondes en enregistrant en format .wav pour l'apprentissage (et un peu moins pour
%le test) et en effectuant au préalable le prétraitement pour extraire les coefficients cepstraux
%(dans ce cas, il faut regarder sur la page web, les instructions pour effectuer ce prétraitement.)
%
%Vous pourrez éventuellement avoir besoin des fonctions Scilab suivantes: {\sf list, strcat, read}.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} {\tt \noindent \'Ecole
%  Polytechnique}\hfill{\tt Année 2007-2008}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large
%  \begin{center}{\bf Projet 4 : Modèle Logit multinomial\\ Application à la détection de
%      déréglements thyroidiens}
%  \end{center}
%} \bigskip \hrule height .5pt \bigskip \centerline{responsable: Randal Douc
%  {\sf (douc@cmapx.polytechnique.fr)}}
%
%\bigskip
%
%\section{Introduction}
%On s'intéresse au cas d'une variable de réponse $Y$ qualitative pouvant prendre $m+1$ modalités (en
%l'occurrence, $Y\in\{0,1,\ldots, m\}$) associée à des variables explicatives exogénes
%$X=(X(1),\dots,X(p))^T$ oô l'exposant $T$ désigne la transposition. On s'intéresse au modéle dit de
%{\og}régression logistique multinomiale {\fg} dans lequel la loi conditionnelle s'écrit
%\begin{equation} \label{def:logit} \forall k \in \{0,\ldots, m\},\quad \P_\theta(Y = k|X)
%  = \frac{\exp\left(\theta_k^T X\right)}{\sum_{l=0}^{m} \exp\left(\theta_l^T X\right)}
%\end{equation}
%oô $\theta_k = (\theta_k(1),\ldots,\theta_k(p))^T$ est un paramétre vectoriel. On supposera de plus
%que la loi marginale des variables explicatives ne dépend pas des paramétres du modéle
%$\theta=\begin{pmatrix}\theta_0\\ \vdots \\\theta_m \end{pmatrix}$.
%
%\section{Interprétation de la modélisation logit multinomial}
%\label{sec:interpret}
%Nous allons donner ici une interprétation en terme d'utilité quant au choix de la modélisation
%décrite en Equation (\ref{def:logit}). Supposons qu'un individu ait à effectuer un choix rationnel
%entre $m+1$ modalités procurant $m+1$ niveaux de satisfaction différents. On suppose que le niveau
%de satisfaction de la modalité $l$ (pour $0\leq l\leq m$) est mesurée par une fonction d'utilité
%dépendant de façon linéaire du vecteur de variables exogénes $X$ et d'un bruit additif non observé:
%$$
%U_l=\theta_l^T X +\epsilon_l
%$$ 
%oô $(\epsilon_l)_l$ sont indépendants et de même loi, loi dont la fonction de répartition est
%donnée par:
%$$
%F(z)=\P(\epsilon_l\leq z)=\exp(-\exp(-z))
%$$
%(Cette loi est appelée loi de {\em Gompertz} ou loi des valeurs extrêmes).
%
%Si on note par $Y$ le choix de la modalité par l'individu. On a donc que $Y=k$ si et seulement si
%$U_k=\max_{l=0,\ldots, m} U_l$.
%
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:interpret}.\arabic{enumi}}}
%\item Montrer que
%$$
%\P_\theta(Y=k|X)=\int_{-\infty}^\infty \left(\prod_{l=0, l\neq k}^m
%  F([\theta_k-\theta_l]^T X + s)F'(s)ds \right)
%$$
%\item En déduire que
%$$
%\P_\theta(Y=k|X)=\frac{\exp\left(\theta_k^T X\right)}{\sum_{l=0}^{m} \exp\left(\theta_l^T
%    X\right)}
%$$
%{\bf Indication:} On pourra utiliser la question précédente et faire le changement de variable
%$t=\exp(-s)$.
%
%\end{enumerate}
%
%\section{Maximum de vraisemblance}
%\label{sec:maxLogit}
%Dans toute la suite, on considérera un modéle logit à 3 modalités ($m=2$), et on suppose que l'on
%dispose de $N$ observations $Y=(Y_1, \ldots, Y_N)$ tirés suivant une loi logit à 3 modalités,
%associées aux vecteurs de variables exogénes $X_1,\ldots,X_N$. Nous utiliserons par la suite la
%notation: $z_{1:N}=(z_1,\ldots,z_N)$.
%
%\begin{enumerate}
%  \renewcommand{\theenumi}{{\bf \ref{sec:maxLogit}.\arabic{enumi}}}
%\item Montrer par des arguments d'identifiabilité que l'on peut imposer $\theta_0=0$. {\bf Les
%    paramétres du modéles s'écriront désormais
%    $\theta=\begin{pmatrix}\theta_1\\\theta_2\end{pmatrix}$. Le vecteur $\theta$ est donc un
%    vecteur de dimension $2p$.}
%\item Ecrire la vraisemblance $\ell_N(Y_{1:N}|X_{1:N};\theta)$ conditionnelle associée aux
%  observations pour le paramétre $\theta$.
%\item En déduire l'expression du gradient:
%$$
%\frac{\partial \log \ell_N(Y_{1:N}|X_{1:N};\theta)}{\partial \theta_k}=\sum_{i=1}^N ({\mathbf
%  1}(Y_i=k)-p_{i,k})X_i
%$$
%avec $p_{i,k}=\frac{\exp\left(\theta_k^T X_i\right)}{\sum_{l=0}^{m} \exp\left(\theta_l^T
%    X_i\right)}$.
%\item En déduire l'expression de la matrice hessienne (pour $k$,$l$ dans $\{1,2\}$):
%$$
%\frac{\partial^2 \log \ell_N(Y_{1:N}|X_{1:N};\theta)}{\partial \theta_k \partial \theta_l^T}=
%\begin{cases}
%  \sum_{i=1}^N p_{i,k}p_{i,l} X_i X_i^T & \mbox{ si } k \neq l\\
%  -\sum_{i=1}^N p_{i,k}(1-p_{i,k}) X_i X_i^T & \mbox{ si } k =l\\
%\end{cases}
%$$
%\item (Facultatif) Montrer que le hessien est une matrice négative.
%\end{enumerate}
%La question précédente montre que la fonction $\theta \mapsto \log \ell_N(Y_{1:N}|X_{1:N};\theta)$
%est concave. Des algorithmes d'optimisation comme celui de Newton Raphson sont donc convergents.
%Programmer la maximisation de la vraisemblance suivant l'algorithme:
%$$
%\begin{pmatrix}\theta_1^{(j+1)}\\\theta_2^{(j+1)}\end{pmatrix}=
%\begin{pmatrix}\theta_1^{(j)}\\\theta_2^{(j)} \end{pmatrix}- \left(
%  \frac{\partial^2 \log \ell_N(Y_{1:N}|X_{1:N};\theta^{(j)})}{\partial \theta_k^{(j)}
%    \left(\partial \theta_l^{(j)}\right)^T}\right)_{1\leq k,l\leq 2}^{-1}
%\begin{pmatrix}
%  \frac{\partial \log \ell_N(Y_{1:N}|X_{1:N};\theta^{(j)})}{\partial
%    \theta_1^{(j)}}\\
%  \frac{\partial \log \ell_N(Y_{1:N}|X_{1:N};\theta^{(j)})}{\partial \theta_2^{(j)}}
%\end{pmatrix}
%$$
%On notera $\hat \theta_N=\begin{pmatrix}\hat \theta_{1,N} \\ \hat \theta_{2,N}\end{pmatrix} $ la
%valeur limite des paramétres obtenue par cet algorithme.
%\section{Phase d'apprentissage et de test}
%\label{sec:simulEch}
%On se propose d'appliquer un modéle logit multinômial à 3 modalités à des données de patients
%pouvant soit souffrir d'hypothyroÔdie (Y=0), soit souffrir d'hyperthyroÔdie (Y=1), soit présenter
%des sécrétions thyroÔdiques normales (Y=2). Les causes d'un dysfonctionnement de la thyroÔde sont
%multiples et nous nous intéressons seulement ici à 6 variables quantitatives qui pourraient être à
%l'origine du déréglement. Les données seront chargées (gr‚ce à l'instruction {\em read} de scilab) à
%partir de\\
%\url{http://www.cmap.polytechnique.fr/~douc/Page/Teaching/Stat/Logit/train.dat}\\
%Chaque ligne représente un des 3772 patients recensés dans la base de données. La derniére colonne
%donne l'état du patient (0, 1 ou 2), les 6 premiéres colonnes seront les données exogénes
%quantitatives. Nous imposerons que la premiére colonne des variables exogénes vaut nécessairement 1
%(i.e. pour tout $i=1,\ldots,3772$, $X_i(1)=1$ pour que la régression logistique puisse tenir compte
%des constantes), les 6 suivantes correspondront aux 6 premiéres colonnes du fichier train.dat ce
%qui conduit finalement à choisir pour chaque patient $i$, un vecteur de variables exogénes de
%taille 7.
%
%On appliquera l'algorithme de Newton-Raphson pour calculer le maximum de vraisemblance associé à
%ces observations. Tracer une courbe mettant en évidence la décroissance de la log-vraisemblance.
%Une fois que l'algorithme a convergé, les valeurs des paramétres sont elles toutes significatives?
%Pour le paramétre estimé $\hat\theta_n$ obtenu par maximum de vraisemblance, utiliser un test de
%rapport de vraisemblance pour déterminer si le paramétre non nul le plus proche de 0 est
%significatif ou non.
%
%Cette premiére étape s'appelle l'étape d'apprentissage. La seconde étape, l'étape de test
%consistera à utiliser les informations obtenues durant la phase d'apprentissage (à travers la
%donnée de $\hat \theta_n$) pour savoir dans quel catégorie se situe le patient (hyperthyroÔdie,
%hypothyroÔdie ou absence de déréglement). Les données seront chargées à partir de \\
%\url{http://www.cmap.polytechnique.fr/~douc/Page/Teaching/Stat/Logit/test.dat} Pour cette
%phase de test, on estimera pour chaque patient les probabilités d'appartenance à chaque catégorie
%suivant la formule (\ref{def:logit}) en ayant remplacée $\theta$ par $\hat \theta_n$ obtenu durant
%la phase d'apprentissage. La prédiction de l'état du patient correspondra alors à la plus forte
%probabilité ainsi estimée. Comme la base de données de test présente aussi en derniére colonne
%l'état réel du patient, vous pourrez comparer la prédiction obtenue avec l'état effectif du
%patient. Pour la base de test, quel taux d'erreur obtenez vous?
%
%Nous précisons que ces questions sont données à titre indicatif. Toute initiative concernant le
%traitement statistique des données est bien-s˚r la bienvenue.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \setcounter{footnote}{0} {\tt \noindent \'Ecole
  Polytechnique}\hfill{\tt Année 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 2 : Mélange de Poisson et algorithme EM}
} \bigskip \hrule height .5pt \bigskip \centerline{responsable : Stéphane Gaïffas {\sf (stephane.gaiffas@cmap.polytechnique.fr)}}
\medskip

\bigskip

On considére l'estimation d'un modéle dit {\og}de mélange{\fg} dans lequel on suppose que la loi
des observations (supposées indépendantes) s'écrit sous la forme
\begin{equation}
  \label{eq:model}
  f_\theta(x) = \sum_{k=1}^d w_k g_{\lambda_k}(x)
\end{equation}
oô $(w_k)_{1\leq k\leq n} \in [0,1]$ sont les {\og}poids (ou proportions){\fg} du mélange tels que
$\sum_{k=1}^k w_k = 1$ et $g_{\lambda_k}$ sont des lois de probabilités dépendant (éventuellement)
d'un paramétre $\lambda_k$. Le modéle est donc déterminé par les paramétres $(w_k)_{1\leq k\leq n}$
et $(\lambda_k)_{1\leq k\leq n}$.

L'objectif est de modéliser des données de comptage issues du domaine de la métrologie du trafic
réseau (en l'occurrence des comptes de paquets de données transmis entre deux serveurs) et l'on
s'intéressera au cas particulier oô $X$ est une variable entiére et $g_{\lambda}$ est la loi de
Poisson telle que
\begin{equation}
  \label{eq:Poisson}
  g_\lambda(x) = \frac{1}{x!} \operatorname{e}^{-\lambda} \lambda^x  
\end{equation}

\section{Interprétation probabiliste du mélange}
\begin{enumerate}
  \renewcommand{\theenumi}{{\bf \thesection.\arabic{enumi}}}
\item Montrer que la variable aléatoire $X$ peut être vue comme générée par le mécanisme
  probabiliste suivant
  \begin{enumerate}
  \item On tire $Y \in \{1,\dots,d\}$ en sorte que $\P(Y = k) = w_k$;
  \item Conditionnellement au résultat, on tire $X$ de façon à ce que
    \begin{equation*}
      \P(X=x|Y=k) = g_{\lambda_k}(x)
    \end{equation*}
    $Y$ est dite variable {\og}latente{\fg} ou non-observable.
  \end{enumerate}
\item \label{item:probcond} Calculer la probabilité conditionnelle $\P(Y=k|X)$ d'appartenance à la
  $k$-iéme composante du mélange. On prendra notamment conscience du fait que le modéle de mélange
  est fondamentalement un modéle pour une population inhomogéne et que $\P(Y=k|X)$ constitue la
  façon optimale de prédire la sous-population (plutôt appelée {\og}composante{\fg} dans le
  contexte des mélanges) dont est issue l'observation $X$.
\item En supposant que l'on dispose de $n$ observations $X_1, \dots, X_n$, écrire la vraisemblance
  du modéle mélange.
\end{enumerate}
Bien qu'il soit possible de calculer la vraisemblance des observations (cf.  question ci-dessus),
la forme de celle-ci est suffisamment complexe pour que sa maximisation explicite soit impossible.
Il devient dés lors nécessaire d'avoir recours à l'optimisation numérique pour déterminer
l'estimateur du maximum de vraisemblance, cas assez fréquent en statistique.

\section{L'algorithme EM}
L'algorithme EM, oô E signifie {\em Expectation} et M {\em Maximization}, constitue un algorithme
d'optimisation numérique spécifique à une classe de modéles qui inclut le modéle de mélange
considéré ici. Son principe, trés simple, est le suivant.

\bigskip \hrule height .5pt \smallskip {\tt \noindent \centerline{\bf-- Algorithme EM --}

  \noindent {\tt Initialisation :} Choisir une valeur arbitraire $\hat{\theta}_0$\\
  {\tt Itérations :} Pour $m=1,2,\ldots$, effectuer
  \begin{enumerate}
  \item[{\tt 1.}] ({\it Etape E}) Calculer la {\og}quantité intermédiaire{\fg}
    \begin{equation}
      \label{eq:QEM}
      Q_{\hat{\theta}_{m}}(\theta)
      = \E_{\hat{\theta}_{m}} \left[\log \P_\theta(\mathbf{Y},\mathbf{X}) |
        \mathbf{X}\right]    
    \end{equation}
  \item[{\tt 2.}] ({\it Etape M}) Maximiser $Q_{\hat{\theta}_{m}}(\theta)$ en $\theta$ et prendre
    \begin{equation}
      \label{eq:Mstep}
      \hat\theta_{m+1} = \arg\max_\theta \; Q_{\hat{\theta}_{m}}(\theta)  
    \end{equation}
  \end{enumerate}
  jusqu'à stabilisation de la séquence $\hat{\theta}_{m}$.\\
} \hrule height .5pt \bigskip

Etant entendu que $\mathbf{X}$ désigne l'ensemble des observations disponibles et $\mathbf{Y}$ les
variables latentes associées, $\P_\theta$ leur loi jointe\footnote{Dans l'écriture ci-dessus on
  suppose tacitement que les variables $X$ et $Y$ sont toutes deux discrétes ce qui est le cas qui
  nous intéresse ici.} et $\E_\theta$ l'espérance par rapport à cette loi.
L'équation~\eqref{eq:QEM} définit une fonction de $\theta$, indexée par $\hat{\theta}_{m}$,
dépendant également des observations $\mathbf{X}$ (du fait de l'espérance conditionnelle). L'étape
M définit donc une régle de mise à jour qui à $\hat{\theta}_{m}$ et étant donné les observations
$\mathbf{X}$ associe une nouvelle estimation $\hat{\theta}_{m+1}$ du paramétre $\theta$.

Nous allons tout d'abord montrer que cet algorithme constitue bien, de façon générique, une façon
de maximiser itérativement la vraisemblance.

\begin{enumerate}
  \renewcommand{\theenumi}{{\bf \thesection.\arabic{enumi}}}
\item Montrer que
  \begin{equation*}
    Q_{\hat{\theta}_{m}}(\theta) - Q_{\hat{\theta}_{m}}(\hat\theta_m) =
    \E_{\hat{\theta}_{m}} \left[\log \left.
        \frac{\P_\theta(\mathbf{Y}|\mathbf{X})}{\P_{\hat\theta_m}(\mathbf{Y}|\mathbf{X})}
      \right| \mathbf{X}\right] + \log\P_\theta(\mathbf{X}) -
    \log\P_{\hat\theta_m}(\mathbf{X})
  \end{equation*}
\item Remarquer que le premier terme du membre de droite de l'équation précédente est lié à la
  divergence de Kullback-Leibler entre les lois conditionnelles paramétrés par $\hat{\theta}_{m}$
  et $\theta$.
\item \label{item:propEM} En déduire l'inégalité
  \begin{equation*}
    \log\P_\theta(\mathbf{X}) - \log\P_{\hat\theta_m}(\mathbf{X}) \geq
    Q_{\hat{\theta}_{m}}(\theta) - Q_{\hat{\theta}_{m}}(\hat\theta_m)
  \end{equation*}
  et, par la suite, le fait que $\P_{\hat\theta_m}(\mathbf{X})$ est une séquence croissante de
  valeurs de la vraisemblance.
\end{enumerate}

L'algorithme EM permet donc, partant d'un point arbitraire, de faire croître de façon monotone la
vraisemblance. Le second aspect important est que cet algorithme est également implémentable --~on
sait évaluer numéri\-quement la quantité intermédiaire $Q_{\hat{\theta}_{m}}$ et la maximiser
explicitement~-- pour une classe de modéles assez large, même si nous ne nous bornons ici à le
vérifier que pour le modéle de mélange de Poisson qui nous intéresse plus directement.

\section{Algorithme EM pour le mélange de Poisson}
\begin{enumerate}
  \renewcommand{\theenumi}{{\bf \thesection.\arabic{enumi}}}
\item En supposant que la loi marginale des observations $X$ est donnée
  par~\eqref{eq:model}--\eqref{eq:Poisson}, montrer que
  \begin{multline*}
    Q_{\hat{\theta}_{m}}(\theta) = \sum_{i=1}^n \E_{\hat{\theta}_{m}} [\log
    \P_\theta(Y_i,X_i) | X_i] \\
    = \sum_{i=1}^n\sum_{k=1}^d \left(\log w_k - \lambda_k + X_i \log \lambda_k\right)
    \P_{\hat{\theta}_{m}}(Y_i = k|X_i) - \sum_{i=1}^n \log X_i!
  \end{multline*}
\item En déduire que l'étape M conduit aux équations de mise à jour suivantes
  \begin{equation*}
    \hat{w}_{m+1,k} = \frac{\sum_{i=1}^n \P_{\hat{\theta}_{m}}(Y_i =
      k|X_i)}{\sum_{l=1}^d \sum_{i=1}^n \P_{\hat{\theta}_{m}}(Y_i = l|X_i)}
  \end{equation*}
  (en prenant en compte le fait que le poids $w_k$ sont soumis à la contrainte $\sum_{k=1}^d w_k =
  1$) et
  \begin{equation*}
    \hat\lambda_{m+1,k} = \frac{\sum_{i=1}^n X_i \P_{\hat{\theta}_{m}}(Y_i =
      k|X_i)}{\sum_{i=1}^n \P_{\hat{\theta}_{m}}(Y_i = k|X_i)}
  \end{equation*}
\end{enumerate}
Ce qui montre en particulier que pour effectuer l'étape M de l'algorithme EM il suffit d'évaluer,
pour tous les indices d'observations $i$ ($1\leq i \leq n$) et toutes les composantes du mélange
$k$ ($1\leq k \leq d$), la probabilité a posteriori $\P_{\hat{\theta}_{m}}(Y_i = k|X_i)$, dont
nous avons déjà déterminé l'expression (cf. \ref{item:probcond}).

\section{Implémentation et analyse des données}
On utilisera les données disponibles en
\begin{quote}
\url{http://www.tsi.enst.fr/~cappe/cours/data/bpc10ms_1mn.dat}  
\end{quote}
qui consistent en 6000 comptes
correspondant à une mesure réguliére (toutes les 10~ms) de l'activité d'une passerelle
({\og}gateway{\fg}) entre un réseau local et l'internet\footnote{voir
\url{http://www.tsi.enst.fr/~cappe/cours/data/bpc10ms_1mn.html} pour une description plus compléte
des don\-nées et de leur provenance).}.

\begin{enumerate}
  \renewcommand{\theenumi}{{\bf \thesection.\arabic{enumi}}}
\item Implémenter l'algorithme EM pour le modéle de mélange de lois de Poisson pour un nombre de
  composantes $d$ facilement modifiable ($d$ doit être un paramétre du programme!) Pour valider le
  code, on véri\-fiera que les séquences produites par l'algorithme vérifient bien la propriété
  démontrée en \ref{item:propEM}, et ce, quelle que soit la séquence d'observation $X_1, \dots,
  X_n$.
\item Illustrer le résultat de l'estimation (pour différentes valeurs de $d$) en commentant en
  particulier l'influence de $d$; on comparera notamment la loi de probabilité correspondant au
  mélange avec l'histogramme des données.
\item Afficher l'estimation de $\P_{\hat{\theta}}(Y_i = k|X_i)$ correspondant aux données. Quel
  intérêt ce calcul peut il avoir dans l'application considérée~? Au vu des résultats, peut on
  imaginer des améliorations du modéle~?
\end{enumerate}
(Texte proposé par Olivier Cappé.)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 3 : Estimation non-param\'etrique d'une densit\'e} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Marc Hoffmann {\sf (hoffmann@ceremade.dauphine.fr)}}
\end{center}

\bigskip


\section{Introduction}
On veut estimer ``globalement" une densit\'e de probabilit\'e inconnue sur un intervalle donn\'e, disons $[0,1]$ pour simplifier, \`a partir de l'observation de la r\'ealisation d'un $n$-\'echantillon $(X_1,\ldots, X_n)$. Cela signifie que les variables al\'eatoires r\'eelles $X_1, X_2,\ldots, X_n$ sont ind\'ependantes et identiquement distribu\'ees. Dans toute la suite, on notera $x \mapsto f(x)$ leur densit\'e de probabilit\'e commune. Le but est d'estimer les valeurs $\big(f(x), x \in [0,1]\big)$ simultan\'ement. Pour all\'eger la terminologie et les notations, nous ne distinguons pas une  variable al\'eatoire de sa r\'ealisation. Nous nous autorisons l'abus de langage (et de notation) consistant \`a dire que l'on a "observ\'e un vecteur al\'eatoire $(X_1,\ldots, X_n)$". 

\section{Histogramme des fr\'equences}
Soit $m \geq 1$ un entier. On d\'efinit les {\it boites} $B_1, B_2,\ldots, B_m$ en posant :
$$B_1=\left[0, \tfrac{1}{m}\right),\;\;B_2=\left[\tfrac{1}{m}, \tfrac{2}{m}\right),\ldots, \;\;B_m=\left[\tfrac{(m-1)}{m}, 1\right].$$
On appelle {\it fen\^etre} associ\'ees aux boites $B_j$ le nombre $h=1/m$. Pour $j=1,\ldots, m$, on d\'efinit : $\nu_j=\text{Card}\left\{X_i \in B_j, \;i=1,\ldots, n\right\},$ ainsi que $\widehat{p_j}=\frac{\nu_j}{n}$ et
$p_j=\int_{B_j}f(u)du.$
L'estimateur par histogramme des fr\'equences est alors d\'efini par la formule
$$\widehat{f_n(x)}=\sum_{j=1}^m \frac{\widehat{p_j}}{h}\;I(x \in B_j)\;\;\;\;\;\text{pour}\;\;x \in [0,1],$$
o\`u $\;I(x \in B_j)$ d\'esigne l'indicatrice de $B_j$, qui vaut $1$ si $x \in B_j$ et $0$ sinon.
Pour motiver la construction de $\widehat{f_n(x)}$, faisons le raisonnement heuristique suivant : pour $x \in B_j$ et $h$ petit
$$\mathbb{E}[\widehat{f_n(x)}]=\frac{\mathbb{E}[\widehat{p_j}]}{h}=\frac{p_j}{h}=\frac{\int_{B_j} f(u)du}{h} \approx \frac{f(x)h}{h}=f(x),$$
o\`u $\mathbb{E}$ d\'esigne l'esp\'erance math\'ematique. Ainsi, en moyenne, $\widehat{f_n(x)}$ est proche de $f(x)$ lorsque la mesure de $B_j$, c'est-\`a-dire la fen\^etre est petite.
\begin{enumerate}
\item Soit $j$ l'indice de la boite contenant $x$. Montrer que
$$\mathbb{E}[\widehat{f_n(x)}]=\frac{p_j}{h}\;\;\;\text{et}\;\;\;\text{Var}\left[\widehat{f_n(x)}\right]=\frac{p_j(1-p_j)}{nh^2}.$$
\end{enumerate}
\section{Etude de l'erreur moyenne quadratique int\'egr\'ee}
D\'efinissons {\it l'erreur quadratique moyenne int\'egr\'ee} de l'estimateur $\widehat{f_n}=(\widehat{f_n(x)}, x \in [0,1])$ de $f$ en posant
$${\mathcal R}(\widehat{f_n},f)=\mathbb{E}\left[\int_0^1 \big(\widehat{f_n(u)}-f(u)\big)^2 du\right].$$ 
Fixons $x \in B_j$, supposons $f$ r\'eguli\`ere.
On d\'esigne par $b(x)=\mathbb{E}[\widehat{f_n(x)}]-f(x)$ le {\it biais} de l'estimateur $\widehat{f_n(x)}$ et par $v(x) =\text{Var}\left[\widehat{f_n(x)}\right]$ sa {\it variance}.
\begin{enumerate}
\item Montrer que  $$b(x) \approx f'(x)\big(h(j-\tfrac{1}{2})-x\big)$$
en pr\'ecisant le sens du symbole $\approx$ pour des hypoth\`eses convenables sur $f$. 
\item Si $\tilde x_j$ d\'esigne le centre de la boite $B_j$, montrer que 
$$\int_0^1 b(x)^2dx =\sum_{j=1}^m \int_{B_j} b(x)^2dx \approx \sum_{j=1}^m \big(f'(\tilde x_j)\big)^2 \,\frac{h^3}{12} \approx \frac{h^2}{12}\int_0^1\big(f'(x)^2\big)dx,$$
en pr\'ecisant le sens des approximations. Notons que cette derni\`ere quantit\'e augmente avec la taille $h$ de la fen\^etre. 
\item Supposons $h$ petit, de sorte que
$v(x) \approx \frac{p_j}{nh^2}.$ En reproduisant l'argument pr\'ec\'edent pour approcher $p_j$ et en ne conservant que le terme dominant dans l'approximation montrer que
$$v(x)\approx \frac{f(x)}{nh}\;\;\;\;\;\;\text{et}\;\;\;\int_0^1 v(x)dx \approx \frac{1}{nh}.$$
Notons cette fois-ci que cette derni\`ere quantit\'e d\'ecro\^{i}t lorsque $h$ augmente.
\item Obtenir un r\'esultat du type : si $f$ suffisamment r\'eguli\`ere, alors 
$${\mathcal R}(\widehat{f_n},f)=\frac{h^2}{12}\int_0^1 f'(u)^2du+\frac{1}{nh}+\tfrac{1}{nh} \varepsilon(n,h),$$
o\`u $\lim_{n \rightarrow \infty}\varepsilon(n,h_n)=0$ si $\lim_{n \rightarrow \infty}h_n=0$, $\lim_{n \rightarrow \infty}nh_n=+\infty$ et $\lim_{n \rightarrow \infty}nh_n^4=0$. 
\item On note $\widehat{f_{n}}=\widehat{f_{n,h}}$ pour mettre en \'evidence la d\'ependance en $h$ de l'estimateur. Montrer que
$$\lim_{n \rightarrow \infty}n^{2/3}\inf_{h}{\mathcal R}(\widehat{f_{n,h}},f)=(3/4)^{2/3}(\int_0^1 f'(u)^2du)^{1/3}.$$
\end{enumerate}
Interpr\'eter ce r\'esultat. Le comparer en particulier avec l'estimation d'un densit\'e param\'etr\'ee de la forme $(f(\vartheta,x), x \in [0,1])$ pour l'erreur moyenne quadratique ${\mathcal R}$ lorsque le mod\`ele param\'etrique $(f(\vartheta, \cdot), \vartheta \in \Theta)$ est r\'egulier.

\section{Choix automatique de la fen\^etre : la validation crois\'ee}
D'un point de vue m\'ethodologique, l'inconv\'enient majeur du r\'esultat pr\'ec\'edent est que la taille de fen\^etre optimale
$h_n^\star=h_n^\star(f)$ d\'epend de $f$, qui est pr\'ecis\'ement l'objet que l'on cherche \`a estimer !
Nous allons chercher un choix de $h$ dict\'e par l'observation $X_1,\ldots, X_n$ uniquement, et dont l'erreur imite le mieux possible l'erreur id\'eale fournie par le choix de $h_n^\star$. Ecrivons d\'esormais $\widehat{f_n(x)}=\widehat{f_{n,h}(x)}$ et consid\'erons 
\begin{align*}
&L_n(h)=\int_0^1\big(\widehat{f_{n,h}(u)}-f(u)\big)^2du\\
=&\int_0^1(\widehat{f_{n,h}(u)})^2du-2\int_0^1\widehat{f_{n,h}(u)}f(u)du+\int_0^1 f(u)^2du.
\end{align*}
\begin{enumerate}
\item Montrer que minimiser ${\mathcal R}(\widehat{f_{n,h}},f)$ est \'equivalent \`a minimiser l'esp\'erance de 
$$J_n(h)=\int_0^1(\widehat{f_{n,h}(u)})^2du-2\int_0^1\widehat{f_{n,h}(u)}f(u)du.$$
\item Notons $\widehat{f_{n,h,i}}(x)$ l'estimateur de $f$ au point $x$ obtenu en ignorant la donn\'ee $X_i$. 
\begin{definition}
L'estimateur du risque par validation crois\'ee est
$$\widehat{J_n}(h)=\int_0^1 (\widehat{f_{n,h}(u)})^2du-\frac{2}{n}\sum_{i=1}^n \widehat{f_{n,h,i}}(X_i)$$
\end{definition}
\item Montrer que $\lim_{n\rightarrow \infty}\frac{\mathbb{E}[\widehat{J_n}(h)]}{\mathbb{E}[J_n(h)]}=1$, ce qui justifie {\it a posteriori} cette approche. 
\item En principe, pour minimiser $h \mapsto \widehat{J_n}(h)$, on doit reconstruire $n$ histogrammes pour chaque valeur de $h$. Heureusement, on dispose du raccourci suivant.
Montrer que :
$$\widehat{J_n}(h)=\frac{2}{(n-1)h}-\frac{1}{h}\frac{n+1}{n-1}\sum_{j=1}^m \widehat{p_j}^2.$$
\end{enumerate}
\section{Mise en oeuvre num\'erique}
On se propose d'\'etudier les propri\'et\'es de l'histogramme sur un jeu de donn\'ees simul\'ees $X_1,\ldots, X_n$, o\`u les $X_i$ sont des r\'ealisations de variables i.i.d. de densit\'e $f \in {\mathcal F}$.
On travaillera sur un ensemble ${\mathcal F}$ de densit\'es ``test". Par exemple, ${\mathcal F}$ inclut la densit\'e uniforme, les lois B\'eta de param\`etres $(\alpha,\beta)$ avec $\alpha >0$ et $\beta >0$ et dont la densit\'e est donn\'ee par
$$f_{\alpha,\beta}(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1},$$
mais aussi un m\'elange de deux lois normales
$$f_{\mu_1,\mu_2, \sigma_1, \sigma_2, \pi}(x) = \pi g_{\sigma_1^2, \mu_1}(x)+(1-\pi)g_{\mu_2,\sigma_2^2}(x),\;\;\pi \in [0,1]$$
avec $g_{\sigma^2,\mu}(x)=(2\pi\sigma^2)^{-1/2}\exp\big(-\tfrac{1}{2\sigma^2}(x-\mu)^2\big)$
(en pratique, on ne se pr\'eoccupera pas que $f_{\mu_1,\mu_2, \sigma_1, \sigma_2, \pi}$ ne soit pas \`a support dans $[0,1]$ et on ram\`enera le probl\`eme de l'estimation sur $[0,1]$ \`a l'estimation sur 
$$[\min X_i, \max X_i]$$ par dilatation-translation). D'autres choix pour $f$ de sorte d'enrichir la classe ${\mathcal F}$ seront les bienvenus. Dans le projet, on pourra se sp\'ecialiser sur une classe d'exemples (\'eventuellement diff\'erents que les propositions ci-dessus).
On choisira $n \in N=\{10,100, 500, 1000, 10000\}$, mais l\`a encore, d'autres choix sont possibles.
\begin{enumerate}
\item Pour plusieurs choix de $f \in {\mathcal F}$, simuler $X_1,\ldots, X_n$ de densit\'e $f$.
\item Constuire l'estimateur par histogramme  (faire une repr\'esentation graphique) pour plusieurs choix de fen\^etres $h$ et discuter succintement le choix de $h$ en fonction de l'aspect visuel de la repr\'esentation (en superposant par exemple l'estimateur et la densit\'e "inconnue``).
\item Calculer la fen\^etre par validation crois\'ee, et calculer (dans le mesure du possible, en r\'ealit\'e, chercher une approximation de) la fen\^etre id\'eale $h=h(f)$ qui minimise ${\mathcal R}$.
\item Comparer les erreurs quadratiques obtenues  $\int_{0}^1 \big(\hat f_{n,h}(x)-f(x)\big)^2dx $ pour diff\'erentes exp\'eriences de simulation de r\'ealisations de ${\bf X}^i=(X_1^i,\ldots, X_n^i)$, pour $i=1,\ldots, M$ et $M$ choisi assez grand (au moins de l'ordre de $n$).

A partir de chaque erreur $\int_{0}^1 \big(\hat f_{n,h}(x)-f(x)\big)^2dx =\int_{0}^1 \big(\hat f_{n,h}({\bf X}^i)(x)-f(x)\big)^2dx $ obtenue pour l'exp\'erience ${\bf X}^i$, on pourra consid\'erer l'erreur empirique moyenne
$${\mathcal E}_n = M^{-1}\sum_{i=1}^M \int_{0}^1 \big(\hat f_{n,h}({\bf X}^i)(x)-f(x)\big)^2dx.$$ 
\item {\it (Plus d\'elicat).} Dans le cas o\`u l'on choisit une famille param\'etr\'ee, avec $f$ de la forme $f(x)=g(\theta,x)$, o\`u $g$ est connue et $\theta$ inconnu, par exemple, une loi normale de param\`etre $\theta = (\mu,\sigma^2)$, comparer les performance de l'estimateur par histogramme contre l'estimateur $f(\hat \theta, x)$, o\`u $\hat \theta$ est un estimateur standard de $\theta$ (obtenu par une m\'ethode de moment ou par le maximum de vraisemblance) en terme d'erreur empirique moyenne ${\mathcal E}_n$.

Pour comparer m\'ethode param\'etrique et non-param\'etrique, on pourra repr\'esenter (en \'echelle logarithmique) $\log({\mathcal E}_n)$ contre $\log(n)$ pour $n \in N$, ce qui devrait fournir une estimation de l'exposant de l'erreur en consid\'erant le coefficient directeur de la droite de r\'egression du nuage de points obtenus.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \bf Projet 4 : Estimation bootstrap de l'efficacit\'e relative de deux s\'erums}  \bigskip
\hrule height .5pt \bigskip
\begin{center} {{\bf responsable}: Christophe Giraud {\sf (christophe.giraud@polytechnique.edu)}}
\end{center}

{\bf Mots clefs:} r\'egression logistique, test de parall\'elisme, estimation bootstrap.

\bigskip
Notre objectif est de comparer les niveaux d'anticorps anticoronavirus dans deux \'echantillons de s\'erum pr\'elev\'es en mai et en juin sur une m\^eme vache. Les donn\'ees sont disponibles \`a l'adresse suivante:\\* {\tt http://www.cmap.polytechnique.fr/$\sim$giraud/MAP433/data.pdf} \\* 
Ce sont des mesures de densit\'e optique $Y$ pour diff\'erents niveaux de dilution $d$. Pour chaque date et chaque dilution on dispose de deux mesures de densit\'e optique du s\'erum. 

\medskip
{\bf Travail \`a rendre} par courriel  \`a christophe.giraud@polytechnique.edu \\*
Vous me rendrez  un rapport au format pdf comprenant \smallskip

\quad - les codes que vous avez utilis\'e (en int\'egralit\'e), \smallskip

\quad - les sorties de votre code (r\'esultats num\'eriques, graphiques, etc), \smallskip

\quad - les r\'eponses (concises mais compl\`etes) aux questions pos\'ees.
\bigskip

{\bf Mod\`ele statistique:} on mod\'elise la densit\'e $Y^{(\mois)}_{i,j}$ pour le mois "\textsf{mois}", la log-dilution $x_{i}=\log_{10}(1/d_i)$ (o\`u $d_{i}$ est la dilution du s\'erum),  et la mesure $j$ par
$$Y_{i,j}^{(\mois)}=f(x_{i},\theta^{(\mois)})+\varepsilon_{i,j}^{(\mois)}, \quad i=1,\ldots,k,\ \ j=1,\ldots,r,\ \textrm{et } \mois=\mai,\juin$$
avec 
$$f(x,\theta)=\theta_{1}+{\theta_{2}-\theta_{1}\over 1+\exp(\theta_{3}(x-\theta_{4}))}$$
et les $\varepsilon_{i,j}^{(\mois)}$ i.i.d. centr\'ees et de variance $\sigma^2$ inconnue. 

Le but de l'analyse est d'estimer l'efficacit\'e relative $\rho$ du s\'erum de juin par rapport au s\'erum de mai. Le s\'erum de juin a une efficacit\'e relative $\rho$ par rapport au s\'erum de mai s'il se comporte comme une dilution $\rho$ du s\'erum de mai. Autrement dit, $\rho$ est tel que 
\begin{equation}\label{hypo}
f(x,\theta^{(\mai)})=f(x+\log_{10}\rho,\theta^{(\juin)}),\quad \textrm{pour tout }x\in[0,1].
\end{equation}
On estime $\theta^{(\mois)}$ par $\hat\theta^{(\mois)}$ minimisant 
$$M^{(\mois)}(\theta)={1\over kr}\sum_{i=1}^k\sum_{j=1}^r(Y_{i,j}^{(\mois)}-f(x_{i},\theta))^{2},$$
et on note $n=kr$, $\theta=(\theta^{(\mai)},\theta^{(\juin)})^{T}$ et $\hat\theta_{n}=(\hat\theta^{(\mai)},\hat\theta^{(\juin)})^{T}$.
\section{Etude th\'eorique pr\'eliminaire}
Le nombre $r$ de r\'ep\'etitions  \'etant suppos\'e fixe, on va \'etudier le comportement de $\hat \theta_{n}$ lorsque $n=kr\to \infty$.
On note $\nabla_{\theta} f$ le gradient de $f$ par rapport \`a $\theta$ et on  suppose que
$$ {1\over k}\sum_{i=1}^k(\nabla_{\theta} f)(\nabla_{\theta} f)^{T}(x_{i},\theta)= \underbrace{\int_{0}^1(\nabla_{\theta} f)(\nabla_{\theta} f)^{T}(x,\theta)\,dx}_{=H(\theta)}+O(1/k)$$ 
\begin{enumerate}
\item Montrez que $\sqrt{n}(\hat\theta_{n}-\theta)$ converge en loi lorsque $n\to \infty$ et identifiez la loi limite en fonction de $\sigma^2$ et des $H(\theta^{(\mois)})$. \smallskip

\begin{small}
\underline{Indications:} comme $\hat \theta^{(\mai)}$ et $\hat \theta^{(\juin)}$ sont ind\'ependants, \'etudiez les s\'epar\'ement. Et toute ressemblance avec le paragraphe 5.4.2 du poly n'est pas fortuite....
\end{small}  \smallskip

\item Pour estimer $\rho$, il faut commencer par v\'erifier que la relation (\ref{hypo}) est en accord avec les donn\'ees. Nous allons donc tester 
$${\bf H0}:\ \theta_{i}^{(\mai)}=\theta_{i}^{(\juin)}\ i=1,2,3$$
contre
$${\bf H1}: \exists i\in\{1,2,3\} \ \textrm{tel que}\  \theta_{i}^{(\mai)}\neq\theta_{i}^{(\juin)}.$$
Remarquez que {\bf H0} s'\'ecrit $A\theta=0$ pour une certaine matrice A de taille $3\times 8$ et de rang 3. Si $A\theta=0$, montrez que $\sqrt{n}A\hat\theta_{n}$ converge en loi vers une variable gaussienne $\mathcal{N}(0,\sigma^2V(\theta))$.
\item Proposez un estimateur consistant $\hat \sigma^2_{n}$ de $\sigma^2$. On pose 
$$T_{n}={n\over \hat\sigma^2_{n}} (A\hat\theta_{n})^{T}\widehat V(\hat\theta_{n})^{-1}A\hat\theta_{n},$$
avec $\widehat V(\theta)$ la version empirique de $V(\theta)$.
Quel est le comportement asymptotique de $T_{n}$ lorsque $A\theta\neq 0$? Montrez que si $A\theta=0$, la variable $T_{n}$ converge en loi vers un $\chi^2(3)$.
\item Proposez un test de niveau asymptotique 5\% de {\bf H0} contre {\bf H1}.
\end{enumerate}

\section{Estimation des param\`etres et analyse du parall\'elisme}
\begin{enumerate}
\item Calculez $\hat\theta_{n}$ et $T_{n}$. L'hypoth\`ese {\bf H0} est-elle rejet\'ee?
\item On note $\tilde\theta_{n}$ le minimiseur de $M^{(\mai)}(\theta^{(\mai)})+M^{(\juin)}(\theta^{(\juin)})$ sous la contrainte $A\theta=0$. On estime $\rho$ par $\hat\rho=10^{(\tilde\theta_{4}^{(\juin)}-\tilde\theta_{4}^{(\mai)})}$. calculez $\hat \rho$.
\end{enumerate}

\section{Intervalle de confiance par r\'e-\'echantillonage}
En adaptant les calculs de la premi\`ere partie, on peut d\'eduire la loi limite de $\sqrt{n}(\hat \rho-\rho)$ et batir des intervalles de confiance asymptotique pour $\rho$. Lorsque la taille $n$ de l'\'echantillon est faible, cette approximation n'est cependant pas valide. Dans ce cas, une alternative int\'eressante est de construire un intervalle de confiance par bootstrap. Le principe du bootstrap est le suivant. Supposons qu'on puisse r\'ep\'eter $B$ fois l'exp\'erience biologique de fa\c{c}on ind\'ependantes. Pour l'exp\'erience $b$ on obtiendrait un estimateur $\hat\rho_{b}$ et on aurait donc un \'echantillon de $B$ estimateurs i.i.d. distribu\'es comme $\hat \rho$. Pour $B$ grand on pourrait donc estimer la distribution de $\hat \rho$ (et ainsi contruire un intervalle de confiance pour $\rho$). 

Les m\'ethodes de r\'e-\'echantillonage sont une mani\`ere de mimer la r\'ep\'etition d'une exp\'erience. Les estimateurs $\hat\rho_{b}$ sont calcul\'es \`a partir d'un \'echantillon bootstrap
$$Y_{i,j}^{(\mois),b}=f(x_{i},\tilde\theta_{n}^{(\mois)})+\varepsilon_{i,j}^{(\mois),b}$$
o\`u les $\varepsilon^{b}$ sont obtenus de la fa\c{c}on suivante.  On note $\hat\varepsilon_{i,j}^{(\mois)}=Y_{i,j}^{(\mois)}-f(x_{i},\tilde\theta_{n}^{(\mois)})$ et $\tilde\varepsilon_{i,j}$ les $\hat\varepsilon_{i,j}$ recentr\'es (en retranchant la moyenne empirique). Pour chaque $b$, chaque variable $\varepsilon_{i,j}^{(\mois), b}$ est obtenue par un tirage al\'eatoire (avec remise) parmi les $\{\tilde \varepsilon_{i,j}^{(\mois)},\ i=1,\ldots,k, j=1,\ldots,r, \mois=\mai,\juin\}$. 

Enfin, l'intervalle de confiance bootstrap de $\rho$ de niveau $\alpha$ est donn\'e par 
$$I_{B}(\alpha)=[F^{*}_{B}(\alpha/2),F^{*}_{B}(1-\alpha/2)]\quad \textrm{o\`u} \ \ F^*_{B}(\alpha)=\inf\left\{x\in{\bf R}: \ {1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat\rho_{b}\leq x\}}\geq \alpha\right\}.$$
\begin{enumerate}
\item Calculer l'intervalle $I_{B}(\alpha)$ pour $B=1000$ et $\alpha=5\%$.
(Il est possible de montrer que $I_{B}(\alpha)$ est un intervalle de confiance de niveau asymptotique $\alpha$ lorsque $B,n\to\infty$.
La preuve de ce r\'esultat est difficile.)
\item {\bf *Question facultative*} 
L'approche pr\'ec\'edente est le bootstrap naif. On peut montrer qu'il vaut mieux chercher \`a estimer la loi de $\hat Z=\sqrt{n\over \hat s^2}(\hat \rho-\rho)$ par bootstrap pour obtenir un intervalle de confiance plus pr\'ecis. \\*
{\bf a.} Quelle est la loi asymptotique de $\sqrt{n}(\hat \rho-\rho)$? en d\'eduire un estimateur $\hat s^2$ de sa variance asymptotique $s^2$. \\*
{\bf b.} Pour chaque \'echantillon bootstrap on peut calculer la variance $\hat s_{b}^2$ et $\hat Z_{b}=\sqrt{n\over \hat s^2_{b}}(\hat \rho_{b}-\hat\rho)$. Les $\hat Z_{b}$ fournissent un \'echantillon bootstrap de $\hat Z$. On peut donc estimer pour $x\in {\bf R}$ la probabilit\'e ${\bf P}(\hat Z \leq x)$ par ${1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat Z_{b}\leq x\}}$. 
En d\'eduire un intervalle de confiance $I'_{B}(\alpha)$ de $\rho$ en fonction de $G^*(\alpha/2)$ et $G^*(1-\alpha/2)$ o\`u 
$$G^*_{B}(\alpha)=\inf\left\{x\in{\bf R}: \ {1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat Z_{b}\leq x\}}\geq \alpha\right\}.$$
Il est possible de montrer que cet intervalle est de meilleure qualit\'e que $I_{B}(\alpha)$.
\end{enumerate}
%\bigskip
%
%{\bf Mots clefs:} r\'egression logistique, test de parall\'elisme, estimation bootstrap.
%
%\bigskip
%Notre objectif est de comparer les niveaux d'anticorps anticoronavirus dans deux \'echantillons de s\'erum pr\'elev\'es en mai et en juin sur une m\^eme vache. Les donn\'ees sont disponibles \`a l'adresse suivante:\\* {\tt http://www.cmap.polytechnique.fr/$\sim$giraud/MAP433/data.pdf}. \\* Ce sont des mesures de densit\'e optique $Y$ pour diff\'erents niveaux de dilution $d$. Pour chaque date et chaque dilution on dispose de deux mesures de densit\'e optique du s\'erum. 
%
%\medskip
%{\bf Mod\`ele statistique:} on mod\'elise la densit\'e $Y^{(\mois)}_{i,j}$ pour le mois "\textsf{mois}", la log-dilution $x_{i}=\log_{10}(1/d_i)$ (o\`u $d_{i}$ est la dilution du s\'erum),  et la mesure $j$ par
%$$Y_{i,j}^{(\mois)}=f(x_{i},\theta^{(\mois)})+\varepsilon_{i,j}^{(\mois)}, \quad i=1,\ldots,k,\ \ j=1,\ldots,r,\ \textrm{et } \mois=\mai,\juin$$
%avec 
%$$f(x,\theta)=\theta_{1}+{\theta_{2}-\theta_{1}\over 1+\exp(\theta_{3}(x-\theta_{4}))}$$
%et les $\varepsilon_{i,j}^{(\mois)}$ i.i.d. centr\'ees et de variance $\sigma^2$ inconnue. 
%
%Le but de l'analyse est d'estimer l'efficacit\'e relative $\rho$ du s\'erum de juin par rapport au s\'erum de mai. Le s\'erum de juin a une efficacit\'e relative $\rho$ par rapport au s\'erum de mai s'il se comporte comme une dilution $\rho$ du s\'erum de mai. Autrement dit, $\rho$ est tel que 
%\begin{equation}\label{hypo}
%f(x,\theta^{(\mai)})=f(x+\log_{10}\rho,\theta^{(\juin)}),\quad \textrm{pour tout }x\in[0,1].
%\end{equation}
%On estime $\theta^{(\mois)}$ par $\hat\theta^{(\mois)}$ minimisant 
%$$M^{(\mois)}(\theta)={1\over kr}\sum_{i=1}^k\sum_{j=1}^r(Y_{i,j}^{(\mois)}-f(x_{i},\theta))^{2},$$
%et on note $n=kr$, $\theta=(\theta^{(\mai)},\theta^{(\juin)})^{T}$ et $\hat\theta_{n}=(\hat\theta^{(\mai)},\hat\theta^{(\juin)})^{T}$.
%\section{Etude th\'eorique pr\'eliminaire}
%Le nombre $r$ de r\'ep\'etitions  \'etant suppos\'e fixe, on va \'etudier le comportement de $\hat \theta_{n}$ lorsque $n=kr\to \infty$.
%On note $\nabla_{\theta} f$ le gradient de $f$ par rapport \`a $\theta$ et on  suppose que
%$$ {1\over k}\sum_{i=1}^k(\nabla_{\theta} f)(\nabla_{\theta} f)^{T}(x_{i},\theta)= \underbrace{\int_{0}^1(\nabla_{\theta} f)(\nabla_{\theta} f)^{T}(x,\theta)\,dx}_{=H(\theta)}+O(1/k)$$ 
%\begin{enumerate}
%\item Montrez que $\sqrt{n}(\hat\theta_{n}-\theta)$ converge en loi lorsque $n\to \infty$ et identifiez la loi limite en fonction de $\sigma^2$ et des $H(\theta^{(\mois)})$.
%
%\underline{Indications} : comme $\hat \vartheta(\mai)$ et $\hat \vartheta(\juin)$ sont ind´ependants, \'etudiez les s\'epar\'ement. 
%Et toute ressemblance avec le paragraphe 5.4.2 du poly n’est pas fortuite.... 
%
%\item Pour estimer $\rho$, il faut commencer par v\'erifier que la relation (\ref{hypo}) est en accord avec les donn\'ees. Nous allons donc tester 
%$${\bf H0}:\ \theta_{i}^{(\mai)}=\theta_{i}^{(\juin)}\ i=1,2,3\quad \textrm{contre} \ {\bf H1}: \exists i\in\{1,2,3\} \ \textrm{tel que}\  \theta_{i}^{(\mai)}\neq\theta_{i}^{(\juin)}.$$
%Remarquez que {\bf H0} s'\'ecrit $A\theta=0$ pour une certaine matrice A de taille $3\times 8$ et de rang 3. Si $A\theta=0$, montrez que $\sqrt{n}A\hat\theta_{n}$ converge en loi vers une variable gaussienne $\mathcal{N}(0,\sigma^2V(\theta))$.
%\item Proposez un estimateur consistant $\hat \sigma^2_{n}$ de $\sigma^2$. On pose 
%$$T_{n}={n\over \hat\sigma^2_{n}} (A\hat\theta_{n})^{T}\widehat V(\hat\theta_{n})^{-1}A\hat\theta_{n},$$
%avec $\widehat V(\theta)$ la version empirique de $V(\theta)$.
%Quel est le comportement asymptotique de $T_{n}$ lorsque $A\theta\neq 0$? Montrez que si $A\theta=0$, la variable $T_{n}$ converge en loi vers un $\chi^2(3)$.
%\item Proposez un test de niveau asymptotique 5\% de {\bf H0} contre {\bf H1}.
%\end{enumerate}
%
%\section{Estimation des param\`etres et analyse du parall\'elisme}
%\begin{enumerate}
%\item Calculez $\hat\theta_{n}$ et $T_{n}$. L'hypoth\`ese {\bf H0} est-elle rejet\'ee?
%\item On note $\tilde\theta_{n}$ le minimiseur de $M^{(\mai)}(\theta^{(\mai)})+M^{(\juin)}(\theta^{(\juin)})$ sous la contrainte $A\theta=0$. On estime $\rho$ par $\hat\rho=10^{(\tilde\theta_{4}^{(\juin)}-\tilde\theta_{4}^{(\mai)})}$. calculez $\hat \rho$.
%\end{enumerate}
%
%\section{Intervalle de confiance par r\'e-\'echantillonage}
%En adaptant les calculs de la premi\`ere partie, on peut d\'eduire la loi limite de $\sqrt{n}(\hat \rho-\rho)$ et batir des intervalles de confiance asymptotique pour $\rho$. Une alternative int\'eressante lorsque la taille de l'\'echantillon n'est pas tr\`es gros est de construire un intervalle de confiance par bootstrap. Le principe du bootstrap est le suivant. Supposons qu'on puisse r\'ep\'eter $B$ fois l'exp\'erience biologique de fa\c{c}on ind\'ependantes. Pour l'exp\'erience $b$ on obtiendrait un estimateur $\hat\rho_{b}$ et on aurait donc un \'echantillon de $B$ estimateurs i.i.d. distribu\'es comme $\hat \rho$. Pour $B$ grand on pourrait donc estimer la distribution de $\hat \rho$ (et ainsi contruire un intervalle de confiance pour $\rho$). 
%
%Les m\'ethodes de r\'e-\'echantillonage sont une mani\`ere de mimer la r\'ep\'etition d'une exp\'erience. Les estimateurs $\hat\rho_{b}$ sont calcul\'es \`a partir d'un \'echantillon bootstrap
%$$Y_{i,j}^{(\mois),b}=f(x_{i},\tilde\theta_{n}^{(\mois)})+\varepsilon_{i,j}^{(\mois),b}$$
%o\`u les $\varepsilon^{b}$ sont obtenus de la fa\c{c}on suivante.  On note $\hat\varepsilon_{i,j}^{(\mois)}=Y_{i,j}^{(\mois)}-f(x_{i},\tilde\theta_{n}^{(\mois)})$ et $\tilde\varepsilon_{i,j}$ les $\hat\varepsilon_{i,j}$ recentr\'es (en retranchant la moyenne empirique). Pour chaque $b$, chaque variable $\varepsilon_{i,j}^{(\mois), b}$ est obtenue par un tirage al\'eatoire (avec remise) parmi les $\{\tilde \varepsilon_{i,j}^{(\mois)},\ i=1,\ldots,k, j=1,\ldots,r, \mois=\mai,\juin\}$. 
%
%Enfin, l'intervalle de confiance bootstrap de $\rho$ de niveau $\alpha$ est donn\'e par 
%$$I_{B}(\alpha)=[F^{*}_{B}(\alpha/2),F^{*}_{B}(1-\alpha/2)]\quad \textrm{o\`u} \ \ F^*_{B}(\alpha)=\inf\left\{x\in{\bf R}: \ {1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat\rho_{b}\leq x\}}\geq \alpha\right\}.$$
%\begin{enumerate}
%\item Calculer l'intervalle $I_{B}(\alpha)$ pour $B=1000$ et $\alpha=5\%$.
%(Il est possible de montrer que $I_{B}(\alpha)$ est un intervalle de confiance de niveau asymptotique $\alpha$ lorsque $B,n\to\infty$.
%La preuve de ce r\'esultat est difficile.)
%\item {\bf *Question facultative*} 
%L'approche pr\'ec\'edente est le bootstrap naif. On peut montrer qu'il vaut mieux chercher \`a estimer la loi de $\hat Z=\sqrt{n\over \hat s^2}(\hat \rho-\rho)$ par bootstrap pour obtenir un intervalle de confiance plus pr\'ecis. \\*
%{\bf a.} Quelle est la loi asymptotique de $\sqrt{n}(\hat \rho-\rho)$? en d\'eduire un estimateur $\hat s^2$ de sa variance asymptotique $s^2$. \\*
%{\bf b.} Pour chaque \'echantillon bootstrap on peut calculer la variance $\hat s_{b}^2$ et $\hat Z_{b}=\sqrt{n\over \hat s^2_{b}}(\hat \rho_{b}-\hat\rho)$. Les $\hat Z_{b}$ fournissent un \'echantillon bootstrap de $\hat Z$. On peut donc estimer pour $x\in {\bf R}$ la probabilit\'e ${\bf P}(\hat Z \leq x)$ par ${1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat Z_{b}\leq x\}}$. 
%En d\'eduire un intervalle de confiance $I'_{B}(\alpha)$ de $\rho$ en fonction de $G^*(\alpha/2)$ et $G^*(1-\alpha/2)$ o\`u 
%$$G^*_{B}(\alpha)=\inf\left\{x\in{\bf R}: \ {1\over B}\sum_{b=1}^{B}{\bf 1}_{\{\hat Z_{b}\leq x\}}\geq \alpha\right\}.$$
%Il est possible de montrer que cet intervalle est de meilleure qualit\'e que $I_{B}(\alpha)$.
%\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 5 : Lois Gamma} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Mathieu Rosenbaum {\sf (mathieu.rosenbaum@polytechnique.edu)}}
\end{center}


\noindent {\it Remarque}: Les traitements informatiques peuvent
\^etre
effectués avec le logiciel de votre choix.\\
  
\noindent On s'intéresse à un échantillon $(X_1,\ldots,X_n)$ de
variables aléatoires i.i.d. de loi Gamma, $\Gamma(p,\theta)$, $p\in\mathbb{N}^*$, $\theta>0$, de densité

$$f_\theta(x)=\frac{x^{p-1}}{\Gamma(p)}\theta^p\text{exp}(-\theta x)\mathrm{1}_{x>0}.$$\\

\noindent {\bf Q1} Montrer que la somme de $p$ variables iid de loi exponentielle de paramétre $\theta$
suit une loi $\Gamma(p,\theta)$.\\ 

\noindent On considére dans toute la suite du projet le cas $p=2$.\\

\noindent {\bf Q2} En utilisant la question précédente, donner une méthode de simulation de la loi $\Gamma(2,\theta)$
à partir de la simulation de la loi uniforme sur $[0,1]$. Pour chaque
$\theta\in\{0.1, 0.2,\ldots,2\}$, tirer 500 échantillons de taille
$n = 20$ de variables iid de loi $\Gamma(2,\theta)$.\\

\noindent On considére dans la suite deux estimateurs de $\theta$ :
l'estimateur du maximum de vraisemblance, noté $\hat{\theta}_1$ et
$\hat{\theta}_2$ défini pour un échantillon quelconque par
$$
\frac{9\pi n^2}{16\big(\sum_{i=1}^n\sqrt{X_i}\big)^2}.\\
$$

\noindent {\bf Q3} Exprimer $\hat{\theta}_1$ en fonction de
$(X_1,\ldots,X_n)$ et expliquer le choix de  $\hat{\theta}_2$.
Présenter un histogramme de $\hat{\theta}_1$ et $\hat{\theta}_2$
correspondant aux 500 échantillons tirés avec $\theta =1$.\\

\noindent {\bf Q4} Estimer à partir des échantillons à disposition
la fonction de risque quadratique associée aux deux estimateurs.
Quel estimateur est-il préférable d'utiliser ? Ce résultat était-il
prévisible ?\\

\noindent {\bf Q5} Construire deux tests asymptotiques de $\theta =
1$ contre $\theta\neq 1$ au niveau de confiance de 95\% à partir de
$\hat{\theta}_1$ et $\hat{\theta}_2$. Définir notamment, pour un
échantillon donné, les statistiques de test $T_1$ et $T_2$ et les
régions critiques $W_1$ et $W_2$ correspondantes. Présenter un
tableau indiquant, pour les 5 premiers échantillons tirés avec
$\theta = 1$, la valeur des statistiques de test, la p-value et la
décision obtenue.\\


\noindent {\bf Q6}  On considére toujours les deux tests précédents
de $\theta = 1$ contre $\theta\neq 1$. On rappelle que leur fonction
puissance est définie pour $k\in \{1,2\}$ par :
\begin{eqnarray*}
\rho_k:\mathbb{R}^{+*}&\rightarrow& [0,1]\\
\theta &\rightarrow&\PP_{\theta}(W_k).
\end{eqnarray*}
Proposer un estimateur de $\rho_k(\theta)$ pour $k\in\{1,2\}$ et
$\theta\in\{0.1, 0.2,\ldots,2\}$ à partir des échantillons simulés.
Présenter un graphe des deux fonctions puissances (on indiquera sur
le graphe les niveaux estimés des deux tests). L'un des tests est-il
meilleur que l'autre ? Commenter.\\

\noindent {\bf Q7} On s'intéresse maintenant à un intervalle de
confiance sur $\theta$, lorsque le vrai paramétre est $\theta =
1$. Construire un intervalle de confiance asymptotique de niveau
95 \% à partir de $\hat{\theta}_1$. On note $IC_1$ cet intervalle.
On rappelle que le taux de couverture d'un intervalle de confiance
$IC$ est défini par $p= \PP_\theta(\theta \in IC)$. Proposer, à
partir des 500 échantillons simulés, un estimateur du taux de
couverture correspondant à $IC_1$.\\

\noindent {\bf Q8} On présente dans cette question une méthode de
construction d'intervalles de confiance par bootstrap. Cette
méthode est admise. Un échantillon bootstrap est un échantillon
issu d'un tirage uniforme avec remise de $n$ observations de
l'échantillon initial $(X_1,\ldots,X_n)$. Le principe de la
méthode est de tirer $B$ échantillons bootstrap et de calculer les
$B$ estimateurs $(\hat{\theta}_1^{(b)})_{b=1,\ldots,B}$ associés à
chaque échantillon bootstrap. L'intervalle de confiance bootstrap,
noté $IC_2$, est $[q_{\alpha/2},q_{1-\alpha/2}]$, oô, pour tout
$\beta$, $q_{\beta}$ est le quantile empirique d'ordre $\beta$ de
$\hat{\theta}_1^{(1)},\ldots,\hat{\theta}_1^{(B)}$. Reprendre les
questions de Q7 avec $IC_2$ pour $B=1000$.
Que constate-t-on ? Commenter.\\
%(auteur du texte : M. Rosenbaum)

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 6 : Lois de Lévy} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Mathieu Rosenbaum {\sf (mathieu.rosenbaum@polytechnique.edu)}}
\end{center}



\bigskip

\noindent {\it Remarque}: Les traitements informatiques peuvent
\^etre
effectués avec le logiciel de votre choix.\\

\noindent On s'intéresse à un échantillon $(X_1,\ldots,X_n)$ de
variables aléatoires i.i.d. de loi de Lévy $L(\theta)$ de densité

$$f_\theta(x)=\sqrt{\frac{\theta}{2\pi}}\frac{\text{exp}(-\theta/2x)}{x^{3/2}}\mathrm{1}_{x>0}.$$\\

\noindent {\bf Q1} Montrer que si $X$ suit une loi de Lévy
$L(\theta)$, $1/X$ suit une loi gamma $\Gamma(1/2,\theta/2)$ de
densité
$$g_\theta(x) = \frac{\sqrt{\theta/2}}{\Gamma(1/2)}x^{-1/2}\text{exp}(-x\theta/2)\mathrm{1}_{x>0}.$$

\noindent {\bf Q2} En utilisant la question précédente, pour chaque
$\theta\in\{0.1, 0.2,\ldots,2\}$, tirer 500 échantillons de taille
$n = 20$ de variables iid de loi de Lévy $L(\theta)$.\\

\noindent On considére dans la suite deux estimateurs de $\theta$ :
l'estimateur du maximum de vraisemblance, noté $\hat{\theta}_1$ et
$\hat{\theta}_2$ défini pour un échantillon quelconque par
\begin{align*}
\hat{\theta}_2
&=\Big[\Phi^{-1}\big(\frac{n+\sum_{i=1}^n\mathrm{1}_{X_i>1}}{2n}\big)\Big]^2,\text{
si } \sum_{i=1}^n\mathrm{1}_{X_i>1}<n,\\
&=4 \text{ sinon,}
\end{align*}
oô $\Phi$ est la fonction de
répartition d'une loi normale
centrée réduite.\\

\noindent {\bf Q3} Exprimer $\hat{\theta}_1$ en fonction de
$(X_1,\ldots,X_n)$ et expliquer le choix de  $\hat{\theta}_2$.
Présenter un histogramme de $\hat{\theta}_1$ et $\hat{\theta}_2$
correspondant aux 500 échantillons tirés avec $\theta =1$.\\

\noindent {\bf Q4} Estimer à partir des échantillons à disposition
la fonction de risque quadratique associée aux deux estimateurs.
Quel estimateur est-il préférable d'utiliser ? Ce résultat était-il
prévisible ?\\

\noindent {\bf Q5} Construire deux tests asymptotiques de $\theta =
1$ contre $\theta\neq 1$ au niveau de confiance de 5\% à partir de
$\hat{\theta}_1$ et $\hat{\theta}_2$. Définir notamment, pour un
échantillon donné, les statistiques de test $T_1$ et $T_2$ et les
régions critiques $W_1$ et $W_2$ correspondantes. Présenter un
tableau indiquant, pour les 5 premiers échantillons tirés avec
$\theta = 1$, la valeur des statistiques de test, la p-value et la
décision obtenue.\\

\noindent {\bf Q6}  On considére toujours les deux tests précédents
de $\theta = 1$ contre $\theta\neq 1$. On rappelle que leur fonction
puissance est définie pour $k\in \{1,2\}$ par :
\begin{eqnarray*}
\rho_k:\mathbb{R}^{+*}&\rightarrow& [0,1]\\
\theta &\rightarrow&\PP_{\theta}(W_k).
\end{eqnarray*}
Proposer un estimateur de $\rho_k(\theta)$ pour $k\in\{1,2\}$ et
$\theta\in\{0.1, 0.2,\ldots,2\}$ à partir des échantillons simulés.
Présenter un graphe des deux fonctions puissances (on indiquera sur
le graphe les niveaux estimés des deux tests). L'un des test est-il
meilleur que l'autre ? Commenter.\\

\noindent {\bf Q7} On s'intéresse maintenant à un intervalle de
confiance sur $\theta$, lorsque le vrai paramétre est $\theta =
1$. Construire un intervalle de confiance asymptotique de niveau
95 \% à partir de $\hat{\theta}_1$. On note $IC_1$ cet intervalle.
On rappelle que le taux de couverture d'un intervalle de confiance
$IC$ est défini par $p= \PP_\theta(\theta \in IC)$. Proposer, à
partir des 500 échantillons simulés, un estimateur du taux de
couverture correspondant à $IC_1$.\\

\noindent {\bf Q8} On présente dans cette question une méthode de
construction d'intervalles de confiance par bootstrap. Cette
méthode est admise. Un échantillon bootstrap est un échantillon
issu d'un tirage uniforme avec remise de $n$ observations de
l'échantillon initial $(X_1,\ldots,X_n)$. Le principe de la
méthode est de tirer $B$ échantillons bootstrap et de calculer les
$B$ estimateurs $(\hat{\theta}_1^{(b)})_{b=1,\ldots,B}$ associés à
chaque échantillon bootstrap. L'intervalle de confiance bootstrap,
noté $IC_2$, est $[q_{\alpha_2},q_{1-\alpha_2}]$, oô, pour tout
$\beta$, $q_{\beta}$ est le quantile empirique d'ordre $\beta$ de
$\hat{\theta}_1^{(1)},\ldots,\hat{\theta}_1^{(B)}$. Reprendre les
questions de Q7 avec $IC_2$.
Que constate-t-on ? Commenter.\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 7 :  Estimation d'une fonction de régression} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable:  Marc Hoffmann {\sf (hoffmann@ceremade.dauphine.fr)}}
\end{center}


\bigskip

Le probléme de prédiction ou d'explication d'une variable $Y$ à l'aide d'une autre variable $X$
est souvent rencontré en pratique. La fonction qui fournit la meilleure prévision (en moyenne 
quadratique) de $Y$ en fonction de $X$ est l'espérance conditionnelle
$$
f(x)={\mathbf E}[Y|X=x].
$$
Cette fonction est appelée fonction de régression et son estimation à partir de $n$ copies
indépendantes du couple $(X,Y)$ est un probléme fondamental en statistique.

Considérons le cas oô $X\in\RR^d$ et $Y\in\RR$. Si l'on ne connaît pas de forme paramétrique 
spécifique pour la fonction $f$ (par exemple, fonction linéaire ou polynôme trigonométrique de degré 2), alors
les méthodes d'estimation classiques (moindres carrés, maximum de vraisemblance, etc) ne peuvent pas être
utilisées directement. On parle alors de probléme d'estimation non-paramétrique. L'objet de ce travail personnel 
est d'étudier une méthode d'estimation non-paramétrique et de l'illustrer sur des jeux de données simulées.

 
\section{Estimateur par projection}

Supposons que la variable explicative $X$ suit la loi uniforme sur $[0,1]^d$ et que 
$\{(X_i,Y_i)$, $1\le i\le n\}$ sont $n$ copies indépendantes de $(X,Y)$. 
De plus, on suppose que la fonction de régression $f$ appartient à $L^2([0,1]^d)$.
Alors, pour toute base orthonormée $\varphi_1,\varphi_2,\ldots$ de $L^2([0,1]^d)$, on a
$$
f(x)=\sum_{j=1}^\infty \theta_j \varphi_j(x),\qquad \forall x\in\RR^d, 
$$
avec des coefficients $\theta_j=\langle f,\varphi_j\rangle=\int_{[0,1]^d}f\varphi_j$ vérifiant $\sum_{j=1}^\infty \theta_j^2<\infty$. Cela implique que $\theta_j\to 0$ lorsque $j\to\infty$. L'idée de l'estimateur par projection consiste donc à remplacer $f$ par une approximation 
$$
f_{N,\theta}(x)=\sum_{j=1}^N \theta_j \varphi_j(x),\qquad \forall x\in\RR^d,
$$
et d'estimer le paramétre fini-dimensionnel $\theta=(\theta_1,\ldots,\theta_N)'$ par la méthode classique 
des moindres carrés. Le choix du niveau de troncature est un point important et il sera fait en fonction des 
données. Soit $\PPhi_N$ la matrice $n\times N$ dont la $j^{\text{éme}}$ colonne est $\Phi_{\bullet j}=(\varphi_j(X_1),\ldots,\varphi_j(X_n))'$ pour $j=1,\ldots,N$. On suppose par la suite que $\PPhi'_N\PPhi_N$ est une matrice définie strictement positive.

\begin{enumerate}

\item Calculer l'estimateur des moindres carrés $\hat\theta_{n,N}$ du paramétre $\theta$ dans le modéle approché $Y_i=f_{N,\theta}(X_i)+U_i$ et en déduire un estimateur $\hat f_{n,N}(x)$ de $f(x)$.
\item Soit $\bY=(Y_1,\ldots,Y_n)'$. Prouver que $(\hat f_{n,N}(X_1),\ldots,\hat f_{n,N}(X_n))'=\bA_N\bY$ oô
$\bA_N=\PPhi_N(\PPhi_N'\PPhi_N)^{-1}\PPhi_N'$ est un projecteur orthogonal sur le sous-espace vectoriel de $\RR^n$
engendré par les colonnes de la matrice $\PPhi_N$.

\item Montrer que lorsque $n\to\infty$, la matrice $\frac1n \PPhi'_N\PPhi_N$ converge vers la matrice identité.
Vérifier qu'en remplaçant $\PPhi'_N\PPhi_N$ par l'approximation $nI_{N\times N}$ dans la définition de $\hat f_{n,N}(x)$, on obtient l'estimateur 
$$
\tilde f_{n,N}(x)=\sum_{j=1}^N \tilde\theta_j \varphi_j(x),\qquad \tilde\theta_j=\frac1n\sum_{i=1}^n Y_i\varphi_j(X_i).
$$

\item Montrer que $\tilde\theta_j$ est l'estimateur par la méthode des moments du paramétre $\theta_j$.

\item On suppose maintenant que
$$
Y_i=f(X_i)+U_i
$$
oô les variables $U_i$ sont iid indépendantes de $\{X_i\}_{i=1,\ldots,n}$. On suppose de plus que la variance 
$\sigma^2=\mathbf E[U_i^2]$ existe et est connue. Calculer le biais $b_{n,N}(x)$ 
de l'estimateur $\tilde f_{n,N}(x)$. Comment se comporte-t-il lorsque $N$ augmente?

\item Pour toute fonction $h\in L^2([0,1]^d)$, on note $\|h\|=[\int_{[0,1]^d}h^2(x)\,dx]^{1/2}$.  
Montrer que le risque quadratique intégré $R(\tilde f_{n,N},f)=\esp[\|\tilde f_{n,N}-f\|^2]$ est borné
par $\sum_{j=N+1}^\infty \theta_j^2+N(\|f\|_\infty^2+\sigma^2)/n$, oô
$$
\|f\|_\infty=\sup_{x} |f(x)|.
$$
Comment choisiriez-vous le paramétre $N$ si 
vous connaissiez la fonction $f$? 

\item Supposons maintenant que $f$ est bornée par $M$ et l'on connaît un entier $k>0$ et un réel $L>0$ tels que 
$\sum_{j=1}^\infty j^{2k}\theta_j^2\le L$. Prouver que $\sum_{j>N}\theta_j^2\le L N^{-2k}$ et en déduire une majoration
du risque $R(\tilde f_{n,N},f)$. Explicitez la valeur de $N$ (en fonction de $n,k,L,M$ et $\sigma$) qui minimise ce
majorant de $R(\tilde f_{n,N},f)$.

\item On suppose maintenant que pour un entier naturel $N_0<n$, le vecteur $(f(X_1),\ldots,f(X_n))'$ appartient
à l'espace vectoriel engendré par les vecteurs $\{(\varphi_j(X_1),\ldots,\varphi_j(X_n))';\ 1\le j\le N_0\}$.
Montrer que $\hat\sigma_{N_0}^2=\frac1{n-N_0} \|(I_{n\times n}-A_{N_0})\bY\|^2$ est un estimateur sans biais de $\sigma^2$.



\section{Simulations}

On considére le cas unidimensionnel ($d=1$) et choisit comme base orthonormée de $L^2([0,1])$ 
la base trigonométrique: $\varphi_1(x)\equiv 1$ et
$$
\varphi_j(x)=\begin{cases}
\sqrt{2}\cos(2k\pi x),&\ \text{si } k=(j+1)/2\in\ZZ,\\
\sqrt{2}\sin(2k\pi x),&\ \text{si } k=j/2\in\ZZ,
\end{cases},\qquad j=1,2,\ldots.
$$
On veut vérifier que la méthode de sélection automatique du niveau de troncature donne des résultats 
satisfaisants. Pour cela : 

\begin{itemize}
\item[$\triangleright$] Poser $n=100$ et générer $n$ variables iid $X_1,\ldots,X_n$ de loi uniforme sur $[0,1]$.
\item[$\triangleright$] Choisir $f(x)=(x^2 2^{(x-1)}-(x-0.5)^3)\sin(10x)$, $\sigma=0.2$ et calculer le vecteur
$\bY=(f(X_1),\ldots,f(X_n))'+\sigma\boldsymbol{\xi}$ oô $\boldsymbol{\xi}$ est un vecteur gausien $\mathcal N(0,I_{n\times n})$.
\item[$\triangleright$] Tracer le nuage des points $(X_i,Y_i)$, $i=1,\ldots,n$ et, dans le même repére orthogonal
la courbe de la fonction $f$.  
\item[$\triangleright$] Pour $N=5,10,15,20,\ldots,50$, calculer l'estimateur $\tilde f_{n,N}$ et tracer
sa courbe superposée de la courbe de $f$ et du nuage des points $\{(X_i,Y_i)\}$. Déterminer visuellement la valeur de $N$ qui correspond au meilleur estimateur.
\item[$\triangleright$] Calculer l'estimateur $\hat\sigma^2_{N_0}$ pour $N_0=50$ et déterminer
$$
\hat N=\text{arg}\min_{N=1,\ldots,50}\Big( \|(I_{n\times n}-A_N)\bY\|^2-(n-2N)\hat\sigma_{N_0}^2\Big).
$$
Cette valeur de $\hat N$, est-elle significativement différente de la valeur ``optimale'' déterminée dans la question précédente? 
\item[$\triangleright$] Tracer la courbe de l'estimateur $\tilde f_{n,\hat N}$ superposée de la courbe de $f$.
\item[$\triangleright$] Répéter cette expérience $100$ fois ; on obtient ainsi les valeurs $\hat N_1,\ldots,\hat N_{100}$. Pour avoir une idée de la répartition de ces valeurs, on pourra tracer l'histogramme de $\hat N_1,\ldots,\hat N_{100}$.
\end{itemize} 
\end{enumerate}
(auteur du texte : A. Dalalyan).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
%{\tt \noindent \'Ecole
%  Polytechnique}
%\hfill{\tt Ann\'ee 2012-2013}
%\hfill{\tt MAP433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 11 :
%Estimation minimax dans le mod\`ele gaussien} }
%\bigskip \hrule height .5pt
%\bigskip
%\begin{center} {responsable: Alexandre Tsybakov {\sf
%(alexandre.tsybakov@ensae.fr)}}
%\end{center}
%
%\bigskip
%
%Supposons que l'on dispose d'une observation
%$X=(X_{1},\ldots,X_{n})\in\R^n$ dont la loi appartient \`a une
%famille de lois de probabilit\'e $(\PP_{\theta}, \theta\in\Theta)$
%sur $\R^n$, o\`u $\Theta\subseteq \R^n$ est un ensemble donn\'e.
%Soit $\hat\theta : \R^n\to \R^n$ une fonction bor\'elienne qui
%d\'efinit l'estimateur $\hat\theta=\hat\theta(X)$ de $\theta$.
%Notons $R(\hat\theta, \theta)$ le risque quadratique de l'estimateur
%$\hat\theta$ au point $\theta\in\Theta$ :
%$$R(\hat\theta,
%\theta)\triangleq\EE_{\theta}\Big[\frac1{n}\big\|\hat\theta(X)-
%\theta\big\|^2\Big],
%$$
%o\`u $\EE_{\theta}$ d\'esigne l'esp\'erance par rapport \`a
%$\PP_\theta$ et $\|\cdot\|$ est la norme euclidienne dans $\R^n$.
%Une question qui se pose alors est de trouver un estimateur optimal
%par rapport \`a ce crit\`ere de risque. Comme il n'existe pas
%d'estimateur $\hat\theta$ ayant le risque $R(\hat\theta, \theta)$
%minimal pour tout $\theta$ (voir la Section 6.2.1 du cours), la
%d\'efinition valide de l'optimalit\'e repose sur le passage du
%risque ponctuel $R(\hat\theta, \theta)$ au risque maximal
%$${\cal R}^*(\hat\theta)=\sup_{\theta\in\Theta}R(\hat\theta,
%\theta).
%$$
%On dit que l'estimateur $\tilde \theta$ est {\it optimal au sens
%minimax sur} $\Theta$  (ou, pour abr\'eger, $\tilde \theta$ est un
%{\it estimateur minimax sur} $\Theta$), si
%$${\cal R}^*(\tilde\theta)=\min_{\hat\theta}{\cal R}^*(\hat\theta)=
%\min_{\hat\theta}\sup_{\theta\in\Theta}R(\hat\theta, \theta),
%$$
%o\`u $\min_{\hat\theta}$ d\'esigne le minimum sur tous les
%estimateurs. La valeur
%$$\min_{\hat\theta}\sup_{\theta\in\Theta}R(\hat\theta, \theta)$$
%s'appelle {\it risque minimax sur} $\Theta$.
%
%Bien \'evidemment, la forme de l'estimateur minimax d\'epend de
%l'ensemble $\Theta$. L'objectif de ce projet est de trouver les
%estimateurs minimax (ou asymptotiquement minimax quand $n\to\infty$)
%pour quelques exemples importants de $\Theta$ dans le mod\`ele
%gaussien basique :
%\begin{equation}\label{1}
%X_i= \theta_i +\xi_i, \quad i=1,\dots,n,
%\end{equation}
%o\`u $\theta_1,\dots,\theta_n$ sont les coordonn\'ees de $\theta$ et
%$\xi_1,\dots,\xi_n$ sont des variables gaussiennes i.i.d. de moyenne
%0 et de variance $\sigma^2>0$.
%
%L'analyse de l'optimalit\'e au sens minimax s'appuie sur la notion
%de risque de Bayes. Le risque de Bayes de l'estimateur $\hat\theta$
%est d\'efini par
%$$
%{\cal R}^{B}(\hat \theta)=\int_{\Theta}R(\hat\theta, \theta)\,
%\pi(d\theta),
%$$
%o\`u $\pi$ est une mesure de probabilit\'e sur $\Theta$ appel\'ee
%loi a priori de $\theta$. Il est utile de noter que
%\begin{equation}\label{2}
%{\cal R}^*(\hat \theta) \ge {\cal R}^{B}(\hat \theta)
%\end{equation}
% pour tout
%estimateur $\hat\theta$ et toute loi a priori $\pi$. L'estimateur
%$\hat \theta^B$ qui fournit le minimum du risque de Bayes parmi tous
%les estimateurs s'appelle estimateur de Bayes.\\
%
%\medskip
%
%{\bf Question 1.} On s'int\'eressera d'abord \`a la forme de
%l'estimateur de Bayes pour une famille $(\PP_{\theta},
%\theta\in\Theta)$ g\'en\'erale. Pour abr\'eger les notations, on
%peut consid\'erer $\theta$ comme une variable al\'eatoire de loi
%$\pi$, $\PP_{\theta}$ comme la loi conditionnelle de $X$ sachant
%$\theta$ et le risque de Bayes comme l'esp\'erance de
%$\|\hat\theta(X)- \theta\|^2/n$ par rapport \`a la loi jointe de
%$(X,\theta)$. Montrez que l'on peut alors \'ecrire l'estimateur de
%Bayes sous la forme : $\hat \theta^B=
%\EE(\theta|X)=(\EE(\theta_1|X),\dots,\EE(\theta_n|X))$, i.e., $\hat
%\theta^B$ est l'esp\'erance de la loi conditionnelle de $\theta$
%sachant $X$, dite "loi a posteriori" de~$\theta$.
%
%\medskip
%
%Nous allons supposer dans la suite que $\PP_\theta$ est engendr\'e
%par les observations gaussiennes~(\ref{1}). Consid\'erons d'abord le
%cas o\`u il n'y a aucune contrainte sur $\theta$, i.e.,
%$\Theta=\R^n$.
%
%\medskip
%
%{\bf Question 2.} Soit $\Theta=\R^n$ et soit $\pi$ la loi gaussienne
%sur $\R^n$ de moyenne 0 et de matrice de covariance diagonale, avec
%les \'el\'ements diagonaux $\sigma_i^2>0$, $i=1,\dots,n$. Explicitez
%l'estimateur de Bayes $\hat \theta^B$ ainsi que la valeur minimale
%du risque de Bayes ${\cal R}^{B}(\hat \theta^B)$.
%
%\medskip
%
%{\bf Question 3.} Montrez que l'estimateur $\tilde\theta=X$ est
%minimax sur $\Theta=\R^n$. On cherchera d'abord le risque ${\cal
%R}^*(X)$, puis on le comparera avec la valeur minimale du risque de
%Bayes calcul\'ee dans la question pr\'ec\'edente pour
%$\sigma_i^2=A$, $\forall \ i$.
%
%
%\medskip
%
%{\bf Question 4.} Consid\'erons maintenant l'ensemble des
%param\`etres
%$$\Theta=\Theta_0\triangleq \Big\{\theta \in \R^n: \
%\theta_1=\theta_2=\cdots=\theta_n\Big\}.
%$$
%Dans ce cas, le mod\`ele (\ref{1}) devient le mod\`ele de
%$n$-\'echantillon de la loi ${\cal N}(a,\sigma^2)$, o\`u $a\in \R$
%est le seul param\`etre inconnu ($\theta_i=a$, $i=1,\dots,n$).
%Montrez que ${\bar X}_n$, la moyenne arithm\'etique des $X_i$, est
%un estimateur minimax de $a$ par rapport au risque quadratique usuel
%sur $\R$. Par cons\'equent, $\tilde\theta=({\bar X}_n, \dots, {\bar
%X}_n)$ est un estimateur minimax sur $\Theta_0$ pour le
%mod\`ele~(\ref{1}).
%
%\medskip
%
%Finalement, consid\'erons l'ensemble des param\`etres qui est une
%boule euclidienne dans $\R^n$ :
%$$\Theta=\Theta(Q)\triangleq \Big\{\theta \in \R^n: \
%\frac1n\|\theta\|^2 \le Q\Big\},
%$$
%o\`u $Q>0$ est une constante donn\'ee. Il s'av\`ere que l'estimateur
%$X$ n'est pas minimax sur $\Theta(Q)$. De plus, la forme de
%l'estimateur minimax sur $\Theta(Q)$ n'est connue que pour des
%valeurs particuli\`eres de $Q$. Par contre, il est possible de
%construire un estimateur qui est minimax parmi les estimateurs
%lin\'eaires et asymptotiquement minimax parmi tous les estimateurs,
%au sens qui sera pr\'ecis\'e dans la suite.
%
%\medskip
%
%{\bf Question 5.} Introduisons une famille des estimateurs
%lin\'eaires $(\hat \theta(\lambda), \lambda\in \R)$ d\'efinie par
%$\hat \theta_i(\lambda)=\lambda X_i$, $i=1,\dots,n$, o\`u $\hat
%\theta_i(\lambda)$ est la $i$\`eme coordonn\'ee de $\hat
%\theta(\lambda)$. Explicitez {\it l'estimateur minimax lin\'eaire}
%sur $\Theta(Q)$, i.e., l'estimateur $\hat \theta(\lambda^*)$ tel que
%$$
%\sup_{\theta\in\Theta(Q)}R(\hat\theta(\lambda^*), \theta)=
%\min_{\lambda\in \R}\sup_{\theta\in\Theta(Q)}R(\hat\theta(\lambda),
%\theta)\triangleq {\cal R}_{\rm Lin}^*(Q)
%$$
%et montrez que le {\it risque minimax lin\'eaire} ${\cal R}_{\rm
%Lin}^*(Q)$ vaut $\frac{Q\sigma^2}{Q+\sigma^2}$.
%
%\medskip
%
%{\bf Question 6.} Montrez que, pour tout estimateur $\hat \theta$,
%il existe un estimateur $\hat \theta'$ \`a valeurs dans $\Theta(Q)$,
%tel que $R(\hat\theta, \theta) \ge R(\hat\theta', \theta)$, $\forall
%\theta \in \Theta(Q)$. En d\'eduire qu'il suffit de consid\'erer le
%risque minimax pour les estimateurs \`a valeurs dans $\Theta(Q)$ :
%$$
%\inf_{\hat\theta}\sup_{\theta\in\Theta(Q)}R(\hat\theta, \theta)=
%\inf_{\hat\theta\in \Theta(Q)}\sup_{\theta\in\Theta(Q)}R(\hat\theta,
%\theta).
%$$
%
%\medskip
%
%{\bf Question 7.} ({\it Cette question est facultative.}) Montrez la
%minoration asymptotique du risque minimax :
%$$
%\liminf_{n\to\infty} \
%\inf_{\hat\theta}\sup_{\theta\in\Theta(Q)}R(\hat\theta, \theta) \ge
%\frac{Q\sigma^2}{Q+\sigma^2}\,.
%$$
%{\it Indication :} utilisez la Question 6 et la minoration par le
%risque de Bayes avec la loi a priori $\pi$ d\'efinie dans la
%Question 1 et $\sigma_i^2= \delta Q$, $\delta\in ]0,1[$,
%$i=1,\dots,n.$ Le point d\'elicat est que le support de cette loi
%n'est pas \'egal \`a $\Theta(Q)$, donc on ne peut pas appliquer
%(\ref{2}) directement.
%
%
%\medskip
%
%{\bf Question 8.} D\'eduire de ce qui pr\'ec\`ede que l'estimateur
%minimax lin\'eaire $\hat \theta(\lambda^*)$ est aussi {\it
%asymptotiquement} minimax sur $\Theta(Q)$ parmi {\it tous} les
%estimateurs en ce sens que
%$$
%\lim_{n\to\infty}\frac{
%\sup_{\theta\in\Theta(Q)}R(\hat\theta(\lambda^*),\theta)}
%{\inf_{\hat\theta}\sup_{\theta\in\Theta(Q)}R(\hat\theta, \theta)}=1.
%$$
%
%\bigskip
%
%Un grand d\'efaut de l'estimateur minimax lin\'eaire $\hat
%\theta(\lambda^*)$ est ce qu'il d\'epend du rayon~$Q$ qui est
%g\'en\'eralement inconnu dans la pratique. Cependant, de fa\c{c}on
%remarquable, il existe des estimateurs qui ne dependent pas de $Q$
%et qui sont asymptotiquement minimax sur $\Theta(Q)$ parmi tous les
%estimateurs {\it simultan\'ement pour tous $Q>0$}. De tels
%estimateurs sont appel\'es {\it adaptatifs} sur l'\'echelle des
%ensembles $\{\Theta(Q), Q>0\}$. Notre objectif est maintenant  de
%mettre en \'evidence le fait que l'estimateur de Stein
%$$
%\hat\theta_S = \left(1-\frac{n\sigma^2}{\|X\|^2}\right) X
%$$
%est adaptatif.
%
%
%\medskip
%
%{\bf Question 9.} A l'aide du Lemme de Stein, montrez que pour tout
%$\theta\in\R^n$,
%\begin{equation}\label{3}
%\EE_{\theta} \|\hat\theta_S - \theta\|^2 \le n\sigma^2 - \beta
%\EE_{\theta}\left( \|X\|^{-2}\right)
%\end{equation}
%avec la constante $\beta>0$ que l'on pr\'ecisera. Transformez
%(\ref{3}) en :
%\begin{equation}\label{4}
%\EE_{\theta} \|\hat\theta_S - \theta\|^2 \le
%\frac{n\sigma^2\|\theta\|^2 + 4 n\sigma^4}{\|\theta\|^2 +
%n\sigma^2}\,.
%\end{equation}
%D\'eduisez de (\ref{4}) et de ce qui pr\'ec\`ede que l'estimateur de
%Stein est adaptatif sur l'\'echelle $\{\Theta(Q), Q>0\}$ :
%$$
%\forall \ Q>0 \ : \quad \lim_{n\to\infty}\frac{
%\sup_{\theta\in\Theta(Q)}R(\hat\theta_S,\theta)}
%{\inf_{\hat\theta}\sup_{\theta\in\Theta(Q)}R(\hat\theta, \theta)}=1.
%$$
%L'estimateur $\hat\theta_S$ est-il minimax ou asymptotiquement
%minimax sur $\Theta=\R^n$?
%
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\tt \noindent \'Ecole
  Polytechnique}
\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \bf Projet 8:
Facteurs pr\'edictifs du diab\`ete par  Lasso et Elastic-Net  }
\bigskip \hrule height .5pt
\bigskip
\begin{center} {responsable: Christophe Giraud {\sf
(christophe.giraud@polytechnique.edu)}}
\end{center}

\bigskip
{\bf Mots clefs: s\'election de variables, estimateur Lasso, estimateur Elastic-Net, Cross-Validation, optimisation convexe.}\medskip

L'objectif de ce projet est d'analyser les facteurs pr\'edictifs  du diab\`ete \`a partir  de donn\'ees physiologiques et s\'erologiques de  $n=442$ patients souffrant du diab\`ete. La variable $y$ refl\`ete la progression de la maladie et les $p=64$ variables explicatives $x^{(1)},\ldots,x^{(64)}$ d\'ecrivent l'\^age, le sexe, l'indice de masse corporel, diverses mesures s\'erologique, etc.
L'objectif est double:
\begin{enumerate}
\item[(a)] parvenir \`a pr\'edire $y$ \`a partir des diff\'erentes mesures $x^{(1)},\ldots,x^{(64)}$,
\item[(b)] s\'electionner les variables $x^{(j)}$ influentes pour pr\'edire $y$.
\end{enumerate}
{\bf Les donn\'ees} sont \`a t\'el\'echarger
\begin{itemize}
\item[] $Y$ : \ {\tt http://www.cmap.polytechnique.fr/$\sim$giraud/MAP433/Y.txt}
\item[] $X$ : \ {\tt http://www.cmap.polytechnique.fr/$\sim$giraud/MAP433/X.txt}
\end{itemize}

{\bf Travail \`a rendre} par courriel  \`a christophe.giraud@polytechnique.edu \\*
Vous me rendrez  un rapport au format pdf comprenant \smallskip

\quad - les codes que vous avez utilis\'e (en int\'egralit\'e), \smallskip

\quad - les sorties de votre code (r\'esultats num\'eriques, graphiques, etc), \smallskip

\quad - les r\'eponses (concises mais compl\`etes) aux questions pos\'ees.
\bigskip


{\bf Le mod\`ele}\\*
Nous allons consid\'erer le mod\`ele lin\'eaire:
$$y_{i}=\beta_{1}x_{i}^{(1)}+\ldots,\beta_{64} x_{i}^{(64)}+\eps_{i},\quad i=1,\ldots,n.$$
En notant $Y$ le vecteur d'entr\'ees $y_{i}$, $\beta$ le vecteur d'entr\'ees $\beta_{j}$ et $X$ la matrice $n\times p$ de lignes $X[i,]=[x_{i}^{(1)},\ldots,x_{i}^{(64)}]$, le mod\`ele pr\'ec\'edent est \'equivalent \`a $Y=X\beta+\eps$.


\section{Partie pr\'eliminaire}
\begin{enumerate}
\item[{\bf N1.}] Les variables sont-elles centr\'ees? r\'eduites? Les variables explicatives sont-elle corr\'el\'ees?
\item[{\bf T1.}] On note $\hat \beta_{OLS}$ l'estimateur de $\beta$ obtenu en minimisant
$\hat \beta_{OLS}=\rm{arg}\!\min_{\beta}\|Y-X\beta\|^2.$
Montrez que $\hat \beta_{OLS}=(X^TX)^{-1}X^TY$.
\item[{\bf N2.}] Calculez $\hat \beta_{OLS}$ num\'eriquement. Quelles variables semblent les plus importantes?
\end{enumerate}

\section{Estimateur Lasso}
L'estimateur Lasso est obtenu comme solution du probl\`eme de minimisation:
\begin{equation}\label{lasso}
\hat\beta^{\lambda}=\textrm{arg}\!\min_{\beta}F_{\lambda}(\beta) \quad \textrm{o\`u }\quad F_{\lambda}(\beta)={1\over 2}\|Y-X\beta\|^2+\lambda\sum_{j=1}^p|\beta_{j}|\quad\textrm{pour }\lambda> 0.
\end{equation}
On notera $X_{j}$ la $j$-i\`eme colonne de $X$ et on supposera pour simplifier que $X_{j}^TX_{j}=1$ pour $j=1,\ldots,p$.

\subsection{Propri\'et\'es \'el\'ementaires}
\begin{enumerate}
\item[{\bf T2.}] Quelle propri\'et\'e caract\'eristique poss\`ede la fonction $F_{\lambda}$? Supposons que le rang de $X$ est \'egal \`a $p$. La fonction $F_{\lambda}$ atteint-elle son minimum? est-il unique?
\item[{\bf T3.}] Montrer que
\[{\partial\over \partial \beta_{j}}F_{\lambda}(\beta)=
-X_{j}^T(Y-X\beta)+\lambda{\beta_{j}\over |\beta_{j}|}\quad\textrm{pour tout}\ \beta_{j}\neq 0.\]
\item[{\bf T4.}] En d\'eduire une valeur $\lambda_{\max}$ telle que si $\hat\beta^{\lambda}=0$ alors $\lambda\geq \lambda_{\max}$. R\'eciproque (facultatif)?
\end{enumerate}
Dans les deux questions suivantes, nous supposerons  que $X^TX=I_{p}$ o\`u $I_{p}$ est la matrice identit\'e.
\begin{enumerate}
\item[{\bf T5.}]  Que vaut $\hat\beta^{\lambda}$ dans ce cas? Quelles variables sont s\'electionn\'ees (variables $j$ telles que $\hat\beta^\lambda_{j}\neq 0$)?
\item[{\bf T6.}] Supposons que les $\eps_{i}$ sont i.i.d. de loi $\mathcal{N}(0,\sigma^2)$. En utilisant la propri\'et\'e ${\bf P}(\xi \geq x)\leq e^{-x^2/2}$ pour $\xi$ de loi $\mathcal{N}(0,1)$ et  $x>0$, montrez que la probabilit\'e que l'ensemble des variables s\'electionn\'ees par $\hat \beta^{\sqrt{\alpha\sigma^2\log(p)}}$ ne soit pas inclus dans $\{j : \beta_{j}\neq 0\}$
 est inf\'erieure \`a $2p^{-(\alpha/2-1)}$ pour $\alpha>2$.
\end{enumerate}

\subsection{Calcul de l'estimateur Lasso}
Dans le cas g\'en\'eral o\`u $X^TX\neq I_{p}$, il n'y a pas de formule explicite pour $\hat \beta^{\lambda}$. On peut cependant calculer efficacement $\hat \beta^{\lambda}$ avec un algorithme tr\`es simple.
\begin{enumerate}
\item[{\bf T7.}] Soit $\beta\in{\bf R}^p$ et $\beta^{(j)}$ d\'efini par $\beta^{(j)}_{k}=\beta_{k}$ si $k\neq j$ et
\[\beta^{(j)}_{j}=R_{j}\left(1-{\lambda \over |R_{j}|}\right)_{+}
\quad\mathrm{avec }\ \ R_{j}=X_{j}^T\bigg(Y-\sum_{k\neq
j}\beta_{k}X_{k}\bigg).\] Montrer que $F_{\lambda}(\beta^{(j)})\leq
F_{\lambda}(\beta)$ avec in\'egalit\'e stricte si $\beta^{(j)}\neq\beta$.
\item[{\bf T8.}] En d\'eduire un algorithme de minimisation num\'erique  de $F_{\lambda}$. Vaut-il mieux impl\'ementer cet algorithme avec un langage compil\'e ou un langage interpr\'et\'e? Quelle est la nature du langage que vous avez utilis\'e?
\item[{\bf N3.}] Calculez $\hat\beta^{\lambda}$ pour tout  $\lambda\in\Lambda=\{k\lambda_{\max}/10^3: k=1,\ldots,10^3\}$. On pourra proc\'eder comme suit: on commencera par les plus grandes valeurs de $\lambda$ et pour calculer $\hat\beta^{k\lambda_{\max}/10^3}$ on initialisera l'algorithme avec $\hat\beta^{(k+1)\lambda_{\max}/10^3}$ (cela permet un net gain en temps de calcul).
\item[{\bf N4.}] Tracez pour chaque $j$ la valeur de $\hat \beta^{\lambda}_{j}$ en fonction de $\lambda$ (vous pouvez superposer les courbes sur un m\^eme graphique \`a l'aide de diff\'erentes couleurs). Qu'observez-vous?
\end{enumerate}

\section{Cross-Validation}
L'objectif de cette partie est de s\'electionner la "meilleure" valeur $\lambda\in\Lambda$ pour pr\'edire $y$ \`a l'aide de  $\sum_{j}\hat\beta^{\lambda}_{j}x^{(j)}$. Plus pr\'ecis\'ement, si $y_{new}, x^{(j)}_{new}$ sont de nouvelles observations, on aimerait choisir le $\lambda_{*}$ qui donne en moyenne le plus petit r\'esidu $(y_{new}-\sum_{j}\hat\beta^{\lambda}_{j}x_{new}^{(j)})^2$. Ce $\lambda_{*}$ est inconnu, mais on peut essayer de l'estimer \`a l'aide de la $K$-fold cross-validation. 

Le principe est le suivant: pour $k=1,\ldots,K$ on note $I_{k}=\{1+(k-1)n/K ,\ldots,kn/K \}$ et $I_{-k}=\{1,\ldots,n\}\setminus I_{k}$.
On calcule les estimateurs Lasso  $\hat \beta^{\lambda:k}$ en se restreignant aux observations pour les individus d'indice $i$ dans $I_{-k}$. Autrement dit, en notant $X[I_{-k},]$ la matrice obtenue en ne conservant que les lignes d'indice dans $I_{-k}$, l'estimateur 
$\hat \beta^{\lambda:k}$ est solution de~(\ref{lasso}) avec $Y$ remplac\'e par $Y[I_{-k}]$ et $X$ remplac\'e par 
$X[I_{-k},]$. La performance de l'estimateur $\hat \beta^{\lambda}$ est alors estim\'ee par
\[ \mathcal{R}(\lambda)={1\over K}\sum_{k=1}^K\big\|Y[I_{k}]-X[I_{k},]\hat\beta^{\lambda:k}\big\|^2,\quad \textrm{pour }\lambda\in\Lambda\]
et l'estimateur cross-valid\'e est d\'efini par $\hat\beta^{CV}=\hat\beta^{\hat \lambda}$ o\`u $\hat \lambda$ est un minimiseur de  $\mathcal{R}(\lambda)$ sur $\Lambda$.
\begin{enumerate}
\item[{\bf N5.}] Calculez l'estimateur  $\hat\beta^{CV}$ pour $K=13$. Que vaut $\mathcal{R}(\hat \lambda)$?
\item[{\bf N6.}] Quelles sont les variables s\'electionn\'ees? Comparez ce r\'esultat \`a celui obtenu avec $\hat \beta_{OLS}.$
\end{enumerate}

\section{Elastic-Net}
Lorsque les variables $x^{(j)}$ pr\'esentent de fortes corr\'elations, il est souhaitable de modifier un peu l'estimateur Lasso. Par exemple, on peut modifier le probl\`eme de minimisation comme suit (Elastic-net): pour $\lambda> 0,\mu\geq 0$
\begin{equation}\label{enet}
\hat\beta^{\lambda,\mu}=(1+\mu)\times\textrm{arg}\!\min_{\beta}F_{\lambda,\mu}(\beta) \quad \textrm{o\`u }\quad F_{\lambda,\mu}(\beta)={1\over 2}\|Y-X\beta\|^2+{1\over 2}\mu\|\beta\|^2+\lambda\sum_{j=1}^p|\beta_{j}|.
\end{equation}

\begin{enumerate}
\item[{\bf T9.}] Que dire de la fonction $F_{\lambda,\mu}$?
 En vous inspirant de la Partie 2, proposez un algorithme pour r\'ealiser la minimisation $\textrm{arg}\!\min_{\beta}F_{\lambda,\mu}(\beta)$.
\item[{\bf N7.}] Pour chaque $\mu\in\{0,0.01,0.02,0.05,0.1,1\}$, tracez les valeurs de $\hat \beta^{\lambda,\mu}_{j}$ en fonction de $\lambda\in\Lambda$. 
\item[{\bf N8.}] Calculez l'estimateur cross-valid\'e $\hat\beta^{\hat\lambda,\hat\mu}$ en faisant varier  $\mu$ dans 
$$\{0,0.01,0.02,0.05,0.1,1\}$$ et $\lambda$ dans $\Lambda$. Quelles sont les variables s\'electionn\'ees? 
 Que vaut le risque $\mathcal{R}(\hat \lambda,\hat \mu)$? a-t-on un gain comparativement au Lasso?
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
%  \noindent Ecole Polytechnique}\hfill{\tt Ann\'ee 2012-2013}
%\hfill{\tt MAP  433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 13 : Estimation de variance par Bootstrap} } \bigskip
%\hrule height .5pt \bigskip
%\begin{center} {responsable: Marc Hoffmann {\sf (hoffmann@ceremade.dauphine.fr)}}
%\vspace{0.5cm}
%\end{center}
%%\begin{center}
%%{\large{\bf Version pr\'eliminaire !}}
%%\begin{center}
%%{\large{\bf Corrig\'e succint}}
%%\end{center}
%
%%\end{center}
%\bigskip
%
%
%\section{Introduction}
%%Lorsque l'on veut estimer une quantit\'e d'int\'erêt \`a l'aide de plusieurs observations entach\'ees d'erreurs exp\'erimentales, il est classique de mod\'eliser le probl\`eme par 
%On considére le probléme de {\it l'estimation d'un param\`etre de translation} $\vartheta \in \mathbb{R}$ \`a partir de l'observation de (la r\'ealisation de) $n$ variables al\'eatoires ind\'ependantes et identiquement distribu\'ees $(X_1,\ldots, X_n)$ de loi commune
%$$\mathbb{P}[X_1 \in A] = \int_A g(x-\vartheta)dx,$$
%pour tout ensemble bor\'elien $A$ de $\mathbb{R}$, et
%o\`u $x \leadsto g(x)$ est une densit\'e de probabilit\'e {\it inconnue} v\'erifiant :
%$$\int_{\mathbb{R}}xg(x)dx=0,\;\;v^2=\int_{\mathbb{R}}x^2g(x)dx<+\infty.$$
%
%Un estimateur naturel de $\vartheta$ est la moyenne empirique $\bar X_n=\tfrac{1}{n}\sum_{i=1}^nX_i$. On \'etudie dans ce projet la {\it pr\'ecision d'estimation} de $\bar X_n$, en particulier lorsque $n$ n'est pas tr\`es grand, via la m\'ethode de Bootstrap, introduite par Efron en 1979.
%
%\section{Comportement asymptotique de la variance empirique}
%On \'etudie dans cette section le contrôle classique de la pr\'ecision d'estima\-tion de $\bar X_n $ par le th\'eor\`eme central limite. Cette m\'ethode, tr\`es g\'en\'erale, comporte toutefois l'inconv\'enient de n'être parfaitement justifi\'ee que dans la limite $n \rightarrow \infty$.
%\begin{itemize}
%\item[{\bf 1.}] Rappeler pourquoi l'approximation suivante est valable :
%$$\vartheta = \bar X_n + \frac{v}{\sqrt{n}}\xi_n,$$
%o\`u, pour tout $x \in \mathbb{R}$, 
%$$\lim_{n \rightarrow \infty}\mathbb{P}[\xi_n \leq x] = \Phi(x)=\int_{-\infty}^x e^{-u^2/2}\frac{du}{\sqrt{2\pi}}.$$
%et que pour tout $\alpha \in (0,1)$, en posant 
%$$I_{n,\alpha}(v)=\left[\bar X_n -\frac{v}{\sqrt{n}}\Phi^{-1}(1-\alpha/2),\bar X_n +\frac{v}{\sqrt{n}}\Phi^{-1}(1-\alpha/2)\right],$$
%on a
%\begin{equation} \label{covering}
%\lim_{n \rightarrow \infty}\mathbb{P}[\vartheta \in I_{n,\alpha}(g)]=1-\alpha
%\end{equation}
%%et interpr\'eter\footnote{En particulier, 
%Il est int\'eressant de noter que le nombre d'observations $n$ et le niveau de risque $\alpha$ sont des quantit\'es antagonistes, dans le sens o\`u il faut augmenter $n$ si l'on veut diminuer $\alpha$ tout en pr\'eservant la même pr\'ecision d'estimation. Toutefois, $\Phi^{-1}(1-\alpha/2)$ et $1/\sqrt{n}$ sont dans des \'echelles diff\'erentes lorsque $n \rightarrow \infty$ et $\alpha \rightarrow 0$ : on pourra pour s'en convaincre calculer un \'equivalent de $\Phi^{-1}(1-\alpha/2)$ et commenter ce r\'esultat. Indication\-: utiliser $x/(1+x^2) \geq 1/2x$ lorsque $x \geq 1$ et en d\'eduire $1-\Phi(x) \geq \tfrac{e^{-x^2/2}}{2x\sqrt{2\pi}}$.\\
%
%%\noindent {\it \underline{Corrig\'e} : on \'ecrit le th\'eor\`eme central-limite. Concernant la comparaison des ordres de grandeurs $1/\sqrt{n}$ et $\Phi^{-1}(1-\alpha/2)$ lorsque $\alpha \rightarrow 0$. On a, de fa\c con \'el\'ementaire
%%$$
%%\begin{array}{lll}
%%1-\Phi(x)& =&\displaystyle \int_x^\infty e^{-u^2/2}\frac{du}{\sqrt{2\pi}} \\ \\
%%&=  &\displaystyle  e^{-x^2/2}\int_0^\infty e^{-u^2/2}e^{-ux} \frac{du}{\sqrt{2\pi}}\\ \\
%%& \leq &\displaystyle  e^{-x^2/2}\int_0^\infty e^{-u^2/2}
%%\frac{du}{\sqrt{2\pi}}=\frac{1}{2}e^{-x^2/2}.
%%\end{array}$$
%%Puisque $$1-\Phi(\Phi^{-1}[1-\alpha/2])=\frac{\alpha}{2},$$
%%on en d\'eduit que
%%$$\alpha \leq \exp(-\frac{1}{2}\Phi^{-1}(1-\alpha/2)^2),$$
%%d'o\`u :
%%$$\Phi^{-1}(1-\alpha/2)\leq \sqrt{2\log\frac{1}{\alpha}}.$$
%%D'autre part, 
%%$$\begin{array}{lcl}
%%1-\Phi(x) & \geq & \displaystyle \int_{x}^\infty \frac{x^2}{u^2}e^{-u^2/2}
%%\frac{du}{\sqrt{2\pi}} \\ \\
%% & \stackrel{\text{par parties}}{=} & \displaystyle
%%\frac{x^2}{\sqrt{2\pi}}\left(x^{-1}e^{-x^2/2}-\int_x^\infty e^{-u^2/2}du\right) \\ \\
%%& = & \frac{x}{\sqrt{2\pi}} e^{-x^2/2} -x^2[1-\Phi(x)].
%%\end{array}$$
%%Soit $x\geq 1$. Alors $x/(1+x^2)\geq 1/2x$ et donc 
%%$$1-\Phi(x) \geq \frac{e^{-x^2/2}}{2x\sqrt{2\pi}}.$$
%%Il vient
%%$$
%%\begin{array}{lll}
%%1-\Phi[\Phi^{-1}(1-\alpha/2)] &  = &\displaystyle \frac{\alpha}{2} \\ \\
%% & \geq &\displaystyle 
%%\frac{\exp(-\frac{1}{2}\Phi^{-1}(1-\alpha/2)^2)}{2\Phi^{-1}(1-\alpha/2)\sqrt{2\pi}}
%%\\
%%\\ & \geq &\displaystyle\frac{1}{2\sqrt{2\pi}}
%%\frac{\exp(-\frac{1}{2}\Phi^{-1}(1-\alpha/2)^2)}{\sqrt{2
%%\log \frac{1}{\alpha}}},
%%\end{array}$$
%%puisque $\Phi^{-1}(1-\alpha/2)\leq \sqrt{2\log\frac{1}{\alpha}}$ comme on l'a vu
%%pr\'ec\'edemment. Posons
%%$$r(\alpha):=2 \cdot \sqrt{\pi \log\frac{1}{\alpha}}.$$
%%Alors
%%$$\sqrt{2\log \frac{1}{\alpha r(\alpha)}} \leq \Phi^{-1}(1-\alpha/2).$$
%%}
%
%\item[{\bf 2.}] Cependant, $v$ n'est pas connu. Montrer qu'en posant 
%$V_n=\frac{1}{n}\sum_{i=1}^n \big(\bar X_n-X_i\big)^2$
%alors on a encore le r\'esultat de la question ${\bf 1}$ en remplaçant $I_{n,\alpha}(v)$ par 
%$I_{n,\alpha}(V_n^{1/2})$.\\
%
%%\noindent {\it \underline{Corrig\'e :} Il suffit de montrer $V_n \rightarrow v^2$ en probabilit\'e. Le r\'esultat suivra du r\'esultat plus g\'en\'eral : si $X_n \rightarrow X$ en loi et $Y_n \rightarrow y$ o\`u $y$ est une constante, alors le couple $(X_n,Y_n)$ converge en loi vers $(X,y)$. Pour montrer la convergence de $V_n$ vers $v^2$, le plus simple est encore de remarquer que
%%$$V_n=\frac{1}{n}\sum_{i=1}^n X_i^2 - \big(\frac{1}{n}\sum_{i=1}^n X_i\big)^2.$$
%%%\big[(\xi_i-\frac{1}{\sqrt{}})\big]$
%%On applique alors la loi des grands nombre s\'epar\'ement aux deux termes, et on a la convergence vers
%%$v^2+\vartheta^2 - \vartheta^2=v^2$.}
%
%\end{itemize}
%\section{Le r\'e-\'echantillonnage par Bootstrap}
%On va maintenant s'int\'eresser \`a la pr\'ecision effective (sur des simulations) de cette approche lorsque $n$ n'est pas trop grand, et pr\'esenter une m\'ethode alternative par r\'e-\'echantillonnage tr\`es efficace, que l'on cherche\-ra \`a justifier partiellement.\\
%
%Notons $E_n=\{X_1(\omega),\ldots, X_n(\omega)\}$ l'ensemble de valeurs des observations de l'\'echantillon\footnote{On v\'erifiera qu'avec probabilit\'e $1$, tous les $X_i$ prennent des valeurs diff\'erentes.}. Soit $\mathbb{Q}_n$ la mesure uniforme qur $E_n$ (il s'agit donc d'une mesure de probabilit\'e qui d\'epend de la r\'ealisation $\omega$ de l'\'echantillon). A l'aide d'un ordinateur, on peut simuler de nouvelles {\it pseudo-observations}
%$$X_1^\star, X_2^\ast,\ldots, X_M^\ast$$ 
%ind\'ependantes et identiquement distribu\'ees, de loi ${\mathbb Q}_n$. Le gain est que l'on peut choisir $M$ et esp\'erer fabriquer de nouvelles observations $X_i^\star$ dont le comportement typique est celui d'une observation de l'\'echantillon initial $(X_1,\ldots, X_n)$.
%\begin{itemize}
%\item[{\bf 3.}] Montrer que si $x \leadsto h(x)$ est une fonction r\'eguli\`ere, on a
%$$\frac{1}{M}\sum_{j=1}^M h(X_j^\ast) \approx {\mathbb{E}}_{{\mathbb Q}_n}\big[h(X_1^\star)\big]  = \frac{1}{n}\sum_{i=1}^nh(X_i)\approx \int_{\mathbb{\mathbb{R}}}h(x)g(x-\vartheta)dx,
%$$
%o\`u l'on pr\'ecisera le sens de ces approximations lorsque $M$ et $n$ sont grands, et, dans la mesure du possible, l'ordre de grandeur de l'erreur. 
%
%%\noindent {\it \underline{Corrig\'e} : On applique deux fois la loi des grands nombres, une premi\`ere fois sur ``l'espace des simulations" et une deuxi\`eme fois sur l'espace de probabilit\'e initial.
%%Concernant la pr\'ecision d'estimation, on a, si $U_1,\ldots, U_m$ sont des variables al\'eatoires i.i.d. ayant un moment d'ordre deux
%%$$\mathbb{E}\big[\big(\frac{1}{m}\sum_{i=1}^m U_i\big)^2\big]^{1/2}=\frac{\sigma}{\sqrt{n}},$$
%%o\`u $\sigma^2$ d\'esigne la variance commune des $U_i$. En \'ecrivant correctement les variables sur un espace de probabilit\'e commun, et en conditionnant par rapport \`a la loi des $X_i$ dans un premier temps, on trouve une erreur born\'ee (dans le sens pr\'ec\'edent) par $\sup_x|h(x)|(M^{-1}+n^{-1})^{1/2}$.}
%%
%\item[{\bf 4.}] Choisir une densit\'e $x \leadsto g(x)$ et un se donner un param\`etre $\vartheta$ (par exemple $\vartheta=0$ que l'on va estimer). Ecrire un programme qui, \'etant donn\'e $g$ et $\vartheta$, simule une variable al\'eatoire de densit\'e $x\leadsto g(x-\vartheta)$.
%
%Pour $g$ on pourra choisir parmi les densit\'es classiques uniforme, exponentielle, gaussiennes, mais d'autres choix seront les bienvenus.
%\item[{\bf 5.}]
%Ecrire un programme ayant pour entr\'ee $\vartheta$, $g$, $n$ et $M$ qui
%\begin{itemize}
%\item[1] Simule un $n$-\'echantillon de variables al\'eatoires $X_i \sim g(x-\vartheta)dx$.
%\item[2] Simule, \`a partir de la mesure uniforme $\mathbb{G}_n$ un $n$-\'echantillon {\it Bootstrap} $(X_1^\ast,\ldots, X_n^\ast)$, et
%calcule
%$\bar X_{n}^\ast =\frac{1}{n}\sum_{j=1}^n X_j^\ast.$
%\item[3] R\'ep\`ete l'\'etape pr\'ec\'edente $M$ fois pour obtenir $M$ r\'eplications {\it Bootstrap} 
%$\bar X_{n,1}^\ast,\ldots, \bar X_{n,M}^\ast$.
%\item[4] Calcule la variance classique $V_n$ et la variance {\it Bootstrap} :
%$$V_{n,M}^{(boot)}=\frac{1}{M}\sum_{j=1}^M \big(\bar X_{n,j}^\ast-\frac{1}{M}\sum_{j'=1}^M \bar X_{n,j'}^\ast \big)^2$$ 
%et les compare.
%\end{itemize} 
%\item[{\bf 6.}] Pour plusieurs choix de $g$, entreprendre une \'etude syst\'ematique de la qualit\'e de pr\'ecision de la m\'ethode {\it Bootstrap} contre la m\'ethode empirique classique en fonction de $n$, $M$ et $\alpha$. 
%\end{itemize}
%On pourra faire plusieurs repr\'esentations graphiques de la {\it pr\'ecision} de la m\'ethode, c'est \`a dire la longueur de l'intervalle 
%$$I_{n,\alpha}(V_n^{1/2})\;\;\;\;\text{contre}\;\;\;\;I_{n,\alpha}\big((V_{n,M}^{(boot)})^{1/2}\big)$$ 
%en fonction de $n$ et $\alpha$.
%  
%\underline{Attention} : si la pr\'ecision d'une m\'ethode est meilleure qu'une autre mais que $\vartheta$ n'appartient pas \`a l'intervalle $I_{n,\alpha}$ correspondant, elle est de peu d'int\'erêt ! On r\'ep\`etera plusieurs fois les exp\'eriences en ``comptant" \`a chaque fois les cas o\`u la pr\'ecision est meilleure et o\`u la valeur inconnue est effectivement comprise dans l'intervalle $I_{n,\alpha}$ correspondant.
%
%\section{Bootstrap par percentile}
%Une alternative \`a la m\'ethode pr\'ec\'edente -qui se g\'en\'eralise dans de nombreuses autres situations- consiste \`a travailler directement sur la distribution empirique de l'estimateur par {\it Bootstrap} : \`a l'\'etape  3 de l'algorithme pr\'ec\'edent, on a construit une suite d'estimateurs de $\vartheta$ 
%$$\vartheta^\ast_{n,1},\ldots, \vartheta_{n,M}^\ast$$
%en posant $\vartheta_{n,j}^\ast = \bar X_{n,j}^\ast$ pour $j=1,\ldots, M$, et on peut aussi {\it directement} consid\'erer la fonction de r\'epartition empirique associ\'ee \`a la mesure uniforme sur  
%l'ensemble des valeurs $\vartheta^\ast_{n,j}$, c'est-\`a-dire la fonction
%$$x \in \mathbb{R} \leadsto F_{n,M}(x)=\frac{1}{M}\sum_{j=1}^M 1_{\{\vartheta_{n,j}^\ast \leq x\}} \in [0,1].$$
%C'est aussi la fonction de r\'epartition {\it typique} de la valeur d'un estimateur obtenu par r\'eplication {\it Bootstrap}. On peut d\'efinir la fonction de  quantile empirique (continue \`a gauche) :
%$$\alpha \in [0,1] \leadsto F_{n,M}^{-1}(\alpha)=\inf\{x \in \mathbb{R},\;\;F_{n,M}^{-1}(x) \geq \alpha\}.$$
%Pour $0 < \alpha < 1$, on d\'efinit l'intervalle de pr\'ecision de $\vartheta$ par percentile {\it bootstrap} comme
%$$I_{n,M, \alpha}^{(p-boot)} = \left[F_{n,M}^{-1}(\alpha/2), F_{n,M}^{-1}(1-\alpha/2)\right].$$ 
%\begin{itemize}
%\item[{\bf 7.}] Justifier une telle construction.
%
%%\noindent {\it \underline{Corrig\'e :} Par construction, si $\hat \vartheta$ est une variable al\'eatoire sur l'espace des simulations de loi $\mathbb{Q}_n$, on a 
%%$$
%%\mathbb{P}_{\mathbb{Q}_n}\big[\hat \vartheta \in I_{n,M, \alpha}^{(p-boot)}\big] = 1-\alpha.
%%$$
%%Le principe de la construction repose ensuite sur le fait que lorsque $M$ est grand, $\vartheta$ et $\hat \vartheta$ sont ``proches" au sens de la question {\bf T4}. On ``fait" l'approximation suivante :
%%$$\mathbb{P}_{\mathbb{Q}_n}\big[\hat \vartheta \in I_{n,M, \alpha}^{(p-boot)}\big] \approx \mathbb{P}\big[\vartheta \in I_{n,M,\alpha}^{(p-boot)}\big],$$
%%bien que formellement, la construction de $I_{n,M,\alpha}^{(p-boot)}$ fasse intervenir un al\'ea suppl\'ementaire\footnote{que l'on peut incorporer implicitement dans les notations.} Une justification rigoureuse et quantifi\'ee de ces approximations est un peu d\'elicate, et est l'objet de la question {\bf T10}.
%%}
%
%
%\item[{\bf 8.}] Comparer num\'eriquement les performances de l'intervalle par percentile {\it Bootstrap} relativement aux autres m\'ethodes.
%\item[{\bf 9.}] On suppose qu'il existe une transformation monotone $x \leadsto \rho(x)$ de sorte que $\rho(\bar X_n)$ soit une variable gaussienne de moyenne $\rho(\vartheta)$. Soit $U_{n,j}^\ast = \rho(\vartheta_{n,j}^\ast)$ pour $j=1,\ldots, M$ et
%$\alpha \leadsto Q_{n,M}^{-1}(\alpha)$ la fonction de quantile construite \`a partir des valeurs $\{\rho(\vartheta_{n,1}^\ast),\ldots,\rho(\vartheta_{n,M}^\ast)\}$. Montrer que
%$$\mathbb{P}\big[\vartheta \in I_{n,M,\alpha}^{(p-boot)}\big] = \mathbb{P}\big[Q_{n,M}^{-1}(\alpha/2) \leq \rho(\vartheta) \leq Q_{n,M}^{-1}(1-\alpha/2)\big]$$
%et en d\'eduire que dans ces conditions, on a un r\'esultat de type \eqref{covering} pour $I_{n,M,\alpha}^{(p-boot)}$.\\
%
%
%%\noindent {\it \underline{Corrig\'e :} Une transformation monotone pr\'eserve les quantiles empiriques, donc
%%$$Q_{n,M}^{-1}(\alpha) = \rho(F_{n,M}^{-1}(1-\alpha/2)\big),$$
%%et
%%\begin{align*}
%%\mathbb{P}\big[\vartheta \in I_{n,M,\alpha}^{(p-boot)}\big] & = \mathbb{P}\big[\rho(F_{n,M}^{-1}(\alpha/2)) \leq \rho(\vartheta)  \leq \rho\big(F_{n,M}^{-1}(1-\alpha/2)\big)\big] \\
%%& =  \mathbb{P}\big[Q_{n,M}^{-1}(\alpha/2) \leq \rho(\vartheta) \leq Q_{n,M}^{-1}(1-\alpha/2)\big].
%%\end{align*}
%%%Puisque $\rho(\bar X_n)$ est gaussienne de moyenne $\rho(\vartheta)$ (et de variance $c^2$), le quantile d'ordre $\alpha$ de $\rho(\bar X_n)$ est $\rho(\vartheta)-z_{\alpha}c$, o\`u $z_\alpha$ d\'esigne le quantile d'ordre $\alpha$ de la gaussienne standard. Donc : 
%%$$Q_{n,M}^{-1}(\alpha/2)=\rho(\bar X_n)-z_{\alpha/2}c,$$
%%et de même $Q_{n,M}^{-1}(1-\alpha/2)=\rho(\bar X_n)+z_{\alpha/2}c$.
%%Il vient
%%\begin{align*}
%%& \mathbb{P}\big[Q_{n,M}^{-1}(\alpha/2) \leq \rho(\vartheta) \leq Q_{n,M}^{-1}(1-\alpha/2)\big] \\ 
%%= &\mathbb{P}\big[\rho(\bar X_n)-cz_{\alpha/2} \leq \rho(\vartheta) \leq \rho(\bar X_n)+cz_{\alpha/2}\big]
%%\\ 
%%=&  \mathbb{P}\big[-z_{\alpha/2} \leq \tfrac{\rho(\bar X_n)-\rho(\vartheta)}{c} \leq z_{\alpha/2}\big] = 1-\alpha. 
%%\end{align*}
%
%%}
%\end{itemize}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
%  \noindent Ecole Polytechnique}\hfill{\tt Ann\'ee 2012-2013}
%\hfill{\tt MAP  433}\\
%\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 14 : Mod{\'e}lisation et
%    classification de textures} } \bigskip \hrule height .5pt \bigskip
%\begin{center} {responsable: Fran{\c c}ois Roueff {\sf (francois.roueff@telecom-paristech.fr)}}
%\vspace{0.5cm}
%\end{center}
%
%\noindent \textbf{Avertissement}: La bo{\^\i}te {\`a} outil \texttt{Stixbox} (pour octave, matlab ou scilab) peut s'av{\'e}rer
%utile  pour calculer les fonctions quantiles des lois utilis{\'e}es dans ce sujet de
%projet, voir
%
% \url{http://www.maths.lth.se/matstat/stixbox/Contents.html}
%
% Le but de ce projet est de mod\'eliser la distribution des diff\'erences (\`a
% distance fix{\'e}e) de niveaux de gris des images et d'utiliser cette mod{\'e}lisation
% pour {\'e}valuer la proximit{\'e} statistiques de 2 textures donn{\'e}es. Par souci de
% simplification, on se contentera en effet de comparer 2 images plut{\^o}t que de
% construire un classifieur {\`a} partir d'une base d'images, ce qui n{\'e}cessiterait
% d'aborder un probl{\`e}me de \emph{classification non--supervis{\'e}e}.
%
% Une image num\'erique \`a niveaux de gris est un signal discret bidimensionnel
% $(a(i,j))_{1\leq i \leq M, 1 \leq j \leq N}$, \`a valeurs dans un ensemble
% discret $\{1 \dots G\}$\footnote{Pour pouvoir effectuer des op\'erations sur
%   des images il faut souvent ``caster'' celle-ci en double precision par
%   exemple par la commande \com{a=double(a)}.}. Un tel signal est obtenu en
% ``chargeant'' une image dans un format reconnu par le logiciel utilis{\'e} (par exemple
% avec la commande \com{imread} en octave, matlab ou
% scilab). % Pour charger et voir l'image a.tif, utilisez les commandes \\
%% \com{a=imread('a.tif');}\\
%% \com{imagesc(a);}\\
%% \com{colormap gray;}\\
%% cette derni\`ere commande pr\'ecisant que les valeurs $a(i,j)$ correspondent
%% \`a des intensit\'es de gris (le minimum est le noir et le maximum le
%% blanc). 
%Si on part d'une image couleur, $a$ est une matrice
%tridimensionnelle que l'on peut transformer en une image \`a niveau de gris
%en moyennant les 3 couleurs.
%%\com{a(:,:)=(a(:,:,1)+a(:,:,2)+a(:,:,3))/3;}\\
%Par convention l'axe des
%$x$ est l'axe vertical, l'axe des $y$ l'horizontal, et le point
%$(0,0)$ est le point en haut \`a gauche de votre image. 
%
%
%Nous appelons \emph{sauts d'amplitude horizontaux et verticaux} (\`a distance 1) les quantit\'es
%$h(i,j)=a(i,j+1)-a(i,j)$ et 
%$v(i,j)=a(i+1,j)-a(i,j)$. % Pour obtenir les premiers, tapez par exemple:\\
%% \com{b=a(:,2:end)-a(:,1:end-1);}
%
%Une forte discontinuit\'e dans l'image provoque une r\'eponse importante,
%tandis qu'une zone homog\`ene provoque des r\'eponses petites en valeur
%absolue. Nous allons consid\'erer la distribution marginale de ces sauts, c'est
%\`a dire (dans le cas horizontal) supposer que chaque $h(i,j)$ est une
%r\'ealisation d'une variable al\'eatoire $H_{i,j}$, et que les $H_{i,j}$ sont
%identiquement distribu\'ees. Nous supposerons \'egalement (ce qui est
%clairement une simplification du probl\`eme) que les $H_{i,j}$ sont
%ind\'ependantes. Nous notons $X_k$ le r\'eordonnement des variables $H_{i,j}$
%sous forme d'un vecteur al\'eatoire \`a $P=M \times N$ \'el\'ements. On suppose
%donc $X_k$, $k=1,\dots,P$ sont i.i.d., et on note $X$ une v.a. al{\'e}atoire
%g{\'e}n{\'e}rique ayant m{\^e}me loi que les $X_k$.
%
%%  Ceci est effectu\'e
%% sur les donn\'ees sous matlab par la commande \com{reshape}.
%
%% Commencez par visualiser l'image des sauts d'amplitude (vous pouvez utiliser
%% les commandes \com{colormap jet} et \com{colorbar} apr\`es \com{imagesc(b)}), puis l'histogramme associ\'e \`a la variable $X$:\\
%% \com{hist(reshape(b,prod(size(b)),1),100);}
%
%% Qu'en pensez-vous ? 
%
%
%On trouvera une base
%d'images de texture au format \emph{tif} sur le site
%
%\url{http://sipi.usc.edu/database/database.php?volume=textures}
%
%\noindent On peut choisir une image de cette base ou toute autre image \emph{textur{\'e}e
%  suffisamment homog{\`e}ne} pour les questions des
%paragraphes~\ref{sec:model-gauss-sauts}
%et~\ref{sec:modelisation-laplacienne}.
%
%
%
%\section{Mod\'elisation gaussienne}
%\label{sec:model-gauss-sauts}
%
%Nous supposons tout d'abord que la densit\'e de la variable $X_1$ suit une loi gaussienne: 
%$$g(x)=\frac{1}{\sqrt{2 \pi \sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right).$$
%% Rappelons les expressions des moyenne et variance empiriques associ\'es:
%% $$\hat \mu = \frac 1 P \sum_{k=1}^P X_k,$$
%% $$\hat \sigma ^ 2= \frac 1 P \sum_{k=1}^P (X_k-\hat \mu)^2.$$
%
%Les moyenne et variance empiriques correspondent alors {\`a} l'estimateur du
%maximum de vraisemblance. Examinons rapidement si la loi gaussienne est adapt{\'e}e
%pour mod{\'e}liser les sauts d'une image. Sans entrer dans les d{\'e}tails d'un
%``vrai'' test d'ad{\'e}quation de mod{\`e}le, contentons--nous d'observer
%\emph{visuellement} cette ad{\'e}quation {\`a} partir d'un histogramme des donn{\'e}es,
%puis d'un graphe de comparaison de quantiles.  On rappelle que le
%\emph{quantile} d'ordre $p$ d' une variable al{\'e}atoire r{\'e}elle $H$ est d{\'e}fini par
%$$
%Q(p)= \inf \{t ~:~\PP\{H\leq t\}\geq p\} \;.
%$$
%Les \emph{quantiles empiriques} d'un vecteur d'observations est d{\'e}fini de
%m{\^e}me en rempla{\c c}ant la fonction de r{\'e}partition $t\mapsto\PP\{H\leq
%t\}$ par la fonction de r{\'e}partition empirique. La statistique d'ordre d'un
%vecteur de donn{\'e}es de taille $P$ correspond en particulier {\`a} la
%fonction quantile empirique {\'e}chantillonn{\'e}e tous les $1/P$.
%
%\begin{enumerate}
%\item Comparer la densit\'e de la gaussienne associ\'ee aux param{\`e}tres estim{\'e}s
%  \`a un histogramme des sauts. Commenter.
%\item Faire un graphe de la statistique d'ordre des observations contre les
%  quantiles correspondants de la loi $\mathcal{N}(0,1)$. Pourquoi peut-on, pour
%  une comparaison visuelle, se contenter de la loi gaussienne centr{\'e}e
%  normalis{\'e}e ? Commenter le r{\'e}sultat.
%\item Comparer ces 2 m{\'e}thodes (histogramme et graphe des quantiles). Laquelle
%  vous semble la plus avantageuse d'un point de vue pratique ?
%\end{enumerate}
%
%\section{Mod\'elisation par une loi ``Laplacienne g\'en\'eralis\'ee''}
%\label{sec:modelisation-laplacienne}
%
%Nous proposons de mod\'eliser la loi de $X$ par une densit\'e 
%\begin{equation}
%\label{LapGen}
%h(x)= C(\alpha, \eta) \exp\left( -|\eta x|^\alpha \right),
%\end{equation}
%avec $\eta>0$, $\alpha>0$.
%%  et $C(\alpha,\eta)=\frac{\alpha \eta}{2} \Gamma\left(
%%   \alpha^{-1}\right) ^{-1}$. 
%On notera, pour tout $x>0$, 
%$$
%\Gamma(x)=\int_0^\infty t^{x-1}\exp(-t)\,dt.
%$$
%Cette fonction ainsi que la fonction \emph{Gamma incompl{\`e}te}
%$$
%\Gamma(u,x)=\int_0^u t^{x-1}\exp(-t)\,dt
%$$
%sont en g{\'e}n{\'e}ral impl{\'e}ment{\'e}es dans les logiciels de calcul num{\'e}rique.
%
%On se propose d'utiliser la m\'ethode des moments pour estimer $\alpha$ et
%$\eta$. 
%
%\begin{enumerate}
%\item Calculer la constante $C(\alpha,\eta)$ {\`a} l'aide de la fonction $\Gamma$.
%\item Exhiber une transformation des donn{\'e}es qui fait appara{\^\i}tre une
%  mod{\'e}lisation par la famille des lois Gamma.
%\item Calculer $E(|X|^p)$ pour $p\in\N$. En d\'eduire que la variance
%  $\sigma^2$ de $X$ et son kurtosis $\kappa=E(X^4)/E(X^2)^2$ sont donn\'es par
% \begin{equation}
% \label{sigma}
% \sigma ^2 =\frac{\Gamma\left(\frac 3 \alpha \right)}{\eta^2
%   \Gamma\left(\frac 1 \alpha \right)},
% \end{equation}
% \begin{equation}
% \kappa=\frac{\Gamma\left(\frac 1 \alpha \right)\Gamma\left(\frac 5 \alpha \right)}{
%   \Gamma\left(\frac 3 \alpha \right)^2}.
% \end{equation}
%\item Tracer la fonction $\kappa$ en fonction de $\alpha$.
%\item Estimer ensuite le kurtosis empirique sur vos observations, $\hat \kappa$
%  et d\'eduire un estimateur $\hat\alpha$ de $\alpha$ en r{\'e}solvant
%  num\'eriquement l'\'equation
%$$\kappa(\alpha)=\hat \kappa\;.$$
%(Il suffit pour cela de tabuler les
%valeurs de $\kappa$ en fonction de $\alpha$ pour une pr{\'e}cision donn{\'e}e).
%Utiliser l'\'equation (\ref{sigma}) pour estimer $\eta$ par $\hat \eta$.
%\item Comparer visuellement l'ad{\'e}quation de la loi ainsi estim{\'e}e avec vos
%  donn{\'e}es, {\`a} partir d'un histogramme et des quantiles empiriques. Comparer {\`a} la
%  mod{\'e}lisation gaussienne.
%\end{enumerate}
%
%\section{Intervalles de confiance}
%\label{sec:interv-de-conf-laplacienne}
%
%Dans toute cette partie on reprend le mod{\`e}le donn{\'e} par la densit{\'e} $h$ d{\'e}finie
%en ~(\ref{LapGen}).  On d{\'e}finit la fonction $w:(0,\infty)\rightarrow(0,\infty)$
%par
%$$
%w(x)=\frac{\Gamma(5x)*\Gamma(x)}{\Gamma(3x)^2}.
%$$
%On se propose de d{\'e}terminer un intervalle de confiance pour l'estimateur
%$\hat{x}=1/\hat{\alpha}$ obtenu par la m{\'e}thode des moments, c'est-{\`a}-dire en
%r{\'e}solvant l'{\'e}quation
%$$
%w(\hat{x})=\frac{\overline{X^4}_n}{(\overline{X^2}_n)^2},
%$$
%o{\`u} on utilise la notation classique, pour tout vecteur $(Y_1,\ldots,Y_n)$,
%$$
%\overline{Y^p}_n=\frac1n\sum_{k=1}^nY^p_k.
%$$
%Des intervalles de confiance pour $\hat{x}$ et $\hat{\alpha}$ sont obtenus en r{\'e}solvant les questions suivantes. 
%
%\begin{enumerate}
%\item Montrer que l'on a le r{\'e}sultat asymptotique suivant.
%$$
%\sqrt{n}\left[ (\overline{X^4}_n, \overline{X^2}_n) - (\esp_{\alpha,\eta}[X_1^4],\esp_{\alpha,\eta}[X_1^2]) \right] \cl \calN(0,\Sigma).
%$$
%Expliciter la matrice $\Sigma$ en fonction de 
%$$
%m_p:=\esp_{\alpha,\eta}[X_1^p],\quad p=2,4,6,8.
%$$ 
%\item On d{\'e}finit la fonction $\phi:(0,\infty)^2\rightarrow(0,\infty)$ par
%$$
%\phi(u,t)=w^{-1}(u/t^2),
%$$
%o{\`u} $w^{-1}$ d{\'e}signe la fonction r{\'e}ciproque de $w$.  Calculer les d{\'e}riv{\'e}es
%partielles $\partial_u\phi$ et $\partial_v\phi$ de $\phi$ {\`a} l'aide de $w$, de
%la fonction \emph{digamma} $\Psi$ (la d{\'e}riv{\'e}e de $\log(\Gamma(x))$) et
%$w^{-1}$.
%
%\item En d{\'e}duire l'expression de $\nabla\phi$ au point $(m_4,m_2)$ en fonction de
%  $x=1/\alpha$, $m_2$ et $m_4$.
%
%\item Appliquer la $\delta$-m{\'e}thode pour obtenir la limite asymptotique de la loi de 
%$$
% \sqrt{n}(\phi(\overline{X^4}_n, \overline{X^2}_n) - x)
%$$
%Expliciter en particulier la renormalisation $R(x,(m_p)_{p=2,4,6,8})$ qui permet d'obtenir
%$$
%\sqrt{\frac{n}{R(x,(m_p)_{p=2,4,6,8})}}\,\,(\phi(\overline{X^4}_n, \overline{X^2}_n) - x)\cl \calN(0,1).
%$$ 
%\item Qu'obtient-on quand on remplace $x,(m_p)_{p=2,4,6,8}$ respectivement par $\hat{x},(\overline{X^p}_n)_{p=2,4,6,8}$ 
%  dans le terme de renormalisation de l'{\'e}quation pr{\'e}c{\'e}dente ?
%\item En conclure le calcul d'un intervalle de confiance de niveau de confiance asymptotique $1-p$ donn{\'e} pour $x$ puis pour
%  $\alpha$.
%% \item Ecrire une proc{\'e}dure Matlab calculant un intervalle de confiance de niveau et une image donn{\'e}s et appliquer
%%   la aux images  analys{\'e}es pr{\'e}c{\'e}demment pour le niveau $1-\alpha=95\%$. Utilisez pour ce faire la commande \com{qnorm}.
%\end{enumerate}
%
%
%\section{Comparaison par paires de textures}
%\label{sec:class-de-text}
%
%Une m{\'e}thode de classification de texture consiste {\`a} supposer qu'une texture est une classe d'images pour lesquelles la loi de
%la v.a. $X$ associ{\'e}e aux sauts de l'image  admet le m{\^e}me param{\`e}tre de forme $\alpha$.
%\begin{enumerate}
%\item Soit 2 images $I$ et $I'$ de textures et $X$ et $X'$ les v.a.  associ{\'e}e
%  aux sauts de ces images.  On suppose que ces de 2 images sont
%  ind{\'e}pendantes. Utiliser la loi asymptotique obtenue ci-dessus pour d{\'e}duire un
%  test pour les hypoth{\`e}ses:
%
%$$
%H_0=\{\text{$I$ et $I'$ sont dans la m{\^e}me classe de texture}\}
%$$
%contre
%$$
%H_1=\{\text{$I$ et $I'$ sont dans des classes de texture distinctes}\}
%$$
%pour un niveau $p\in(0,1)$ donn{\'e}.
%\item Ecrire une proc{\'e}dure calculant la $P$-valeur de ce test pour 2 images donn{\'e}es.
%\item Appliquer ce test {\`a} des paires d'images bien choisies parmi les images de
%texture disponibles sur le site
% 
%\url{http://sipi.usc.edu/database/database.php?volume=textures}
%
%et commenter le r{\'e}sultat.
%\end{enumerate}
%
%
%% \section{Etude multi\'echelles}
%
%% Dans les questions pr\'ec\'edentes, vous avez \'etudi\'e deux mod\`eles pour
%% la distribution des sauts d'intensit\'e entre pixels voisins. On peut se
%% demander comment varie cette distribution lorsque l'on ne consid\`ere plus des pixels voisins,
%% mais des pixels \`a une certaine distance. L'approche la plus simple consiste \`a regarder les
%% sauts entre pixels $a(i,j)$ et $a(i,j+k)$ pour diff\'erentes valeurs de
%% $k$. Cependant, il est pr\'ef\'erable de filtrer l'image avant de calculer les
%% sauts. En effet, pour sous-\'echantillonner l'image d'un facteur 2
%% (r\'eduire sa taille d'un facteur deux dans chaque direction) le th\'eor\`eme
%% de Shannon indique qu'il faut filtrer l'image par un filtre passe bas \'eliminant les
%% fr\'equences sup\'erieures \`a la moiti\'e de la fr\'equence la plus
%% \'elev\'ee de l'image. La fonction \com{reduit} fournie permet de
%% sous-\'echantilloner proprement l'image d'un facteur $2$. Nous proposons donc le protocole suivant: 
%% \begin{itemize}
%
%% \item \`a partir de l'image initiale, fabriquez une s\'erie d'images en
%%   sous-echantillonant plusieurs fois d'un facteur deux (applications
%%   successives de la fonction \com{reduit}),
%% \item pour chacune des images, apr\`es calcul des sauts, \'evaluez les param\`etres de la gaussienne
%%   g\'en\'eralis\'ee correspondante,
%
%% \end{itemize}
%
%% Qu'observez-vous ?
%

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} 
{\tt \noindent \'Ecole
  Polytechnique}
\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large {\bf Projet 9 :
Débruitage d'un signal par seuillage d'ondelettes  }}
\bigskip \hrule height .5pt
\bigskip
\begin{center} {responsable: Marc Hoffmann {\sf
(hoffmann@ceremade.dauphine.fr)}}
\end{center}
{\bf R\'esum\'e} : Nous abordons certaines questions relatives \`a la reconstruction d'un signal $1$-dimensionnel \`a partir d'observations bruit\'ees.\\
{\bf Mots-cl\'es} : vecteur gaussien, simulation de variables al\'eatoires, projection orthogonale.
%\section{Introduction}
\section{Approximation par moyennes locales}
Soit $f$ une fonction de $L^2([0,1])$. On d\'efinit son approximation %constante par morceaux 
\`a l'\'echelle $j \geq 0$ en posant
$$f_j(x)=2^j \int_{I_{j,k}} f(t)dt\;\;\;\hbox{si}\;\;\;x \in I_{j,k},\;k=0,\ldots,2^j-1,$$
o\`u $I_{j,k}$ d\'esigne l'intervalle $[k2^{-j}, (k+1)2^{-j}[$. Autrement dit, $f$ est approch\'ee par sa moyenne sur chaque intervalle $I_{j,k}$. L'approximation $f_j$ peut aussi s'interpr\'eter comme une projection :  si  $P_j$ d\'esigne la projection orthogonale sur le sous-espace vectoriel $V_j$ de $L^2([0,1])$ d\'efini par
$$V_j=\{f \in L^2([0,1])\;;\;f\;\hbox{est constante sur}\;I_{j,k},\;k=0,\ldots,2^{j}-1 \},$$
on a le r\'esultat suivant : 
%\begin{lemma} 
%\begin{equation} \label{proj}
$$
f_j = P_j f. \eqno(\star)
$$
%\end{equation}
%\end{lemma}
\begin{itemize}
\item[{\bf T1}] Prouver $(\star)$.
\end{itemize}
(Indication : on pourra 
introduire les fonctions
%montrer qu'une base orthonorm\'ee de $V_j$ est donn\'ee par  
$$\big(\varphi_{j,k}(x)=2^{j/2}\varphi(2^jx-k),\;k=0,\ldots,2^j-1\big),$$
avec $\varphi(x)=1$ si $x \in [0,1]$ et $0$ sinon.) 
%\end{itemize}
%En particulier, on v\'erifie que l'on a bien
%$$f_j=\sum_{k=0}^{2^j-1} c_{j,k}(f) \varphi_{j,k},$$
 %o\`u $c_{j,k}(f)=\int_{[0,1]}f(t)\varphi_{jk}(t)dt$. 
 %Remarquons que, puisque $V_j \subset V_{j+1}$, 
 \begin{itemize}
\item[{\bf T2}] Prouver que l'approximation $P_{j+1}f$ contient plus d'information sur $f$ que $P_jf$ dans le sens suivant :
\begin{equation} \label{propriete1}
%$$
P_jf_{|I_{j,k}}=\frac{1}{2}\left[P_{j+1}f_{|I_{j+1, 2k}}+P_{j+1}f_{|I_{j+1,2k+1}} \right].
\end{equation}
%$$
\end{itemize}
Notons de plus que l'on dispose d'un contr\^ole de l'erreur d'approximation de $f$ par $P_jf$ d\`es lors que $f$ poss\`ede suffisamment de r\'egularit\'e :

\begin{definition} Soit $0 < \alpha \leq 1$ et $L >0$. Une fonction $f: [0,1]\rightarrow \mathbb{R}$ v\'erifie la condition de r\'egularit\'e $H(\alpha,L)$ si pour tout $x,y \in [0,1]$ : 
$$|f(y)-f(x)| \leq L|y-x|^\alpha.$$
\end{definition}
%\begin{lemma}
\begin{itemize}
\item[{\bf T3}] Prouver que si $f$ v\'erifie la condition $H(\alpha,L)$, alors
$$\|P_jf-f\|_{L^2} \leq L2^{-j\alpha}.$$
%\end{lemma}
%Si $k(x)$ d\'esigne l'entier tel que $x \in I_{j,k(x)}$, on a $P_jf(x)-f(x)=2^j\int_{I_{j,k(x)}}[f(t)-f(x)]dt,$
%et le r\'esultat s'en d\'eduit imm\'ediatement en utilisant la propri\'et\'e $H(\alpha,L)$.
\end{itemize}
\section{Lissage par projection}
%Dans la pratique, on n'a pas acc\'es directement \`a un signal $f \in L^2([0,1])$.
 \subsection{Un mod\`ele de "signal plus bruit"}
 On suppose que l'on observe la  r\'ealisation de $(Y_{J,k}, k=0,\ldots, 2^{J}-1)$, avec
\begin{equation} \label{modele}
Y_{J,k}=2^J\int_{I_{J,k}}f(t)dt+\xi_{J,k}
\end{equation}
o\`u $J$ est un niveau de r\'esolution maximal, et $\xi_{J,k}$ repr\'esente une erreur exp\'erimentale syst\'ematique. On suppose que les $\xi_{J,k}$ sont des variables al\'e\-atoires gaussiennes centr\'ees r\'eduites, ind\'ependantes. Lorsque $J$ est grand, le mod\`ele postul\'e par \eqref{modele} correspond \`a l'\'echantillonnage bruit\'e d'un signal. En posant $\sigma_J=2^{-J/2}$ et $Z_{J,k}=\sigma_{J}Y_{J,k}$, on se ram\`ene donc \`a l'observation de
$$Z_{J,k}=c_{J,k}(f)+\sigma_J \xi_{J,k},\;\;k=0,\ldots,2^J-1
,$$
oô $c_{j,k}(f)=\int_{[0,1]}f(t)\varphi_{jk}(t)dt$.
Ceci donne lieu \`a la reconstruction {\it bruit\'ee} de $f$ \`a l'\'echelle $J$ : 
$$\hat f_J:=\sum_{k=0}^{2^J-1} Z_{J,k} \varphi_{J,k}.$$
Bien que l'on ait $\mathbb{E}\{Z_{J,k}\}=c_{J,k}(f)$ ($\mathbb{E}$ d\'esigne l'esp\'erance math\'ematique sur un espace de probabilit\'e ad\'equat) et donc $\mathbb{E}\{\hat f_J\}=f_J$, l'estimateur $\hat f_J$ de $f$ n'est pas bon : on peut \'ecrire $\hat f_J=f_J+h_J$, avec
$$h_J=\sigma_J \sum_{k=0}^{2^J-1} \xi_{J,k} \varphi_{J,k},$$
et, pour chaque $x \in [0,1]$, $h_J(x)$ est une variable gaussienne, centr\'ee, de variance $1$ qui n'est donc pas "petite", m\^eme lorsque $J$ est grand.
\begin{itemize}
\item[{\bf T4}] Formaliser cette derniére remarque.
\end{itemize}

\subsection{L'estimateur par projection $f^\star_j$}  Dans ce contexte, l'id\'ee de projection consiste \`a {\it lisser}  les observations $Z_{J,k}$, en projetant $\hat f_J$ sur un espace d'approximation $V_j$ plus {\it grossier} que $V_J$, c'est-\`a-dire tel que $j$ soit petit devant $J$. On d\'efinit alors
$$f_j^\star:=P_j\hat f_J,$$
et il convient de choisir judicieusement le niveau de projection, ou de lissage $j$. Pour cela, \'etudions l'erreur moyenne quadratique $e_{J,j}=\mathbb{E}\{\|f-f_j^\star\|_{L^2}^2\}$ sous l'hypoth\`ese $H(\alpha, L)$ . 
\begin{itemize}
\item[{\bf T5}] Montrer 
$$e_{J,j}=\|f-P_jf\|_{L^2}^2+\mathbb{E}\{\|P_jh_J\|_{L^2}^2\}.$$
%\mathbb{E}\{\|f-P_j(P_Jf+h_J)\|_{L^2}^2\}=\|f-P_jf\|_{L^2}^2+\mathbb{E}\{\|P_jh_J\|_{L^2}^2\}.$$
\item[{\bf T6}] Montrer que l'on peut écrire 
%\'ecrit
$$P_jh_J=\sum_{k=0}^{2^j-1}\eta_{j,k}^{(J)}\varphi_{jk},$$
%et donc $\|P_jh_J\|_{L^2}^2=\sum_{k=0}^{2^j-1}\big(\eta_{j,k}^{(J)}\big)^2$. 
où les $\eta_{jk}^{(J,k)}$ sont des variables al\'eatoires gaussiennes centr\'ees,
% puisque obtenues par transformation lin\'eaire d'un vecteur gaussien centr\'e. 
%Un rapide calcul, par exemple, permet de v\'erifier que leur 
dont la variance ne d\'epend pas de $j$ et vaut $2^{-J}=\sigma_J^2$. 
\item[{\bf T7}] En déduire que l'erreur moyenne quadratique $e_{J,j}$, sous l'hypoth\`ese $H(\alpha, L)$, est major\'ee par
$$L^22^{-2j\alpha}+2^{j-J},$$
ce qui fournit une erreur minimale de l'ordre de 
$$c(\alpha,L)2^{-2J\alpha/(2\alpha+1)}.$$
%pour $j$ optimal choisi de sorte que $2^j$ soit de l'ordre de $2^{J/(2\alpha+1)}$. 
\end{itemize}


Choisir $j$ trop grand revient a {\it sous-lisser} le signal bruit\'e, et choisir $j$ trop petit revient \`a le {\it sur-lisser}. L'inconv\'enient de cette m\'ethode est que le choix optimal de $j$ d\'epend explicitement de la connaissance {\it a priori} de la r\'egularit\'e $\alpha$ du signal inconnu $f$, ce qui, sauf exception notoire, est peu r\'ealiste. On va circonvenir \`a cet inconv\'enient en raffinant l'analyse de l'approximation par moyennes locales.
\section{Repr\'esentation multi-\'echelle d'un signal}
Avec les notations du paragraphe 1, \'ecrivons
$$P_{j+1}f=P_jf+Q_jf,$$
o\`u $Q_jf=(P_{j+1}-P_j)f$ d\'esigne la projection orthogonale sur le compl\'ementaire $W_j$ de $V_j$  dans $V_{j+1}$. La propri\'et\'e \eqref{propriete1} montre que $Q_jf$ {\it oscille}, dans le sens o\`u :
\begin{equation} \label{propriete2}
Q_jf_{|I_{j+1,2k}}=-Q_jf_{|I_{j+1, 2k+1}}.
\end{equation}
La propri\'et\'e d'oscillation \eqref{propriete2} nous permet d'\'ecrire
$$Q_jf=\sum_{k=0}^{2^j-1}d_{jk}(f) \psi_{j,k},$$ 
o\`u $\psi_{j,k}(x)=2^{j/2}\psi(2^jx-k)$, avec 
$\psi(x)=2^{j/2}\psi(2^jx-k)$, o\`u $\psi(x)=1$ si $x \in [0,\frac{1}{2}[$,  $-1$ si $x \in [\frac{1}{2},1[$ et $0$ sinon. La famille $\big(\psi_{j,k}, k=0,\ldots,2^{j}-1 \big)$ constitue une base orthonorm\'ee de $W_j$. On a donc n\'ecessairement
$d_{j,k}(f)=\int_{[0,1]}f(t)\psi_{j,k}(t)dt$. En it\'erant cette d\'ecomposition, on obtient, pour $0 \leq j_0 < j_1$:
$$P_{j_1}f=P_{j_0}f+\sum_{j=j_0}^{j_1-1}Q_jf,$$
ou encore
\begin{equation} \label{decompmultiscale}
\sum_{k=0}^{2^{j_1}-1}c_{j_1,k}(f)\varphi_{j_1k}=\sum_{k=0}^{2^{j_0}-1}c_{j_0,k}(f)\varphi_{j_0,k}+\sum_{j=j_0}^{j_1-1}\sum_{k=0}^{2^{j}-1}d_{j,k}(f)\psi_{jk},
\end{equation}
ce qui exprime la d\'ecomposition de $f$ \`a l'\'echelle d'approximation   {\it fine} $j_1$ comme somme d'une d\'ecomposition {\it grossi\`ere} \`a l'\'echelle $j_0$ \`a laquelle on adjoint une somme de d\'etails ou de fluctuations \`a des \'echelles interm\'ediaires.

La formule \eqref{decompmultiscale} doit \^etre comprise comme un changement de base orthonormal de $V_{j_1}$ : les $\big(\varphi_{j_1k},k=0,\ldots,2^{j_1}-1 \big)$ d'une part, et les $\big(\varphi_{j_0k},k=0,\ldots,2^{j_0}-1, \psi_{jk},j=j_0,\ldots,j_1-1,k=0,\ldots,2^j-1 \big)$ sont des bases orthonorm\'ees de $V_{j_1}$; toute fonction de $V_{j_1}$ admet une d\'ecomposition unique dans chacune de ces bases:

%\begin{lemme} Le changement de base est donn\'e par les formules suivantes : 
\begin{equation} \label{decomp1}
c_{j,k}=\frac{1}{\sqrt{2}}[c_{j+1,2k}+c_{j+1,2k+1}],\;\;\hbox{et}\;\;
d_{j,k}=\frac{1}{\sqrt{2}}[c_{j+1,2k}-c_{j+1,2k+1}],
\end{equation}
et la transformation inverse est donn\'ee par
\begin{equation} \label{recons1}
c_{j+1,2k}=\frac{1}{\sqrt{2}}[c_{j,k}+d_{j,k}],\;\;\hbox{et}\;\;
c_{j+1,2k+1}=\frac{1}{\sqrt{2}}[c_{j,k}-d_{j,k}].
\end{equation}
%\end{lemme}
On peut alors r\'ecapituler cette d\'ecomposition par les deux algorithmes suivants :\\ 


\begin{itemize}
\item [{\bf D\'ecomposition}] (\'echelle fine $j_1$ vers \'echelle grossi\`ere $j_0$ plus les d\'etails)
\begin{itemize}
\item Se donner des coefficients $c_{j_1k}$.
\item Calculer les $c_{j_1-1,k}$ et les $d_{j_1-1,k}$ en utilisant \eqref{decomp1}.
\item Garder les d\'etails $d_{j_1-1,k}$ et it\'erer la d\'ecomposition sur les $c_{j_1-1}$ et ainsi de suite.
\item Stopper \`a l'\'echelle $j_0$.
\end{itemize}

\item[{\bf Reconstruction}] (\'echelle grossi\`ere $j_0$ plus les d\'etails vers \'echelle fine $j_1$)
\begin{itemize}
\item Partir  des coefficients $c_{j_0k}$ et $d_{j_0k}$.
\item Calculer les $c_{j_0+1,k}$ en utilisant  \eqref{recons1}.
\item It\'erer la reconstruction en utilisant les $d_{j_0+1,k}$ et ainsi de suite.
\item Stopper \`a l'\'echelle $j_1$ lorsque les $c_{j_1,k}$ sont calcul\'es.
\end{itemize}
\end{itemize}
\begin{itemize}
\item[{\bf 8}] Démontrer les propriétés \eqref{propriete2}, \eqref{decompmultiscale}, \eqref{decomp1} et \eqref{recons1}. Implémenter cet algorithme et le tester numériquement sur plusieurs exemples de signaux. En particulier, réfléchir à une représentation graphique de la décomposition multiéchelle. Quelle est la complexité de l'algorithme ? 
\end{itemize}
\section{Application \`a l'estimation d'un signal bruit\'e : le seuillage}
On part de l'observation \eqref{modele}. En appliquant l'algorithme de d\'ecomposition entre les \'echelles $j_1=J$ et $j_0=0$, on observe aussi
$$
\left\{
\begin{array}{lll}
W_{jk} & = & d_{jk}(f)+\sigma_J \widetilde{\xi_{jk}},\;k=0,\ldots 2^j-1,j=1,\ldots,J \\ \\
W_0 & = & c_{00}(f)+\sigma_J \widetilde{\xi_{00}},
\end{array}
\right.
$$
o\`u les $\widetilde{\xi_{jk}}$ sont des variables gaussiennes centr\'ees r\'eduites. 
\begin{itemize}
\item[{\bf T9}] Montrer que sous l'hypoth\`ese $H(\alpha,L)$,  la propri\'et\'e d'oscillation
$$\int_{[0,1]}\psi(t)dt=0$$ entra\^{\i}ne l'estimation
$$|d_{j,k}(f)| \leq L2^{-j(\alpha+1/2)}.$$
\end{itemize}
Les $d_{j,k}(f)$ sont d'autant plus petits que $f$ est r\'eguli\`ere (c'est-\`a-dire $\alpha$ grand) ou que $j$ est grand.
Par ailleurs, le terme de bruit $\sigma_J \widetilde{\xi_{jk}}$ est grossi\`erement de l'ordre de $\sigma_J=2^{-J/2}$, au sens o\`u $\mathbb{E}\{(\widetilde{\xi_{jk}})^2\}=1$. En conclusion, lorsque l'observation $W_{j, k}$ n'est pas significativement plus grande que $\sigma_J$, elle n'apporte pas d'information sur $f$, au sens o\`u le coefficient $d_{j,k}$ est domin\'e par le niveau de bruit $\sigma_J$. Ce principe donne lieu \`a l'algorithme de seuillage :
$$\hat f^{\small seuillage}_J=W_0+\sum_{j=0}^J \sum_{k=0}^{2^j-1} T_{\sigma_J}(W_{jk}) \psi_{j,k},$$
o\`u $T_{\sigma_J}(x)=x$ si $|x| \geq \sigma_J\sqrt{2 |\log \sigma_J|}$ et $0$ sinon. Le
choix de $T_{\sigma_J}$ est motiv\'e par la propri\'et\'e suivante :
%\begin{lemme} \label{deviation}
\begin{itemize}
\item[{\bf 10}] Montrer que
$$\mathbb{P}\{|d_{j,k}-W_{j,k}| \geq \sigma_J\sqrt{2 |\log \sigma_J|}\} \;\;\text{est ``petit"}$$
et quantifier cette affirmation précisément. Montrer en particulier que cette probabilité est petite devant la vitesse optimale (renormalis\'ee) de l'estimateur par projection.
\end{itemize}
%\end{lemme}
On obtient ainsi $\hat f^{\small seuillage}_J$ en d\'ecomposant $\hat f_J$ dans la base 
$$\{\varphi_{00}\}\cup\{\psi_{j,k},k=0,\ldots, 2^j-1,j=0,\ldots,J-1\},$$
en ne conservant toutefois que les coefficients $W_{j,k}$ significatifs, ce qui permet de r\'eduire la variance de l'estimation.
\begin{itemize}
\item[{\bf T10}] (Difficile)  Montrer que l'estimateur par seuillage  $\hat f_J^{\small seuillage}$ atteint la vitesse optimale de l'estimateur par projection (\`a un facteur logarithmique pr\`es), sans avoir besoin  de conna\^{\i}tre $\alpha$ et $L$.
\end{itemize}
%\suggestions
\begin{itemize}
%\item On pourra pr\'eciser les preuves des lemmes 1 et 2.
\item[{\bf 11}] Impl\'ementer l'estimateur par projection $\hat f_j$ pour diff\'erents niveaux de lissage $j$ et diff\'erentes fonctions test. 
En particulier, on pourra remarquer que l'algorithme de d\'ecomposition de la section 3 fournit un proc\'ed\'e de calcul rapide de la projection $P_jg$ \`a partir de $P_Jg$.

Pour simplifier la mise en oeuvre des algorithmes, on pourra faire (et justifier) l'approximation
$$2^J\int_{I_{J,k}}f(t)dt \;\;\hbox{proche de}\;\; f(k2^{-J})$$ 
\`a l'\'echelle la plus fine $J$.
%\item Que se passe-t-il si $f$ est constante ? 
\item[{\bf T12}] On pourra justifier le calcul de la variance des $\eta_{j,k}^{(J)}$ ainsi que le calcul de l'erreur moyenne quadratique optimale de l'estimateur par projection.
\end{itemize}
Pour le choix de signaux sur lesquels tester la m\'ethode, on pourra, par exemple, choisir les signaux
$$g_1(x)=\sin(2\pi x),\;\;\;g_2(x)=1_{[0,\frac{1}{3}[}(x)+\textstyle \frac{1}{2}1_{[ \textstyle \frac{1}{3}, 1]}(x),\;\;\;g_3(x)=\exp(x)
$$
en discutant \`a chaque fois les m\'ethodes de reconstruction selon les propri\'et\'es de r\'egularit\'e de $g_i$, $i=1,2,3$. On pourra, en particulier, reconsid\'erer la m\'ethode dans le cas (tr\`es particulier) o\`u le signal $f$ est constant.
%\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large 


{\bf Projet 10 :  Tests multiples et
  analyse 
  différentielle de niveaux d'expression de gènes}  }\bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Stéphane Gaiffas {\sf (stephane.gaiffas@polytechnique.edu)}}
\end{center}

\section{Motivations}

Le problème de test d'hypothèses multiples existe depuis longtemps en
statistique. Les évolutions technologiques de ces derniers années,
concernant notamment les données gé\-nomiques et les données internet,
ont permis la construction de bases de données énormes et/ou en très
grande dimension. Dans ce type d'application, il est crucial de
sélectionner les variables pertinentes avant de faire une
classification ou de construire un modèle de prédiction. On appelle
cette étape ``sélection de variables'' en français dans le vocabulaire
statistique ou ``features selection'' en anglais, dans la communauté
``machine learning''. Une méthode très classique et utilisée pour la
sélection de variables est l'approche par tests mutiples. Dans ce
cadre, on définit une erreur de type I (erreur de première espèce)
pour une hypothèse $H_0$ multiple, et on construit une procédure
garantissant un contrôle de cette erreur.

Un exemple d'application de ces méthodes est l'analyse différentielle
de micro-array. On observe les niveaux d'expressions de gènes mesurés
sous différentes conditions expérimentales, et on cherche les gènes
les plus différem\-ment exprimés entre ces deux conditions. On peut
penser notamment à la différence de niveaux d'expression entre une
cellule cancéreuse et une cellule saine. On présume alors que ces
gènes ont un role important dans le développement de la tumeur.

On suppose que l'on observe les niveaux d'expressions de $m$ gènes. Le
nombre $m$ de gènes est grand, au moins de l'ordre de
$10^4$. L'approche tests multiples est la suivante: pour chaque
différence de niveau d'expression, on calcule la $p$-valeur d'un test
statistique pour l'hypothèse ``la différence entre les deux
expressions est nulle''. Le plus simple pour faire cela est d'utiliser
un test d'adéquation de Student entre deux populations (cellules
saines, cellules cancéreuses). La $p$-valeur de ce test nous donne une
mesure de la confiance que l'on a en cette hypothèse. Une procédure de
tests multiples nous permet ensuite de choisir, à partir de toutes ces
$p$-valeurs, un ensemble de génes différemment exprimés, avec un
contr\^ole de l'erreur de première espèce commise, correspondant au
(nombre de rejets à tort) / (nombre de rejets total).

\section{Aspects théoriques}

Nous nous plaçons dans un espace mesurable $(\cX, \cT)$, muni d'un
sous ensemble $\cP$ de lois sur $(\cX, \cT)$. On suppose que l'on
observe une variable aléatoire $X$ de loi $P \in \cP$. On se donne $m
\geq 2$ sous-ensembles de $\cP$, correspondant à $m$ hypothéses nulles
$H_{i, 0} : P \in \Theta_{i, 0}$. A partir de $X$, on veut tester
l'hypothèse $H_{i, 0}$ contre l'alternative $H_{i, 1} : P \in
\Theta_{i, 0}^\complement$ simultanément pour tout $i=1, \ldots,
m$. Pour $P \in \cP$, on pose $\cH_0(P) = \{ 1 \leq i \leq m : P \in
\Theta_{i, 0} \}$, l'ensemble des indices $i$ tels que $H_{i, 0}$ est
vérifiée par $P$ (les ``vrais positifs''). Le cardinal d'un ensemble
$E$ est noté $|E|$, et on notera $m_0(P) = |\cH_0(P)|$. On notera
aussi $\cH = \{ 1, \ldots, m \}$ et $\cH_1(P) = \cH \setminus
\cH_0(P)$.

\subsection{Regardons de plus prés les $p$-valeurs}
\label{sec:p-valeurs}

Fixons $i \in \{ 1, \ldots, m \}$, et supposons que nous avons un test
région de rejet $\{ S_i(X) \geq s \}$ pour tester $H_{i, 0}$ contre
$H_{i, 1}$. La variable aléatoire $S_i(X)$ est une statistique de test
et $s$ est un seuil (il s'agit donc d'un test du type ``on rejette
quand la statistique est trop grande). Une façon générale de définir
la $p$-valeur $p_i(X)$ de ce test est de poser
\begin{equation*}
  p_i(X) = \sup_{P \in \Theta_{0, i}} T_{P, i}(s),
\end{equation*}
où $T_{P, i}(s) = \P_{X \sim P}(S_i(X) \geq s)$.
\begin{enumerate}
\item Interprétez cette définition, et faites le lien avec la
  définition donnée dans le cours.
\item Montrez que l'on a
  \begin{equation*}
    \P_{X \sim P} (p_i(X) \leq u) \leq u
  \end{equation*}
  pour tout $u \in [0, 1]$ et $P \in \Theta_{0, i}$. On dit alors que
  $p_i(X)$ est ``stochastiquement dominée'' par une loi uniforme sur
  $[0, 1]$ sous l'hypothèse $H_{i, 0}$. C'est une propriété
  fondamentale des $p$-valeurs.
\item Posons $F_{P, i}(s) = \P_{X \sim P} (S_i(X) \leq s)$ et $F_{P,
    i}^{-1}(t) = \min \{ s \in \R \cup \{ -\infty \} : F_{P, i}(s)
  \geq t \}$. Si $F_{P, i}$ est continue pour tout $P \in \Theta_{0,
    i}$, montrer que l'on a alors
  \begin{equation*}
    p_i(x) = \min \{ \alpha \in [0, 1] : S_i(x) \geq \sup_{P \in
      \Theta_{0, i}} F_{P, i}^{-1}(1 - \alpha) \}
  \end{equation*}
  pour toute réalisation $x$ de $X$. Si de plus $\Theta_{0, i}$ est un
  singleton, montrer qu'alors $p_i(X)$ est de loi uniforme sur $[0,
  1]$.
\end{enumerate}

\subsection{Procédure de tests multiples}



Nous supposons que nous avons des $p$-valeurs $p_i(X)$ pour des tests
d'hypothèse $H_{i, 0}$ contre $H_{i, 1}$, pour $i = 1, \ldots, m$. Au
vu ce que précède, nous supposons que ces $p$-valeurs vérifient
\begin{equation}
  \P_{X \sim P}(p_i(X) \leq u) \leq u
\end{equation}
pour tout $u \in [0, 1]$, tout $i \in \cH_0(P)$ et tout $P \in \cP$.
\begin{enumerate}
\item Remarquez que cela entraîne que rejeter $H_{i, 0}$ quand $p_i(X)
  \leq \alpha$ fournit un test de niveau $\alpha$.
\end{enumerate}
Une procédure de tests multiples est une fonction
\begin{equation*}
  R : q = (q_i)_{i=1, \ldots m} \in [0, 1]^m \mapsto R(q) \subset \{1,
  \ldots, m \},
\end{equation*}
qui à une suite dans $[0, 1]^m$ (des $p$-valeurs) associe un
sous-ensemble de $\{1, \ldots, m\}$ (les indices des hypothèses $H_{i,
  0}$ rejetées). On notera $\bp = (p_1, \ldots, p_m) \in [0, 1]^m$ un
vecteur de $p$-valeurs, de sorte que $i \in R(\bp)$ signifie que
$H_{i, 0}$ est rejetée. Notez que nous allons omettre à partir de
maintenant la dépendance de $\bp$ en $X$, sauf quand cela est gênant.

La notion d'erreur de première espèce la plus répandue pour le
problème de test multiple est le FDR (False Discovery Rate). Le FDR
est donné, pour tout $P \in \cP$, par
\begin{equation*}
  \fdr(R(\bp), P) = \E \Big[ \frac{|R(\bp) \cap \cH_0(P)|}{|R(\bp)| \vee
    1} \Big].
\end{equation*}
Le but est alors de construire une procédure de test multiple
vérifiant 
$$\fdr(R(\bp), P) \leq \alpha$$
 pour tout $P \in \cP'$ pour un
niveau $\alpha$ fixé, avec $\cP' \subset \cP$ une famille de lois la
plus grande possible.
\begin{enumerate}
\item Expliquez cette définition intuitivement.

\item La procédure de test multiple la plus simple est celle de
  ``Bonferroni'' et est donnée par $R(\bp) = \{ 1 \leq i \leq m : p_i
  \leq \alpha / m \}$. Montrez que le $\fdr$ de cette procédure est
  plus petit que $\alpha$. Quel est à votre avis le problème avec
  cette procédure?
\end{enumerate}

Le seuillage est la procédure de test multiple la plus naturelle: on
considére alors simplement
\begin{equation*}
  R_t(\bp) = \{ 1 \leq i \leq m : p_i \leq t(\bp) \},
\end{equation*}
où la fonction de seuil $t(\cdot)$ peut dépendre des données, et sera
comme on va le voir plus astucieuse que celle utilisé dans la
procédure de Bonferroni.

\subsection{Contr\^ole du FDR}

\begin{enumerate}
\item Montrez que l'on peut décomposer le FDR de la procédure $R_t$ de
  la façon suivante:
  \begin{equation*}
    \fdr(R_t, P) = \frac{\alpha}{m} \sum_{i \in \cH_0(P)} \E \Big[
    \frac{\ind{p_i \leq t(\bp)}}{\alpha \hat G_m(\bp, t(\bp)) \vee
      (\alpha / m)} \Big],
  \end{equation*}
  où $\hat G_m(\bp, t) = m^{-1} \sum_{i=1}^m \ind{p_i \leq t}$ est la
  fonction de répartition empirique des $p$-valeurs.
\item Montrez que si $t$ et $\hat G_m$ étaient déterministes, on
  aurait $\fdr(R_t, P) \leq \alpha$ en choisissant un seuil $t \leq
  \alpha \hat G_m(\bp, t)$. Cela motive la définition suivante: on dit
  qu'une fonction de seuil $t$ est \emph{auto-consistante} si $t(q)
  \in \cT(q)$ pour tout $q \in [0, 1]^m$, où
  \begin{equation*}
    \cT(q) = \{ u \in [0, 1] : \hat G_m(q, u) \geq u / \alpha \}.
  \end{equation*}
\item Remarquez qu'un tel $t$ seuil vérifie $R_t \subset \{ 1 \leq i
  \leq m : p_i \leq \alpha |R_t| / m \}$, d'où ce nom. Remarquez aussi
  que ce type de seuil est très simple à utiliser en pratique, car il
  ne dépend que de $\alpha$ et de la famille $\bp$ de $p$-valeurs.
\item Montrez que si $t(\bp) \in \cT(\bp)$, on a
  \begin{equation*}
    \fdr(R_t, P) \leq \frac{\alpha}{m} \sum_{i \in \cH_0(P)} \E \Big[
    \frac{\ind{p_i \leq t(\bp)}}{t(\bp)} \Big].
  \end{equation*}
\item Nous avons maintenant besoin du résultat suivant. Soit $U$ une
  variable aléatoire positive vérifiant $\P(U \leq u) \leq u$ pour
  tout $u \in [0, 1]$. Alors on a 
  \begin{equation*}
    \E \Big[ \frac{\ind{U \leq V}}{V} \Big] \leq 1
  \end{equation*}
  si $V = g(U)$ avec $g : \R^+ \rightarrow \R^+$
  décroissante.
  % dés que l'une des deux conditions suivantes est vérifiée:
%   \begin{enumerate}
%   \item 
%   \item $u \mapsto P(V < v | U \leq u)$ est croissante sur $\{ u \in
%     [0, 1] : \P(U \leq u) > 0 \}$.
%   \end{enumerate}
  Démontrez ce résultat.
  % quand (a) est vérifiée (facile) et quand (b)
  % est vérifiée (difficile et facultatif. \texttt{ASTUCE}).
\item On introduit la famille de lois suivante:
  \begin{align*}
    \cP_I = \big\{ P \in \cP &: (p_i(X))_{i \in \cH_0(P)} \text{
      indépendantes et } \\
    & \quad \quad (p_i(X))_{i \in \cH_0(P)} \text{ indépendantes de
    } (p_i(X))_{i \in \cH_1(P)} \big\}.
  \end{align*}
  Déduire de ce qui précède le théorème suivant.
  \begin{theorem}
    \label{thm:fdr-control}
    Soit $R_t$ une procédure de test mutiple basée sur une fonction de
    seuil $t(\cdot)$ vérifiant:
    \begin{itemize}
    \item $t(\cdot)$ est auto-consistante
    \item $t(q) \leq t(q')$ pour tout $q, q' \in \R^m$ vérifiant $q_i
      \leq q_i'$ pour tout $i=1, \ldots, m$.
    \end{itemize}
    Alors, on a 
    \begin{equation*}
      \fdr(R_t, P) \leq \alpha m_0(P) / m \leq \alpha
    \end{equation*}
    pour toute loi $P \in \cP_I$.
  \end{theorem}
  Ce théorème est établi sous une hypothèse forte et assez irréaliste,
  qui demande que la famille de loi générant les données mène à des
  $p$-valeurs indépendantes. Cette hypothèse a été affaiblie dans
  plusieurs papiers de recherche, mais demandent plus d'arguments
  techniques. On peut notamment obtenir le même résultat lorsque $P$
  est une loi gaussienne multivariée dont la matrice de covariance a
  toutes ses entrées positives.
\end{enumerate}

\subsection{La procédure de Benjamini-Hochberg}

Nous savons donc maintenant qu'une procédure de test multiple
vérifiant les hypothéses du Théorème~\ref{thm:fdr-control} a son FDR
contr\^olé. Il est donc naturel de choisir le seul
\begin{equation*}
  \hat t(\bp) = \max \cT(\bp).
\end{equation*}
\begin{enumerate}
\item Expliquez pourquoi on choisit ce seuil, et montrer qu'il s'écrit
  \begin{equation*}
    \hat t(\bp) = \frac \alpha m \max\{ 0 \leq k \leq m : p_{(k)} \leq
    \alpha k / m \},
  \end{equation*}
  où $p_{(1)} \leq \cdots \leq p_{(m)}$ et $p_{(0)} = 0$. Ce seuil
  s'appelle la correction de ``Benjamini-Hochberg'', et fournit une
  procédure de test multiple très simple donnant de bons résultats.
\end{enumerate}

\section{Application à l'analyse différentielle}

Supposons que l'on observe un échantillon
\begin{equation*}
  X = (X_1, \ldots, X_n) = (Y_1, \ldots, Y_{n_1}, Z_1, \ldots,
  Z_{n_2})
\end{equation*}
avec $n_1 + n_2 = n$, où $X_i \in \R^m$ est le vecteur des niveaux
d'expression de la cellule $i$, où $Y_1, \ldots, Y_{n_1}$ correspond à
un premier groupe de cellules, et $Z_1, \ldots, Z_{n_2}$ à un deuxième
groupe de cellules. On suppose que les $Y_1, \ldots, Y_{n_1}$ sont
i.i.d, que les $Z_1, \ldots, Z_{n_2}$ sont i.i.d, et que les $(Y_i)$
sont indépendants des $(Z_i)$. On suppose que $Y_1$ est de loi
$N(\mu_1, \sigma^2 I_{n_1})$ et que $Z_1$ est de loi $N(\mu_2,
\sigma^2 I_{n_2})$, où $I_d$ est la matrice identité dans $\R^{d
  \times d}$, $\mu_1, \mu_2 \in \R^m$.
\begin{enumerate}
\item Proposez un test pour l'hypothèse
  \begin{equation*}
    H_{i, 0} : \mu_{i, 1} = \mu_{i, 2} \text{ contre } H_{i, 1} :
    \mu_{1, i} \neq \mu_{i, 2},
  \end{equation*}
  et calculez sa $p$-valeur. Décrivez la procédure de test multiple
  dans ce cadre, pour un contr\^ole du FDR plus petit qu'un niveau
  $\alpha$ fixé.
\end{enumerate}


Nous allons à présent utiliser cette méthode sur des données
génomiques. Nous allons pour cela utiliser le logiciel \texttt{R}. Une
initiation basique très interactive et intuitive à \texttt{R} est
disponible ici : \texttt{http://tryr.codeschool.com}.

Ce logiciel contient beaucoup de packages, en particulier pour l'étude
de données génomiques, grâce au repository \texttt{Bioconductor},
qu'on peut consulter ici: \texttt{http://www.bioconductor.org}. Pour
installer les outils dont vous allez avoir besoin, nous allons d'abord
installer le package \texttt{BiocInstaller}. Ce package permet
d'installer des packages disponibles sur \texttt{BioConductor}. Cela
se fait facilement dans l'interface graphique de \texttt{R} (il faut
choisir \texttt{BioConductor Binary} dans l'adresse de téléchargement
des packages et installer \texttt{BiocInstaller}. Une fois ce package
installé, tapez dans \texttt{R} la commande
\texttt{library(BiocInstaller)} qui charge cette librairie. Cette
librairie fournit une fonction \texttt{biocLite}, qui permet
d'installer facilement des packages \texttt{BioConductor}.  Tapez
\texttt{biocLite(c("limma", "marray", "multtest"))} pour installer la
librarie de tests multiples \texttt{multtest} et la librairie
\texttt{Biobase} qui contient des jeux de données.
\begin{enumerate}
\item Tapez \texttt{data(golub)} pour charger le jeu de données que
  nous allons étudier. Tapez \texttt{help(golub)} pour avoir une
  explication sur ces données, et expliquez ce que contiennent
  \texttt{golub.cl} et \texttt{golub.gnames}.
\end{enumerate}
Dans la suite on n'hésitera pas à utiliser \texttt{help} sur n'importe
quelle fonction, pour comprendre ce qu'elle fait (et pour pouvoir
répondre aux questions...). 

L'objet \texttt{golub} est un tableau contenant les niveaux
d'expressions de 3051 génes sur 38 tumeurs. Il ne s'agit pas de
données brutes, mais de données prétraitées (centrées et normalisées),
comme on peut voir en affichant les boxplots.
\begin{enumerate}
\item Tapez \texttt{boxplot(golub)} et expliquez ce que vous voyez.
\end{enumerate}
Une représentation graphique de ces niveaux d'expression peut être
obtenue en tapant \texttt{image(golub)}.
\begin{enumerate}
\item Créez le tableau ne contenant que les 100 premiers gènes des 38
  tumeurs, et affichez son image.
\end{enumerate}
Passons maintenant à la procédure de tests multiples.
\begin{enumerate}
\item Tapez \texttt{teststat <- mt.teststat(golub,
    golub.cl)}. Expliquez ce que fait cette commande.
\item Tapez \verb|p_value <- 2 * (1 - pnorm(abs(teststat)))| puis
  tapez \\ \verb|print(round(cbind(1:20, p_value[1:20]), 2))|. %
  Expliquez ce que font ces deux commandes, et les valeurs affichées.
\item Tapez
\begin{verbatim}
procs <- c("Bonferroni", "BH")
res <- mt.rawp2adjp(p_value, procs)
adjp <- res$adjp[order(res$index), ]
round(adjp[1:50, ], 2)
\end{verbatim}
  Expliquez ce que fait chaque commande, et commentez.
\item Tapez
\begin{verbatim}
mt.reject(adjp, seq(0, 1, 0.1))$r
which <- mt.reject(adjp, 0.1)$which[, 3]
golub.gnames[which, 2]
\end{verbatim}
  Expliquez ce que font ces commandes, et dire précisément ce à quoi
  correspond chaque résultat.
\item Pour finir, tapez
\begin{verbatim}
procs_names <- c("Raw p-values", "Bonferroni", "BH")
mt.plot(adjp, teststat, plottype = "pvsr",
    proc = procs_names, leg = c(2000, 0.4), lty = 1:3,
    col = 1:3, lwd = 2)
\end{verbatim}
  Expliquez ce que font ces commandes et conclure.
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large 


{\bf Projet 11 :  Minimisation du risque empirique pour le problème d'agrégation convexe}  }\bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Guillaume Lecué {\sf (guillaume.lecue@cmap.polytechnique.fr)}}
\end{center}


\section{Introduction au problème d'agrégation convexe}
\label{sec:aggregation-convexe}
L'objectif de ce Projet Individuel  est de proposer une introduction à l'apprentissage statistique, aux méthodes de processus empiriques et à la méthode de Maurey par le biais du probléme d'agrégation convexe.

On se propose d'étudier des données de type entrée/sortie. L'objectif étant d'inférer ou prédire une sortie associée à une nouvelle entrèe en fonction des données précédemment observées. On dispose de $n$ données $(X_i,Y_i)_{i=1}^n$ où $X_i$ est une donnée d'entrée à valeurs dans un espace mesurable quelconque $\cX$ et $Y_i$ est un ``label'' ou sortie associée à l'entrée $X_i$ à valeurs dans un intervalle borné $[-b,b]$ pour un certain $b>0$. On reÁoit une nouvelle entrée $X$ et on souhaite prédire la sortie $Y$ la plus naturellement associée à $X$ en restant en accord avec ce qui a été observé avant. Ce problème a de multiple applications concrétes.

On modèlise ce problème de la manière suivante: les données $(X_i,Y_i)$ pour $i=1,\ldots,n$ et le ``nouveau'' couple entrée/sortie $(X,Y)$ sont supposés indépendants et identiquement distribués. On souhaite construire des fonctions qui dépendent des données $\cD:=\{(X_1,Y_1),\ldots,(X_n,Y_n)\}$ et de la nouvelle entrée $X$ pour prédire au mieux la sortie $Y$. De telles procédures sont appelées procèdures d'apprentissage, estimateurs ou statistiques. On va donc s'intérésser aux fonctions mesurables $\hat f_n:(\cX\times[-b,b])^n\times \cX\longmapsto\R$ telles que la distance moyenne entre $\hat f_n(\cD,X)$ (la prédiction qui est faite à partir des données $\cD$ pour l'entrée $X$) et $Y$ (en quelque sorte la ``vraie'' sortie) soient la plus petite possible. On considére la distance $L_2$ (mais d'autres distances sont aussi envisageables). On définit alors le risque quadratique de $\hat f_n$ par
\begin{align}
  \label{eq:risque-quad}
\nonumber  R(\hat f_n)&=\E_{(X,Y)}(\hat f_n(\cD,X)-Y)^2=\E\big[(\hat f_n(\cD,X)-Y)^2|\cD\big]\\
&=\int_{\cX\times\R}(\hat f_n(\cD,x)-y)^2d\Pro_{(X,Y)}(x,y)
\end{align}où $\E_{(X,Y)}$ est l'espérance par rapport à $(X,Y)$ et $\Pro_{(X,Y)}$ est la mesure de probabilité de $(X,Y)$. Pour simplifier l'écriture, on ne présisera plus que les statistiques $\hat f_n$ dépendent des données $\cD$. Suivant cette convention, le risque quadratique d'un estimateur $\hat f_n$ s'écrit  $R(\hat f_n)=\E\big[(\hat f_n(X)-Y)^2|\cD\big]$. On cherche donc à constuire des estimateurs $\hat f_n$ ayant le plus petit risque quadratique $R(\hat f_n)$.

Dans ce projet individuel, on s'intéréssera à un certain type d'estimateur: ceux qui peuvent s'écrire comme combinaison convexe d'éléments d'un ensemble fini de fonctions de $\cX$ dans $[-b,b]$. Un tel ensemble s'appelle un \textit{dictionnaire}. Un dictionnaire peut se construire à partir d'éléments d'une base qu'on pense particulièrement bien adaptée au probléme traité, ou d'un grand nombre de fonctions simples comme des indicatrices de demi-espace ou encore, si on dispose d'autres données, on peut aussi construire une multitude d'estimateurs (possiblement non-adaptatifs) et en faire un dictionnaire, etc.. Qu'importe la manière dont a été construit ce dictionnaire, pour notre problème d'agrégation, on notera ses éléments par $f_1,\ldots,f_M$. Les $f_j$ sont donc des fonctions de $\cX$ à valeurs dans $[-b,b]$. On s'intéressera alors à des estimateurs de la forme
\begin{equation}
  \label{eq:methode_agregation}
  \hat f_n=\sum_{j=1}^M w_j f_j
\end{equation}où les poids $w_j$ sont positifs et de somme égale à $1$ (de telle sorte que $\hat f_n$ est bien une combinaison convexe d'éléments du dictionnaire). Un tel estimateur est appelé \textit{méthode d'agrégation.} On souhaite choisir les poids $w_j$ de telle sorte que (\ref{eq:methode_agregation}) fasse aussi bien que la meilleure combinaison convexe d'élément dans $F=\{f_1,\ldots,f_M\}$, le dictionnaire. Les poids $w_j$ devront donc être choisis à l'aide des données $\cD$.

D'un point de vue mathématique, ce problème d'optimalité (i.e. ``faire mieux que la meilleure combinaison convexe dans $F$) se traduit par une \textit{inégalité oracle}: construire $\hat f_n$ telle que ``avec grande probabilité (vis-à-vis des données)'', on a
\begin{equation}
  \label{eq:ineg-oracle}
  R(\hat f_n)\leq \inf_{f\in {\rm conv}(F)}R(f)+r(n,M)
\end{equation}où ${\rm conv}(F)$ est l'enveloppe convexe de $F$ définie par
\begin{equation*}
{\rm conv}(F)=\big\{\sum_{j=1}^M\lambda_j f_j:\lambda_j\geq0,\sum_j\lambda_j=1\big\}
\end{equation*}et $r(n,M)$ est le terme résiduel qu'on souhaite aussi petit que possible. On sera aussi intéressé par des résultats en espérance, càd des inégalités oracle du type:
\begin{equation}
  \label{eq:ineg-oracle-exp}
  \E R(\hat f_n)\leq \inf_{f\in {\rm conv}(F)}R(f)+r(n,M)
\end{equation}où l'espérance $\E$ est prise par rapport aux données $\cD$. La construction d'estimateur tels que (\ref{eq:ineg-oracle}) et/ou (\ref{eq:ineg-oracle-exp}) sont satisfaites avec un terme résidual $r(n,M)$ aussi petit que possible s'appele le probléme d'agrégation convexe. Il existe d'autres problèmes d'agrégation : faire mieux que le meilleur élément dans $F$, faire mieux que le meilleur élément dans l'espace linéaire engendré par $F$ etc.. Pour ce Projet Individuel, on s'interessera d'abord au problème d'agrégation convexe.  


\section{Vitesse optimale d'agrégation et minimiseur du risque empirique}
\label{sec:vitesse-opti}
Un exemple de méthode d'agrégation est le \textit{minimiseur du risque empirique} défini par:
\begin{equation}
  \label{eq:ERM}
  \hat f_n^{ERM}\in\argmin_{f\in\coF}R_n(f)
\end{equation}où $R_n(f)$ est le risque empirique de $f$ défini par 
\begin{equation}
  \label{eq:risque-empirique}
  R_n(f)=\frac{1}{n}\sum_{i=1}^n(f(X_i)-Y_i)^2.
\end{equation} L'objectif de ce PI est de montrer que cette méthode est optimale pour le problème d'agrégation convexe. On doit d'abord définir ce qui est entendu par optimal. On introduit ici une définition d'optimalité pour ce problème.



{\bf Définition.} {\it Soit $n$ (nombre d'observations) et $M$ (nombre d'éléments dans le dictionnaire) deux entiers. On dit que $\hat f_n$ est une \textbf{procédure optimale d'agrégation convexe} et que  $r(n,M)$ est une \textbf{vitesse optimale d'agrégation} quand il existe deux constantes absolues $c_0>0$ et $c_1>0$ telles que les deux points suivants sont vérifiés:
  \begin{itemize}
  \item Pour tout dictionnaire $F=\{f_1,\ldots,f_M\}$ de cardinal $M$ et tout couple $(X,Y)$ de variables aléatoires tels que $|Y|\leq b$ et $|f_j(X)|\leq b, \forall j=1,\ldots,M$ p.s., on a
    \begin{equation*}
      \E R(\hat f_n)\leq \min_{f\in\coF}R(f)+ c_0 r(n,M).
    \end{equation*}
\item Pour toute statistique $\tilde f_n$, il existe un dictionnaire $F=\{f_1,\ldots,f_M\}$ et un couple $(X,Y)$ de variables aléatoires tels que $|Y|\leq b$ et $|f_j(X)|\leq b, \forall j=1,\ldots,M$ p.s. et
    \begin{equation*}
      \E R(\tilde f_n)\geq \min_{f\in\coF}R(f)+ c_1 r(n,M).
    \end{equation*}
  \end{itemize}
  }
%\end{def}
On remarque que la vitesse optimale d'agrégation convexe est définie ici à une constante absolue prés. La théorie minimax nous apprend que la vitesse minimale d'agrégation convexe est donnée par 
\begin{equation}
  \label{eq:vitesse-optimale-convexe}
  \psi^{(C)}_{n,M}=\left\{
    \begin{array}{cc}
      \frac{M}{n} & \mbox{ quand } M\leq \sqrt{n}\\
      & \\
      \sqrt{\frac{1}{n}\log\Big(\frac{eM}{\sqrt{n}}\Big)} & \mbox{ sinon.}
    \end{array}
\right.
\end{equation} L'objectif de ce PI est de démontrer que le minimiseur du risque empirique défini en (\ref{eq:ERM}) atteint cette vitesse. C'est-à-dire que $\ERM$ vérfie une inégalité oracle comme (\ref{eq:ineg-oracle-exp}) où le terme résiduel est proportionnel à  $\psi^{(C)}_{n,M}$.

\begin{theorem}\label{theo:main}
  Il existe une constante absolue $c_0>0$ telle que pour tout $n\geq1$ et $M\geq1$, ce qui suit est vérifié. Pour tout dictionnaire $F$ de cardinal $M$ et tout couple $(X,Y)$ de variables aléatoires tels que $|Y|\leq b$ p.s. et $|f(X)|\leq b,\forall f\in F$ p.s., on a pour $\ERM$ le minimiseur du risque empirique sur $\coF$,
  \begin{equation*}
    \E R(\ERM)\leq \min_{f\in F}R(f)+c_0 b^2 \psi_{n,M}^{(C)}.
  \end{equation*}
\end{theorem}



On ne prouvera ce résultat que dans le cas (le plus intéressant) $M\geq\sqrt{n}$. Pour cela, on aura recours à un résultat sur les processus empiriques qu'on pourra admettre dans une première lecture et à la méthode de Maurey. C'est cette méthode qu'on introduit en premier lieu.

\section{La méthode empirique de Maurey}
\label{sec:Maurey}
La méthode empirique de Maurey a été introduite pour le calcul de l'entropie de la boule unité $B_1^d$ par rapport à la métrique euclidienne de $\R^d$. On rappelle ici ce calcul.

On commence par quelques notations. Les boules unités pour les normes $\ell_1^d$ et $\ell_2^d$ sont
\begin{equation*}
  B_1^d=\big\{x\in\R^d:\sum_{j=1}^M|x_j|\leq 1\big\} \mbox{ et } B_2^d=\big\{x\in\R^d:\sum_{j=1}^Mx_j^2\leq 1\big\}.
\end{equation*}Pour tout ensemble $T\subset\R^d$, on note par $N(T,\eps B_2^d)$ le plus petit nombre de translatés de $\eps B_2^d$ nécessaires pour recouvrir entièrement $T$. L'entropie de $T$ par rapport à $\ell_2^d$ est la fonction $\eps\longmapsto \log N(T,\eps B_2^d):=\cN(T,\eps,\ell_2^d)$. On va démontrer la proposition suivante (qui est optimale à des constantes absolues prés) par la méthode empirique de Maurey.

\begin{Proposition}\label{prop:entropieB1}
Il existe une constante absolue $c_0>0$ telle que pour tout $\eps>0$,
  \begin{equation*}
    \log N(B_1^d,\eps B_2^d)\leq c_0\left\{
      \begin{array}{cc}
        0   & \mbox{ si } \eps\geq1,\\
        \frac{1}{\eps^2}\log(d\eps^2) & \mbox{ si } d^{-1/2}\leq \eps\leq1,\\
        d \log\Big(\frac{e}{d\eps^2}\Big) & \mbox{ si } \eps\leq d^{-1/2}.
      \end{array}
\right.
  \end{equation*}  
\end{Proposition}


\begin{itemize}
\item[\bf{Q}1.1] Montrer le cas $\eps\geq1$.
\item[\bf{Q}1.2] Soit $x\in B_1^d$ et $ d^{-1/2}\leq \eps\leq1$. On veut montrer que $x$ est proche (au sens $\ell_2^d$) d'un sous-ensemble $\Lambda$ de $B_1^d$ dont le logarithme du cardinal est plus petit que $c_0 \eps^{-2}\log(d\eps^2)$. Pour cela, on utilise la méthode empirique de Maurey. On écrit $x=\sum_{j=1}^d x_j e_j$ où $(e_1,\ldots,e_M)$ est la base canonique de $\R^d$ et $\sum_{j}|x_j|\leq1$. On considère une variable aléatoire $Z$ à valeurs dans $\{0,\pm e_1,\ldots,\pm e_d \}$ telle que $\Pro[Z=0]=1-\norm{x}_1$ et $\Pro[Z={\rm sign}(x_i)e_i]=|x_i|$. Montrer que $\E Z=x$.
\item[\bf{Q}1.3] Soit $Z_1,\ldots,Z_p$ des variables aléatoires i.i.d. distribuées comme $Z$. Montrer que
  \begin{equation*}
    \E\norm{x-\frac{1}{m}\sum_{i=1}^m Z_i}_2^2=\frac{\E\norm{Z-\E Z}_2^2}{m}\leq \frac{4}{m}.
  \end{equation*}
\item[\bf{Q}1.4] En déduire que pour  $m_\eps$ le plus petit entier $m$ tel que $4/m\leq \eps^2$, l'ensemble 
  \begin{equation}
    \label{eq:Lambda}
    \Lambda:=\Big\{\frac{1}{m_\eps}\sum_{i=1}^{m_\eps} z_i:z_1,\ldots,z_{m_\eps}\in\{0,\pm e_1,\ldots,\pm e_d \}\Big\}
  \end{equation} est un $\eps$-réseau de $B_1^d$ pour $\ell_2^d$ (c'est-à-dire que pour tout $x\in B_1^d$ il existe $y\in \Lambda$ tel que $\norm{x-y}_2\leq \eps$).
\item[\bf{Q}1.5] Montrer que le cardinal de $\Lambda$ est tel que
  \begin{equation*}
    \log |\Lambda|\leq \frac{c_0}{\eps^2}\log(d\eps^2).
  \end{equation*}En déduire le cas $d^{-1/2}\leq \eps\leq1$ de Proposition~\ref{prop:entropieB1}.
\item[\bf{Q}1.6] Montrer que pour tout $\eps,\eta>0$, on a
  \begin{equation*}
    \log N(B_1^d,\eps B_2^d)\leq \log N(B_1^d,\eta B_2^d)+\log N(\eta B_2^d,\eps B_2^d).
  \end{equation*}
\item[\bf{Q}1.7] Par un argument volumique, montrer que
  \begin{equation}
    \label{eq:vol-argument}
    N(\eta B_2^d,\eps B_2^d)\leq \Big(1+\frac{2\eta}{\eps}\Big)^d.
  \end{equation}
\item[\bf{Q}1.8] Déduire le troisième cas de Proposition~\ref{prop:entropieB1} de Q1.7, Q1.6 et du deuxième cas.
\end{itemize}

\section{Un résultat sur les processus empirique}
\label{sec:resultat-processus}
On introduit quelques notations classique en apprentissage statistique. La fonction de perte quadratique d'une fonction $f:\cX\longmapsto\R$ est donnée par,
\begin{equation*}
  \ell_f(x,y)=(y-f(x))^2, \quad \forall x\in\cX, y\in \R.
\end{equation*} Le risque quadratique d'une fonction $f$ s'écrit alors $R(f)=\E\ell_f(X,Y)$.

Soit $f,g$ deux fonctions. On note par $[f,g]$ le ségment de $f$ à $g$.

\begin{itemize}
\item[\bf{Q}2.1] Montrer que $R(\cdot)$ atteint son minimum sur $[f,g]$.
\end{itemize}

Soit $f^*\in\argmin_{h\in[f,g]}R(h)$. Pour tout $h\in[f,g]$, on note par 
\begin{equation*}
  \cL_h(x,y)=\ell_h(x,y)-\ell_{f^*}(x,y), \quad \forall x\in\cX, y\in \R
\end{equation*}la \textit{fonction de perte en excés} de $h$. Par ailleurs, on note
\begin{equation}
  \label{eq:P_etP_n}
  P \cL_h=\E \cL_h(X,Y) \mbox{ et } P_n\cL_h=\frac{1}{n}\sum_{i=1}^n \cL_h(X_i,Y_i).
\end{equation}

On admettra le résultat suivant.

\begin{Proposition}
  \label{prop:isomorphy-segment}Il existe une constante absolue $c_0>0$ telle que ce quit suit a lieu. Pour tout $x>0$, avec probabilité plus grande que $1-4\exp(-x)$, pour tout $h\in[f,g]$,
\begin{equation*}
  \big|P\cL_h-P_n\cL_h\big|\leq \frac{1}{2}\max\big(P\cL_h,\frac{c_0xb^2}{n}\big).
\end{equation*}
\end{Proposition}

\section{Preuve du Théorème~\ref{theo:main} pour le cas $M\geq \sqrt{n}$}
\label{sec:preuve}
On considère l'entier 
\begin{equation*}
  m=\left\lceil\sqrt{\frac{n}{\log\big(eM/\sqrt{n}\big)}}\right\rceil
\end{equation*}et le sous-ensemble $\cC^\prime\subset \cC:=\coF$ défini par
\begin{equation*}
  \cC^\prime=\Big\{\frac{1}{m}\sum_{j=1}^m h_j:h_1,\ldots,h_m\in F\Big\}
\end{equation*}où, on rappelle que $F=\{f_1,\ldots,f_M\}$ est le dictionnaire.

\begin{itemize}
\item[\bf{Q}3.1] Montrer en utilisant la méthode de Maurey que
  \begin{equation*}
    \min_{f\in\cC^\prime}R(f)\leq \min_{f\in\cC}R(f)+\frac{4b^2}{m}.
  \end{equation*}Pour cela, on pourra introduire $f^*_\cC\in\argmin_{f\in\cC}R(f)$.
\item[\bf{Q}3.2] En utilisant la Proposition~\ref{prop:isomorphy-segment} et une ``union bound'', prouver que pour $N=|\cC^\prime|$ et $\cC^\prime=\{g_1,\ldots,g_N\}$ tel que $R(g_1)=\min_{g\in\cC^\prime}R(g)$, on a pour tout $x>0$, avec probabilité au moins $1-4\exp(-x)$, pour tout ségment $[g_1,g_j], j=1,\ldots,N$,
  \begin{equation}\label{eq:omega(x)}
    \big|P\cL_g^{1j}-P_n\cL_g^{1j}\big|\leq (1/2)\max\big(P\cL_g^{1j},\gamma(x)\big),\quad \forall g\in[g_1,g_j]
  \end{equation}où $\gamma(x)=c_0b^2(x+\log N)/n$ et $\cL^{1j}_g$ est la fonction d'excés de risque de $g$ par rapport au ségment $[g_1,g_j]$ (càd si $g^*_{1j}\in\argmin_{g\in[g_1,g_j]}R(h)$ alors $\cL_g^{1j}=\ell_g-\ell_{g^*_{1j}}$). On note par $\Omega(x)$ l'événement sur lequel (\ref{eq:omega(x)}) a lieu (pour tout $j$).
\end{itemize}



On fixe $X_1,\ldots,X_n$. On écrit $\ERM=\sum_{j=1}^M\beta_j f_j$ et on considère  $\Theta: \,\Omega^\prime\rightarrow F$ defini sur un autre espace de probabilité $(\Omega^\prime,\cA^\prime,\Pro^\prime)$ tel que $\Pro^\prime[\Theta=f_j]=\beta_j,\forall j=1,\ldots,M$ et on prend $m$ copies i.i.d.  $\Theta_1,\ldots,\Theta_m$ de $\Theta$. On note par $\E_\Theta^\prime$ l'espérance par rapport à $\Theta_1,\ldots,\Theta_m$ et par $\V_\Theta$ la variance par rapport à $\Theta$. 

\begin{itemize}
\item[\bf{Q}3.3] Montrer que   $\E_\Theta^\prime \Theta_j=\ERM$ pour tout $j=1,\ldots,m$ et en utilisant la méthode de Maurey que 
\begin{equation}
  \label{eq:Maurey-2}
  \E_\Theta^\prime R\Big(\frac{1}{m}\sum_{j=1}^m\Theta_j\Big)=R(\ERM)+\frac{\E\V_\Theta^\prime(Y-\Theta(X))}{m}.
\end{equation}Montrer que la méthode de Maurey fournit une preuve que, pour le risque empirique, on a aussi
\begin{equation}
  \label{eq:Maurey-3}
  \E_\Theta^\prime R_n\Big(\frac{1}{m}\sum_{j=1}^m\Theta_j\Big)=R_n(\ERM)+\frac{1}{m}\Big(\frac{1}{n}\sum_{i=1}^n\V_\Theta^\prime(Y_i-\Theta(X_i))\Big).
\end{equation}
\end{itemize}



On introduit la notation suivante:
\begin{equation*}
  g_\Theta=\frac{1}{m}\sum_{j=1}^m\Theta_j \mbox{ et } i_\Theta\in\{1,\ldots,N\} \mbox{ tel que } g_{i_\Theta}=g_\Theta.
\end{equation*}On remarque que $g_\Theta$ est un point aléatoire prenant ses valeurs dans $\cC^\prime$ (en tant que fonction mesurable de $\Omega^\prime$ dans $\cC^\prime$) et que sur l'événement $\Omega(x)$, on a la propriété d'isomorphie suivante sur le segment $[g_1,g_\Theta]$:
\begin{equation}
  \label{eq:iso-property-segments-Theta}
  \big|P_n\cL^{1i_\Theta}_g-P\cL^{1i_\Theta}_g\big|\leq (1/2)\max\big(P\cL^{1i_\Theta}_g,\gamma(x)\big), \quad \forall g\in[g_1,g_{i_\Theta}].
\end{equation}

\begin{itemize}
\item[\bf{Q}3.4] On fixe $\Theta_1,\ldots,\Theta_m$. En introduisant le risque de  
$$g^*_{1i_\Theta}\in\argmin_{g\in[g_{i_\Theta},g_1]} R(g),$$ montrer que 
\begin{equation}\label{eq:equa-2}
  R(\ERM)\leq \min_{f\in\cC}R(f)+\frac{4b^2}{m}+P\cL^{1 i_\Theta}_{g_\Theta}+R(\ERM)-R(g_\Theta).
\end{equation}
\item[\bf{Q}3.5] Montrer que sur l'événement   $\Omega(x)$, on a pour tout $\Theta_1,\ldots,\Theta_m$
\begin{align*}
    R(\ERM)\leq \min_{f\in\cC}&R(f)+\frac{4b^2}{m}+\gamma(x)\\
&+2\big(R_n(g_\Theta)-R_n(\ERM)\big)+R(\ERM)-R(g_\Theta).
\end{align*} 
\item[\bf{Q}3.6] En prenant l'espérance par rapport à  $\Theta_1,\ldots,\Theta_m$ (defini sur $\Omega^\prime$), montrer que sur $\Omega(x)$,
\begin{align*}
    R(\ERM)\leq \min_{f\in\cC}&R(f)+\frac{4b^2}{m}+\gamma(x)\\
&+2\E_\Theta^\prime\big(R_n(g_\Theta)-R_n(\ERM)\big)+\E_\Theta^\prime \Big(R(\ERM)-R(g_\Theta)\Big). 
\end{align*}
\item[\bf{Q}3.7] Démontrer le Théorème~\ref{theo:main} dans le cas $M\geq\sqrt{n}$. On montrera d'abord un résultat en déviation : pour tout $x>0$, avec probabilité plus grande que $1-4\exp(-x)$, 
  \begin{equation*}
    R(\ERM)\leq \min_{f\in \coF}R(f)+c_0b^2\max\Big(\sqrt{\frac{1}{n}\log\Big(\frac{eM}{\sqrt{n}}\Big)},\frac{ x}{n}\Big).
  \end{equation*}On concluera par intégration de ce résultat pour obtenir un résultat en espérance.
\end{itemize}




\begin{thebibliography}{1}

\bibitem{Lec20}
Guillaume Lecu{\'e}.
\newblock Empirical risk minimization is optimal for the convex aggregation
  problem.
\newblock To appear in Bernoulli journal, 2011.

\bibitem{TsyCOLT07}
Alexandre Tsybakov.
\newblock Optimal rate of aggregation.
\newblock In {\em Computational Learning Theory and Kernel Machines
  (COLT-2003)}, volume 2777 of {\em Lecture Notes in Artificial Intelligence},
  pages 303--313. Springer, Heidelberg, 2003.

\end{thebibliography}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage \setcounter{section}{0} \setcounter{equation}{0} \thispagestyle{empty} {\tt
  \noindent \'Ecole Polytechnique}\hfill{\tt Ann\'ee 2013-2014}
\hfill{\tt MAP433}\\
\hrule height .5pt \bigskip {\Large \centerline{\bf Projet 12 : La méthode EM ``Expectation-Maximization''} } \bigskip
\hrule height .5pt \bigskip
\begin{center} {responsable: Guillaume Lecué {\sf guillaume.lecue@cmap.polytechnique.fr}}
\end{center}

\bigskip
L'objectif de ce projet  est de présenter une méthode d'approximation de l'estimateur du maximum de vraisemblance dans le cas de données à valeurs manquantes et de mélanges.

Les estimateurs du maximum de vraisemblance (EMV) font vraisemblablement partie des méthodes statistiques les plus populaires pour l'analyse de données. Pour mettre en oeuvre une telle méthode,  une condition importante est de travailler avec une log-vraisemblance facile  à minimiser sur l'espace des paramétres. Cela implique de trés bonnes propriétés de la fonction de log- vraisemblance (comme de la convexité). Cependant, dans de nombreux problémes d'analyse de données, l'application du principe de maximum de vraisemblance conduit à des problémes numériques d'une grande complexité. De plus, la fonction de vraisemblance étudiée posséde souvent plusieurs extrema. Par conséquent, dans de nombreux cas, les EMV sont calculés grâce à des techniques d'optimisation numérique, statique, dynamique ou mélant les deux approches.

Un cas remarquable de calcul récursif des EMV est la méthode appelée \textbf{Expectation-Maximisation} (EM) (cf. \cite{Dempster} and \cite{McLachan}). Cette approche est privilégiée lorsque la difficulté pour obtenir des EMV provient de la présence de valeurs manquantes (encore appelées variables cachées ou latentes). Si les variables manquantes avaient été observées, l'estimation MV en aurait été largement simplifiée. Dans ce contexte, la méthode EM opére de maniére récursive. Chaque récursion consiste en une étape E dans laquelle on calcule l'espérance conditionnelle par rapport aux données inconnues, étant données les variables observées, et une étape M dans laquelle on maximise par rapport aux paramétres. La construction de l'algorithme est telle que l'on peut garantir qu'a chaque itération la valeur de la fonction de vraisemblance augmente. En raison de sa simplicité et de sa robustesse, la méthode EM est très largement employée, et bien qu'elle converge de maniére relativement lente, de nouvelles améliorations sont publiées régulièrement dans la littérature spécialisée.


\section{Construction de l'algorithme}
\label{sec:algo}
Le principe de l'algoritme EM repose sur une inégalité portant sur l'espérance conditionnelle de la log-vraisemblance de variables manquantes.  Nous présentons maintenant quelques éléments nécesaires à la compréhension de l'algorithme EM.

On se donne un modèle statistique d'estimation de densité à partir de données partiellement obervées. Soit $\{f(\cdot,p):p\in\cP\}$ un ensemble de densité (par rapport à la measure de Lebesgue) sur $\R^d$ où $\cP$ est un ensemble de paramétres. On suppose que $d=d_1+d_2$. On observe $X\in\R^{d_1}$ et on note par $X^m\in\R^{d_1}$ une valeur \textit{manquante} (non-observée) telle que $X^c=(X,X^m)$ est la valeur \textit{compléte}. C'est-à-dire $X^c$ est distribuée selon une certaine densité $f_{p^*}$ pour un certain  $p^*\in\cP$. On cherche à estimer le paramétre $p^*$ à partir de la donnée obervée $X$. 

Sous $p$ (càd quand $X^c$ est distribuée selon $f(\cdot,p)$), on note par $f_X(\cdot,p)$ une densité marginale de $X$ donnée pour Lebesgue presque tout $x\in\R^{d_1}$ par
\begin{equation*}
  f_X(x,p)=\int_{\R^{d_2}}f((x,x^m),p)dx^m.
\end{equation*}De même, on note $f_{X^m}(\cdot,p)$ une densité marginale de $X^m$ sous $p$. On rappelle aussi que des densités conditionelles de $X^m$ sachant $X$ et $X$ sachant $X^m$ sont données respectivement pour Lebesgue presque tout $x\in\R^{d_1}$ et $x^m\in\R^{d_2}$ par
\begin{equation*}
  f(x^m|x,p)=\frac{f((x,x^m),p)}{f_X(x,p)} \mbox{ et } f(x|x^m,p)=\frac{f((x,x^m),p)}{f_{X^m}(x^m,p)}.
\end{equation*}

\begin{Question}
  \textit{Soit $X^c=(X,X^m)$ une loi normale sur $\R^{d}$ (où
    $d=d_1+d_2$) de moyenne $\mu$ et de matrice de covariance $\Sigma$
    données par la décomposition en bloques selon $d=d_1+d_2$,
    \begin{equation*}
      \mu=\left(
        \begin{array}{c}
          \mu_1\\
          \mu_2
        \end{array}
      \right)  \mbox{ et } \Sigma=\left(
        \begin{array}{cc}
          \Sigma_{11} & \Sigma_{12}\\
          \Sigma_{12}^\top & \Sigma_{22}
        \end{array}
      \right).
    \end{equation*} On suppose que $\Sigma_{11}$ est inversible. Montrer que pour le paramètre $p=(\mu,\Sigma)$, la densité conditionalle de $X^m$ sachant $X=x$ (sous $p$), $x^m\mapsto f(x^m|x,p)$ est la densité d'une Gaussienne sur $\R^{d_2}$ de moyenne $\mu_2+\Sigma_{12}^\top\Sigma_{11}^{-1}(x-\mu_1)$ et de matrice de covariance $\Sigma_{22}-\Sigma_{12}^\top\Sigma_{11}^{-1}\Sigma_{12}$.}
  \end{Question}




La fonction de  log-vraisemblance pour une observation $x$ est donnée par : $p\in\cP\mapsto \log f_X(x,p)$. On se fixe une estimation a priori $p^{old}\in\cP$ du paramètre $p$ à estimer. On va mettre à jour récursivement le paramètre $p^{old}$. On rappelle que $x$ est connu et fixé. On peux alors donner une estimation de la densité conditionelle de $X^m$ sachant $X=x$  par $x^m\mapsto f(x^m|x,p^{old})$.

\begin{Question}
  \textit{On introduit les fonctions (qui dépendent de $x$)
    \begin{equation*}
      Q(p,p^{old})=\E \big[\log f(X^c,p)|X=x,p^{old}\big]=\int_{\R^{d_2}}\log f((x,x^m),p) f(x^m|x,p^{old})d x^m
    \end{equation*}et
    \begin{equation*}
      H(p,p^{old})=\E \big[\log f(X^m|x,p)|X=x,p^{old}\big]=\int_{\R^{d_2}}\log f(x^m|x,p) f(x^m|x,p^{old})d x^m.
    \end{equation*}Montrer que
    \begin{equation*}
      \log f_X(x,p)=Q(p,p^{old})-H(p,p^{old})
    \end{equation*}et, à l'aide des propriétés fondamentales de la divergence de Kullback-Laiber : 
    \begin{equation*}
      H(p^{old},p^{old})-H(p,p^{old})=-\int_{\R^{d_2}}f(x^m|x,p^{old})\log\Big(\frac{f(x^m|x,p)}{f(x^m|x,p^{old})}\Big)dx^m\geq0.
    \end{equation*}}
 \end{Question}



Par conséquent, si on est capable de trouver un paramètre $p^{new}$ tel que $Q(p^{new},p^{old})>Q(p^{old},p^{old})$ alors
\begin{equation*}
  \log f_X(x,p^{new})>\log f_X(x,p^{old})
\end{equation*}et donc on a réussi à augmenter la vraisemblance. Typiquement, $p^{new}$ sera choisi en maximisant $p\mapsto Q(p,p^{old})$. 

En résumant, la construction de l'algorithme EM est une succession d'itérations des deux étapes Expectation et Maximization 

\begin{itemize}
\item[\textbf{Etape E :}] Calculer $Q(p,p^{old})$.
\item[\textbf{Etape M :}] Calculer $p^{new}\in\argmax Q(p,p^{old})$.
\end{itemize}Une réitère en prenant $p^{new} \hookrightarrow p^{old}$. On augmente ainsi à chaque étape la log-vraisemblance du problème. Dans la plupart des cas, cette approche itérative converge vers un maximum global unique et permet ainsi d'obtenir un EMV. Toutefois, les itérations EM peuvent également se terminer sur un maximum local (d'où l'importance de ``bien'' choisir la valeur d'initialisation $p^{old}$), voire ne pas converger du tout.


% \section{Exemple~1 : lancer de deux pièces}
% \label{sec:pieces}
% \begin{figure}[htbp]
% \centering
%  \includegraphics[height=9cm]{AlgoEM-CoinFlipping.png}
%  \caption{Algorithmes EMV et EM pour le lancer de deux pièces.}
%  \label{fig:EM-lancer-piece}
% \end{figure}
% \textbf{Question~3 :} \textit{Expliquer, commenter et simuler l'exemple du lancer de pièces de la Figure~\ref{fig:EM-lancer-piece}.} 

\section{Exemple~1 : distribution exponentielle avec données censurées}
\label{sec:expo-donnee-censuree}
Les données censurées se rencontrent fréquemment en épidémiologie, et en particulier dans les études de survie (cf. \cite{cox}). On les retrouve également pour l'analyse de données issues d'instruments de mesure pour lesquels la gamme de mesure observables est trop limitée. 

Ici, on considère un variable aléatoire $T$ de loi exponentielle et de paramétre $a>0$. On rappelle que  $T$ admet une densité (par rapport à la mesure de Lebesgue) donnée par 
\begin{equation*}
  f(t,a)=\left\{
    \begin{array}{ccc}
      0 & \mbox{ si } t\leq0\\
      a \exp(-at) &\mbox{ si } t>0.
    \end{array}
\right.
\end{equation*}

\begin{Question}
  \textit{Monrer que $T$ est une variable aléatoire ``avec perte de
    mémoire'', c'est-à-dire : pour tout $s,t>0$,
    $\Pro[T>s+t|T>t]=\Pro[T>s]$.}
  \end{Question}


L'objectif est d'estimer le paramètre $a$ à partir d'un ensemble de $N$ observations, en tenant compte du fait qu'il existe un mécanisme de censure de seuil constant $C$ : si une mesure $T$ est plus grande que $C$ alors on ne connaÓt pas sa valeur, mais on sait seulement que le seuil a été dépassé. Supposons que les obervations $t_1,\ldots,t_k$ n'ont pas excédé le seuil et que $t_{k+1},\ldots, t_N$ sont au-dessus du seuil. Les informations disponibles sont donc $t_1,\ldots,t_k$ et $[t_{k+1},\ldots, t_N\geq C]$. L'information compléte est constituée par le vecteur $t^c=(t_1,\ldots,t_k,t_{k+1},\ldots,t_N)^\top$. 

\begin{Question}
  \textit{On se fixe une valeur d'initialisation $a^{old}$ de
    l'algorithme EM. Montrer que
    \begin{align*}
      Q(a,a^{old})&=\E\big[\log f(T^c,a)| t_1,\ldots,t_k,t_{k+1}\geq C,\ldots,t_N\geq C, a^{old}\big]\\
&=N \log a-a\Big[\sum_{i=1}^k t_i+(N-k)\Big(C+\frac{1}{a^{old}}\Big)\Big].
    \end{align*}En déduire que si $a^{new}$ maximise $a\mapsto Q(a,a^{old})$ alors
    \begin{equation*}
      a^{new}=\frac{N}{\sum_{i=1}^kt_i+(N-k)\Big(C+\frac{1}{a^{old}}\Big)}.
    \end{equation*} En déduire, que l'algo EM converge vers
    \begin{equation*}
      \hat a=\frac{k}{\sum_{i=1}^k t_i+(N-k)C}.
    \end{equation*} Montrer que $\hat a$ est l'EMV d'une expérience où les données observées sont $N$ variables aléatoires i.i.d. $X_1,\ldots,X_N$ distribuées comme $X=TI(T\leq C)+C I(T>C)$ et $k=|\{i:X_i\leq C\}|$.}
  \end{Question}



  \begin{Question}
    \textit{Montrer expérimentalement la convergence de l'algo EM pour
      ces données censurées. Estimer la vitesse de convergence en
      fonction du nombre d'itérations.}
 \end{Question}



\section{Exemple~2 : Modèle de mélange Gaussien}
\label{sec:melange-Gaussien}
Etant donné un ensemble de densités (appelées composantes du mélange) sur $\R^d$ noté $\{f_k(\cdot,p_k):k\in\{1,\ldots,K\},p_k\in\cP_k\}$ où pour tout $k=1,\ldots,K$, $\cP_k$ est un ensemble de paramétres indexant la $k$-ième composante $f_k(\cdot,p_k)$ du mélange. Un mélange étant une densité de la forme
\begin{equation}
  \label{eq:melange}
  f^{mix}(x,(\alpha_1,\ldots,\alpha_K,p_1,\ldots,p_K))=\sum_{k=1}^K\alpha_k f_k(x,p_k)
\end{equation}où $(\alpha_1,\ldots,\alpha_K,p_1,\ldots,p_K)$ est le paramétre de la loi composée. Les poids $\alpha_1,\ldots,\alpha_K$ sont non négatifs et somment à $1$, i.e. $\sum_{k=1}^K\alpha_k=1$. La pluspart du temps, les densités $f_x(\cdot,p_k)$ sont du même type (par exemple Gaussiennes - on parle alors de mélanges Gaussiens, etc.)

\begin{Question}
  \textit{Mettre en oeuvre une méthode de simulation d'un mélange
    Gaussien. Représenter graphiquement un mélange de 10 gaussiennes
    dans $\R^2$.}
\end{Question}


Supposons qu'un échantillon de taille $N$ soit tiré selon la distribution d'un mélange. Le calcul des paramétres $\alpha_1,\ldots,\alpha_K,p_1,\ldots,p_K$ pose typiquement des problèmes numériques.  L'algorithme EM propose une approche naturelle à ce problème. En effet, on suppose que l'information compléte est donnée par $x^c=k_1,\ldots,k_N, x_1,\ldots,x_N$; en d'autres termes, on fait l'hypothèse que l'on connaît l'indice $k_n$ de la composante $f_{k_n}(\cdot,p_{k_n})$ qui a permis de générer l'observation $x_n$. Avec cette information compléte, la log-vraisemblance s'écrit (pour l'information complète) :
\begin{equation*}
  \log f(x^c,p)=\sum_{n=1}^N \log\alpha_{k_n}+\sum_{n=1}^N \log f_{k_n}(x_n,p_{k_n}).
\end{equation*}
  
On a donc ainsi transformer un problème de calcul de l'EMV dans un modèle de mélange en un problème de données manquantes pour lequel on sait appliquer l'algorithme EM. On initialise le paramétre $p^{old}=(\alpha_1^{old},\ldots,\alpha_K^{old}, p_1^{old},\ldots, p_K^{old})^\top$. 

\textbf{Etape E :} On note par $x=(x_1,\ldots,x_N)$ l'information observée et par $x^m=(k_1,\ldots,k_N)$ l'information manquante.
\begin{Question}
\textit{  Montrer que
  \begin{equation*}
    Q(p,p^{old})=\sum_{n=1}^N\sum_{k=1}^K f(k|x_n,p^{old})\log \alpha_k+\sum_{n=1}^N\sum_{k=1}^K f(k|x_n,p^{old})\log f_k(x_n,p_k)
  \end{equation*}où $f(\cdot|x_n,p)$ est la densité conditionnelle de $k$ (l'indice de la densité, vu comme une variable aléatoire à valeurs dans $\{1,\ldots,K\}$) sachant qu'on a obervé $x_n$ sous $p$.}
\end{Question}



\textbf{Etape M :} On optimise l'expression $Q(p,p^{old})$ directement par rapport aux poids $\alpha_1,\ldots,\alpha_K$. 
\begin{Question}
 \textit{ Montrer que pour tout $k=1,\ldots,K$,
  \begin{equation*}
    \alpha_k^{new}=\frac{1}{N}\sum_{n=1}^N f(k|x_n,p^{old}).
  \end{equation*}}
\end{Question}


Les itérations ci-dessus pour les poids restent valides quelle que soit la forme des composantes du mélange. Pour l'estimation des paramétres $p_1^{new},\ldots,p^{new}_K$, on étudie le cas des mélanges Gaussiens sur $\R$. La $k$-ième composante Gaussienne $f_k(\cdot,(\mu_k,\sigma_k))$ est paramétrée par sa moyenne $\mu_k$ et sa variance $\sigma_k^2$.

\begin{Question}
  \textit{Montrer que la loi conditionelle de la donnée manquante
    $k=k_n$ par rapport à la donnée observée $x_n$ sous $p^{old}$ est donnée par
    \begin{equation*}
      f(k|x_n,p^{old})=\frac{(\alpha_k^{old}/\sigma^{old}_k)\exp\big[-(x_n-\mu_k^{old})^2/(2(\sigma_k^{old})^2)\big]}{\sum_{\kappa=1}^K(\alpha_\kappa^{old}/\sigma^{old}_\kappa)\exp\big[-(x_n-\mu_\kappa^{old})^2/(2(\sigma_\kappa^{old})^2)\big]}
    \end{equation*}où $p^{old}=(\alpha_1^{old},\ldots,\alpha_K^{old}, \mu_1^{old},\ldots,\mu_K^{old},\sigma_1^{old},\ldots,\sigma_K^{old})$. En déduire, que la maximisation par rapport aux $\mu_k,\sigma_k$ de $p\mapsto Q(p,p^{old})$ donne pour tout $k=1,\ldots,K$,
    \begin{equation*}
      \mu_k^{new}=\frac{\sum_{n=1}^N x_n f(k|x_n,p^{old})}{\sum_{n=1}^N f(k|x_n,p^{old})}
    \end{equation*}et 
    \begin{equation*}
      (\sigma_k^{new})^2=\frac{\sum_{n=1}^N (x_n-\mu_k^{new})^2f(k|x_n,p^{old})}{\sum_{n=1}^N f(k|x_n,p^{old})}.
    \end{equation*} Implémenter l'algorithme EM pour les mélanges Gaussiens sur $\R$. Représenter graphiquement l'évolution des itérations. Estimer l'erreur d'approximation $L_2$ entre le vrai mélange et le mélange estimé par l'algo EM}
\end{Question}

\begin{Question}
  Proposer un algorithme de ``Clustering'' à l'aide d'un modèle de mélange Gaussien et de la méthode EM. Etendre cette méthode sur $\R^2$ et simuler cette méthode de clustering. 
\end{Question}


\begin{thebibliography}{1}


\bibitem{Dempster}
Dempster, A. P., Laird, N. M. and Rubin, D. B.
\newblock   Maximum likelihood from incomplete data via the em algorithm (with discussion). 1977.
\newblock  J. R. Statist. Soc., Ser. B,
39:1-38.\texttt{ http://www.aliquote.org/pub/EM.pdf}.

\bibitem{McLachan}
McLachan, G. J. and Krishnan, T.
\newblock  The EM Algorithm and Extensions. 1997.  Wiley.

\bibitem{cox}
Cox, D. R. and Oakes, D.
\newblock Analysis of survival data. 1984.
\newblock Monographs on Statistics and Applied Probability, Chapman \& Hall, London.

\end{thebibliography}





\end{document}

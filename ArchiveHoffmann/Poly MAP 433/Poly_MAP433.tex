\documentclass[a4paper,11pt]{book}

\usepackage[applemac]{inputenc}
\usepackage[french]{babel}
\usepackage{amsfonts,a4wide,amsmath,amssymb,bbm,fancyhdr,makeidx,latexsym,amsthm,amsbsy,amscd,amstext}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{picins}
%\usepackage{showkeys}



\setlength{\parskip}{0.2cm}
%\setlength{\textwidth}{12.4cm}
\setlength{\textwidth}{360pt}
%\setlength{\textwidth}{14.3cm}
\setlength{\textwidth}{14.8cm}
%\setlength{\textheight}{19.3cm}
\setlength{\textheight}{20.4cm}
%\setlength{\textheight}{21.4cm}
\linespread{1}

\voffset = 1cm

\pagestyle{fancy}
% Ceci permet d’avoir les noms de chapitre et de section
% en minuscules
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{} % supprime les en-têtes et pieds prédéfinis
\fancyhead[LE,RO]{\bfseries\thepage}% Left Even, Right Odd
\fancyhead[LO]{\bfseries\rightmark} % Left Odd
\fancyhead[RE]{\bfseries\leftmark} % Right Even
\renewcommand{\headrulewidth}{0.5pt}% filet en haut de page
\addtolength{\headheight}{0.5pt} % espace pour le filet
\renewcommand{\footrulewidth}{0pt} % pas de filet en bas
\fancypagestyle{plain}{ % pages de tetes de chapitre
\fancyhead{} % supprime l’entete
\renewcommand{\headrulewidth}{0pt} % et le filet
}

\newtheorem{theoreme}{Th\'eor\`eme}[chapter]
\newtheorem{exemple}{Exemple}[chapter]
\newtheorem{definition}{D\'efinition}[chapter]
\newtheorem{hypothese}{Hypoth\`ese}[chapter]
\newtheorem{lemme}{Lemme}[section]
\newtheorem{remarque}{Remarque}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{exercice}{Exercice}[chapter]
\newtheorem{corollaire}{Corollaire}[chapter]

\DeclareMathOperator{\E}{{\mathbb E}}
\DeclareMathOperator{\F}{{\mathbb F}}
\DeclareMathOperator{\G}{{\mathbb G}}
\DeclareMathOperator{\D}{{\mathbb D}}
\DeclareMathOperator{\R}{{\mathbb R}}
\DeclareMathOperator{\C}{{\mathbb C}}
\DeclareMathOperator{\Z}{{\mathbb Z}}
\DeclareMathOperator{\N}{{\mathbb N}}
\DeclareMathOperator{\K}{{\mathbb K}}
\DeclareMathOperator{\T}{{\mathbb T}}
\DeclareMathOperator{\PP}{{\mathbb P}}
\DeclareMathOperator{\QQ}{{\mathbb Q}}
\DeclareMathOperator{\Q}{{\mathbb Q}}
\DeclareMathOperator{\IF}{{\mathbb I}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Pour le modèle linéaire

\DeclareMathOperator{\bX}{\boldsymbol{X}}
\DeclareMathOperator{\bY}{\boldsymbol{Y}}
\DeclareMathOperator{\bx}{\boldsymbol{x}}
\DeclareMathOperator{\vp}{\boldsymbol{p}}
\DeclareMathOperator{\vq}{\boldsymbol{q}}
\DeclareMathOperator{\estMC}{\widehat \vartheta_n^{\,\,{\tt mc}}}
\DeclareMathOperator{\estMCNL}{\widehat \vartheta_n^{\,\,{\tt mcnl}}}
\DeclareMathOperator{\estMV}{\widehat \vartheta_n^{\,\,{\tt mv}}}
\DeclareMathOperator{\design}{\mathbb{M}}
\DeclareMathOperator{\est}{\widehat \vartheta_{\mathnormal{n}}}
\DeclareMathOperator{\var}{\mathrm{Var}}
\DeclareMathOperator{\estMVc}{\widehat \vartheta_{n,0}^{\,{\tt mv}}}
\DeclareMathOperator{\Xbar}{\overline{\mathnormal{X}}_\mathnormal{n}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\cdot}{{\scriptstyle \bullet} }

\title{Introduction aux méthodes statistiques}
\author{Marc Hoffmann}
\date{Juin 2014}
\makeindex

\begin{document}

\frontmatter
\maketitle
\tableofcontents

\chapter*{Présentation du document}
Ces notes de cours présentent une introduction classique aux méthodes statistiques. Le terme \og statistique(s)\fg{}  reste souvent assez vague en mathématiques appliquées : il concerne aussi bien le traitement des bases de données
que l'utilisation de techniques numériques en modélisation stochastique (image, écono\-métrie et finance, physique, biologie) ;  dans ce cours, il désigne plutôt une {\it problématique} -- au sein de la théorie des probabilités -- qui consiste en l'étude d'objets mathématiques bien définis : les expériences statistiques.

Nous nous plaçons dans un cadre volontairement un peu abstrait, où l'on dispose d'une notion d'expérience statistique associée à une observation dans un modèle stochastique. Le but est de dégager des méthodes quantitatives basées sur des principes relativement généraux, qui permettent de \og retrouver \fg{} les paramètres d'un modèle et de \og prendre des décisions \fg{} à partir d'observations issues de ce modèle. Nous voulons quantifier l'erreur de reconstruction ou de décision dans un contexte (relativement) universel, de sorte que des problèmes issus de disciplines différentes puissent être traités de la même manière, en principe. Bien entendu, chaque discipline scientifique a sa spécificité, mais nous insisterons sur des méthodes communes -- par exemple le principe de maximum de vraisemblance ou la méthode des moindres carrés -- qui s'étudient de façon unifiée grâce à la théorie des probabilités.
\\

Nous supposons le lecteur familier avec le cours de MAP 311, et nous faisons référence tout au long de ces notes au polycopié de S. Méléard \cite{M}. On trouvera tous les compléments de probabilités éventuellement nécessaires dans le livre de J. Jacod et P. Protter \cite{JP} par exemple.

Le Chapitre 1 rappelle les principaux outils de probabilités, et insiste sur les notions fondamentales utiles en statistique :
vecteurs gaussiens (lois dérivées des vecteurs gaussiens) et théorèmes limites (modes de convergence et théorème central-limite). Il permet aussi de fixer les notations utilisées dans ce cours.

Le Chapitre 2 présente la notion formelle d'expérience statistique accompagnée des exem\-ples essentiels que sont les modèles d'échantillonnage ou de densité, et les modèles de régression.

Le Chapitre 3 étudie le modèle d'échantillonnage dans sa plus grande généralité. Nous nous posons une question apparemment naïve : si l'on observe (la réalisation) de $n$ variables aléatoires réelles indépendantes de même loi inconnue,  que peut-on dire de cette loi ? Ceci nous permet de poser les jalons des méthodes développées dans les chapitres suivants : estimation, régions et intervalles de confiance, tests, lorsque le nombre d'observations $n$ est fixé ou bien dans la limite $n \rightarrow \infty$. Le modèle est très simple d'un point de vue probabiliste (les observations sont indépendantes et identiquement distribuées), mais très ardu d'un point de vue statistique, puisque l'on ne fait pas d'hypothèse sur la loi inconnue, et nous verrons très vite les limites de cette généralité.

Les Chapitres 4 et 5 sont consacrés aux méthodes classiques de construction d'estimateurs pour les modèles paramétriques, lorsque la loi inconnue est décrite par un paramètre de dimension finie. On se place dans les modèles de densité et régression, et on construit les estimateurs par moments, les $Z$- et $M$- estimateurs, l'estimateur du maximum de vraisemblance et l'estimateur des moindres carrés.

Le Chapitre 6 développe -- dans le modèle de densité par souci de simplicité -- différentes notions de comparaison d'estimateurs et la recherche d'un estimateur optimal associé à une expérience statistique. C'est un problème ancien qui remonte au programme de Fisher des années 1920, et qui n'a pas de solution totalement satisfaisante : un estimateur optimal dans un sens naïf n'existe pas, il faut faire des concessions. Si l'on suppose suffisamment de régularité (dans ce cours, nous ne rechercherons pas les hypothèses minimales), on peut néanmoins réaliser un programme d'optimalité asymptotique que nous présenterons brièvement, reposant sur le principe du maximum de vraisemblance. Il est associé à une quantité intrinsèque au modèle, l'information de Fisher, que nous étudierons en tant que telle.

Curieusement, la notion de modèle régulier en statistique est limitative : nous verrons sur des exemples que l'on estime souvent \og mieux \fg{} des paramètres dans des modèles irréguliers. Mais un traitement systématique est plus difficile.

Les Chapitres 7 et 8 sont consacrés aux tests statistiques -- dans un cadre non-asymptotique, puis asymptotique -- et leur lien canonique avec les intervalles et régions de confiance. Si l'on accepte un certain principe (dit de Neyman) qui hiérarchise les erreurs de décision que l'on commet lorsque l'on fait un test, alors on peut dans certains cas donner une solution optimale au problème de test. On abordera les tests classiques paramétriques (Neyman-Pearson, Wald) et le test d'adéquation du $\chi^2$, incontournable en pratique.

{\large {\bf Les paragraphes suivis d'une étoile$^\star$ pourront être omis en première lecture}}.

Les exercices à la fin de certains chapitres sont souvent des compléments techniques de certains aspects du cours et sont en général moins fondamentaux que les exercices proposés en P.C.\\

Faute de place et de temps, certains thèmes essentiels ne sont pas abordés : l'approche bayésienne, la statistique computationnelle (algorithmique statistique, bootstrap). Par ailleurs,  l'estimation non-paramétrique et ses applications en débruitage de signal ou d'image ainsi que l'apprentissage et la classification font l'objet du cours de MAP 533 d'A. Tsybakov. Nous donnons à la fin de ce polycopié quelques indications et références bibliographiques. \vspace{2mm}\\

Il existe par ailleurs de nombreux ouvrages qui traitent de méthodes statistiques au niveau où nous nous plaçons. Ils font toujours un compromis (au prix de sacrifices) entre rigueur mathématique et clarté des idées : citons deux livres emblématiques dont nous nous sommes largement inspirés : \og All of Statistics \fg{} de L. Wasserman \cite{W} qui présente beaucoup d'idées sans preuve rigoureuse et \og Statistical Mathematics \fg{} de A.A. Borovkov \cite{B}, qui développe de façon systématique la théorie et qui reste un grand classique du genre. De nombreux polycopiés sur le sujet circulent\footnote{Citons les polycopiés et les notes de cours de  Dominique Picard de l'Université Paris Diderot, et d'Alexandre Tsybakov de l'Université Pierre et Marie Curie, auquels nous avons fait de nombreux emprunts.} également. %Enfin, ce polycopié repose en grande partie sur le matériel des enseignements de statistique -- au niveau Master -- de Paris 7.\\
Enfin, un cours de statistique, même mathématique, ne se passe pas de {\tt données} ou de simulations. L'accès à des quantités astronomiques de {\tt données} est devenu facile aujourd'hui : par exemple
({\tt www.stat.cmu.edu/$\sim$larry/all-of-statistics})
qui fournit les {\tt données} traitées dans les exemples du livre  la page de L. Wasserman \cite{W}. Pour des {\tt données} financières, économi\-ques ou démogra\-phiques, ({\tt www.economy.com/freelunch/}) ou le site de l'INSEE ({\tt www.insee.fr}).\\


Finalement, je tiens à remercier chaleureusement Mathieu Rosenbaum dont la lecture attentive a permis d'améliorer significativement une première version de ce cours, ainsi que les élèves et collègues dont les nombreuses remarques ont permis d'affiner la présentation de ces notes.





\mainmatter

\part{Modélisation statistique}



\chapter{Outils de probabilités} \label{chapitre 1}

Nous considérons des variables aléatoires à valeurs réelles ou vectorielles,
discrètes ou de loi absolument continue. On envisagera (superficiellement) des cas plus complexes de mélanges de lois discrètes et continues.
\section{Loi d'une variable aléatoire réelle}
On désigne par $(\Omega, {\mathcal A}, \mathbb{P})$ un espace de probabilités. Les points $\omega \in \Omega$ s'interprètent comme les résultats d'une expérience aléatoire. Les objets d'intérêt sont les événements, c'est-à-dire les éléments de la tribu ${\mathcal A}$.  Une variable aléatoire réelle est une application mesurable
$$X: (\Omega, {\mathcal A}) \longrightarrow (\mathbb{R}, {\mathcal B}),$$ où ${\mathcal B}$ est la tribu borélienne sur $\mathbb{R}$.

\begin{definition} La fonction de répartition de la variable aléatoire réelle $X$ est l'application $F: \mathbb{R}\rightarrow [0,1]$ définie par
$$F(x)=\mathbb{P}\big[X \leq x\big] = \mathbb{P}\big[\omega \in \Omega,\;X(\omega) \leq x\big],\;\;\;x\in \mathbb{R}.$$
\end{definition}
La fonction $F$ est croissante, continue à droite, tend vers $0$ en $-\infty$ et vers $1$ en $+\infty$.
%$$\lim_{x\rightarrow -\infty}F(x)=0,\;\;\text{et}\;\; \lim_{x \rightarrow +\infty}F(x)=1.$$
Pour tout réel $x$,
$$\mathbb{P}\big[X=x\big] = F(x) - F(x-).$$
%En particulier, si $F$ est continue au point $x$, on a $\mathbb{P}\big[X=x\big]=0$.
La loi d'une variable aléatoire désigne d'habitude la mesure image de $\mathbb{P}$  par $X$ sur $(\mathbb{R}, {\mathcal B})$, notée $\PP^X$ et définie par
$$\mathbb{P}^X(A)=\mathbb{P}[X \in A],\;\;\;A \in {\mathcal B}(\mathbb{R}).$$
Puisque la fonction de répartition $F$ caractérise $\mathbb{P}^X$ (voir Méléard \cite{M}, Proposition 4.2.3 p. 71), on peut parler indifféremment de $F$ ou de $\mathbb{P}^X$ pour désigner la loi de $X$.
\begin{definition}
On appelle loi ou distribution de $X$ la donnée de $F$. \index{loi} \index{distribution}
\end{definition}
\subsection{Variables discrètes}
Une variable aléatoire réelle $X$ est discrète si elle prend un ensemble de valeurs au plus dénombrable $\{x_i, i \in \mathbb{N}\}\subset \mathbb{R}$. La donnée des $\big\{\big(x_i, \mathbb{P}[X_i=x_i]\big), i \in \mathbb{N}\big\}$ détermine entièrement $F$ (et donc caractérise la loi de $X$).
\begin{remarque}
\emph{
Si les $x_i$ sont isolés (par exemple si $X$ est à valeurs dans $\mathbb{N}$ ou $\mathbb{Z}$), la fonction de répartition $F$ de $X$ est constante par morceaux, et les points de discontinuité de $F$ sont les points $x_i$. De plus,
$$\mathbb{P}\big[X=x_i\big] = F(x_i)-F(x_i-) ,\;\;i \in \mathbb{N}.$$
}
\end{remarque}
\begin{exemple}
\emph{
\begin{enumerate}
\item Une variable aléatoire $X$ suit la loi de Bernoulli \index{Bernoulli, loi de} de paramètre $p \in [0,1]$  si
$$\PP\big[X=1\big] = p =1- \PP\big[X=0\big].$$
Dans ce cas
$$F(x) = p 1_{[0,1)}(x) + 1_{[1,+\infty)}(x),\;\;x \in \mathbb{R}.$$
\item Une variable aléatoire $X$ suit la \index{binomiale, loi} loi binomiale de paramètres $(n,p)$ avec $p\in [0,1]$ et $n \in \mathbb{N}\setminus\{0\}$ si
$$\PP\big[X=k\big] = C_n^k\,p^k(1-p)^{n-k},\;\;\;\;k = 0,\ldots, n.$$
Dans ce cas\footnote{avec la convention $\sum_\emptyset = 0$.}
$$F(x) = \sum_{k \leq x} C_n^k\,p^k(1-p)^{n-k},\;\;x \in \mathbb{R}.$$
\item Une variable aléatoire $X$ suit la \index{Poisson, loi de} loi Poisson de paramètre $\lambda >0$,
% notée  ${\mathcal P}(\lambda)$,
si
$$\PP\big[X=k\big] = e^{-\lambda}\tfrac{\lambda^k}{k!},\;\;\;\;k \in \mathbb{N}.$$
Dans ce cas,
$$F(x) = e^{-\lambda}\sum_{k \leq x}\frac{\lambda^k}{k!},\;\;x \in \mathbb{R}.$$
\end{enumerate}
}
\end{exemple}

\subsection{Variables de loi absolument continue}
Une variable aléatoire réelle $X$ est de loi absolument continue (ou à densité) si sa fonction de répartition s'écrit
$$F(x) = \int_{(-\infty,x]} f(t)dt,\;\;x \in \mathbb{R}$$
où $dt$ désigne la mesure de Lebesgue sur\footnote{Comprendre ici et dans toute la suite \og la mesure de Lebesgue sur $(\R,{\mathcal B})$ \fg{}. Idem pour la mesure de Lebesgue sur $\R^n$, c'est-à-dire sur $(\R^n, {\mathcal B}^n)$, où ${\mathcal B}^n$ est la tribu des boréliens de $\R^n$.} $\mathbb{R}$. La fonction $f$, définie à un ensemble négligeable près, est une densité de probabilité :
$$f\geq 0\;\;\;\text{et}\;\;\;\int_{\R}f(t)dt=1.$$
Dans ce cas, la fonction de répartition $F$ de $X$ est différentiable presque-partout et on a
 $$F'(x) = f(x)\;\;\;\text{presque-partout}.$$
Si elle existe, la densité d'une variable aléatoire détermine entièrement sa fonction de répartition $F$, et donc caractérise sa loi. La loi d'une variable absolument continue est diffuse : pour tout $x\in \R$, on a $\PP\big[X=x\big]=0$.

\begin{exemple}
\emph{
 \begin{enumerate}
 \item Une variable aléatoire $X$ suit la \index{uniforme, loi} loi uniforme sur $[a,b]$, avec $a<b$,
 %notée ${\mathcal U}(a,b)$
 si elle admet pour densité
 $$f(t) = \frac{1}{b-a}1_{[a,b]}(t).$$
 Dans ce cas
 $$F(x) =
 \left\{
\begin{array}{clc}
0 & \text{si} & x < a \\
\displaystyle \frac{x-a}{b-a} & \text{si} & x \in [a,b] \\
1 & \text{si} & x > b.
\end{array}
 \right.
 $$
 \item Une variable aléatoire suit la \index{exponentielle, loi} loi exponentielle de paramètre $\lambda >0$,
 %notée ${\mathcal E}(\lambda)$
 si elle admet pour densité
 $$f(t) = \lambda e^{-\lambda t}1_{[0,+\infty)}(t).$$
 Dans ce cas,
 $$F(x) =
 \left\{
\begin{array}{ll}
0 & \text{si} \;\; x < 0 \\
 1-e^{-\lambda x} & \text{sinon} .
 \end{array}
 \right.
 $$
\item Une variable aléatoire suit la \index{gaussienne, normale, loi} loi normale de moyenne $\mu \in \mathbb{R}$ et de variance $\sigma^2 >0$, notée ${\mathcal N}(\mu, \sigma^2)$ si elle admet pour densité
$$f(t) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right).$$
Dans ce cas,
$$F(x) = \Phi\left(\frac{x-\mu}{\sigma}\right),\;\;x \in \mathbb{R},$$
où
$$\Phi(x) = \int_{-\infty}^x e^{-t^2/2}\frac{dt}{\sqrt{2\pi}}.$$
\end{enumerate}
}
\end{exemple}
\subsection{Formules d'intégration}
Si $X$ est une variable aléatoire réelle de loi $F$ (ou encore $\mathbb{P}^X$), on a, pour toute fonction test\footnote{Dans toute la suite, une fonction test désignera une fonction borélienne positive (ou intégrable, ou bornée) de sorte que les formules d'intégration associées soient bien définies.}
$\varphi$,
\begin{equation} \label{formule mesure image}
\mathbb{E}\big[\varphi(X)\big] = \int_{\Omega}\varphi\big(X(\omega)\big)\mathbb{P}(d\omega) = \int_{\mathbb{R}}\varphi(x)\PP^X(dx)
\end{equation}
(voir Méléard s\cite{M}, Proposition 4.5.1 p. 85), dès que la fonction $\omega \leadsto \varphi\big(X(\omega)\big)$ est intégrable par rapport à la mesure $\mathbb{P}(d\omega)$.
On écrit aussi
$$\int_{\mathbb{R}}\varphi(x)\mathbb{P}^X(dx) = \int_{\mathbb{R}}\varphi(x)dF(x).$$
\begin{remarque}
\emph{
La mesure $\mathbb{P}^X(dx)$, définie sur $\mathbb{R}$ peut être construite à partir de la fonction de répartition $F$. Pour cela, on pose
$$\mathbb{P}^X\big[(a,b]\big]=F(b)-F(a),\;\;\;\text{pour tous}\;\;a<b\;\;\text{réels},$$
et ce qui définit $\mathbb{P}^X$ sur un sous-ensemble de ${\mathcal B}$. Le prolongement à ${\mathcal B}$ en entier se fait à l'aide du théorème de la classe monotone (voir par exemple Jacod et Protter, \cite{JP}).
}
\end{remarque}
\subsubsection{Cas discret}
Si $X$ est discrète, prenant ses valeurs dans un ensemble $\{x_i,\,i \in \mathbb{N}\} \subset \R$ de points isolés,  $F$ est constante par morceaux, et ses discontinuités ont lieu aux points $x_i$ où ses sauts sont d'amplitude $\mathbb{P}[X=x_i]>0$, et
$$
\int_{\mathbb{R}}\varphi(x)dF(x) = \sum_{i \in \mathbb{N}}\varphi(x_i)\mathbb{P}[X=x_i].
$$
\subsubsection{Cas continu}
Si $X$ est (de loi) absolument continue de densité $f$, on a
$$
\int_{\mathbb{R}}\varphi(x)dF(x) = \int_{\mathbb{R}}\varphi(x)f(x)dx,
$$
ce qui est cohérent du point de vue des notations avec la propriété  $F'(x) = f(x)$ presque-partout.
\subsubsection{Mélange de lois discrètes et continues} \label{melange}
Une variable aléatoire réelle n'est par exclusivement discrète ou (de loi) absolument continue.
\begin{exemple}
\emph{
Soit $X$ une variable aléatoire réelle de loi ${\mathcal N}(0,1)$. La variable
$$Y = X1_{X \geq 0}$$ n'est ni discrète, ni continue: elle n'est pas discrète puisqu'elle peut prendre toutes les valeurs positives, mais elle n'est pas (de loi) absolument continue puisque
$$\mathbb{P}[Y=0] = \tfrac{1}{2} \neq 0.$$
\\
La fonction de répartition de $X$ s'écrit
$$F(x) = \tfrac{1}{2}\,1_{x \geq 0} + \Big(\int_0^x \exp(-t^2/2)\frac{dt}{\sqrt{2\pi}}\Big)\,1_{x \geq 0},$$
et on a\footnote{On peut aussi écrire la loi de $X$ de la façon suivante
$$\mathbb{P}^X(dx) = \tfrac{1}{2}\delta_0(dx)+\tfrac{1}{\sqrt{2\pi}}e^{-x^2/2}1_{x \geq 0}dx,$$
où $\delta_0(dx)$ désigne la mesure de Dirac au point $0$ et $dx$ désigne la mesure de Lebesgue sur $\mathbb{R}$. Le contexte dictera le choix des notations.
}
pour toute fonction test $\varphi$,
$$\mathbb{E}\big[\varphi(X)\big]  = \int_{\mathbb{R}}\varphi(x)dF(x) = \tfrac{1}{2}\varphi(0)+\int_{0}^{+\infty}\varphi(t)\exp(-t^2/2)\frac{dt}{\sqrt{2\pi}}.$$
 }
\end{exemple}
\begin{remarque}
\emph{
La loi d'une variable aléatoire peut être discrète, absolument continue, ou bien encore avoir une partie discrète et une partie absolument continue, comme dans les exemples ci-dessus. Attention : ceci n'épuise pas toutes les possibilités !
%{\tt en dire plus.}
}
\end{remarque}

\section{Paramètres de position} \label{parametres de position}
Etant donnée une variable aléatoire réelle, on cherche une description de sa loi à l'aide d'indicateurs déterministes les plus simples possible.
On utilise souvent en première approximation quatre indicateurs (s'ils existent) basés sur les quatre premiers moments (à normalisation affine près) qui sont la moyenne, la variance, le coefficient d'asymétrie -- ou skewness -- et le coefficient d'aplatissement -- ou kurtosis.

Un autre type d'approximation se base sur les quantiles de la loi considérée, qui mesurent dans un certain sens la dispersion de la loi. Plus difficiles à manipuler, ils présentent l'avantage d'être toujours définis.

\subsection{Espérance-variance}
%\begin{definition}
Une variable aléatoire réelle $X$ admet un moment d'ordre $p \in \mathbb{N}\setminus{0}$ si
$$\mathbb{E}\big[|X|^p\big] = \int_{\Omega}|X(\omega)|^p\,\mathbb{P}(d\omega)<+\infty.$$
Dans ce cas, son moment d'ordre $p$ est
$$\mathbb{E}\big[X^p\big] =  \int_{\Omega}X(\omega)^p\,\mathbb{P}(d\omega).$$
%\end{definition}
\begin{definition}
La moyenne ou espérance $\mu_X$, si elle existe, est le moment d'ordre 1 de la variable aléatoire $X$:
$$\mu_X = \mathbb{E}\big[X\big]$$
% = \int_{\mathbb{R}} x\, dF_X(x) =
%\left\{
%\begin{array}{ll}
 %\sum_{i \in \mathbb{N}}x_i \mathbb{P}[X=x_i] & \text{si}\;X\;\text{est discrète} \\ \\
 %\int_{\mathbb{R}} x\,f_X(x)dt & \text{si}\;X\;\text{est continue},
%\end{array}
%\right.$$
 \index{espérance} \index{moyenne}
 La \index{variance} variance $\mathrm{Var}[X]$ (encore notée $\sigma^2_X$) de $X$,  si elle existe, est le moment d'ordre 2 recentré de $X$ :
$$\sigma_X^2 = \mathrm{Var}[X] = \mathbb{E}\big[(X-\mu_X)^2\big] = \int_{\mathbb{R}}(x-\mu_X)^2 dF(x).$$
La racine carrée de la variance $\sigma_X = (\mathrm{Var}[X])^{1/2}$ s'appelle \index{écart-type} l'écart-type de $X$.
\end{definition}
Le calcul effectif des moments se fait en utilisant la loi de $X$. Par exemple :
$$
\mathbb{E}\big[X^p\big] = \int_{\mathbb{R}} x^p\, dF(x) =
\left\{
\begin{array}{ll}
 \sum_{i \in \mathbb{N}}x_i^p\, \mathbb{P}[X=x_i] & \text{si}\;X\;\text{est discrète} \\ \\
 \int_{\mathbb{R}} x^p\,f(x)dx & \text{si}\;X\;\text{est continue}.
\end{array}
\right.
$$
La moyenne $\mu_X$ fournit la meilleure prédiction de $X$ par une constante dans le sens suivant :
\begin{proposition} \label{caracterisation moyenne}
Si $X$ admet un moment d'ordre 2, alors
$$\mathbb{E}\big[(X-\mu_X)^2\big] = \min_{c \in \mathbb{R}}\mathbb{E}\big[(X-c)^2\big].$$
\end{proposition}
\begin{proof}
On a, pour tout réel $c$,
$\mathbb{E}\big[(X-c)^2\big] = \big(\mathbb{E}\big[X\big]-c\big)^2+\text{Var}[X]$.
\end{proof}
Le couple espérance-variance fournit un indicateur très  simple pour contrôler les fluctuations de $X$ autour de sa moyenne $\mu_X$ via \index{Tchebychev, inégalité de} l'inégalité de Tchebychev:
\begin{equation} \label{tchebychev}
\mathbb{P}\big[|X-\mu_X|\geq t\big] \leq \frac{\sigma_X^2}{t^2},\;\;t > 0.
\end{equation}

\subsubsection{Famille de dilatation-translation associée à une loi}
Si $X$ a un moment d'ordre $2$, écrivons la décomposition
$X = m_X + \sigma_X \xi$
où $\xi$ est centrée-réduite, c'est-à-dire
$$\mathbb{E}[\xi] = 0,\;\;\text{et}\;\;\text{Var}[\xi] = \mathbb{E}[\xi^2]=1.$$ Alors, avec des notations évidentes,
$$F_X(x) = F_\xi\left(\frac{x-m_X}{\sigma_X}\right),\;\;x\in \R$$
et si $X$ est (de loi) absolument continue, sa densité s'écrit
$$f_X(x) = \frac{1}{\sigma_X}f_\xi\left(\frac{x-m_X}{\sigma_X}\right),\;\;x \in \R.$$
Plus généralement, étant donné une loi $F$, on peut considérer la famille de lois
%$(F_{\mu, \sigma}, \mu \in \mathbb{R}, \sigma >0)$
définies par
$$F_{\mu,\sigma}(x) = F\left(\frac{x-\mu}{\sigma}\right),\;\;x \in \mathbb{R},\;\; \mu \in \mathbb{R},\;\; \sigma >0.$$
Les paramètres $\mu$ et $\sigma$ jouent respectivement les rôles de localisation (ou translation, ou position) et de  dilatation (ou d'échelle).
 \begin{remarque}
\emph{
Pour définir une famille de translations-dilatations associée à une loi $F$, il n'est pas nécessaire que cette loi admette un moment d'ordre 1 ou 2.
}
\end{remarque}

\subsection{Coefficients d'asymétrie et d'aplatissement}
Le \index{asymétrie, skewness}coefficient d'asymétrie (skewness) et le \index{aplatissement, kurtosis}coefficient d'aplatissement (kurtosis) correspondent, à normalisation par la moyenne et la variance près, aux moments d'ordre $3$ et $4$ respectivement.
\subsubsection{Asymétrie (skewness)}
\begin{definition} \label{def loi symetrique}
La loi de $X$ est symétrique par rapport à $\mu \in \R$ si
$$\forall x \in \R,\;\;\;F(\mu+x) = 1-F(\mu-x)$$
où $F$ est la fonction de répartition de $X$.
%, ce qui s'exprime encore de la façon suivante
%$$\forall x \in \R,\;\;\PP\big[X \leq \mu+x\big] = \PP\big[X \leq \mu-x\big].$$
\end{definition}
Dans le cas absolument continu, si $f$ est la densité de $X$, cela entraîne
$$f(\mu+x) = f(\mu-x)\;\;\;\;\text{presque-partout}.$$
On dit qu'une loi est symétrique  si elle est symétrique par rapport à $0$.
%\begin{exercice}
%\emph{
%Si $X$ admet nu moment d'ordre 1 et et symétrique par rapport à $\mu$, sa moyenne et sa médiane sont égale à $\mu$.
%}
%\end{exercice}

Si $X$ admet un moment d'ordre 3, on introduit une mesure \og d'éloigne\-ment \fg{}  aux distributions symétriques de la manière suivante
\begin{definition} Le coefficient d'asymétrie (skewness) d'une variable aléatoire réelle $X$ telle que $\E\big[|X|^3\big]<+\infty$ est
$$\alpha\big[X\big]=\frac{\E\big[\big(X-\E[X]\big)^3\big]}{\sigma_X^3}.$$
\end{definition}
Le coefficient d'asymétrie est une mesure grossière de symétrie : si la loi de $X$ est symétrique, alors $\alpha\big[X\big]=0$. Mais avoir $\alpha\big[X\big] = 0$ ne signifie pas que la loi de $X$ est symétrique.
%exo contre eg
\begin{remarque}
\emph{
Le coefficient $\alpha \big[X\big]$ est invariant par dilatation-translation : pour tout $\mu \in \R$ et pour tout $\sigma >0$, on a
$$\alpha \big[\mu+\sigma X\big] = \alpha \big[X \big].$$
}
\end{remarque}
%Avoir $\alpha(X)$
\subsubsection{Aplatissement (kurtosis)}
\begin{definition}
Le coefficient d'aplatissement (kurtosis) d'une variable aléatoire réelle $X$ telle que $\E\big[X^4\big]<+\infty$ est
$$\kappa\big[X\big] = \frac{\E\big[\big(X-\E[X]\big)^4\big]}{\sigma_X^4}-3.$$
\end{definition}
Le coefficient d'aplatissement est une mesure grossière de l'écartement de la loi de $X$ à la loi gaussienne en terme de queues de distribution, c'est-à-dire du comportement de
$$\PP\big[|X|\geq x\big]\;\;\text{au voisinage de}\;\;x \rightarrow +\infty.$$

Si $X \sim {\mathcal N}(0,1)$, on a $\kappa(X) = 0$. Lorsque $\kappa\big[X\big] <0$ on dit que les queues de distribution de la loi de $X$ sont plus légères que les queues gaussiennes, alors qu'elles sont plus lourdes lorsque $\kappa\big[X\big] >0$. Par l'inégalité de Cauchy-Schwarz, on a toujours $\kappa\big[X\big] \geq -2$.
\begin{remarque}
\emph{
Comme pour le coefficient d'asymétrie, le coefficient d'aplatissement est invariant par dilatation-translation :  pour tout $\mu \in \R$ et pour tout $\sigma >0$, on a
$$\kappa\big[\mu+\sigma X\big] = \kappa\big[X\big].$$
}\end{remarque}

\subsection{Quantiles} \label{quantiles}
Si $X$ est une variable aléatoire réelle dont la fonction de répartition $F$ est continue et strictement croissante, le \index{quantile} quantile d'ordre $p$, $0 < p < 1$, de la loi $F$ est défini comme l'unique solution $q_p$ de l'équation
\begin{equation} \label{def quantile}
F(q_p) = p.
\end{equation}
On a, par construction, la propriété caractéristique
$$\mathbb{P}\big[X \leq q_p\big] = p.$$
Si $F$ n'est pas strictement croissante ou n'est pas continue, il se peut que \eqref{def quantile} n'ait pas de solution ou bien ait une infinité de solutions. On peut alors modifier la définition \eqref{def quantile} de la façon suivante.

\begin{definition} Le quantile $q_p$ d'ordre $p$, $0 < p < 1$ de la loi $F$ est la quantité
$$q_p = \tfrac{1}{2}\big(\inf\{x,\;F(x)>p\}+\sup\{x,\;F(x) < p\}\big).$$
\end{definition}
Si $\eqref{def quantile}$ admet une solution unique, les deux définitions coïncident. Si $\eqref{def quantile}$ n'a pas de solution, alors $p$ n'a pas d'antécédent et $q_p$ est un point de saut de $F$ qui vérifie : $F(q_p-) \leq p < F(q_p)$.  Si \eqref{def quantile} a une infinité de solutions, alors l'ensemble de ces solutions est un intervalle borné et $q_p$ est le milieu de cet intervalle.

\begin{definition} La médiane \index{médiane} de $X$ désigne le quantile d'ordre $1/2$ de la loi $F$. Les quartiles de $X$ désignent la médiane, $q_{1/4}$ et $q_{3/4}$.
\end{definition}

On a toujours
$$\mathbb{P}\big[X \geq q_{1/2}\big] \geq \tfrac{1}{2},\;\;\text{et}\;\;\mathbb{P}\big[X \leq q_{1/2}\big] \geq \tfrac{1}{2}.$$
Si $F$ est continue, $F_X(q_{1/2})=\frac{1}{2}$.

\begin{remarque}
\emph{
La médiane est un indicateur de localisation d'une loi de probabilité, alors que l'intervalle interquartile $q_{3/4}-q_{1/2}$ est un indicateur d'échelle. Médiane et intervalles interquartiles sont des analogues de la moyenne et de l'écart-type, et sont toujours définis.
}
\end{remarque}

La médiane jouit d'une propriété analogue à celle de la moyenne (Proposition \ref{caracterisation moyenne}) lorsque l'on remplace le moment d'ordre $2$ par la valeur absolue.
\begin{proposition} Si $X$ admet un moment d'ordre 1, alors
$$\mathbb{E}\big[|X-a|\big] = \min_{c \in \mathbb{R}} \mathbb{E}\big[|X-c|\big],$$
pour tout $a \in \R$ vérifiant $\mathbb{P}\big[X \geq a\big] \geq \tfrac{1}{2}$ et $\mathbb{P}\big[X \leq a\big] \geq \tfrac{1}{2}$.

En particulier
$$\mathbb{E}\big[|X-q_{1/2}|\big] = \min_{c \in \mathbb{R}} \mathbb{E}\big[|X-c|\big].$$
\end{proposition}
\begin{proof} Montrons $\E\big[|X-c|\big] \geq \E\big[|X-a|\big]$ pour tout $c\in \R$. Sans perdre de généralité, on suppose $c >a$.
On a alors
$$
\begin{array}{lll}
|X-c| = & |X-a|+(c-a)\;\;& \text{sur}\;\;\;\{X \leq a\}, \\
|X-c|\geq & |X-a|\;\;& \text{sur}\;\;\;\{a < X \leq (a+c)/2\}, \\
|X-c|\geq & |X-a|-(c-a)\;\;& \text{sur}\;\;\;\{X > (a+c)/2\}. \\
\end{array}
$$
En écrivant
$$|X-c|\geq |X-a|+(c-a)1_{\{X \leq a\}}-(c-a)1_{\{X > (a+c)/2\}}$$
et en intégrant cette dernière inégalité, on obtient
$$\E\big[|X-c|\big] \geq \E\big[|X-a|\big]+(c-a)\big(\PP\big[X\leq a \big]-\PP\big[X > (a+c)/2\big]\big).$$
La propriété de $a$ garantit de plus $\PP\big[X\leq a\big] \geq \PP\big[X >(a+c)/2\big]$, ce qui permet de conclure, puisque $\PP\big[X > a\big] = 1-\PP\big[X \leq a\big] \leq 1/2$.
\end{proof}

\section{Vecteurs gaussiens} \index{gaussiens, vecteurs}
\subsection{Loi normale multivariée}
\subsubsection{Préliminaires}
Si
$$\bX = (X_1,\ldots, X_n)^T$$
est un vecteur aléatoire de $\R^n$, son espérance est définie composante par composante en prenant les espérances des $X_i$ lorsque cela a un sens.

La variance de $\bX$ est la matrice
$$\Sigma\big[\bX\big] = \E\big[(\bX-\E[\bX])(X-\E[\bX])^T\big]$$
appelée aussi matrice de variance-covariance de $\bX$. Elle existe dès lors que  $$\E\big[\|\bX\|^2\big]<+\infty,$$
 où $\|\bx\| = (\bx^T\bx)^{1/2}$ est la norme euclidienne du vecteur  $\bx \in \R^n$. On a les propriétés suivantes :
 \begin{enumerate}
 \item $\Sigma\big[\bX\big] = \E\big[\bX^T\bX\big] - \E\big[\bX\big]\E\big[\bX\big]^T$
 \item Pour tout $a\in \R^n$, $\mathrm{Var}\big[a^T\bX\big] = a^T\Sigma\big[\bX\big]a$. En particulier, $\Sigma\big[\bX\big]$ est symétrique positive.
 \item Si $A$ est une matrice $k\times n$ et $b \in \R^k$, on a $\Sigma\big[A\bX+b\big] = A\Sigma\big[\bX\big]A^T$.
  \end{enumerate}
\subsubsection{Vecteurs gaussiens}
Si $\text{Id}_n$ désigne la matrice unité $n \times n$,  on note
$${\mathcal N}(0,\text{Id}_n)$$
la loi du vecteur aléatoire
$$\bX = (\xi_1,\ldots, \xi_n)^T$$ dont toutes les composantes sont des variables aléatoires gaussiennes indépendantes, centrées réduites. On écrit $\bX \sim {\mathcal N}(0,{\text{Id}_n})$.

On a les propriétés suivantes :

\begin{enumerate}

\item La moyenne de $\bX$ est $0$ et sa matrice de variance-covariance est $\text{Id}_n$.

\item La loi de $\bX$ est absolument continue, de densité par rapport à la mesure de Lebesgue sur $\R^n$ donnée par
$$f_{\bX}(\bx) = (2\pi)^{-n/2}\exp\left(-\frac{1}{2}\bx^T\bx\right),\;\;\bx \in \R^n.$$

\item La fonction caractéristique (voir Méléard \cite{M}, Définition 6.1. p. 125) de $\bX$ est donnée par
$$\phi_{\bX}(a) = \E\big[e^{i a^T {\bX}}\big] = \exp\left(-\frac{1}{2}a^Ta\right),\;\;a \in \R^n. $$

\end{enumerate}
\begin{definition}
Un vecteur aléatoire $\bX$ à valeurs dans $\R^n$ est gaussien (ou normal) si, pour une matrice $A$ de taille $n \times n$ et un vecteur $\boldsymbol{\mu} \in \R^n$, on a
$$\bX = \boldsymbol{\mu} + A\, \boldsymbol{\xi},\;\;\;\boldsymbol{\xi} \sim {\mathcal N}(0,{\mathrm{Id}_n}).$$
\end{definition}
On a les propriétés suivantes :

\begin{enumerate}
\item La moyenne (vectorielle) de $\bX$ est $\E \big[\bX\big] = \boldsymbol{\mu}.$
\item La matrice de covariance de $\bX$ est $\Sigma_{\bX} = \text{Var}\big[\bX\big] = AA^T$.
\item La fonction caractéristique de $\bX$ vaut
\begin{align*}
\phi_{\bX}(a) &= \E\big[e^{ia^T\bX}\big] \\
&= \E\big[e^{ia^T(\boldsymbol{\mu}+A\boldsymbol{\xi})}\big] \\
&= \exp\left(ia^T\boldsymbol{\mu}\right)\E\big[e^{i(A^Ta)^T\boldsymbol{\xi}}\big] \\
&=\exp\big(ia^T\boldsymbol{\mu}-\tfrac{1}{2}(a^TA)^Ta^TA \big) \\
&= \exp\big(ia^T\boldsymbol{\mu}-\tfrac{1}{2}a^T\Sigma a\big),\;\;a\in \R^n.
\end{align*}
\end{enumerate}
On a la caractérisation suivante d'un vecteur gaussien :
% en termes de fonctions caractéristiques :
\begin{proposition}
Une application $\phi: \R^n \rightarrow \mathbb{C}$ est la fonction caractéristique d'un vecteur gaussien si et seulement si il existe $\boldsymbol{\mu} \in \R^n$ et une matrice $\Sigma$ symétrique positive (dont toutes les valeurs propres sont positives ou nulles) tels que
$$\phi(a) = \exp\big(ia^T\boldsymbol{\mu}-\tfrac{1}{2}a^T\Sigma a\big),\;\;a\in \R^n.
$$
\end{proposition}

\begin{proof}
Le calcul de la fonction caractéristique d'un vecteur gaussien établi plus haut monte que la condition est nécessaire. Pour montrer la condition suffisante, il suffit d'exhiber un vecteur gaussien de $\R^n$ dont $\phi$ est la fonction caractéristique. Pour cela, on peut poser $\bX = \boldsymbol{\mu} + \Sigma^{1/2}\boldsymbol{\xi}$, où $\Sigma^{1/2}$ est une racine carrée de $\Sigma$ et $\boldsymbol{\xi} \sim {\mathcal N}(0,{\text{Id}_n})$.
\end{proof}
En conséquence, la loi d'un vecteur gaussien $\bX$ est entièrement détermi\-née par sa moyenne $\boldsymbol{\mu}$ et sa matrice de covariance $\Sigma$. On écrira par la suite $\bX \sim {\mathcal N}(\boldsymbol{\mu},\Sigma)$.
\begin{remarque}
\emph{
Dans la décomposition $\Sigma = A^TA$ d'une matrice symétrique positive, la matrice $A$ n'est pas unique. On peut prendre pour $A$ une racine carrée de $\Sigma$, mais il existe aussi d'autres choix où $A$ n'est pas nécessairement symétrique. Si $\Lambda$ désigne la matrice diagonale formée à partir des valeurs propres $\lambda_j$ de $\Sigma$, de rang $k \leq n$ alors, on a la décomposition
$$\Sigma = \Gamma \Lambda \Gamma^T = \sum_{j=1}^n \boldsymbol{\gamma}_{\cdot, j}\lambda_j\boldsymbol{\gamma}_{\cdot, j}^T = \sum_{i = 1}^k \boldsymbol{a}_{\cdot,j}\boldsymbol{a}_{\cdot,j}^T = AA^T$$
où les $\boldsymbol{\gamma}_{\cdot, j}$ sont les colonnes de $\Gamma$, $\boldsymbol{a}_{j} =\sqrt{\lambda_j} \boldsymbol{\gamma}_{\cdot, j}$ et
$A$ est une matrice $n\times n$ définie par $A = (\boldsymbol{a}_{1},\ldots, \boldsymbol{a}_{k},0\ldots,0 )$.
}
\end{remarque}

Une caractérisation équivalente de la loi d'un vecteur gaussien est la suivante :

\begin{proposition}
Un vecteur aléatoire $\bX$ est gaussien si et seulement si toute combinaison linéaire des composantes de $\bX$ est une variable aléatoire gaussienne réelle\footnote{On admet dans cette terminologie qu'une constante est une variable aléatoire gaussienne, de moyenne elle-même et de variance $0$.}.
\end{proposition}
\begin{proof} Si $\bX \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma)$, pour tout $u \in \R$, on a
\begin{align*}
\phi_{a^T\bX}(u)  &= \E\big[e^{ia^T\bX u}\big] \\
&= \phi_{\bX}(ua) \\
&= \exp\big(iua^T\boldsymbol{\mu}-\tfrac{1}{2}u^2a^T\Sigma a\big),
\end{align*}
donc $a^T\bX \sim \mathcal{N}(a^T\boldsymbol{\mu}, a^T\Sigma a)$. Réciproquement, si pour tout $a\in \R^n$, la variable aléatoire réelle $a^T\bX$ est gaussienne, alors $\E\big[\|\bX\|^2\big]<+\infty$ (prendre pour $a$ les projections sur les coordonnées), donc
$\boldsymbol{\mu} = \E\big[\bX\big]$ et $\Sigma = \Sigma\big[X\big]$ existent. Soit $a\in \R^n, m \in \R$ et $s^2 \geq 0$ de sorte que
$a^T\bX \sim \mathcal{N}(m,s^2)$. Nécessairement,
$$m = a^T\boldsymbol{\mu}\;\;\;\text{et}\;\;\;s^2 = a^T\Sigma a,$$
par linéarité de l'espérance et parce que  $\mathrm{Var}\big[a^T\bX\big] = a^T\Sigma[\bX]a$ (voir le paragraphe précédent). Donc
\begin{align*}
\phi_{a^T\bX}(u) &= \exp\big(imu-\tfrac{1}{2}s^2u^2\big) \\
&= \exp\big(iua^T\boldsymbol{\mu}-\tfrac{1}{2}u^2a^T\Sigma a\big)\\
&= \phi_{a^T\bX}(1)\\
& = \phi_{\bX}(a).
\end{align*}
Puisque le choix de $a\in \R^n$ est arbitraire, on a la conclusion.
\end{proof}
\subsubsection{Densité de la loi normale multivariée}
Si $\Sigma$ est définie positive, la loi de $\bX$ est absolument continue par rapport à la mesure de Lebesgue sur $\R^n$, et la densité du vecteur $\bX$ est obtenue à partir de la densité de $\boldsymbol{\xi}$ via la représentation $\bX = \boldsymbol{\mu} + A \boldsymbol{\xi}$ par changement de variable affine (Méléard \cite{M}, paragraphe 4.10.2 p. 107):
\begin{align*}
f_{\bX}(\bx) &= \text{det}A^{-1}f_{\boldsymbol{\xi}}\big(A^{-1}(\bx-\mu)\big)\\
& = \frac{1}{(2\pi)^{n/2}\sqrt{\text{det}\Sigma}}\exp\left(-\frac{1}{2}(\bx-\boldsymbol{\mu})^T\Sigma^{-1}(\bx-\mu)\right),\;\;\bx\in \R^n.
\end{align*}
\subsubsection{Loi normale multivariée dégénérée}
Si $\Sigma$ est singulière, soit $\mathrm{Rang}(\Sigma)=k<n$, le vecteur $\bX$ n'a plus de densité sur $\R^n$. La représentation
$\bX = \boldsymbol{\mu} +\Sigma^{1/2}\boldsymbol{\xi}$ montre que $\bX$ se concentre à une transformation affine près sur l'image de $\Sigma^{1/2}$, qui est un sous-espace de dimension $k$.
\begin{proposition} Si $\bX \sim \mathcal{N}(0, \Sigma)$, avec $\mathrm{Rang}(\Sigma) = k < n$, alors il existe un sous-espace vectoriel $H \subset \R^n$ de dimension $n-k$ tel que pour tout $a \in H$, la loi de $a^T\bX$ est dégénérée, c'est-à-dire $a^T\bX$ est une constante (déterministe).
\end{proposition}
\begin{proof} On pose $H = \mathrm{Ker}(\Sigma)$. Alors $H$ est de dimension $n-k$ et si $a\in H$,  pour tout $u \in \R^n$, on a
\begin{align*}
\phi_{a^TX}(u) &= \E\big[e^{iu\,a^T \bX}\big] \\
& = \exp\big(iu\,a^T\boldsymbol{\mu}-\tfrac{1}{2}u^2a^T\Sigma a\big)\\
&= \exp\big( iu\,a^T\boldsymbol{\mu}\big) \;\;\;\;\text{puisque}\;\;\;\Sigma a=0.
\end{align*}
\end{proof}
\subsubsection{Indépendance de deux vecteurs gaussiens}
Si $\bX$ et ${\bf Y}$ sont deux vecteurs aléatoires à valeurs dans $\R^p$ et $\R^q$ respectivement, et tels que $\E\big[\|\bX\|^2\big]<+\infty$ et $\E\big[\|{\bf Y}\|^2\big]<+\infty$, leur matrice de covariance est la matrice $p\times q$ définie par
$$\Sigma\big[\bX,{\bf Y}\big] = \E\big[(\bX-\E[\bX])({\bf Y} - \E[{\bf Y}])^T\big].$$
L'indépendance entre des transformations linéaires d'un vecteur gaussien se lit sur la matrice de covariance :
\begin{proposition} \label{correlation=independance en gaussien}
Si $\bX$ est un vecteur gaussien de $\R^n$ et si $A$ et $B$ sont deux matrices $n \times p$ et $n \times q$, alors les vecteurs $A\bX$ et $B \bX$ sont indépendants si et seulement si
$$\Sigma\big[A\bX,B\bX\big]=0.$$
\end{proposition}
\begin{proof}
On concatène $A\bX$ et $B\bX$ en un vecteur ${\bf Y} = (A\bX,B\bX)^T$ de $\R^{p+q}$ qui est gaussien comme transformation linéaire du vecteur gaussien $\bX$. On a
$$\Sigma_{{\bf Y}} =
\left(
\begin{array}{cc}
\Sigma_{A\bX} & \Sigma\big[A\bX,B\bX\big] \\ \\
\Sigma\big[A\bX,B\bX\big] & \Sigma_{B\bX}
\end{array}
\right)
=
\left(
\begin{array}{cc}
\Sigma_{A\bX} & 0 \\ \\
0 & \Sigma_{B\bX}
\end{array}
\right)
$$
si $\Sigma\big[A\bX,B\bX\big] =0$. Il vient, pour $u = (a,b) \in \R^p\times \R^q$,
\begin{align*}
\phi_{{\bf Y}}(u) & = \phi_{{\bf Y}}(a,b) \\
& = \exp\big(ia^T\E[A\bX]+b^T\E[B\bX]-\tfrac{1}{2}(a^T,b^T)\Sigma_{{\bf Y}}(a,b)^T\big) \\
& =\exp\big(ia^T\E[A\bX]-\tfrac{1}{2}a^T\Sigma_{A\bX}a+ ib^T\E[B\bX]-\tfrac{1}{2}b^T\Sigma_{B\bX}b\big) \\
& = \phi_{\bX}(a)\phi_{\bX}(b).
\end{align*}
Réciproquement, si $A\bX$ et $B\bX$ sont indépendants, on a $\Sigma\big[A\bX,B\bX\big] =0$ par le même calcul.
\end{proof}
\subsection{Dérivées des lois gaussiennes}
Il s'agit de trois familles de lois très classiques en statistique -- et utilisées pour la construction de tests et d'intervalles de confiance -- obtenues comme transformation de lois gaussiennes : \index{$\chi^2$, loi du}{loi du $\chi^2$, \index{Student, loi de}loi de Student et \index{Fisher, loi de}loi de Fisher-Snedecor.
\subsubsection{Loi du $\chi^2$ à $n$ degrés de liberté}
\begin{definition}
Une variable aléatoire réelle $Y$ suit la loi du $\chi^2$ à $n$ degrés de liberté si elle peut s'écrire
$$Y = \sum_{i = 1}^n X_i^2,$$
où les variables $X_1,\ldots, X_n$ sont indépendantes, de même loi ${\mathcal N}(0,1)$.
\end{definition}
On écrit $Y \sim \chi^2(n)$. Autrement dit, si $\bX \sim \mathcal{N}(0,\mathrm{Id}_n)$, alors $\|\bX^2\|\sim\chi^2(n)$.
On a les propriétés suivantes :

\begin{enumerate}

\item La densité de la loi du $\chi^2(n)$ est donnée par
$$y \leadsto c(n)y^{n/2-1}e^{-y/2},\;\;\;y \in \R_+\setminus \{0\}$$
avec $c(n) = 2^{-n/2}\Gamma(n/2)^{-1}$ et $\Gamma(x) = \int_0^{+\infty}u^{x-1}e^{-u/2}du$.

\item Si $Y\sim \chi^2(n)$, on a $\E\big[Y\big] = n$ et $\mathrm{Var}\big[Y\big] = 2n$.

%\item Si $Y\sim \chi^2(n)$, sa transformée de Laplace\footnote{Puisque $Y$ est à valeurs dans $\R_+$, on utilise sa transformée de Laplace plutôt que sa fonction caractéristique.} est donnée par
%$${\mathcal L}(u) = \E\big[e^{-uY}\big] = \left(\frac{1}{1-2u}\right)^n.$$
\end{enumerate}
On utilise souvent le résultat suivant :
%check ce qu on entend par la
\begin{proposition} Soit $\bX$ un vecteur aléatoire de $\R^n$ tel que $\bX \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma)$, où $\Sigma$ est définie positive.
Alors
$$(\bX-\boldsymbol{\mu})^T\Sigma^{-1}(\bX-\boldsymbol{\mu}) \sim \chi^2(n).$$
\end{proposition}
\begin{proof}
On a
$$(\bX-\boldsymbol{\mu})^T\Sigma^{-1}(\bX-\boldsymbol{\mu}) = \|\Sigma^{-1/2}\bX-\boldsymbol{\mu}\|^2.$$
On conclut en utilisant : $\Sigma^{-1/2}\bX-\boldsymbol{\mu} \sim \mathcal{N}(0,\mathrm{Id}_n)$.
\end{proof}
\subsubsection{Loi $\mathfrak{T}$ de Student}
\begin{definition}
Une variable aléatoire réelle $T$ suit la loi de Student à $n$ degré de libertés si
$$T = \frac{\xi}{\sqrt{Y/n}},$$
où $\xi \sim {\mathcal N}(0,1)$ et $Y \sim \chi^2(n)$ sont indépendantes.
\end{definition}
On écrit $T \sim \mathfrak{T}(n)$. On a les propriétés suivantes
\begin{enumerate}
\item La densité de la loi $\mathfrak{T}(n)$ est donnée par
$$y \leadsto c(n)\left(1+\frac{y^2}{n}\right)^{-(n+1)/2},\;\;\;y\in \R$$
avec
$$c(n) = \frac{1}{\sqrt{n}B(1/2,n/2)},\;\;\;\text{et}\;\;\;B(p,q) = \Gamma(p)\Gamma(q)/\Gamma(p+q).$$
\item La loi $\mathfrak{T}(n)$ est symétrique.
\item La loi $\mathfrak{T}(1)$ est la loi de Cauchy.
\item Lorsque $n$ est grand, $Y/n$ est proche de $1$ par la loi des grands nombres et la loi $\mathfrak{T}(n)$ se \og rapproche\fg{} de la loi ${\mathcal N}(0,1)$.
\end{enumerate}
 %exo kurtosis
La loi $\mathfrak{T}$ de Student intervient en statistique comme une approximation de la loi ${\mathcal N}(0,1)$, lorsque la variance $1$ est approchée par une loi du $\chi^2$ à $n$ degrés de liberté renormalisée.
\begin{remarque}
\emph{
Par cette approximation même, la loi $\mathfrak{T}(n)$ est plus \og dispersée \fg{} que la loi ${\mathcal N}(0,1)$ : si $T \sim \mathfrak{T}(n)$ et $\xi \sim \mathcal{N}(0,1)$, on a, par exemple,
$$\kappa\big[T\big] > \kappa\big[X\big],$$
où $\kappa[\cdot]$ est le coefficient d'aplatissement (la kurtosis) défini dans la Section \ref{parametres de position}. Le cas extrême est $n=1$ où la kurtosis n'est même pas définie (il faut prendre au moins $n=6$).
}
\end{remarque}
\subsubsection{Loi de Fisher-Snedecor}
\begin{definition} Une variable aléatoire $Y$ suit la loi de Fisher-Snedecor de degrés de libertés $(p,q)$ si
$$Y = \frac{U/p}{V/q},$$
où $U \sim \chi^2(p)$ et $V\sim \chi^2(q)$ sont indépendantes.
\end{definition}
On écrit $Y \sim F_{p,q}$ et on a les propriétés suivantes :
\begin{enumerate}
\item La densité de la loi $F_{p,q}$ est donnée par
$$y \leadsto c(p,q)\frac{y^{p/2-1}}{(q+py)^{(p+q)/2}},\;\;\;y \in \R_+\setminus \{0\},$$
où $$c(p,q) = \frac{p^{p/2}q^{q/2}}{B(p/2,q/2)}.$$
\item Lorsque $q$ est grand, la loi $F(p,q)$ se rapproche de la loi du $\chi^2(p)$. C'est le même raisonnement que pour la loi de Student.
\end{enumerate}
\subsection{Cochran}
Il s'agit d'un résultat d'algèbre linéaire que l'on utilise pour déduire des propriétés de transformations linéaires de vecteurs gaussiens.
\begin{theoreme}[Cochran] \label{cochran} \index{Cochran}
 Soit $\bX\sim\mathcal{N}(0,\mathrm{Id}_n)$ et $A_1,\ldots, A_J$ des matrices $n\times n$ telles que  $\sum_{j=1}^J\mathrm{Rang}(A_j) \leq n$ et vérifiant
 \begin{itemize}
 \item[(i)] les $A_j$ sont symétriques,
 \item[(ii)] $A_jA_k=0$ si $j\neq k$ et  $A_j^2=A_j$\vspace{2mm}.
  \end{itemize}
   Alors
 \begin{enumerate}
 \item Les vecteurs aléatoires $(A_j\bX,j=1,\ldots, J)$ sont mutuellement indépendants, et $A_j\bX \sim {\mathcal N}(0,A_j)$.
 \item Les variables aléatoires $(\|A_j\bX\|^2, j=1,\ldots, J)$ sont mutuellement indépendantes et $\|A_j\bX\|^2 \sim \chi^2\big(\mathrm{Rang(A_j)}\big)$.
 \end{enumerate}
\end{theoreme}
\begin{proof}
On a, pour tout $u \in \R^n$ et $j = 1,\ldots, J$
\begin{align*}
\E\big[e^{iu^TA_j\bX}\big] &= \E\big[e^{i(A_j^Tu)^T\bX}\big]  \\
&= \exp\big(-\tfrac{1}{2}\,(A_j^Tu)^TA_j^Tu\big)\\
& = \exp\big(-\tfrac{1}{2}\,u^TA_j^2 u\big)\;\;\;\;\text{par}\;\;(i) \\
&= \exp\big(-\tfrac{1}{2}\,u^TA_j u\big)\;\;\;\;\text{par}\;\;(ii).
\end{align*}
On a donc $A_j\bX \sim \mathcal{N}(0,A_j)$. Soient $u_1,\ldots, u_J \in \R^n$.  On a
\begin{align*}
\E\big[e^{i \sum_{j = 1}^J u_j^T A_j \bX}\big] & = \E\big[e^{i(\sum_{j = 1}^J A_j^Tu_j)^T \bX}\big] \\
& = \exp\big[-\tfrac{1}{2}\big(\sum_{j = 1}^JA_j^Tu_j\big)^T\big(\sum_{j = 1}^JA_j^Tu_j\big)\big] \\
& = \exp\big[-\tfrac{1}{2}\big(\sum_{j = 1}^JA_j^Tu_j\big)^T\big(\sum_{j = 1}^JA_ju_j\big)\big]\;\;\;\;\text{par}\;\;(i)\\
& = \exp\big(-\tfrac{1}{2}\sum_{j,j' = 1}^Ju_j^TA_j A_{j'}u_{j'}\big)\\
& = \exp\big(-\tfrac{1}{2}\sum_{j = 1}^Ju_j^TA_jA_ju_j\big) \;\;\;\;\text{par}\;\;(ii)\\
& = \prod_{j = 1}^J\exp\big(-\tfrac{1}{2}(A_j^Tu_j)^TA_j^Tu_j\big)  \;\;\;\;\text{par}\;\;(i)\\
& = \prod_{j = 1}^J \E\big[e^{i u_j^T A_j \bX}\big]
\end{align*}
ce qui entraîne l'indépendance (Méléard \cite{M}, Proposition 6.1.4 p. 130) des $A_j\bX$. Pour montrer le point 2 du théorème, on écrit, pour $j$ fixé,
$$A_j = \Gamma \Lambda \Gamma^T$$
où $\Gamma$ est une matrice orthogonale et $\Lambda = \text{Diag}(\lambda_1,\ldots, \lambda_n)$ est la matrice diagonale des valeurs propres de $A_j$. Il vient
\begin{equation} \label{decomp chi2}
\|A_j\bX\|^2  = \bX^TA_j^TA_j\bX = \bX^TA_j\bX =( \Gamma^T \bX)^T\Lambda\Gamma^T\bX.
\end{equation}
par $(i)$ et $(ii)$. Posons ${\bf Y} = \Gamma^T\bX$. On a ${\bf Y} \sim \mathcal{N}(0,{\mathrm Id}_n)$ car $\Gamma$ est orthogonale. En réécrivant \eqref{decomp chi2} à l'aide de ${\bf Y}$, on en déduit
$$\|A_j\bX\|^2  = {\bf Y}^T\Lambda {\bf Y} = \sum_{i = 1}^n \lambda_i Y_i^2 \sim \chi^2\big(\mathrm{Rang}(A_i)\big)$$
puisque $A_i$ est un projecteur, donc $\lambda_i = 0$ ou $1$ et le nombre de $\lambda_i$ non nuls est le rang de $A_i$. L'indépendance des $\|A_j\bX\|^2$ est une conséquence immédiate de celle des $A_j\bX$ prouvée précédemment.
\end{proof}
\section{Convergences et théorèmes limites}
\subsection{Modes de convergences}
On considère une suite $(\xi_n)_n$ de variables aléatoires réelles $\xi_n$ définies sur un espace de probabilité commun $(\Omega, {\mathcal A}, \PP)$.
\begin{definition}
La  suite $(\xi_n)_n$ ou plus simplement $\xi_n$ converge vers $\xi$ en probabilité (notation : $\xi_n \stackrel{\PP}{\rightarrow} \xi$) si pour tout $\varepsilon >0$
$$\lim_{n \rightarrow \infty}\PP\big[|\xi_n-\xi| \geq \varepsilon \big] = 0.$$
La suite $\xi_n$ converge vers $\xi$ presque-sûrement (notation : $\xi_n \stackrel{\mathrm{p.s.}}{\longrightarrow} \xi$) si
$$\PP\big[\limsup_{n\rightarrow \infty}|\xi_n -\xi|>0\big] = 0.$$
La suite $\xi_n$ converge vers $\xi$ dans ${\mathcal L}^p$ (notation : $\xi_n \stackrel{{\mathcal L}^p}{\rightarrow} \xi$), avec $0 < p <\infty$, si
$$\lim_{n\rightarrow\infty}\E\big[|\xi_n-\xi|^p\big]=0.$$
\end{definition}
On a les propriétés suivantes :
\begin{enumerate}
\item La convergence presque-sûre\index{convergence presque-sûre} ou la convergence dans ${\mathcal L}^p$ entraînent la \index{convergence en probabilité} convergence en probabilité.
\item  La convergence presque-sûre et la convergence dans ${\mathcal L}^p$ ne sont pas comparables.
\item Si $\xi_n \stackrel{\PP}{\rightarrow}\xi$, elle admet une sous-suite qui converge presque-sûrement.
\item Si $\xi_n \stackrel{\PP}{\rightarrow} \xi$ et si $|\xi_n| \leq \eta$, avec $\E\big[\eta^p\big]<+\infty$ pour un $p>0$, alors
alors $\xi_n \stackrel{\mathrm{{\mathcal L}^p}}{\rightarrow} \xi$.
\item Si $f$ est continue et $\xi_n \stackrel{\PP}{\rightarrow}\xi$, alors $$f(\xi_n) \stackrel{\PP}{\rightarrow}f(\xi).$$
\end{enumerate}
Pour parler de convergence presque-sûre, il est nécessaire que les variables $\xi_n$ et leur limite soient définies simultanément sur le même espace de probabilité.
\footnote{{\bf Remarque } (qu'on omettra en première lecture): Ce n'est pas forcément le cas pour la convergence dans ${\mathcal L}^p$ ou en probabilité. Dans les chapitres qui suivront, on travaillera souvent avec une suite de variables aléatoires réelles
$$X_1,\ldots, X_n$$
indépendantes, et identiquement distribuées de loi $\mathbb{Q}$ sur $(\R, {\mathcal B})$. On utilisera la construction suivante : pour chaque $n$, on pose
$$\Omega_n = \R^n, \;{\mathcal A}^n = {\mathcal B}^n,\;\;\mathbb{P}_n = \mathbb{Q} \otimes \ldots \otimes \mathbb{Q}\;\;\;\;n-\text{fois}.$$
On peut ainsi définir $\bX = (X_1,\ldots, X_n)^T$ sur $(\Omega_n, {\mathcal A}^n)$ et la loi $\PP^{\bX}$ du vecteur $\bX$ coïncide avec $\PP_n$. Si on considère une suite de variable aléatoires de la forme $\xi_n = \phi_n(X_1,\ldots,X_n)$, où $\phi_n:\R^n\rightarrow \R$ est une application donnée, chaque $\xi_n$ est définie sur un espace différent $(\Omega_n, {\mathcal A}^n, \PP_n)$. Si la \og limite \fg{} de $\xi_n$ est une constante $c \in \R$ déterministe, ce qui sera souvent le cas, alors on peut parfaitement parler de convergence en probabilité et dans ${\mathcal L}^p$ en posant
$$\xi_n \stackrel{\PP_n}{\rightarrow} c\;\;\;\text{si}\;\;\;\forall \varepsilon >0,\;\;\lim_{n \rightarrow \infty} \PP_n\big[|\xi_n-c| \geq \varepsilon\big]=0$$
et
$$\xi_n \stackrel{{\mathcal L}(\PP_n)}{\longrightarrow} c\;\;\;\text{si}\;\;\;\lim_{n \rightarrow \infty} \E_n\big[|\xi_n-c|^p\big]=0.$$
Puisque $\PP_n$ est entièrement déterminée par $\mathbb{Q}$, on écrira, sans qu'il y ait de confusion possible,
$$\xi_n \stackrel{\mathbb{Q}}{\rightarrow}c\;\;\;\;\text{ou}\;\;\;\;\xi_n \stackrel{{\mathcal L}^p(\mathbb{Q})}{\longrightarrow} c.$$

Par contre, on ne peut plus parler de convergence presque-sûre. Toutefois, en travaillant un peu, on peut se placer sur un produit infini et donner de même un sens à la convergence presque-sûre. {\it A posteriori} il n'y a pas d'ambiguité d'écriture. Nous ne reviendrons plus sur ces questions techniques.}
\begin{remarque}
\emph{
La convergence en probabilité est sans doute la notion la plus adaptée à la problématique statistique. Elle traduit la propriété suivante : pour tout niveau de risque $\alpha>0$ et pour toute précision $\varepsilon>0$, il existe un rang $n(\varepsilon, \alpha)$ à partir duquel on peut \og affirmer \fg{} que $\xi_n$ approche $\xi$ avec une erreur inférieure à $\varepsilon$. La probabilité que cette affirmation soit fausse est inférieure à $\alpha$ :
$$\text{pour}\;\;n\geq n(\varepsilon,\alpha),\;\;\;\;\PP\big[|\xi_n-\xi|\leq \varepsilon\big] \geq 1-\alpha.$$
}
\end{remarque}
Cependant, pour contrôler précisément le comportement asymptotique de suites de variables aléatoires, on aura besoin d'un mode de convergence
plus faible : la \index{convergence en loi}convergence en loi.
\begin{definition} \label{def conv loi}
La suite $\xi_n$ converge vers $\xi$ en loi (notation $\xi_n \stackrel{d}{\rightarrow} \xi$) si pour toute fonction $\varphi$ continue bornée, on a
$$\E\big[\varphi(X_n)\big] \rightarrow  \E\big[\varphi(\xi)\big]\;\;\;\text{lorsque}\;\;\;n\rightarrow \infty.$$
\end{definition}
\begin{remarque}
\emph{
On peut remplacer dans la définition la suite réelle $\xi_n$ par une suite de vecteurs aléatoires $\boldsymbol{\xi}_n$ de $\R^d$ avec $d \geq 1$ et $\xi$ par un vecteur aléatoire $\boldsymbol{\xi}$ de $\R^d$.
}
\end{remarque}
La convergence en loi est une notion plus faible que la convergence en probabilité. Elle ne fait intervenir que la suite des lois $\PP^{\xi_n}$ et $\PP^\xi$. En particulier, on n'a pas besoin que les variables $\xi_n$ ou la limite $\xi$ soient définies sur le même espace de probabilité.

On a les propriétés suivantes
\begin{enumerate}
\item $\xi_n \stackrel{d}{\rightarrow} \xi$ si et seulement si pour tout $u \in \R$,
$$\phi_{\xi_n}(u)\rightarrow \phi_\xi(u)\;\;\;\text{lorsque}\;\; n \rightarrow \infty.$$
Cette propriété caractérise la convergence en loi\footnote{On peut remplacer $\xi_n$ et $\xi$ par des vecteurs de $\R^d$ avec $d\geq1$, en prenant $u \in \R^d$.}  (Théorème de Lévy).
\item (Astuce de Wold). La suite de vecteurs $\boldsymbol{\xi}_n$ de $\R^d$ converge vers $\boldsymbol{\xi}$ en loi si et seulement si $a^T\boldsymbol{\xi} \stackrel{d}{\rightarrow} a^T\boldsymbol{\xi}$ pour tout $a\in \R^d$.
\item Dans la Définition \ref{def conv loi}, on peut remplacer $f$ continue bornée par
$$f(x) = 1_{(-\infty,x_0]}(x),\;\;x\in\R$$
en tous les points $x_0 \in \R$ tels que $\PP\big[\xi=x_0\big]=0$. Autrement dit $\xi_n \stackrel{d}{\rightarrow}\xi$ si et seulement si
$$\PP\big[{\xi_n}\leq x\big]\rightarrow \PP\big[\xi \leq x ],\;\;\;\text{lorsque}\;\;n\rightarrow \infty.$$
en tout point $x$ où la fonction de répartition  de $\xi$ est continue.
\item Si $\xi_n \stackrel{d}{\rightarrow}\xi$ et $g:\R\rightarrow \R$ est continue, alors\footnote{On peut remplacer $\xi_n$ et $\xi$ par des vecteurs de $\R^d$ avec $d\geq1$ et $g:\R^d\rightarrow \R$ continue.} $g(\xi_n) \stackrel{d}{\rightarrow} g(\xi)$\vspace{5mm}.
\end{enumerate}

Voici un résultat technique que nous utiliserons constamment dans ce cours :
\begin{proposition}[Slutsky] \label{slutsky} \index{Slutsky, lemme de}
Si $\xi_n \stackrel{d}{\rightarrow}\xi$ et $\eta_n \stackrel{\PP}{\rightarrow} c$ où $c$ est une constante (déterministe), alors
 $$(\xi_n,\eta_n) \stackrel{d}{\rightarrow} (\xi,c).$$
En particulier, si $h:\R \times \R \rightarrow \R$ est continue, alors $h(\xi_n,\eta_n) \stackrel{d}{\rightarrow}h(\xi,c)$. Ceci entraîne alors
$\xi_n+\eta_n \stackrel{d}{\rightarrow} \xi+c$, $\eta_n \,\xi_n\stackrel{d}{\rightarrow} c\,\xi$, et ainsi de suite.
\end{proposition}
\begin{proof} Soient $u,v \in \R$. On écrit
\begin{align*}
&\E\big[e^{i(u\xi_n+v\eta_n)}\big]-\E\big[e^{iu\xi}\big]e^{ivc} \\
=\,& \E\big[e^{iu\xi_n}\big(e^{iv\eta_n} - e^{ivc}\big)\big]+ \big(\E\big[e^{iu\xi_n}\big]- \E\big[e^{iu\xi}\big]\big)e^{ivc}.
\end{align*}
La convergence $\xi_n \stackrel{d}{\rightarrow}\xi$ entraîne immédiatement la convergence vers $0$ du second terme du membre de droite de l'égalité.

Concernant le premier terme, pour $\varepsilon >0$, on introduit l'événement $\{|\eta_n - c|\geq \varepsilon\}$. On a alors
\begin{align*}
&\Big| \E\big[e^{iu\xi_n}\big(e^{iv\eta_n} - e^{ivc}\big)\big] \Big| \\
 =\, &\Big| \E\big[e^{iu\xi_n}\big(e^{iv\eta_n} - e^{ivc}\big)1_{|\eta_n - c| \geq \varepsilon}\big]+\E\big[e^{iu\xi_n}\big(e^{iv\eta_n} - e^{ivc}\big)1_{|\eta_n - c| < \varepsilon}\big] \Big|\\
 \leq \, & 2 \PP\big[|\eta_n - c|\geq \varepsilon\big]+|v|\varepsilon,
\end{align*}
où l'on a utilisé $|e^{iv\eta_n} - e^{ivc}| \leq |v||\eta_n - c|$. On conclut en utilisant $\eta_n \stackrel{\PP}{\rightarrow} c$ puis en faisant tendre $\varepsilon$ vers $0$.
\end{proof}
\subsection{Lois des grands nombres et théorème central-limite}
L'outil probabiliste essentiel de ce cours est le contrôle de la somme de variables aléatoires indépendantes (et souvent équidistribuées).
\subsubsection{Notations}
Si $X_1,\ldots, X_n$ est une suite de variables aléatoires réelles, on notera toujours
$$\overline{X}_n = \frac{1}{n}\sum_{i = 1}^n X_i$$
leur moyenne empirique. Si $X_1,\ldots, X_n$ sont indépendantes et de même loi $\mathbb{Q}$, on écrira
$$X_1\ldots X_n \sim_{\text{i.i.d.}} \mathbb{Q}.$$
Dans ce contexte -- et lorsqu'il n'y aura pas d'ambiguité -- on introduira parfois la notation $X$ pour désigner une variable de même loi que les $X_i$.
\subsubsection{Lois des grands nombres}
\begin{proposition}  \label{simple LGN}
Soient $X_1,\ldots, X_n$ des variables aléatoires indépendantes de même loi, telles que $\var\big[X\big]=\sigma^2<+\infty$. On note $\mu = \E\big[X\big]$.
Alors
$$\E\big[\Xbar\big] = \mu\;\;\;\text{et}\;\;\;\var\big[\Xbar\big] = \frac{\sigma^2}{n}.$$
\end{proposition}
\begin{proof}
On utilise  simplement la linéarité de l'espérance et la propriété
$$\var\big[\sum_{i = 1}^nX_i\big] = \sum_{i = 1}^n \var\big[X_i\big]$$
qui est vérifiée si les $X_i$ sont indépendantes.
\end{proof}
\begin{remarque}
La Proposition \ref{simple LGN} implique la convergence $\Xbar \stackrel{{\mathcal L}^2}{\rightarrow} \mu$ et donc aussi  $\Xbar \stackrel{\PP}{\rightarrow} \mu$.
\end{remarque}
\begin{theoreme}[Loi forte des grands nombres]
Soient $X_1,\ldots, X_n$ des variables aléatoires indépendantes de même loi, telles que $\E\big[|X|\big] <+\infty$. On note $\mu  = \E\big[X\big]$. Alors
$$\Xbar \stackrel{\mathrm{p.s.}}{\longrightarrow}\mu\;\;\;\;\text{lorsque}\;\;\;n \rightarrow \infty.$$
\end{theoreme}
\subsubsection{Théorème central limite} \index{théorème central limite}
Le théorème central limite donne la vitesse de convergence dans la loi des grands nombres. La Proposition \ref{simple LGN} suggère que la bonne normalisation est $\sqrt{n}$ : en effet, on a
$$\E\Big[\Big(\sqrt{n}\big(\Xbar-\mu\big)\Big)^2\Big] = n\E\big[\big(\Xbar-\E[\Xbar]\big)^2\big] = n\mathrm{Var}\big[\Xbar\big] = \sigma^2,$$
qui reste bornée lorsque $n\rightarrow \infty$. On cherche donc le comportement de l'erreur normalisée
$$\sqrt{n}\big(\Xbar - \mu\big),\;\;\;\text{lorsque}\;\;\;n\rightarrow \infty.$$
Malheureusement, si la convergence existe, elle ne peut pas avoir lieu en probabilité\footnote{voir l'Exercice \ref{conv loi tcl}.} et il faut affaiblir le mode de convergence.
\begin{theoreme}[Théorème central limite]
Soient $X_1,\ldots, X_n$ des variables aléatoires indépendantes de même loi, telles que $\E\big[X^2\big]<+\infty$ et $\sigma^2 = \var\big[X\big]>0$. On note $\mu = \E\big[X\big]$. Alors
$$\sqrt{n}\left(\frac{\Xbar-\mu}{\sigma}\right)\stackrel{d}{\rightarrow}{\mathcal N}(0,1).$$
\end{theoreme}
On dira que la suite $\xi_n$ est asymptotiquement normale s'il existe deux constantes $\mu \in \R$ et $\sigma>0$ telles que
$$\sqrt{n}(\xi_n-\mu)\stackrel{d}{\rightarrow} \mathcal{N}(0,\sigma^2).$$
En particulier, le théorème central limite implique que la moyenne empirique est asymptotiquement normale. Le résultat suivant montre que si $\xi_n$ est asymptotiquement normale, alors $g(\xi_n)$ l'est aussi à condition que $g:\R\rightarrow \R$ soit suffisamment régulière.

Cet outil technique essentiel porte en statistique le nom de \og méthode delta\fg{}. \index{méthode delta}
\begin{proposition}[méthode delta] \label{methode delta}
Si $\xi_n$ est asymptotiquement normale et $g:\R\rightarrow \R$ est continûment différentiable, alors $g(\xi_n)$ l'est aussi et
$$\sqrt{n}\big(g(\xi_n)-g(\mu)\big)\stackrel{d}{\rightarrow} {\mathcal N}\big(0,\sigma^2g'(\mu)^2\big).$$
\end{proposition}
\begin{proof}
La fonction
$$h(x)=
\left\{
\begin{array}{lll}
\frac{g(x)-g(\mu)}{x-\mu} & \text{si} & x \neq \mu\\
g'(\mu) & \text{si} & x=\mu
\end{array}
\right.$$
est continue. La normalité asymptotique de $\xi_n$ entraîne en particulier la convergence $\xi_n \stackrel{\PP}{\rightarrow}\mu$, et donc aussi
$$h(\xi_n)\stackrel{\PP}{\rightarrow}h(\mu) = g'(\mu).$$
Or $\sqrt{n}\big(g(\xi_n)-g(\mu)\big) = h(\xi_n)\eta_n$, avec $\eta_n = \sqrt{n}(\xi_n-\mu)\stackrel{d}{\rightarrow}{\mathcal N}(0,\sigma^2)$. La Proposition \ref{slutsky} (Slutsky) permet de conclure
$$h(\xi_n)\eta_n\stackrel{d}{\rightarrow}g'(\mu)\,{\mathcal N}(0,\sigma^2)\stackrel{d}{=}\mathcal{N}\big(\sigma^2g'(\mu)^2\big),$$
le symbole $\stackrel{d}{=}$ signifiant \og égalité en loi \fg{}.
\end{proof}
\subsubsection{Version multidimensionnelle du théorème central limite}
\begin{theoreme} \label{TCL vectoriel}
Soient  $\bX_1,\ldots, \bX_n$ une suite de vecteurs aléatoires de $\R^d$ indépendants et de même loi, tels que
$\E\big[\|\bX\|^2\big]<+\infty$. On note $\boldsymbol{\mu} = \E\big[\bX\big]$ et $\Sigma$ la matrice de variance-covariance $d\times d$ de $\bX$. On a
$$\sqrt{n}\big(\overline{\bX}_n-\boldsymbol{\mu}\big)\stackrel{d}{\rightarrow}{\mathcal N}\big(0,\Sigma\big).$$
\end{theoreme}
La \og méthode delta \fg{} a elle aussi une version multidimensionnelle. Si $g:\R^d \rightarrow \R^k$ est continûment différentiable, elle s'écrit
$$g(x) = \big(g_1(x),\ldots, g_k(x)\big),\;\;g_i:\R^d\rightarrow \R,$$
et on note $J_g(x)$ la matrice de la différentielle de $g$ au point $x \in \R^d$:
$$J_g(x) =
\left(
\begin{array}{ccc}
\partial_1g_1(x) & \ldots & \partial_d g_1(x) \\
\vdots & & \vdots \\
\partial_1 g_k(x) & \ldots & \partial_d g_k(x)
\end{array}
\right).$$
\begin{proposition} \label{methode delta multidimensionnelle}
Soient $\boldsymbol{\xi_1},\ldots, \boldsymbol{\xi_n}$ une suite de vecteurs aléatoires de $\R^d$ asymptotiquement normale, au sens où :
$$\sqrt{n}\big(\boldsymbol{\xi}_n-\boldsymbol{\mu}\big)\stackrel{d}{\rightarrow}\mathcal{N}\big(0,\Sigma\big)$$
où $\boldsymbol{\mu}\in \R^d$ et $\Sigma$ est une matrice $d\times d$ symétrique positive. Alors, si $g:\R^d\rightarrow \R^k$ est continûment différentiable, on a
$$\sqrt{n}\big(g(\boldsymbol{\xi}_n)-g(\boldsymbol{\mu})\big)\stackrel{d}{\rightarrow}\mathcal{N}\big(0,J_g(\mu)\Sigma \,J_g(\mu)^T\big).$$
\end{proposition}
\section{Exercices}
\begin{exercice} \label{convproba et l1}
\emph{
Soient $X_n$ et $Y_n$ deux suites de variables aléatoires réelles telles que $X_n \stackrel{\PP}{\rightarrow}0$ et $\sup_n\E\big[|Y_n|\big]<\infty$. Montrer que $X_nY_n \stackrel{\PP}{\rightarrow 0}$.
}
\end{exercice}
\begin{exercice} \label{conv loi tcl}
\emph{
Soit $X_{n}$ une suite de variables aléatoires indépendantes
centrées réduites. Par le théorème central limite, on a
$$
S_{n}=\frac{1}{\sqrt{n}}\sum_{i=1}^{n} X_{i} \stackrel{d}{\rightarrow} {\mathcal N}(0,1).$$
Le but de
cet exercice est de montrer que $S_{n}$ ne peut pas converger en probabilité.
\begin{itemize}
\item Décomposer la variable $S_{2n}$ en fonction de $S_{n}$ et d'une variable
  aléatoire indépendante de la précédente.
\item Calculer la fonction caractéristique de $S_{2n}-S_{n}$ et montrer que
  cette différence converge en loi.
\item En raisonnant par l'absurde, en déduire que $S_{n}$ ne converge pas en
  probabilité.
\end{itemize}
}
\end{exercice}
\begin{exercice}
\emph{
On pose $$f(x) = \frac{|x|}{1+|x|}.$$
\begin{itemize}
\item Montrer que la suite de variables aléatoires $X_n$ converge en probabilité vers $X$ si et seulement si
$$\lim_{n \rightarrow \infty}\mathbb{E}\big[f(X_n-X)\big]=0.$$
\item Montrer que l'on peut remplacer $f$ par $g(x) = \min\{|x|,1\}$, et plus généralement par toute fonction $f$ positive, continue, bornée, croissante sur $\R_\setminus\{0\}$ vérifiant $f(0)=0$ et $f(x)>0$ si $x>0$.
\item En déduire que si $X_n$ converge vers $X$ en probabilité, il existe une sous-suite qui converge presque-sûrement. (Il existe une autre preuve facile de ce résultat à l'aide du lemme de Borel-Cantelli).
\end{itemize}
}
\end{exercice}
%\begin{exercice}
%\emph{
%Soient $X_1,\ldots, X_n$ des variables aléatoires indépendantes positives, de même loi, avec $\mathbb{E}\big[X_1\big]=1$ et $\text{Var}\big[X_1\big]=\sigma^2 >0$. Montrer que
%$$\frac{2}{\sigma}\big(\sqrt{S_n}-\sqrt{n}\big) \longrightarrow {\mathcal N}(0,1)$$
%en loi quand $n \rightarrow \infty$.
%}
%\end{exercice}
%\begin{exercice}
%\emph{
%Soit $Y^\lambda$ un variable aléatoire de loi de Poisson de paramètre $n >0$. Montrer que
%$$\frac{Y^\lambda-\lambda}{\sqrt{\lambda}}$$
%converge en loi vers une variable aléatoire gaussienne centrée réduite lorsque $\lambda \rightarrow \infty$.
%(Indication: comparer $Y^\lambda$ avec des sommes de $[\lambda]$ ou $[\lambda+1]$ variables aléatoires de Poisson indépendantes de paramètre $1$.)
%}
%\end{exercice}

%\chapter{Modélisation statistique$^\star$}
%\section{Approche historique}
%\subsection{Statisticum, Statistik}
%Les origines du terme \og statistique \fg \; ou \og statistiques \fg \; se perdent com\-me toujours dans un folklore d'anecdotes. Nous ne ferons pas d'histoire : dérivé du latin {\it statisticum}, \og l'état \fg, le terme \og Statistik \fg{} apparaît en Allemagne\footnote{L'ouvrage {\it Statistik}, par Achenwall, date de 1740, mais l'utilisation du terme serait plus ancien.} au dix-septième siècle pour désigner l'ensemble des mesures et du recueil de données nécessaires au fonctionnement des grands empires et  à l'organisation de l'état : recensements et estimations de la population, des richesses, de l'impôt, des armées. De ce point de vue, il n'y a rien de particulièrement original : la (les) statistique(s) remontent à la nuit des temps, et désigne(nt) une activité quantitative qui tombe sous le sens.

%Les progrès de la statistique sont d'abord liés liés à ceux de la représenta\-tion graphique et de l'organisation des données en tableaux. On parle de statistique descriptive, dominée par l'école allemande au dix-huitième siècle. L'activité statistique systématique est importante aussi en Grande Bretagne\footnote{William Playfair (1759--1823) publie en 1786 à Londres "The Commercial and Political Atlas" contenant le premier diagramme en barres connu.} et dans une France centralisée.\footnote{Vauban rédige en 1686 une "Méthode générale et facile pour faire le dénombrement des peuples".
%En 1800, Bonaparte institue les préfets et un "bureau de la statistique de la République".}\\

%C'est avec le développement des probabilités au dix-septième siècle que la statistique devient une discipline scientifique à part entière, en incorporant pour la première fois un raisonnement probabiliste --et donc un modèle du hasard-- dans le traitement d'observations. Le folklore aime attribuer aux études démographiques --déficit des naissances et morts selon le sexe-- la première reflexion \og moderne \fg\; de statistique et qui préfugurent l'actuariat. Les noms souvent cités sont Graunt (1620--1674), William Petty (1623--1687), les frêres Hyugens\footnote{premier calcul de l'espérance de vie humaine en 1669} et Laplace. Nous exposons brièvement la figure de John Arbuthnott (1667--1735).

%\subsection{John Arbuthnott et l'argument de \og divine providence \fg\;}

%En 1712, John Arbuthnott, alors médecin de la Reine Anne présente devant la Royal Societey of London une communication sur l'égalité des sexes à la naissance. Il examine le nombre de baptêmes de filles et de garçons à Londres, entre 1629 et 1710, voir le Tableau \ref{}, extrait\footnote{{\tt http://www.taieb.net/auteurs/Arbuthnot/Arbuthnot.html}.} de Arbuthnott \ref{ARBU}, pp. 189--190. Son constat est le suivant : sur l'ensemble des 82 années retenues, le nombre de naissances masculines est toujours supérieur au nombre de naissance féminines. Il s'interroge sur la possibilité qu'un tel résultat soit \og dû au hasard \fg\;. En supposant les chances égales pour les deux sexes, la probabilité que les naissances masculines soient plus nombreuses que les naissances féminines, 82 fois de suite, vaut $(1/2)^{82}$, {\it \og which will be found easily by the Table of Logarithms to be 1/4 8360 0000 0000 0000 0000 0000}.

%Arbuthnott ne pense pas à utiliser une autre loi binomiale que celle de paramètre $1/2$, comme le lui reprochera plus tard Nicholas Bernoulli en 1713, qui suggère lui même un rapport de naissance homme/femme de 18/17. D'autres auteurs comme De Moivre interviennent dans le débat ... qui ne fait que commencer.

%En langage moderne, Arbuthnott n'a pas tout à fait exprimé son problè\-me en terme de test d'hypothèse, mais il a utilisé un modèle probabiliste pour répondre à un problème posé par des observations\footnote{Cette vision, qui préfigure  avec 200 ans d'avance la problématique statistique, reste toutefois un peu emprisonné dans la pensée de l'époque : son article s'intitule {\it An Argument for Divine Providence, taken frome the constant Regularity observed in the Births of both Sexes} et conclut qant à l'excédent de naissnces masculines de la manière suivante : {\it \og [...] This Event is wisely prevented by the Oeconomy of Nature; and to the judge of the wisdom of the Contrivance, we must observe that the external Accidents to which Males are subject (who must seek their food with danger) do make a great havock of them, and that this loss exceeds far that of the other Sex, occasioned by Disease incident to it, as Experience convinces us. To repair that Loss, provident Nature, by the Disposal of its wife Creator, brings more Males than Females ; and this in almost a constant proportion\fg\;.}}.

%
%\section{Problématique statistique}

%\subsection{Notion d'expérience statistique}
%\subsection{Notion de décision statistique}
%\subsection{Notion de régularité d'un modèle}
%\subsection{Information et approche asymptotique}
%\subsubsection{Estimation}
%\subsubsection{Comparaison d'estimateurs}
%\subsubsection{Décision, test statistique}
%\subsubsection{Approche asymptotique}
%\section{Deux modèles clefs et problèmatiques associées}
%\subsection{Echantillonnage (modèle de densité)}
%\subsection{Régression et notion de variable explicative}
%\section{Erreur de modèle}



\chapter{Expérience statistique} \label{chapitre 2}
Une expérience statistique est la description mathématique de la réalisation d'une variable ou d'un vecteur aléatoire (l'observation) associée à un ensemble de lois de probabilité (le modèle) susceptibles d'avoir engendré cette observation.

A une expérience statistique est toujours associée une probléma\-tique : la reconstruction d'un paramètre du modèle (l'estimation), la décision sur les propriétés du modèle (un test).

\section{Modélisation statistique$^\star$}
\subsection{Exemples introductifs} \label{exemples introductifs}
%Afin de dégager la notion de modèle statistique, nous présentons d'abord six exemples emblématiques -- et relativement différents -- qui conduisent à une approche commune.
\subsubsection{Exemple 1 : Sondage}
Une élection entre deux candidats A et B a lieu : on effectue un sondage à la sortie des urnes. On interroge $n$ votants, $n$ étant considéré comme petit devant le nombre total de votants, et on récolte les nombres $n_A$ et $n_B$ de voix pour $A$ et $B$ respectivement ($n_A+n_B=n$, en ne tenant pas compte des votes blancs ou nuls pour simplifier).
\begin{quote}{\it Problématique statistique : peut-on affirmer que $A$ ou $B$ a gagné au vu de $n_A$ et $n_B$ seulement ? Si l'on décide d'annoncer $A$ (ou $B$) vainqueur, comment quantifier l'erreur de décision ?}
\end{quote}
La réponse va de toute évidence dépendre de $n$ et du rapport $n_A/n_B$.
Ce problème semble intimement lié avec l'expérience suivante : on lance une pièce de monnaie $n$ fois et on compte les nombres $n_P$ et $n_F$ de piles et faces obtenus.

\begin{quote}
{\it Problématique statistique : la pièce est-elle truquée ? Si $n=100$ et $n_P=19$, $n_F=81$, on ne va pas vraiment hésiter. Mais qu'en est-il si $n=20$, $n_P=12$ et $n_F=8$ ?}
\end{quote}
Intuitivement, dans ces deux expériences statistiques, le problème de décision sera d'autant plus difficile à résoudre que la pièce est \og peu truquée \fg{}, ou bien que les deux candidats sont proches dans le cœur des électeurs d'une part, et si l'on a récolté peu de lancers ou de réponses ($n$ petit) d'autre part.

%Une autre question fondamentale est de savoir si les quantités $n_P$ et $n_F$ (ou $n_A$ et $n_B$) contiennent toute l'information du problème, ou bien si la suite des lancers ordonnées de la pièce de monnaie apporte plus d'information que la synthèse seule de $n_P$ et $n_F$.

\subsubsection{Exemple 2 : Reconstruction d'un signal bruité}
On transmet un signal périodique $\big(f(t), t\in [0,T]\big)$ échantillonné à une certaine fréquence $N$. Chaque donnée $f(k/N)$, $k=1,\ldots, NT$, est corrompue lors de la transmission par une erreur $e_k$, de sorte que l'on capte
$$Y_k = f(k/N)+e_k,\;\;k=1,\ldots, NT.$$
On  a $n=NT$ observations. On postule que les erreurs sont indépendantes les unes des autres, nulles en moyenne, et leur \og ordre de grandeur \fg{} sans préciser plus pour le moment est $\sigma >0$.
\begin{quote}
{\it Problématique statistique : comment reconstruire $f$, c'est-à-dire comment construire une fonction $t \leadsto \widehat f\big(t;\; (Y_k)\big)$ ne dépendant que des observations $Y_k$ -- on dira un estimateur de $f$ -- de sorte que $\widehat f$ soit \og proche \fg{} de $f$ ?}
\end{quote}
Intuitivement, la difficulté du problème va dépendre de $N$ et du rapport entre la taille de $f$ et le niveau de bruit $\sigma$, et bien sûr de la complexité du signal\footnote{Un signal constant ou ayant une forme prescrite sera plus facile à reconstruire qu'un signal irrégulier.}. Voici une autre question très proche
\begin{quote}
{\it  Problématique statistique : comment décider  si le canal transmet effectivement un signal (afin de déclencher une alarme, par exemple). Autrement dit, peut-on décider en vue des $Y_k$ si $f = 0$ ou $f \neq 0$ ? Avec quelle probabilité de se tromper ?}
\end{quote}
On peut imaginer un signal en dimension 2 : par exemple, une image définie sur le carré unité $[0,1]\times [0,1]$ pour une certaine discrétisation en pixels auxquels sont associés des niveaux de gris dans $[1,M] \cap \N$. Das ce cas, on observe
$$Y_{k,\ell} = f(k/N,\ell/N)+\xi_{k,\ell},\;\;1\leq k,\ell \leq N,$$
où $$f:[0,1]\times [0,1]  \rightarrow [1,M]\cap \N$$
et les $\xi_{l,\ell}$ sont des erreurs, nulles en moyenne et d'ordre de grandeur $\sigma$.
On a $n = N^2$ observations. On pourra s'intéresser au problème de reconstruction de l'image $f$ ou bien décider si une certaine caractéristique
%\footnote{Par exemple, si l'image est très \og irrégulière \fg{}, $\|f\|$ sera grand pour une certaine norme $\|\cdot\|$ qui mesure cette irrégularité.}
est présente dans l'image ou non.
\subsubsection{Exemple 3 : Evaluation du risque d'un actif financier}
On recueille sur le marché les données du prix $(S_t, t \geq 0)$ d'un actif financier sur l'intervalle de temps $[0,T]$, pour une certaine échelle d'échantillonnage $\Delta$: par exemple, une semaine ou un jour, une heure, quelques minutes, etc. On observe les rendements logarithmiques
$$Y_i^\Delta = \log \frac{S_{i\Delta}}{S_{(i-1)\Delta}}, \;\;\; i\ = 1,\ldots, n = \lfloor T/\Delta \rfloor.$$
On a $n =  \lfloor T/\Delta \rfloor$ observations. Si l'on se place dans la théorie classique de Black-Scholes, la dynamique du prix suit l'équation
\begin{equation} \label{BS}
\frac{dS_t}{S_t} = \mu dt + \sigma dB_t,
\end{equation}
où $(B_t, t \geq 0)$ est un mouvement brownien, $\mu \in \R$ est le drift et $\sigma >0$ la volatilité de l'actif.
\begin{quote}
{\it
Problématique statistique : comment reconstruire\footnote{Par exemple, pour la comparer avec la volatilité implicite donnée par des prix d'options.} la volatilité $\sigma$ à partir des données historiques $Y_i^\Delta$ ? On peut aussi vouloir estimer le risque $\mu/(\sigma\sqrt{T})$ de l'actif\footnote{Que l'on désigne aussi comme son ratio de Sharpe.}.
}
\end{quote}
La réponse va dépendre de $T$, $\sigma$ et $\mu$, mais aussi de $\Delta$, choisi par le statisticien.
%Plus $\Delta$ est petit, plus le nombre de données $n$ est grand. Malheureusement, dans les petites échelles (par exemple si $\Delta$ est plus petit qu'une journée, on parle de données intra--day) la représentation \eqref{BS} n'est plus valide, car les effets de microstructure de marché apparaîssent.\footnote{Une solution populaire en économétrie de la finance consiste à remplacer dans les petites échelle le prix latent $S_t$ par un prix \og corrigé par bruit de microstructure\fg{}
%$$\widetilde S_{\i\Delta} = S_{i\Delta}+\xi_i^\Delta$$
%où $\xi_i^\Delta$ est un bruit nul en moyenne et de niveau $\widetilde \sigma$, appelé volatilité de microstructure. C'est dans ce contexte plus délicat que doit travailler le statisticien.}
\begin{figure}
\begin{center}
\includegraphics[angle=0, width=15cm]{BundLF.pdf}
\end{center}
\caption{Exemple 3 : observation des prix du contrat futur FGBL (Obligation 10 ans de l'Etat allemand), entre avril 1999 et décembre 2005. L'échantillonnage est de $\Delta = 1$ jour. (Source : BNP Paribas)}
\end{figure}
\subsubsection{Exemple 4 : Biopuces et analyse d'ADN}
On dispose d'un procédé de biologie moléculaire, les biopuces (ou microarrays) qui permet de mesurer l'expression de certains gènes d'un individu d'une espèce biologique dans certaines situations\footnote{Par exemple, en laboratoire, on peut mesurer l'intensité de l'expression de certains gènes d'un insecte infecté dans le but de localiser les gènes promoteurs de la réponse immunitaire.}. Dans ce cas, on dispose pour chaque individu $i$ d'une suite de localisations (qui correspondent grossièrement à des gènes) et d'une expression correspondante qui prend la forme
$$\bX_i = (X_1^{(i)},\ldots, X_J^{(i)}),\;\;i=1,\ldots, N$$
où $X_j^{(i)} \geq 0$ est le niveau d'expression des gènes parmi les sites $\{1,\ldots, J\}$ pour l'indi\-vidu $i$ pris dans une population de taille $N$. On a\footnote{Avec le fait notable qu'en pratique $N \ll J$ : $N$ est de l'ordre de quelques individus alors que $J$ est de l'ordre de plusieurs milliers.} $n = J N$ observations.
\begin{quote}
{\it Problématique statistique : peut-on localiser les sites $i$ responsables d'un état donné, sachant que les mesures des $X_j^{(i)}$ sont sujettes à des erreurs ?    Si l'on se donne deux populations, l'une atteinte d'une maladie soupçonnée d'être d'origine génétique, l'autre population étant saine, peut-on décider au vu des données $\bX_i$ (pour chaque population) si la maladie en question est d'origine génétique ?}
\end{quote}
\begin{figure}
\begin{center}
\includegraphics[angle=90, width=12cm]{micro1.pdf}
\end{center}
\caption{Exemple 4. Observation d'une biopuce en laboratoire : chaque carré lumineux mesure l'intensité d'expression d'un gène (en fait d'une séquence d'ARNm codante suffisamment longue pour être mise en correspondance avec un gène via la production de peptides pour lesquels code la séquence d'ADN correspondante). La représentation \og en carrés \fg{} est donnée pour économiser la représentation : il n'y a pas {\it a priori} de structure bi-dimensionnelle associée à cette \og image\fg{}.}
\end{figure}

\subsubsection{Exemple 5 : Contrôle de qualité, données censurées}
On cherche -- en laboratoire -- à tester la fiabilité d'un appareil industriel. On fait fonctionner en parallèle $n$ appareils jusqu'à ce qu'ils tombent tous en panne. On note
$$X_1,\ldots, X_n$$
les instants de panne observés. On dispose donc de $n$ observations.
\begin{quote}
{\it Problématique statistique : comment reconstruire la loi du temps de panne ? Le temps de panne moyen est-il raisonnable (plus petit qu'un seuil donné) ?}
\end{quote}
La précision d'estimation sur la loi du temps de panne des $X_i$ sera d'autant meilleure que $n$ est grand.

Si les appareils sont fiables, ce qui est réaliste en pratique, la quantité $\max_{i = 1,\ldots, n} X_i$ sera souvent hors d'atteinte pour le statisticien. On stoppe l'expérience après un temps terminal $T$ et on observe plutôt
$$X^\star_i = \min\{ X_i, T\},\;\;\;i=1,\ldots n.$$
\begin{quote}
{\it
Problématique statistique : quelle est la perte d'information, quantifiée par $T$, dans cette seconde expérience plus réaliste ?
}
\end{quote}

\subsubsection{Exemple 6 : Influence d'une variable sur une autre}
Comment quantifier une assertion comme \og la taille d'un individu est fonction de son âge \fg{} ?
Si on note $Y$ la taille et $X$ l'âge typiques d'un individu, il est irréaliste de postuler l'existence d'une fonction $f:\R \rightarrow \R$ telle que $Y = f(X)$.

Toutefois, on peut espérer que la \og variabilité \fg{} de $Y$ est \og essentiellement contenue \fg{} dans celle de $X$ dans le sens suivant : si $X$ et $Y$ sont deux variables aléatoires avec $Y$ de carré intégrable, écrivons
$$Y = r(X)+\xi,\;\;\;\text{avec}\;\;\;r(X)=\E\big[Y\,|\,X\big],$$
de sorte que $\xi =Y-\E\big[Y\,|\,X\big]$ est un \og bruit\fg{} centré. Cette décomposition est motivée par la propriété de l'espérance conditionelle qui est la meilleure approximation de $Y$ par une variable $X$- mesurable, au sens suivant :
$$\E\big[\big(Y-r(X)\big)^2\big] = \min_{h}\E\big[\big(Y-h(X)\big)^2\big]$$
où le minimum est pris sur l'ensemble des fonctions boréliennes. C'est une caractérisation de l'espérance conditionnelle pour des variables de carré intégrable (voir, par exemple, Jacod et Protter \cite{JP}).

On traduit \og la taille d'un individu est fonction de son âge \fg{} par \og la variance du bruit $\sigma^2= \E\big[\xi^2\big]$ est petite \fg{} par exemple. On collecte les âges et tailles $(X_i,Y_i)$ d'une population de $n$ individus. Les observations sont les $(X_i,Y_i)$, avec
\begin{equation} \label{representation regression}
Y_i = r(X_i)+\xi_i,\;\;i=1,\ldots, n
\end{equation}
et les $\xi_i$ sont des bruits centrés de taille $\sigma^2$. On a $n$ observations (ou $2n$ selon le point de vue). Les $X_i$ portent le nom de covariables, ou variables explicatives.
\begin{quote}
{\it Problématique statistique : comment reconstruire la fonction $r$ -- appelée fonction de régression -- et estimer l'intensité $\sigma^2$ du bruit ?
}
\end{quote}
Ce contexte est proche de celui de l'exemple 1 du signal bruité, à ceci près que les points $k/N$ sont remplacés par les données aléatoires $X_i$, dont les valeurs ne sont pas choisies par le statisticien. Mais si les $X_i$ sont \og bien répartis\fg{}, on s'attend à ce que les deux modèles soient proches lorsque $n$ est grand.

Les variables $X$ et $Y$ n'ont pas vocation à être de même dimension : on peut remplacer $X$ par un vecteur $\bX \in \R^k$ qui collecte un ensemble de covariables possibles. Dans ce cas, la représentation \eqref{representation regression} devient $Y_i = r(\bX_i)+\xi_i$ où maintenant $r:\R^k \rightarrow \R$, que l'on peut chercher à reconstruire.

%\subsubsection{Exemple 7 : variable qualitative influencée par une variable quantitative}

Il existe aussi des situations où $Y$ est une variable qualitative, c'est-à-dire ne prenant qu'un nombre fini de valeurs.
On peut penser que le risque de maladie coronarienne chez un individu est influencé par toute une série de facteurs : pression systolique, consommation de tabac, d'alcool, taux de cholestérol, poids, âge, terrain familial, etc.  On note $Y_i\in \{0,1\}$ l'absence ou la présence de maladie coronarienne pour un individu $i$ d'étude donné, et
$\bX_i$ le vecteur des covariables constitué des différentes données recueillies chez l'individu $i$. Dans ce cas, on a
$$r(\bx) = \PP\big[Y=1|\,\bX= \bx\big],$$
qui s'interprète comme la probabilité d'être atteint de maladie coronarienne, sachant le vecteur des covariables $\bX$.
\newpage
\subsection{Définition provisoire d'une expérience statistique$^\star$} \label{definition provisoire}
%Le fondement de la modélisation statistique est la notion \og d'observation \fg{}. Caricaturalement, le statisticien traite des observations et cherche à en  extraire toute \og l'information disponible \fg{} en vue de prendre une \og décision \fg{}.
Construire une expérience statistique consiste à identifier trois éléments distincts \vspace{3mm}:

\begin{enumerate}

\item {\it {\large Des observations}}
\begin{equation} \label{data}
{\tt x}_1, {\tt x}_2,\ldots, {\tt x}_n
\end{equation}
où les ${\tt x}_i$ sont des réels, mais on peut imaginer des situation plus complexes.\footnote{On peut considérer des données qualitatives, que l'on pourra coder par des entiers, ou bien des données plus complexes, comme par exemple une surface où la trajectoire d'un processus stochastique.
%(mais, en pratique, après discrétisation, on sera toujours ramené à des réels, et moins que cela en fait, puisque les réels seront eux-même codés par des entiers jusqu'à une certaine précision).
La difficulté provient de l'organisation des ${\tt x}_i$ qui peut être complexe (vecteurs, tableaux) et ne transparaît pas dans l'écriture \eqref{data}.} Ces observations sont associées à la réalisation d'une expérience physique, et le point de départ du statisticien est donc le résultat de cette expérience\vspace{3mm}.

\item {\it {\large Un modèle stochastique}} associé à l'expérience qui a engendré les observations. Les observations sont considérées comme la réalisation de variables aléatoires. La loi de ces variables aléatoires identifie le mécanisme de formation des observations. Cette loi dépend de paramètres inconnus{\vspace{3mm}}.

\item {\it {\large Une problématique}} associée au couple [observations, modèle]. Il s'agit pour le statisticien de \og retrouver\fg{} -- on dira estimer -- les paramètres inconnus.
% associé à l'expérience qui a engendré les observations.
Il faut pouvoir contrôler la qualité de cette estimation.

On peut aussi vouloir prendre une décision, par exemple sous la forme d'un test d'hypothèse sur les paramètres. Il faut pouvoir contrôler l'erreur de décision\vspace{7mm}.\footnote{C'est-à-dire la probabilité d'accepter une hypothèse sur les paramètres alors qu'elle est fausse, ou de la rejeter alors qu'elle est vraie.}
\end{enumerate}

%\begin{remarque}
%\emph{
%Dans cette démarche, le point $2$ est fondamental : il formalise la notion de hasard associé à des observations, et permettra de donner un sens à la notion d'erreur de décision. On appréhende ainsi les méthodes statistiques sous l'angle de la théorie des probabilités\footnote{Il existe d'autres approches des méthodes statistiques qui se passent de la notion de modèle stochastique (analyse des données et analyse en composantes principales \cite{analyse donnees}, bruit déterministe en analyse umérique \cite{num anal}).}.
%}
%\end{remarque}
La problématique statistique consiste à développer le point $3$ dans des situations associées aux points $1$--$2$.
%Précisons -- encore informellement -- un peu tout cela.
\begin{definition}[provisoire d'une expérience statistique] \label{modele stat provisoire}
Une expérience statistique est la donnée d'observations et d'un modèle stochastique susceptible d'avoir engendré ces observations.

Mathématiquement, les observations sont la réalisation d'un vecteur aléatoire $Z$ dont la loi $\PP^Z$ est prise dans une famille ${\mathcal P}$ de probabilités possibles donnée à l'avance et qui définit le modèle stochastique associé à l'observation.
\end{definition}
Cette définition règle\footnote{Avec les notations de la définition \ref{modele stat provisoire}, les observations s'écrivent sous la forme
$$({\tt x}_1,\ldots, {\tt x}_n)^T = Z(\omega)$$
et sont donc appréhendées comme la réalisation d'un vecteur aléatoire $Z$ défini implicitement sur un espace mesurable $(\Omega, {\mathcal A})$. La famille ${\mathcal P}$ est un ensemble de mesures de probabilités définies sur l'image $Z(\Omega)$ de $Z$.}
provisoirement les points 1 et 2.
Au moyen d'une paramétrisa\-tion appropriée, on peut toujours représenter la famille ${\mathcal P}$ sous la forme
$${\mathcal P} = \big\{\PP_\vartheta,\;\;\vartheta \in \Theta\big\},$$
où $\Theta$ est un ensemble de paramètres possibles. Le point 3 se traduit ainsi :
\begin{definition} La problématique statistique (ou l'inférence statistique) consiste, à partir d'une réalisation d'un vecteur aléatoire $Z$, dont la loi $\PP^Z$ est prise dans une famille $\{\PP_\vartheta,\;\; \PP_\vartheta \in \Theta\}$ donnée, à retrouver le paramètre $\vartheta$ tel que $\PP^Z = \PP_\vartheta$.
\end{definition}
Le paramètre $\vartheta$ résume toute l'information que peut apporter l'observation $Z(\omega)$. Identifier $\vartheta$ est équivalent à identifier $\PP_\vartheta$, c'est-à-dire la loi de la variable aléatoire $Z$ dont on a observé une réalisation $Z(\omega)$.

%L'expérience statistique consiste à observer dans une population donnée de taille $n$ les données $(\bX_i,Y_i)$ pour chaque individu $i=1,\ldots,n$
%est si on veut modéliser l'influence du taux de cholesterol sur sa


%un bon exemple de regression ave random design (ou l on ne choisit pas les X_i)
%\newpage

%Ainsi posées, ces définitions ne nous donnent aucune idée de la faisabilité du point $3$ étant donné les points $1$--$2$. On peut tout de même imaginer sans plus de précision pour le moment que la problématique du point $3$ devrait être d'autant plus raisonnable que l'on se place dans une situation où simultanément  $n$ est grand (la dimension de l'observation) et $\Theta$ est \og petit \fg{} (l'ensemble des paramètres).


\section{Formulation mathématique}
\subsection{Expérience engendrée par une observation}
\subsubsection{Situation}
Une expérience statistique est la donnée d'un vecteur aléatoire $Z$ à valeurs dans un espace mesurable $(\mathfrak{Z}, {\mathcal Z})$, le plus souvent $(\R^n, {\mathcal B}^n)$ et définie sur un espace de probabilité $(\Omega, {\mathcal F}, \PP)$.
La problématique statistique consiste à supposer que $\PP^Z$ appartient à une famille de probabilités sur $(\mathfrak{Z}, {\mathcal Z})$, et le but est de \og retrouver \fg{} les propriétés de $\PP^Z$ à partir de l'observation d'une réalisation de $Z$ seulement.\\

On représente cette famille sous la forme
$\big\{\PP_\vartheta, \vartheta \in \Theta \big\},$ où $\vartheta$ est un paramètre et $\Theta$ un ensemble de paramètres. Dans un problème statistique, seul \og l'espace d'état \fg\; $(\mathfrak{Z}, {\mathcal Z})$ et la famille de probabilités $\big\{\PP_\vartheta, \vartheta \in \Theta\big\}$ comptent. Une fois ces éléments spécifiés, la donnée de $Z$ et de l'espace $(\Omega, {\mathcal F}, \PP)$ deviennent superflus.

%Ceci nous amène à la définition suivante.

\begin{definition}[Expérience statistique] \label{def math exp stat}
Une expérience (un modèle) statistique ${\mathcal E}$ est la donnée d'un triplet
$${\mathcal E} = \big(\mathfrak{Z}, {\mathcal Z}, \{\PP_\vartheta, \vartheta \in \Theta\}\big)$$
où $(\mathfrak{Z}, {\mathcal Z})$ est un espace mesurable et $\{\PP_\vartheta, \vartheta \in \Theta\}$ une famille de probabilités définie sur $(\mathfrak{Z}, {\mathcal Z})$. On appelle $\Theta$ l'ensemble des paramètres.
\end{definition}

%\begin{definition} Si l'expérience ${\mathcal E}$ est construite à partir d'une observation $X$ par le procédé ci-dessus, on dit que ${\mathcal E}$ est {\bf engendrée} par l'observation $X$.
%\end{definition}
On parle indifféremment d'expérience statistique ou de modèle statistique. On parlera parfois simplement du modèle $\big\{\PP_\vartheta, \vartheta \in \Theta\big\}$ lorsque le contexte ne prête pas à confusion\footnote{Sans préciser l'espace $(\mathfrak{Z}, {\mathcal Z})$ sur lequel sont définies simultanément toutes les probabilités $\PP_\vartheta$, $\vartheta \in \Theta$.}.

\begin{definition}[Expérience engendrée par une observation] \label{exp engendree}
Si l'expérience sta\-tisti\-que ${\mathcal E}$ est construite à partir d'une observation $Z$ par le procédé ci-dessus, on dit que ${\mathcal E}$ est engendrée par l'observation $Z$.
\end{definition}

\subsubsection{Exemple}
On observe $n$ variables aléatoires indépendantes, gaussiennes de moyenne $\mu \in \R$ et de variance $\sigma^2 >0$. L'expérience statistique associée est décrite comme l'observation de
$$X_1,\ldots, X_n\;\;\text{indépendantes, identiquement distribuées},$$
$$X_i\sim{\mathcal N}(\mu,\sigma^2),\;\;\mu \in \R,\;\;\sigma^2 >0.$$
Il existe donc un espace de probabilités $(\Omega, {\mathcal F}, \PP)$ sur lequel est défini le vecteur aléatoire
$Z = (X_1,\ldots, X_n)^T$
%:\big(\Omega, {\mathcal F}\big)\rightarrow \big(\R^n, {\mathcal B}(\R^n)\big)$,
et
$\PP^Z$ est la loi de $n$ variables gaussiennes indépen\-dantes de moyenne $\mu$ et de variance $\sigma^2$. La probabilité $\PP^Z$, définie sur $\big(\R^n, {\mathcal B}^n\big)$, dépend de $\mu$ et $\sigma^2$ même si cela ne transparaît pas dans les notations. On a
$$\PP^Z[A] = (2\pi)^{-n/2}\int_{A} \exp\big(-\tfrac{1}{2\sigma^2}\sum_{i = 1}^n (x_i-\mu)^2\big)dx_1\cdots dx_n,\;A \in {\mathcal B}^n.$$
Dans ce cas, on construit l'expérience ${\mathcal E}$ associée de la façon suivante : on pose
$$\big(\mathfrak{Z}, {\mathcal Z}\big) = \big(\R^n, {\mathcal B}^n\big),\;\;\vartheta = (\mu, \sigma^2),\;\Theta = \R \times \R_+\setminus \{0\},\;\;\PP_\vartheta = \PP^Z,$$
où ${\mathcal B}^n$ désigne la tribu borélienne de $\R^n$.
\begin{remarque}
\emph{
En toute rigueur, on ne peut pas dire que l'on observe $Z$, mais plutôt que l'on observe une réalisation $Z(\omega)$ de $Z$, qui correspond aux \og données physiques \fg{} ${\tt x}_1, {\tt x}_2, \ldots, {\tt x}_n$ que l'on traite effectivement en pratique. Mathématiquement, cela n'a aucune importance, et on s'autorisera cet abus de langage. Le paragraphe suivant permet de lever cette ambiguité\footnote{En statistique, on parle de $Z$ pour désigner $Z(\omega)$, à l'inverse de la pratique qui consiste à écrire parfois $f(x)$ pour désigner la fonction $f$.} sur laquelle nous ne reviendrons plus.
}
\end{remarque}

\subsection{Observation canonique$^\star$} \label{experience canonique}

Lorsque l'on spécifie directement une expérience statistique ${\mathcal E}$ via la Définition \ref{def math exp stat}, il n'y a pas d'observation $Z$. Une façon immédiate de \og consi\-dérer \fg \; ${\mathcal E}$ comme engendrée par une observation $Z$ consiste à poser
$$(\Omega, {\mathcal F}) = \big(\mathfrak{Z}, {\mathcal Z}\big)\;\;\text{et}\;\;Z(\omega) = \omega,\;\;\omega \in \Omega,$$
et $\PP^Z = \PP_\vartheta$ est la loi de $Z$ qui dépend ici explicitement de $\vartheta$ dans les notations.
\begin{definition}[Observation canonique] \label{exp canonique}
Si l'observation $Z$ est construite à partir d'une expérience statistique ${\mathcal E}$ par le procédé ci-dessus, on dit que $Z$ est l'observation canonique associée à ${\mathcal E}$.
\end{definition}

Ces deux points de vue peuvent parfois être source de confusion, principalement dans les notations.
Dans la pratique (mathématique) on n'aura pas besoin de se soucier du point de vue sous lequel on se place, les  Définitions \ref{exp engendree} et \ref{exp canonique} étant équivalentes.
\subsection{Domination}
Appréhender une famille de mesure $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ sans plus d'hypothèse est très ambitieux, comme on le verra au Chapitre \ref{echantillonnage}. Sous une hypothèse de régularité, dite de domination, on ramène le problème de l'étude des $\PP_\vartheta$ à une famille de fonctions sur $(\mathfrak{Z}, {\mathcal Z})$.

\begin{definition} Etant données deux mesures positives $\sigma$-finies $\mu$ et $\nu$ définies sur $\big(\mathfrak{Z}, {\mathcal Z}\big)$, on dit que $\mu$ domine $\nu$ et on écrit $\nu \ll \mu$ si
$$\mu[A] = 0 \Rightarrow \nu[A]=0.$$
\end{definition}
Le théorème de Radon-Nikodym (voir par exemple Jacod et Protter \cite{JP}, Chapitre 28) entraîne l'existence d'une fonction mesurable positive $z\leadsto p(z)$, notée $z \leadsto \tfrac{d\nu}{d\mu}(z)$, appelée densité de $\nu$ par rapport à $\mu$, définie à un ensemble $\mu$-négligeable près, de sorte que
$$\nu(dz) = p(z) \mu(dz),$$
au sens où
$$\nu[A] = \int_A p(z)\mu(dz) = \int_A \tfrac{d\nu}{d\mu}(z) \mu(dz),\;A \in {\mathcal Z}\vspace{3mm}.$$

\begin{definition} Une expérience statistique ${\mathcal E} = \big(\mathfrak{Z}, {\mathcal Z}, \{\PP_\vartheta, \vartheta \in \Theta\}\big)$ est dominée par la mesure $\sigma$-finie $\mu$ définie sur $\big(\mathfrak{Z}, {\mathcal Z}\big)$ si
pour tout $\vartheta \in  \Theta$, la mesure $\mu$ domine $\PP_\vartheta$.
\end{definition}
Dans ce cas, il existe, pour tout $\vartheta \in \Theta$ une densité
$$z \leadsto p(\vartheta, z) = \frac{d\PP_\vartheta}{d\mu}(z)$$
de sorte que
$$\PP_\vartheta(dz) = p(\vartheta,z)\mu(dz),\;\;z \in \mathfrak{Z}.$$
L'hypothèse de domination permet de \og réduire \fg{} l'étude de la complexité de la famille de mesure $\big\{\PP_\vartheta, \vartheta \in \Theta\big\}$ à celle de l'application
$$p:\Theta \times \mathfrak{Z} \rightarrow \R_+$$
et de la mesure dominante $\mu$. Nous verrons dans les chapitres suivants comment l'étude systématique des propriétés de $p(\cdot,\cdot)$ rend compte des propriétés de ${\mathcal E}$.
\begin{exemple}
\emph{
Un exemple où il n'existe pas de mesure dominante est la famille paramétrique $\{\PP_\vartheta = \delta_\vartheta,\vartheta \in \R\}$, où $\delta_\vartheta$ est la mesure de Dirac au point $\vartheta$. Cet exemple\footnote{En effet, s'il existe une mesure $\sigma$ -finie $\mu$ sur $\R$ qui domine tous les $\PP_\vartheta = \delta_\vartheta$, alors nécessairement $\mu\{\vartheta\}\neq 0$ pour tout $\vartheta \in \R$. Ceci est en contradiction avec l'existence d'une partition dénombrable $A_n$ de $\R$ telle que $\mu(A_n)<+\infty$ pour tout $n$, donc $\mu$ ne peut pas être $\sigma$-finie.} correspond à l'expérience parfaite où une seule observation permet de connaître sans erreur le paramètre $\vartheta$.
}
\end{exemple}
\begin{exemple}
\emph{
Un exemple plus subtil est donné
par l'expérience engendrée par l'observation de $\vartheta X$, où $X$ suit une loi de Poisson de paramètre $1$, et $\vartheta \in \Theta = \R_+\setminus \{0\}$ est le paramètre. Dans ce cas, l'expérience est \og vraiment aléatoire\fg{}, mais on pourra montrer en exercice qu'elle n'est pas dominée\footnote{Indication : la loi de $X$ s'écrit $\PP_\vartheta(dx) = \sum_{k \in \N}\tfrac{1}{k!} e^{-1}\delta_{\vartheta k}(dx)$. On raisonne alors de la même manière que pour l'expérience parfaite.}.
}
 \end{exemple}
\subsection{Modèles paramétriques, non-paramétriques$^\star$}
On distingue deux types d'expériences statistiques : les expériences paramétriques, où $\Theta$ peut s'écrire comme un sous-ensemble de $\R^d$, le paramètre $\vartheta$ pouvant être décrit par un nombre fini de composantes, et les expériences non-paramétriques, où $\vartheta$ est un élément d'un espace fonctionnel.

Par exemple, dans les exemples 2 -- signal bruité -- et 6 -- influence d'une variable sur une autre -- de la Section \ref{exemples introductifs}, le paramètre inconnu est le signal $f$ ou la fonction de régression $r$. Si l'on postule que $f$ (ou $r$) se représente sous la forme
$$f(\vartheta, x) = \sum_{i =1}^d\vartheta_i \varphi_i(x),\;\;x \in \R$$
où les fonctions $\varphi_i$ sont données, l'expérience statistique est paramétrique, et
$$\vartheta  = (\vartheta_1,\ldots,\vartheta_d)^T \in \Theta \subset \R^d.$$
Le choix $d=2$ et $r(\vartheta, x) = \vartheta_0+\vartheta_1 x$ correspond à \og la droite de régression \fg{}, que l'on étudiera en détail dans la Section \ref{regression lineaire simple}.

Si $f$ est un élément quelconque d'un espace fonctionnel (décrit le plus souvent par des propriétés de régularité fonctionnelles : par exemple, $f$ est de carré intégrable et dérivable un certain nombre de fois dans $L^2$), alors l'expérience associée est non-paramétrique et le paramètre $\vartheta$ est la fonction $f$ elle-même. Si les fonctions $\varphi_i$ sont les $d$-premiers éléments d'une base orthogonale de $L^2$ , alors la transition d'une situation paramétrique vers une situation non-paramétrique consiste formellement à passer à la limite dans le nombre de dimensions $d$ qui décrivent le paramètre inconnu.

La distinction paramétrique ou non-paramétrique est un choix de modélisation. Pour l'exemple 2 de la transmission d'un signal bruité  ou de la reconstruction d'une image de la Section \ref{exemples introductifs}, un modèle non-paramétrique semble plus approprié que pour l'exemple du sondage. Pour l'exemple 3 de l'estimation de la volatilité, on a choisi de prendre $\sigma >0$ constant. Si on veut tenir compte des fluctuations de la volatilité dans le temps, une représentation fonctionnelle  $(\sigma(t), t \geq 0)$ est plus appropriée. Le modèle sera plus proche de la réalité, mais le problème statistique plus difficile.

Dans ce cours, hormis le Chapitre \ref{echantillonnage}, nous nous restreindrons à l'étude d'expériences paramétriques.
%\footnote{mais l'inférence non-paramétrique est très fortement liée aux expériences paramétriques, comme le suggère la représentation de $f$ dans cet exemple.}

\section{Exemples}
\subsection{Modèle d'échantillonnage ou du $n$--échantillon}
De par la simplicité de sa structure, c'est une des expérience statistiques les plus étudiées, et qui occupe trois chapitres de ce cours.
\subsubsection{Situation}
Pour $n \geq 1$, on considère (la suite) d'expérience(s) engendrée par l'observation de $n$-variables aléatoires réelles
$$X_1,\ldots, X_n\;\;\;\text{indépendantes, identiquement distribuées},$$
de loi inconnue $F$ sur $\R$, où $F \in \mathfrak{F}$ appartient à une famille de loi $\mathfrak{F}$ donnée. L'expérience statistique ${\mathcal E}^n$ correspondante est engendrée par le vecteur $Z  = (X_1,\ldots, X_n)^T$ et on peut écrire
$${\mathcal E}^n = \big(\R^n, {\mathcal B}^n, \{\PP^{\,n}_F, F \in \mathfrak{F}\}\vspace{2mm}\big)$$
où $\PP_F^n$ est la loi sur $\R^n$ de $n$-variables aléatoires indépendantes de loi $F$. Cela signifie en particulier, que, pour tous $x_1,\ldots, x_n \in \R$, on a
$$\PP_F^{\,n}\big[X_1 \leq x_1,\ldots, X_n \leq x_n\big] = \prod_{i=1}^n F(x_i).$$
En particulier, si $\mathfrak{F}$ est constituée de distributions $F$ absolument continues, de densité $f$, alors le vecteur $(X_1,\ldots, X_n)$ admet une densité par rapport à la mesure de Lebesgue donnée par
$$(x_1,\ldots, x_n) \leadsto p(x_1,\ldots, x_n) = \prod_{i = 1}^n f(x_i).$$
Dans ce cas, on a
\begin{equation} \label{domination echantillonnage}
\PP_F(dx_1\ldots dx_n) =p(x_1,\ldots, x_n)dx_1\ldots dx_n
\end{equation}
et l'expérience ${\mathcal E}^n$ est dominée par la mesure de Lebesgue sur $\R^n$.
\subsubsection{Experience produit et domination}
Si $\mathcal E$ désigne l'expérience engendrée par une seule observation $X\sim F$, c'est-à-dire
$${\mathcal E} = \big(\R, {\mathcal B}, \{F\in \mathfrak{F}\}\big)$$
alors ${\mathcal E}^n$ est le \og produit\fg{} de $n$ copies indépendantes de ${\mathcal E}$ et on écrit parfois
$${\mathcal E}^n = {\mathcal E} \times \ldots \times {\mathcal E}\;\;\;\;(n\text{-fois}).$$

Si la famille $\mathfrak{F}$ est dominée par une mesure $\mu$ sur $\R$, alors l'expérience ${\mathcal E}^n$ est dominée par la mesure produit
$\mu^n = \mu \otimes \ldots \otimes \mu$ sur $\R^n$. En particulier, si $\mu$ est la mesure de Lebesgue sur $\R$, on retrouve  \eqref{domination echantillonnage}.
\subsubsection{Les exemples de la Section \ref{exemples introductifs}}
Les exemples 1 -- sondage --, 3 -- risque d'un actif financier --  et 5 -- contrôle de qualité -- de la Section \ref{exemples introductifs} sont des modèles d'échantillonnage :

\begin{enumerate}
\item Pour l'exemple 1 --sondage ou lancer de dé, on peut associer à chaque votant une variable $X_i$ prenant la valeur  $0$ ou $1$ selon que l'on vote pour A (pile) ou B (face). La loi de $X_i$ est une loi de Bernoulli de paramètre inconnu $\vartheta \in \Theta = [0,1]$. Si $\vartheta < 1/2$, $A$ gagne. Si $\vartheta \neq \tfrac{1}{2}$, la pièce est truquée.

Si l'on récolte la suite complète $X_1,\ldots, X_n$ des votes (des lancers) supposés indépen\-dants et de même loi de Bernoulli de paramètre $\vartheta$, alors on est dans un modèle d'échantillonnage, et l'expérience associée s'écrit
$${\mathcal E}^n = \Big(\{0,1\}^n,\text{tribu des parties de}\;\{0,1\}^n, \big\{\PP_\vartheta^n,\vartheta \in \Theta \big\}\Big),$$
où
$$\PP_\vartheta^n = \PP_\vartheta \otimes \cdots \otimes \PP_\vartheta\;\;(n\;\text{fois}),$$
avec
$$\PP_\vartheta\big[X=1\big]=\vartheta = 1-\PP_\vartheta[X=0],$$
ce que l'on peut encore écrire sous la forme
$$\PP_\vartheta(dx) = \vartheta \delta_{1}(dx)+(1-\vartheta)\delta_{0}(dx),$$
où $\delta_a(dx)$ désigne la mesure de Dirac au point $a$. Cette dernière représentation permet de mettre en évidence la mesure de comptage $\mu(dx) = \delta_0(dx)+\delta_1(dx)$ sur $\{0,1\}$ comme mesure dominante pour $\PP_\vartheta$. La mesure de comptage $\mu^n = \mu \otimes \cdots \otimes \mu$ sur le produit $\{0,1\}^n$ domine alors l'expérience ${\mathcal E}^n$.

Une autre manière de procéder est de considérer que l'on n'observe que le nombre de votants $n_A$ pour le candidat $A$ (ou $n_P$), ce qui donne aussi $n_B$ (ou $n_F$), puisque $n_A+n_B=n_P+n_F=n$. Dans ce cas, on n'a qu'une seule observation $X$, et on modélise $n_A$ comme la réalisation d'une variable aléatoire $X$ binomiale de paramètres $(n,\vartheta)$, où $\vartheta \in \Theta = [0,1]$ est le paramètre inconnu. Dans ce cas, l'expérience statistique s'écrit
$$\widetilde {\mathcal E}^n =  \Big(\{0,n\},\text{tribu des parties de}\;\{0,n\}, \big\{\mathbb{Q}_\vartheta^n,\vartheta \in \Theta \big\}\Big),$$
où cette fois-ci les $\mathbb{Q}_\vartheta^n$ sont définies sur $\{0,\ldots, n\}$ et
$$\mathbb{Q}_\vartheta^n\big[X=x\big] = C_n^x \vartheta^x (1-\vartheta)^{n-x},\;\;x=0,\ldots,n,$$
ce qui s'écrit aussi
$$\mathbb{Q}_\vartheta^n(dx) = \sum_{k=0}^n C_n^k \vartheta^k (1-\vartheta)^{n-k}\delta_k(dx).$$
Cette dernière représentation permet de mettre en évidence la mesure de comptage $\mu_n(dx) = \sum_{k=0}^n\delta_k(dx)$ sur $\{0,\ldots, n\}$ comme mesure dominante du modèle.

Intuitivement les expériences statistiques ${\mathcal E}^n$ et $\widetilde {\mathcal E}^n$ contiennent la même information sur le paramètre $\vartheta$. On verra au Chapitre \ref{theorie asymptotique} comment formaliser et quantifier cette idée.

\item Pour l'exemple 3 -- risque d'un actif financier -- les observations s'écrivent
$$Y_i^\Delta = \mu\Delta + \sigma (B_{i\Delta}-B_{(i-1)\Delta})\sim {\mathcal N}\big(\mu\Delta,\sigma^2\Delta\big)$$
et sont indépendantes, en utilisant les propriétés caractéristiques du mouvement brownien (que l'on pourra admettre) :
$B_t-B_s\sim {\mathcal N}(0,t-s)$ et $B_t-B_s$ est indépendant du passé jusqu'à l'instant $s$.

La loi $F$ de $Y_i^\Delta$ est dominée par la mesure de Lebesgue sur $\R$ et sa densité
$$x \leadsto f(\vartheta, x) = (2\pi\Delta\sigma^2)^{-1/2}\exp\big(-\tfrac{1}{2\sigma^2\Delta}(x-\Delta\mu)^2\big)$$
dépend du paramètre $\vartheta = (\mu,\sigma^2) \in \Theta = \R \times \R_+\setminus\{0\}$.

\item Pour l'exemple 5 -- contrôle de qualité -- c'est évident. Noter qu'un modèle classique de durée de vie est fourni par la famille de lois exponentielles de paramètre $\vartheta \in \R_+\setminus \{0\}$. Dans ce cas, l'expérience ${\mathcal E}$ est dominée par la mesure de Lebesgue sur $\R$ et la loi de $Y_i$ s'écrit
$$\PP_\vartheta(dx) = \vartheta e^{-\vartheta x}1_{\{x \in \R_+\}}dx.$$
Si les variables $Y_i$ sont censurées par un instant terminal $T$ connu, on observe alors plutôt $Y_i^\star = \min\{Y_i, T\}$. Dans ce cas, la loi $\PP^\star$ de $Y_i^\star$ n'est ni discrète, ni continue, comme dans la Section \ref{melange} du Chapitre \ref{chapitre 1}.

On pourra montrer en exercice que $\PP^\star$ est dominée par $\mu(dx) = dx+\delta_{T}(dx)$, où $dx$ est la mesure de Lebesgue sur $\R$ et $\delta_{T}(dx)$ est la mesure de Dirac au point $T$. On a
$$\PP_\vartheta^\star(dx) = p(\vartheta, x)\mu(dx),$$
où $$p(\vartheta,x) =  \vartheta e^{-\vartheta x}1_{\{x < T\}} +c(\vartheta)1_{\{x=T\}},$$
avec $c(\vartheta) = \int_{T}^{+\infty}\vartheta e^{-\vartheta t}dt= e^{-\vartheta T}$.

\end{enumerate}

\subsection{Modèles de régression}
%citer les exemples
\subsubsection{Régression conditionnelle ou modèle de signal  bruité}
On observe une fonction $r : \R^k \rightarrow \R$ échantillonnée en $n$ points, chaque observation étant \og bruitée \fg{} par une erreur systématique :
$$Y_i = r(\bx_i)+\xi_i,\;\;\;i=1,\ldots, n.$$
Les bruits $\xi_i$ sont des variables indépendantes, identiquement distribuées, centrées et de carré intégrable. Les $\bx_i$ sont les points d'échantillonnage, appelés parfois points de \og design  \fg{}, définis sur un domaine ${\mathcal D} \subset \R^k$ en général borné. Si $k=1$, on prend le plus souvent ${\mathcal D} = [0,1]$ et $\bx_i = x_i = i/n$, $i=1,\ldots, n$.
Si $k \geq 1$ on peut imaginer que les points se \og répartissent \fg{} de façon régulière sur ${\mathcal D}$, ou bien au contraire qu'ils se concentrent dans une région de ${\mathcal D}$. Dans cette acceptation du modèle de régression, le statisticien choisit les points $\bx_i$.

Si $r = r(\vartheta,\cdot)$  est connue au paramètre $\vartheta \in \Theta \subset \R^d$ près, le modèle est paramétrique. C'est le cas qui nous intéressera.
Une forme paramétrique particulièrement importante est la régression linéaire $r(\vartheta, \bx) = \vartheta^T\bx$, qui est bien définie dès que $k=d$.
%\footnote{si $k = d-1$ on peut toujours compléter $\bx$ en ajoutant la composante $1$ au vecteur $\bx$, qui jouera le rôle d'ordonnée à l'origine. Par exemple, si $\vartheta = (\vartheta_0, \vartheta_1, \vartheta_2)^T$, on peut modifier $\bx = (x_1, x_2)^T$ en $\tilde \bx = (1,x_1,x_2)^T$ et on a alors $\vartheta^T\tilde \bx = \vartheta_0+\vartheta_1x_1+\vartheta_2x_2.$} $k \leq d \leq k+1$.

L'expérience statistique correspondante ${\mathcal E}^n$ est  engendrée par les $Y_i$, $i=1,\ldots, n$. Ce sont des variables indépendantes mais pas identiquement distribuées (chaque $Y_i$ dépend de $\bx_i$). On a
$${\mathcal E}^n = \big(\R^n, {\mathcal B}^n, \{\PP_\vartheta^{\,n}, \vartheta \in \Theta\}\big),$$
où $\PP_\vartheta^{\,n}$ est la loi conjointe des $Y_i$. En particulier, pour tous $y_1,\ldots, y_n \in \R$,
$$\PP_\vartheta^{\,n}\big[Y_1 \leq y_1,\ldots, Y_n \leq y_n\big] = \prod_{i=1}^n F_{\bx_i}(y_i),$$
où $y \leadsto F_{\bx_i}(y)$ est la fonction de répartition de $Y_i$. Par exemple, si $\xi_i$ a une densité $g$ par rapport à la mesure de Lebesgue sur $\R$, on a
$$F_{\bx_i}(y) = \int_{_\infty}^y g\big(t-r(\vartheta, \bx_i)\big)dt.$$
Dans ce cas, le vecteur $(Y_1,\ldots, Y_n)$ a lui-même une densité par rapport à la mesure de Lebesgue sur $\R^n$, donnée par
$$(y_1,\ldots, y_n) \leadsto p(\vartheta, y_1,\ldots, y_n) = \prod_{i = 1}^n g\big(t-r(\vartheta, \bx_i)\big).$$
On a alors
$$\PP_\vartheta(dy_1\ldots dy_n) = p(\vartheta, y_1,\ldots, y_n) dy_1\ldots dy_n$$
et le modèle est dominé par la mesure de Lebesgue sur $\R^n$.

%Plus généralement, si la loi des bruits $\xi_i$ est dominée par une mesure $\mu$ sur $\R$, alors $\mu$ domine ${\mathcal E}$ et la mesure produit $\mu^n =\mu \otimes \cdots \otimes \mu$ ($n$ fois) sur $\R^n$  domine ${\mathcal E}^n$.
%

L'exemple 2 -- signal bruité -- de la Section \ref{exemples introductifs} est un modèle de régression conditionnelle.

Le terme de régression conditionnelle pour ce modèle se justifie par opposition à la régression non-conditionnelle ou avec variables explicatives, que nous présentons maintenant.
\subsubsection{Régression avec variables explicatives}
Lorsque l'on veut étudier l'influence d'une variable aléatoire $X$ comme dans l'exemple 6 de la Section \ref{exemples introductifs}, ou plus généralement d'un vecteur aléatoire $\bX \in \R^k$ sur une variable aléatoire réelle $Y$, on part généralement de l'observation d'un $n$-échantillon
$$(\bX_1,Y_1),\ldots, (\bX_n, Y_n)$$
de même loi que $(\bX, Y)$. Formellement, on est dans le modèle du $n$-échantillon, mais avec une différence notoire : c'est la loi de $Y$ qui nous intéresse, les $\bX_i$ n'étant que des observations auxiliaires. Les $\bX_i$ portent le nom de covariables, ou variables explicatives.

On peut postuler une représentation du type
\begin{equation} \label{one more regression}
Y = r(\bX)+\xi,
\end{equation}
où $r:\R^k\rightarrow \R$ est la fonction de régression $r(\bx) = \E\big[Y\,|\,\bX=\bx\big]$ qui est la meilleure approximation de $Y$ par une variable aléatoire $\bX$-mesurable au sens suivant :
$$\E\big[\big(Y-r(\bX)\big)^2\big] = \min_h\E\big[\big(Y-h(\bx)\big)^2\big]$$
où le minimum est pris sur les fonctions boréliennes de $\R^k$ dans $\R$, comme nous l'avons déja mentionné dans l'exemple 6 -influence d'une variable sur une autre.

On est alors dans une situation tout à fait analogue avec celle du paragraphe précédent, à la différence près que le statisticien ne choisit pas le \og design \fg{}
$$(\bX_1,\ldots, \bX_n).$$
Cela a des incidences pratiques bien entendu, mais d'un point de vue mathématique, on peut faire une hypothèse relativement faible qui permet d'unifier les deux points de vue :

\begin{hypothese}[Ancillarité du \og design \fg{}] \label{first ancillarity} La loi de $\bX$ ne dépend pas de $\vartheta$.
\end{hypothese}

Autrement dit, toute l'information sur la loi de $Y$ que porte $r(\bX)$ est contenue dans la fonction de régression $r(\cdot)$. Dans ce cas, puisque les $\bX_i$ sont observées et que leur loi ne dépend pas de $\vartheta$, {\it on peut oublier ou ignorer le caractère aléatoire des $\bX_i$} et raisonner dans toute la suite conditionnellement aux $\bX_i = \bx_i$, où les $\bx_i$ sont les valeurs observées\footnote{On reviendra sur ce point de vue dans le Chapitres \ref{regression}.}.

Sous l'Hypothèse \ref{first ancillarity}, le modèle de régression avec variables explicatives coïncide avec le modèle de régression conditionnelle et les formules du paragraphe précédent sont valides dans ce contexte.

\subsubsection{Régression logistique}
Si l'on veut étudier l'influence d'un vecteur $\bX$ sur une variable qualitative $Y \in \{0,1\}$ comme pour l'étude du risque de maladie coronarienne de l'exemple 6,  l'écriture du modèle de régression \eqref{one more regression} prend la forme
$$Y =r(\bX)+\xi =  \PP\big[Y=1|\bX\big] +\xi,$$
avec $\xi = Y- \PP\big[Y=1|\bX\big]$ qui vérifie bien $\E\big[\xi\big]=0$.

Dans un cadre paramétrique, un choix populaire de la fonction $r(\vartheta,\cdot):\R^k \rightarrow [0,1]$  se fait de la manière suivante : on se donne un difféomorphisme $\psi:\R \rightarrow (0,1)$. Dans ce cas, on peut forcer un modèle linéaire du type
$$r(\vartheta, \bx) = \psi(\vartheta^T\bx ),\;\;\vartheta \in \R^{d},\;\;x\in \R^k$$
avec $d=k$. Un exemple incontournable pour les applications est celui de la fonction logistique
$$\psi(x)=\frac{e^x}{1+e^x},\;\;x\in \R,$$
sur lequel nous reviendrons au Chapitre \ref{regression}.

\part{Méthodes d'estimation}

\chapter{Echantillonnage et fonction de répartition empirique} \label{echantillonnage}
\section{Introduction}
\subsection{Situation}
Nous étudions dans ce chapitre le problème très général qui consiste à \og quantifier \fg\; l'information fournie par l'observation d'un $n$-échantillon d'une loi $F$ sur $\R$, sans faire aucune (ou presque aucune) hypothèse sur cette loi.  Ce chapitre est aussi un prétexte pour introduire les différentes problématiques du cours : estimation, tests et régions de confiance, point de vue asymptotique.

Le terme \og quantifier \fg\; utilisé plus haut est imprécis ; nous le qualifierons à travers la construction d'estimateurs de $F$ -- ou de fonctionnelles $T(F)\in \R$ de
$F$ -- et de leur précision d'estimation, ce qui nous amènera à parler de région (et d'intervalles) de confiance.  Nous considèrerons aussi brièvement le problème de test d'hypothèse : à partir de l'observation, décider si la loi $F$ vérifie une propriété donnée.
De manière générale, nous étudierons comment la qualité des procédures statistiques  augmente avec le nombre d'observations $n$. Nous comparerons les points de vue asymptotique (dans la limite $n\rightarrow \infty$) et non-asympto\-tique.

Ici, la structure probabiliste de l'expérience statistique est très simple (variables aléa\-toires indépendantes et identiquement distribuées) mais l'ensemble des paramètres\footnote{c'est-à-dire l'ensemble de toutes les lois de probabilités $F$ sur $\R$.} est énorme ! De ce point de vue, l'expérience statistique considérée est non-paramétrique. Dans les chapitres suivants, nous développerons systématiquement des méthodes lorsque l'on fait des hypothèses supplémentaires sur l'ensemble des paramètres.


%Nous verrons dans les chapitres suivants comment la réduction de l'espace des paramètres enrichit la structure de l'expérience statistique.
\subsection{Notations et définitions préliminaires}
On observe un $n$-échantillon
$$X_1,\ldots, X_n$$
noté le plus souvent
$$\big(X_1,\ldots, X_n\big)^T$$
de loi inconnue $F$ sur $\R$. On ne fait pas d'hypothèse particulière sur la loi commune des $X_i$. L'expérience statistique sous-jacente, au sens de la Définition \ref{def math exp stat} du Chapitre \ref{chapitre 2}, s'écrit
$${\mathcal E}^n = \big(\R^n, {\mathcal B}^n,(\PP_F^{\,n}, F \in \mathfrak{F})\big),$$
où
$$\mathfrak{F} = \big\{F,\;F\;\text{fonction de répartition}\big\}$$
et $\PP_F^{\,n}$ est la loi sur $\R^n$ de $n$ variables aléatoires indépendantes de loi $F$. En particulier, pour tous $x_1,\ldots, x_n \in \R$, on a
$$\PP_F^{\,n}\big[X_1 \leq x_1,\ldots, X_n \leq x_n\big] = \prod_{i=1}^n F(x_i).$$
On écrira parfois $\PP_F$ ou $\PP$ à la place de $\PP_F^{\,n}$ lorsqu'il n'y aura pas de risque de confusion. On écrit aussi $X$ pour l'une quelconque des $X_i$ lorsque l'indice ne joue pas de rôle.

\begin{remarque}
\emph{
Ici, l'ensemble des paramètres est \og énorme \fg{}. En particulier, la famille de distributions $\mathfrak{F}$ n'est pas dominée (puisqu'elle contient par exemple toutes les mesures de Dirac $\delta_x$, $x\in \R$).
}
\end{remarque}
\begin{definition} \label{procedure statistique}
Une statistique, ou une procédure statistique, ou encore un estimateur, associé(e) à l'expérience ${\mathcal E}^n$, est une fonction mesurable des observations $X_1,\ldots, X_n$.  \index{statistique} \index{estimateur} \index{procédure statistique}
\end{definition}

%\begin{remarque}
%\emph{
Lorsque l'on cherche à estimer une fonctionnelle $T(F)\in \R$ de $F$, un estimateur est souvent noté $\widehat T_n$. C'est une variable aléatoire, ne dépendant que  de $X_1,\ldots, X_n$ et pas de $F$ (qui est une quantité inconnue),  qui s'écrit donc
$\widehat T_n = g_n(X_1,\ldots, X_n)$, pour une certaine fonction borélienne $g_n:\R^n \rightarrow \R$ qui ne dépend pas de $F$. Se donner un estimateur, c'est se donner une telle fonction $g_n(\cdot)$.
%}
%\end{remarque}

\section{Estimation ponctuelle} \label{estimation ponctuelle}
Soit $x_0\in \R$. A partir de l'observation $X_1,\ldots, X_n$, que pouvons-nous dire de
$$F(x_0) = \PP\big[X \leq x_0\big]\;?$$

\subsection{Fonction de répartition empirique} \index{fonction de répartition empirique}
L'idée la plus immédiate est d'estimer $F(x_0)$ par la fréquence empirique du nombre de points $X_i$ dans l'intervalle $(-\infty, x_0]$
$$\frac{1}{n}\mathrm{Card}\Big\{X_i \in (-\infty,x_0],\;\;i  = 1,\ldots, n\Big\}$$
qui se rapproche de la fréquence théorique $\PP\big[X\leq x_0]$ par la loi des grands nombres.

\begin{definition}
La fonction de répartition empirique de l'échantillon $(X_1,\ldots, X_n)$ est définie par
$$\widehat F_n(x) = \frac{1}{n} \sum_{i = 1}^n 1_{\{X_i \leq x\}},\;\;\;x\in \R.$$
%avec $1_{\{X_i \leq x\}} = 1$ si $X_i \leq x$ et $0$ sinon.
\end{definition}
%Remarquer que $x \leadsto \widehat F_n(x)$ est elle-même une fonction de répartition\footnote{dépendant de la réalisation de l'observation de $X_1,\ldots, X_n$}.
%\begin{center}
%{\tt More comments here}
%\end{center}
Dans la suite, nous estimerons $F(x_0)$ par $\widehat F_n(x_0)$.

\begin{proposition} \label{basic ft rep}
Pour tout $x_0 \in \R$, on a
$$\E\big[\widehat F_n(x_0)\big] = F(x_0),$$
$$\mathrm{Var}\big[\widehat F_n(x_0)\big] = \E\big[\big(\widehat F_n(x_0) -\E[\widehat F_n(x_0)] \big)^2\big] = \frac{F(x_0)\big(1-F(x_0)\big)}{n}.$$
En particulier, on a $\widehat F_n(x_0) \stackrel{{\mathcal L}^2}{\longrightarrow} F(x_0)$ et donc $\widehat F_n(x_0) \stackrel{\PP}{\longrightarrow} F(x_0)$.
\end{proposition}

\begin{proof} Les variables aléatoires $1_{\{X_i \leq x_0\}}$ sont indépendantes, de loi de Bernoulli de paramètre $\PP[X_i \leq x_0] = F(x_0)$. Donc $n \widehat F_n(x_0)$
est une variable aléatoire binomiale, de paramètres
$\big(n,F(x_0)\big)$. Son espérance et sa variance valent respectivement $nF(x_0)$ et $nF(x_0)\big(1-F(x_0)\big)$. On obtient la proposition en divisant par $n$, et en utilisant le fait que l'espérance est linéaire et la variance quadratique.
\end{proof}

\begin{remarque}
\emph{
La loi forte des grands nombres garantit immédiatement la convergence $\widehat F_n(x_0) \stackrel{\mathrm{p.s.}}{\longrightarrow} F(x_0).$
}
\end{remarque}

\begin{figure}
\begin{center}
\includegraphics[angle=0, width=9cm]{Fig1.pdf}
\end{center}
\caption{Représentation de $x\leadsto \widehat F_n(x)$ (en noir) et $x\leadsto F(x)=(2\pi)^{-1/2}\int_{-\infty}^xe^{-t^2/2}dt$ (en rouge), pour une réalisation de $X_1,\ldots, X_n$ avec $n=20$.}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[angle=0, width=9cm]{Fig2.pdf}
\end{center}
\caption{Représentation de $x\leadsto \widehat F_n(x)$ (en noir) et $x\leadsto F(x)=(2\pi)^{-1/2}\int_{-\infty}^xe^{-t^2/2}dt$ (en rouge), pour une réalisation de $X_1,\ldots, X_n$ avec $n=100$.}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[angle=0, width=9cm]{Fig3.pdf}
\end{center}
\caption{Représentation de $x\leadsto \widehat F_n(x)$ (en noir) et $x\leadsto F(x)=(2\pi)^{-1/2}\int_{-\infty}^xe^{-t^2/2}dt$ (en rouge), pour une réalisation de $X_1,\ldots, X_n$, avec  $n=1000$.}
\end{figure}


\subsection{Précision d'estimation} \label{la precision d estimation}
La Proposition \ref{basic ft rep} fournit un résultat de convergence en apparence très fort : si $\ell(x,y) = (x-y)^2$, avec $x,y \in \R$ désigne la {\it perte quadratique}, on a
\index{perte quadratique}
\begin{equation} \label{perte quad}
\sup_{F \in \mathfrak{F}}\E\big[\ell\big(\widehat F_n(x_0), F(x_0)\big)\big] =\frac{1}{4n}.
\end{equation}
Il suffit pour voir cela d'appliquer la deuxième partie de la Proposition \ref{basic ft rep} en utilisant le fait que
\begin{equation} \label{le gros supremum}
\sup_{F \in \mathfrak{F}}F(x_0)\big(1-F(x_0)\big) = 1/4.
\end{equation}


Cela signifie que, pour la perte quadratique\index{perte quadratique}, l'estimateur $\widehat F_n(x_0)$ approche $F(x_0)$  uniformément en $F$ à vitesse $\sqrt{n}$. Ce résultat est-il optimal, et dans quel sens ? Comment le relier à une notion de précision d'estimation ?  Si $F(x_0)$ est proche de $0$ ou $1$, ce qui peut nous être suggéré par la lecture de $\widehat F_n(x_0)$, peut-on améliorer le facteur $1/4$ dans \eqref{perte quad} et améliorer la précision d'estimation ?

Une manière d'aborder la précision d'estimation consiste à  construire un \index{confiance, intervalle de} intervalle de confiance à partir de la borne \eqref{perte quad} de la façon suivante : on a, pour tout $t >0$
$$\PP\big[|\widehat F_n(x_0)-F(x_0)|\geq t\big]\leq \frac{1}{t^2}\text{Var}\big[\widehat F_n(x_0)\big]\leq \frac{1}{4nt^2}$$
par l'inégalité de Tchebychev \eqref{tchebychev}. Choisissons $\alpha \in (0,1)$, et prenons $t  = t(\alpha,n)$ le plus petit possible de sorte que $1/(4nt^2) \leq \alpha$. Ceci nous fournit le choix
$$t_{n,\alpha} = \frac{1}{2\sqrt{n\alpha}}.$$
On en déduit que l'intervalle\footnote{La notation $[a\pm b]$ désigne l'intervalle $[a-b,a+b]$.}
$${\mathcal I}_{n,\alpha} = \left[\widehat F_n(x_0)\pm\frac{1}{2\sqrt{n\alpha}}\right]$$
contient $F(x_0)$ avec probabilité plus grande que $1-\alpha$.

\begin{definition} L'intervalle ${\mathcal I}_{n,\alpha}$ est appelé intervalle de confiance pour la valeur $F(x_0)$ au niveau $1-\alpha$. La propriété
$$\PP\big[F(x_0)\in {\mathcal I}_{n,\alpha}\big] \geq 1-\alpha$$
s'appelle \og propriété de couverture\fg{} (coverage property).
\end{definition}
\begin{remarque}
\emph{
Un intervalle de confiance est aléatoire. Il est observable (c'est-à-dire construit à partir des observations) et ne peut dépendre de la quantité inconnue $F(x_0)$ qu'à travers la loi des observations $X_1,\ldots, X_n$.
}
\end{remarque}

L'interprétation de ${\mathcal I}_{n,\alpha}$ est claire : on imagine $\alpha$ petit\footnote{La tradition dicte $5\%$, mais d'autres choix sont évidemment pertinents.} et on garantit avec probabilité $1-\alpha$ que la quantité inconnue d'intérêt $F(x_0)$ appartient à ${\mathcal I}_{n,\alpha}$ que l'on observe.

Mais sans autre indication sur ${\mathcal I}_{n,\alpha}$, cette information n'a que peu d'intérêt. On s'attend à ce que la longueur $|{\mathcal I}_{n,\alpha}|$ de l'intervalle, qui joue le rôle de précision d'estimation de $F(x_0)$, soit petite lorsque $n$ est grand\footnote{Sinon, l'intervalle trivial ${\mathcal I}_{n,\alpha} = \R$ (ou même ${\mathcal I}_{n,\alpha} = [0,1]$ puisque $0 \leq F(x_0) \leq 1$) a la propriété de couverture au niveau de confiance $1$ !}. On a
$$|{\mathcal I}_{n,\alpha}| =\frac{1}{2\sqrt{n \alpha}}$$
que l'on interprète comme la précision d'estimation au niveau de confiance $1-\alpha$.

L'ordre de grandeur de ${\mathcal I}_{n,\alpha}$ en $n$ est  $1/\sqrt{n}$, comme pour la perte quadratique. Mais on a aussi
$|{\mathcal I}_{n,\alpha}|\rightarrow +\infty$ lorsque $\alpha \rightarrow 0$. Il s'agit d'un compromis inévitable entre précision d'estimation (vouloir $|{\mathcal I}_{n,\alpha}|$ petit) et risque (vouloir $\alpha$ petit) qui sont antagonistes.

Nous allons explorer plusieurs façons d'améliorer ce résultat.
%{\tt more comment here}
\subsection{Précision d'estimation asymptotique} \label{precision asymptotique}
Une manière de juger de la pertinence de la précision d'un estimateur est de se placer dans le régime asymptotique $n \rightarrow \infty$ et d'étudier la loi asymptotique de l'erreur renormalisée
$$\sqrt{n}\big(\widehat F_n(x_0)-F(x_0)\big),\;\;n\rightarrow \infty,$$
la normalisation par $\sqrt{n}$ étant suggérée\footnote{D'après la Proposition \ref{basic ft rep}, $\E\big[\big(\sqrt{n}\big(\widehat F_n(x_0)-F(x_0)\big)\big)^2\big]$ est constante, donc $\big(\sqrt{n}\big(\widehat F_n(x_0)-F(x_0)\big)\big)^2$, et par suite $\sqrt{n}\big(\widehat F_n(x_0)-F(x_0)\big)$ est \og en moyenne de l'ordre de grandeur de $1$ en $n$ \fg{}.}  par la Proposition \ref{basic ft rep}.
\begin{proposition} \label{basic TCL ft rep}
On a
$$\xi_n = \sqrt{n}\frac{\widehat F_n(x_0)-F(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}\stackrel{d}{\longrightarrow}{\mathcal N}(0,1).$$
De plus, pour tout $\alpha \in (0,1)$,
$$\PP\left[\xi_n \in\big[-\Phi^{-1}(1-\alpha/2), \Phi^{-1}(1-\alpha/2)\big]\right] \rightarrow 1-\alpha,$$
où $\Phi(x) = \int_{-\infty}^xe^{-t^2/2}\tfrac{dt}{\sqrt{2\pi}}$ est la fonction de répartition de la loi ${\mathcal N}(0,1)$.
\end{proposition}

\begin{proof}
Le théorème central-limite donne la convergence
$$\sqrt{n}\frac{\widehat F_n(x_0)-F(x_0)}{F(x_0)^{1/2}\big(1-F(x_0)\big)^{1/2}}\stackrel{d}{\longrightarrow}{\mathcal N}(0,1).$$
La Proposition \ref{basic ft rep} assure que $\widehat F_n(x_0)\big(1-\widehat F_n(x_0)\big) \stackrel{\PP}{\longrightarrow} F(x_0)\big(1-F(x_0)\big)$. On en déduit la première partie en appliquant la Proposition \ref{slutsky} (Slutsky).

Puisque $\xi_n \stackrel{d}{\rightarrow} {\mathcal N}(0,1)$, on a
\begin{align*}
\PP\Big[\xi_n \in \big[-\Phi^{-1}(1-\tfrac{\alpha}{2}), \Phi^{-1}\left(1-\tfrac{\alpha}{2}\right)\big]\Big]
\rightarrow \, & \Phi\big(\Phi^{-1}(1-\tfrac{\alpha}{2})\big)- \Phi\big(-\Phi^{-1}(1-\tfrac{\alpha}{2})\big)
\\
 = \,&1-\alpha
\end{align*}
en utilisant $\Phi(-x) = 1-\Phi(x)$ puisque la loi ${\mathcal N}(0,1)$ est symétrique (Définition \ref{def loi symetrique}).
\end{proof}

On peut interpréter le second point de la Proposition \ref{basic TCL ft rep} de la façon suivante : lorsque \og $n$ est grand\fg{},
$$ \sqrt{n}\frac{\widehat F_n(x_0)-F(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}} \in \left[-\Phi^{-1}(1-\tfrac{\alpha}{2}), \Phi^{-1}(1-\tfrac{\alpha}{2})\right]$$
avec probabilité proche de $1-\alpha$. En isolant $F(x_0)$ dans cette relation et en posant

$${\mathcal J}_{n,\alpha} = \left[\widehat F_n(x_0) \pm \frac{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}{\sqrt{n}}\,\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right],
$$
la quantité $F(x_0)$ inconnue est dans l'intervalle ${\mathcal J}_{n,\alpha}$ avec probabilité proche de $1-\alpha$ dans la limite $n \rightarrow \infty.$
\begin{definition} L'intervalle ${\mathcal J}_{n,\alpha}$ est appelé intervalle de confiance asymptotique de $F(x_0)$ au niveau $1-\alpha$. La propriété
$$\PP\big[F(x_0)\in {\mathcal J}_{n,\alpha}\big] \rightarrow 1-\alpha,\;\;n\rightarrow \infty$$
s'appelle \og propriété de couverture asymptotique \fg{}.
 \end{definition}

La précision asymptotique de ${\mathcal J}_{n,\alpha}$ est
$$|{\mathcal J}_{n,\alpha}| = 2 \frac{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}{\sqrt{n}}\Phi^{-1}(1-\tfrac{\alpha}{2}).
$$
L'ordre de grandeur de ${\mathcal J}_{n,\alpha}$ en $n$ est  $1/\sqrt{n}$, comme pour l'intervalle de confiance ${\mathcal I}_{n,\alpha}$ construit avec la perte quadratique. On a aussi $\Phi^{-1}(1-\alpha/2)\rightarrow \infty$ lorsque $\alpha \rightarrow 0$. Par contre,
$$\Phi^{-1}(1-\tfrac{\alpha}{2}) \ll \sqrt{\alpha},\;\;\;\alpha \rightarrow 0.$$
voir Exercice \ref{precision int conf}
C'est aussi un résultat plus précis en apparence que celui obtenu à l'aide de ${\mathcal I}_{n,\alpha}$ puisqu'on a remplacé le facteur $1/2$ obtenu en prenant la racine  de \eqref{le gros supremum} dans la construction de ${\mathcal I}_{n,\alpha}$ par
$$\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}\leq \frac{1}{2}$$
dans la construction de ${\mathcal J}_{n,\alpha}$. Cependant, cette amélioration n'est valide que dans le régime asymptotique $n\rightarrow \infty$.

\subsection{Précision non-asymptotique}
Nous cherchons un résultat de qualité comparable à celui de la Proposition \ref{basic TCL ft rep} mais valable à $n$ fixé.

Dans l'approche non-asymptotique à l'aide de la perte quadratique, on a perdu en utilisant l'inégalité de Markov qui s'appuie uniquement sur le contrôle de la variance de $\hat F_n(x)$. Le résultat suivant fournit un contrôle plus fin de la probabilité de déviation de la moyenne empirique.

\begin{theoreme}[Inégalité de Hoeffding] \label{hoeffding} \index{Hoeffding, inégalité de}
Soient $Y_1,\ldots, Y_n$ des variables aléatoires réelles indépendantes telles que
$\E[Y_i] = 0$ et $a_i \leq Y_i \leq b_i$. Soit $t >0$. Alors, pour tout $\lambda>0$
$$\PP\big[\sum_{i = 1}^n Y_i \geq t\big]\leq e^{-\lambda t} \prod_{i=1}^n\exp\big( \lambda^2 \frac{(b_i-a_i)^2}{8}\big).$$
\end{theoreme}
\begin{proof}
Si $Y$ est une variable aléatoire à valeurs dans $[a,b]$, posons
$$\psi_Y(\lambda) = \log\E\big[\exp\big(\lambda(Y-\E[Y])\big)\big],\;\;\;\lambda >0.$$
La fonction $\lambda \leadsto \psi_Y(\lambda)$ est deux fois dérivable et, puisque $\E\big[Y\big]=0$, un calcul élémentaire conduit à
\begin{equation} \label{la derivee seconde}
\psi_Y''(\lambda) =  e^{-\psi_Y(\lambda)}\E\big[Y^2\exp\big(\lambda Y\big)\big]- e^{-2\psi_Y(\lambda)}\Big(\E\big[Y\exp\big(\lambda Y\big)\big]\Big)^2.
\end{equation}
Posons, pour $A\in {\mathcal B}$,
$\mathbb{Q}\big[A\big] = e^{-\psi_Y(\lambda)}\E\big[\exp\big(\lambda Y\big)1_A\big]$,
de sorte que $\mathbb{Q}$ est une mesure de probabilité. Alors on peut interpréter \eqref{la derivee seconde} de la manière suivante :
$$\psi''_Y(\lambda) = \mathrm{Var}\big[Z\big],$$
où $Z$ est une variable aléatoire à valeurs dans $[a,b]$ de loi $\mathbb{Q}$. Maintenant, pour toute variable $Z$ à valeurs dans $[a,b]$, on a toujours
$$\Big|Z-\frac{b+a}{2}\Big| \leq \frac{b-a}{2},$$
et donc
%\begin{equation} \label{a integrer}
$$
\mathrm{Var}\big[Z\big] = \mathrm{Var}\big[Z-(b+a)/2\big]\leq \E\big[\big(Z-(b+a)/2\big)^2\big]\leq \frac{(b-a)^2}{4},
%\end{equation}
$$
d'où
\begin{equation} \label{a integrer}
\psi''_Y(\lambda) \leq (b-a)^2/4.
\end{equation}
En intégrant \eqref{a integrer} et en utilisant $\psi_Y(0) = \psi'_Y(0)=0$, on déduit
\begin{equation} \label{la bonne inegalite}
\psi_Y(\lambda) \leq \lambda^2\frac{(b-a)^2}{8}.
\end{equation}
Finalement, pour tous $t,\lambda >0$,
\begin{align*}
\PP\big[\sum_{i = 1}^n Y_i \geq t\big] & = \PP\big[\exp\big(\lambda\sum_{i = 1}^n Y_i\big) \geq \exp(\lambda t)\big] \\
& \leq e^{-\lambda t} \E\big[\exp\big(\lambda \sum_{i = 1}^n Y_i\big) \big]  \;\;\;\text{(inégalité de Tchebychev)}\\
& =  e^{-\lambda t} \prod_{i = 1}^n \E\big[\exp \big(\lambda Y_i \big) \big] \;\;\;\;\text{(indépendance des}\;Y_i)\\
& = e^{-\lambda t} \prod_{i = 1}^n \exp\big(\psi_{Y_i}(\lambda)\big),
\end{align*}
Puisque chaque $Y_i$ est centrée et à valeurs dans $[a_i,b_i]$, on conclut en appliquant l'inégalité \eqref{la bonne inegalite} à chaque $\psi_{Y_i}(\lambda)$.
\end{proof}

\begin{corollaire} \label{corollaire hoeffding}
Si $X_1, \ldots, X_n$ sont des variables aléatoires de Bernoulli de paramètre $p$ et si $\overline{X}_n = \tfrac{1}{n}\sum_{i = 1}^nX_i$, alors, pour tout $t >0$
$$\PP\big[|\overline{X}_n -p|\geq t \big] \leq 2\exp\big(-2nt^2\big).$$
\end{corollaire}
\begin{proof} Appliquons l'inégalité de Hoeffding à $Y_i = X_i-p$. Les conditions du Théorème \ref{hoeffding} sont vérifiées avec $b_i-a_i = 1$. Le choix $\lambda = 4t/n$ conduit à
\begin{equation} \label{first trick}
\PP\big[\sum_{i = 1}^n Y_i\geq t\big] \leq \exp\big(-2t^2/n\big),
\end{equation}
soit encore
$$\PP\big[\Xbar-p\geq t\big] = \PP\big[\sum_{i = 1}^n Y_i\geq nt\big] \leq \exp\big(-2nt^2\big).$$
De même
$$\PP\big[\Xbar-p\leq -t\big] = \PP\big[\sum_{i = 1}^n (-Y_i)\geq nt\big] \leq \exp\big(-2nt^2\big)$$
en appliquant \eqref{first trick} à $-Y_i$.
On conclut en écrivant
$$
\PP\big[|\Xbar-p|\geq t\big] = \PP\big[\Xbar-p\geq t\big] + \PP\big[\Xbar-p\leq -t\big].
$$
\end{proof}
On en déduit un intervalle de confiance non-asymptotique pour $F(x_0)$.
\begin{proposition}
Pour tout $\alpha >0$,
$${\mathcal I}_{n,\alpha}^{\star} = \left[\widehat F_n(x_0) \pm \sqrt{\frac{1}{2n} \log\frac{2}{\alpha}}\right]$$
est un intervalle de confiance pour $F(x_0)$ de niveau $1-\alpha$.
\end{proposition}
\begin{proof}
On applique le Corollaire \ref{corollaire hoeffding} aux $1_{\{X_i \leq x_0\}}$ qui sont des variables aléatoires de Bernoulli indépendantes, de paramètre $F(x_0)$. On a, pour tout $t >0$
$$\PP\big[\big|\widehat F_n(x_0)-F(x_0)\big|>t\big] \leq 2\exp\big(-2nt^2\big).$$
On cherche $t = t(\alpha, n)$ le plus petit possible de sorte que $2\exp(-2nt^2) \leq \alpha$, ce qui donne
$$t(\alpha, n) = \sqrt{\frac{1}{2n} \log\frac{2}{\alpha}}.$$
\end{proof}
\begin{remarque}
\emph{
On a
$$\frac{|{\mathcal I}_{n,\alpha}^\star|}{|{\mathcal I}_{n,\alpha}|} = \frac{2}{\sqrt{2}}\sqrt{\alpha \log(2/\alpha)}\rightarrow 0,\;\;\alpha \rightarrow 0,$$
où ${\mathcal I}_{n,\alpha} = \big[\widehat F_n(x_0) \pm \tfrac{1}{2\sqrt{n\alpha}}\big]$ est l'intervalle de confiance construit à l'aide de l'inégalité de Tchebychev dans la Section \ref{la precision d estimation}. Le gain est significatif. Par exemple, pour $\alpha = 5\%$, on a un rapport de
$$\frac{|{\mathcal I}_{n,\alpha}^\star|}{|{\mathcal I}_{n,\alpha}|}=0,61.$$
Pour $\alpha = 1\%$, le rapport devient $0.33$, soit une précision 3 fois meilleure !
}
\end{remarque}
\begin{remarque}
\emph{Par contre, les ordres de grandeur de ${\mathcal J}_{n,\alpha}$ et ${\mathcal I}_{n,\alpha}^\star$ sont comparables en $n$ et en $\alpha$, voir Exercice \ref{precision int conf}. De ce point de vue, l'intervalle ${\mathcal I}_{n,\alpha}^\star$ est satisfaisant.
}
%{\tt more comments here}
\end{remarque}

\subsection{Décision$^\star$} \label{test ponctuel}
\subsubsection{Notion de test et d'erreur de test}
Soit $F_0$ une distribution donnée. On souhaite répondre à la question suivante : en vue d'un $n$-échantillon $X_1,\ldots, X_n$ de loi $F \in \mathfrak{F}$, est-ce que
$$F(x_0) = F_0(x_0)\;\;\text{ou non ?}$$
On formule le problème de la manière suivante. On contruit à partir des observations une procédure (un estimateur)
$$\varphi_n = \varphi_n(X_1,\ldots,X_n) \in \{0,1\}$$
ne prenant que les valeurs $0$ ou $1$. La valeur $\{\varphi_n = 0\}$ correspondra à la réponse \og oui \fg\; à la question, et la valeur $\{\varphi_n=1\}$ correspondra à la réponse \og non\fg\;.

On dira que l'on teste l'hypothèse nulle
$$H_0:\;\;\;\;F(x_0) = F_0(x_0),$$
contre l'alternative
$$H_1:\;\;\;\;F(x_0) \neq F_0(x_0).$$
Si $\varphi_n$ est une procédure ne prenant que les valeurs $0$ ou $1$, on dira que $\varphi_n$ est un test simple\footnote{On pourrait envisager des tests plus complexes, où une réponse intermédiaire entre $0$ et $1$ est possible.}.  Si $\varphi_n$ est un test simple, il se représente sous la forme
$$\varphi_n = \varphi_n(X_1,\ldots, X_n) = 1_{\big\{(X_1\ldots, X_n) \in {\mathcal R}_n\big\}}$$
où ${\mathcal R}_n \subset \R^n$ est un sous-ensemble de l'espace des observations.
\begin{definition}
L'ensemble ${\mathcal R}_n$ associé au test simple\index{test simple} $\varphi_n$ est appelé zone de rejet du test, ou encore région critique du test.
\end{definition}
\begin{remarque}
\emph{
On définit aussi parfois la zone de rejet comme l'événement
$$\big\{(X_1,\ldots, X_n) \in {\mathcal R}_n\big\}.$$
Cela n'a aucune importance : il n'y a jamais d'ambiguité\footnote{La notion d'expérience canonique, voir Section \ref{experience canonique} du Chapitre \ref{chapitre 2} permet d'ailleurs de concilier les deux points de vue de façon rigoureuse. Nous ne reviendrons plus sur ce point dans la suite du cours.}.
}
\end{remarque}
Lorsque l'on procède à un test, on décide d'accepter l'hypothèse $H_0$ (lorsque l'événe\-ment $\big\{\varphi_n = 0\big\}$ est réalisé) ou de la rejeter (lorsque l'événement $\big\{\varphi_n = 1\big\}$ est réalisé). On peut avoir raison de deux manières : accepter l'hypothèse $H_0$ alors qu'elle est vraie\footnote{C'est-à-dire observer $\{\varphi_n=0\}$ et avoir $F(x_0)=F_0(x_0)$.} ou bien rejeter l'hypothèse $H_0$ alors qu'elle est fausse\footnote{C'est-à-dire observer $\{\varphi_n=1\}$ et avoir $F(x_0)\neq F_0(x_0)$.}.

Mais surtout, on peut aussi se tromper de deux manières : rejeter $H_0$ alors qu'elle est vraie ou encore accepter $H_0$ alors qu'elle est fausse. Ce sont ces deux erreurs que l'on va chercher à rendre petites simultanément.

Pour cela, nous devons définir précisément les conditions
$$F(x_0) = F_0(x_0)\;\;\;\text{et}\;\;\;F(x_0) \neq F_0(x_0).$$
 L'expérience statistique engendrée par les observations a pour ensemble de paramètres
$$\mathfrak{F} = \{F,\;F\;\text{fonction de répartition}\}.$$
Posons
$$\mathfrak{F}_0 = \{F \in \mathfrak{F},\;F(x_0) = F_0(x_0)\}.$$
Alors l'hypothèse $H_0$ se traduit par le sous-ensemble de paramètres $\mathfrak{F}_0$, et l'alternative $H_1$ par le sous-ensemble de paramètres $\mathfrak{F} \setminus \mathfrak{F}_0$.

\begin{definition}
Soit $\alpha \in [0,1]$. Le test $\varphi_n$ est de niveau $\alpha$ (respectivement, asymptotiquement de niveau $\alpha$) si
$$\sup_{F \in \mathfrak{F}_0}\PP_{F}\big[\varphi_n = 1\big] \leq \alpha\;\;\text{(respectivement}\;\;\;
\limsup_{n \rightarrow \infty}\sup_{F \in \mathfrak{F}_0}\PP_{F}\big[\varphi_n = 1\big] \leq \alpha).$$
\end{definition}
Autrement dit, si le \index{test, niveau d'un}niveau d'un test est inférieur à $\alpha$, la probabilité de rejeter l'hypothèse (observer $\{\varphi_n = 1\}$) alors qu'elle est vraie ($F \in \mathfrak{F}_0$)
est inférieure ou égale à $\alpha$. On parle indifféremment d'erreur de première espèce du test $\varphi_n$ ou de niveau du test $\varphi_n$. \index{première espèce, erreur de} \index{niveau d'un test}
\begin{remarque}
\emph{
Bien que cela ne transparaîsse pas dans les notations, le test $\varphi_n$ dépend de $\alpha$ en général.
}
\end{remarque}

\begin{definition}
La puissance d'un test \index{test, puissance d'un} $\varphi_n$ est l'application de $\mathfrak{F}\setminus \mathfrak{F}_0$ dans $[0,1]$ définie par
$$F \in \mathfrak{F} \setminus \mathfrak{F}_0 \leadsto \PP_F\big[\varphi_n = 1\big].$$
\end{definition}
On parle indifféremment de \og puissance du test \fg{} ou bien de \og fonction d'erreur de seconde espèce\fg{}, \index{seconde espèce, erreur de} définie par
$$F \in \mathfrak{F} \setminus \mathfrak{F}_0 \leadsto 1-\PP_F\big[\varphi_n = 1\big].$$

La démarche sera la suivante : on se fixe un niveau de risque $\alpha$, et on cherche un test $\varphi_n$ de niveau $\alpha$ (d'erreur de première espèce inferieure ou égale à $\alpha$) qui a la plus grande puissance possible (l'erreur de seconde espèce la plus petite possible). On étudiera systématiquement ces notions aux Chapitres \ref{tests} et \ref{tests asymptotiques}.

\subsubsection{Construction de tests}

A partir d'estimateurs et d'intervalles de confiance de niveau $1-\alpha$, la construction d'un test $\varphi_n$ est naturelle. On se restreint ici par simplicité au cadre asymptotique. On a, d'après la construction de la Section \ref{precision asymptotique}, pour tout $F \in \mathfrak{F}$,
$$\PP_F\big[F(x_0) \in {\mathcal J}_{n,\alpha}\big]\rightarrow 1-\alpha.$$
Ceci suggère la règle de décision suivante : on accepte $H_0$ si $F_0(x_0) \in {\mathcal J}_{n,\alpha}$ et on rejette $H_0$ sinon.

\begin{proposition} \label{convergence test ponctuel}
Soit $\alpha \in (0,1)$. Le test $\varphi_n = \varphi_{n,\alpha}$ de l'hypothèse nulle $H_0:\,F(x_0) = F_0(x_0)$ contre l'alternative $F(x_0)\neq F_0(x_0)$, défini par la zone de rejet
$${\mathcal R}_{n,\alpha} = \big\{F_0(x_0) \notin {\mathcal J}_{n,\alpha}\big\},$$
est asymptotiquement de niveau $\alpha$. De plus, pour tout point de l'alternative $F \in \mathfrak{F}\setminus \mathfrak{F}_0$, on a
$$\PP_F\big[\varphi_{n,\alpha}=0\big] =\PP_F\big[(X_1,\ldots, X_n) \notin {\mathcal R}_{n,\alpha}\big] \rightarrow 0.$$
\end{proposition}

Autrement dit, l'erreur de première espèce est asymptotiquement plus petite que $\alpha$ et l'erreur de seconde espèce tend vers $0$ ; ou encore, la puissance du test tend vers $1$ en tout point de l'alternative. On dit que le test  est consistant ou convergent. \index{consistant, convergent, test}

\begin{proof} La première partie de la proposition découle de la propriété de couverture asymptotique de ${\mathcal J}_{n,\alpha}$ (le second point de la Proposition \ref{basic TCL ft rep}). Pour le contrôle de l'erreur de seconde espèce, si $F \in \mathfrak{F}\setminus \mathfrak{F}_0$, alors
$$\widehat F_n(x_0)\stackrel{\PP_F}{\longrightarrow} F(x_0)\neq F_0(x_0),$$
Ceci suggère la décomposition
\begin{align*}
& \sqrt{n}\frac{\widehat F_n(x_0)-F_0(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}\\
 =& \sqrt{n}\frac{\widehat F_n(x_0)-F(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}} +\sqrt{n}\frac{F(x_0)-F_0(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}.
\end{align*}
Le premier terme tend en loi sous $\PP_F$ vers une gaussienne centrée réduite d'après la Proposition \ref{basic TCL ft rep}. Le second terme diverge vers $\pm \infty$ lorsque $n \rightarrow \infty$. Puisque
$$\big\{\varphi_{n,\alpha} = 0\big\} = \Big\{\sqrt{n}\Big|\frac{\widehat F_n(x_0)-F_0(x_0)}{\widehat F_n(x_0)^{1/2}\big(1-\widehat F_n(x_0)\big)^{1/2}}\Big| \leq \Phi^{-1}\left(1-\tfrac{\alpha}{2}\Big)\right\}$$
on a $\varphi_{n,\alpha}\rightarrow 1$ en $\PP_F$-probabilité si $F \in \mathfrak{F}\setminus \mathfrak{F}_0$. Ceci implique\footnote{Par exemple par convergence dominée, ou plus simplement parce que la suite de variables aléatoires discrètes $\varphi_{n,\alpha}$ tend en probabilité vers 1, donc en loi vers la loi dégénérée $\delta_1(dx)$, ce qui entraîne la convergence voulue.} $\PP_F\big[\varphi_{n,\alpha}=0\big]\rightarrow 0$.
\end{proof}
La question de l'optimalité d'une telle construction sera discutée dans le Chapitre \ref{tests asymptotiques}.

\section{Estimation uniforme} \label{estimation uniforme}

Les trois problèmes développés précédemment, estimation, intervalle de confiance et test, que ce soit d'un point de vue asymptotique ou non, ne font intervenir la distribution $F$ qu'en un point $x_0$ donné. Ceci est peu satisfaisant si l'on envisage $F$ globalement.

Nous reprenons la problématique de la Section \ref{estimation ponctuelle} simultanément pour toutes les valeurs possibles de $(F(x)$, $x\in \R)$.
A partir de l'observation de $(X_1,\ldots, X_n)$, que peut-on dire de
$$\big(F(x),x \in \R\big)\;?$$

\subsection{Estimation uniforme}
\begin{theoreme}[Glivenko-Cantelli] \index{Glivenko-Cantelli} \label{glivenko cantelli}
Soient $X_1,\ldots, X_n$ des variables aléatoires réelles indépendantes, de même loi $F$, et $\widehat F_n$ leur fonction de répartition empirique.
Alors
$$\sup_{x \in \R}\big| \widehat F_n(x)-F(x)\big|\stackrel{\mathrm{p.s.}}{\rightarrow} 0,\;\;n \rightarrow \infty.$$
\end{theoreme}
\begin{proof}
%On suppose d'abord $F$ continue. Pour tout $k \geq 1$, il existe des points $x_1 < x_2 < \ldots, x_{k-1}$ tels que $F(x_i) = \tfrac{i}{k}$. Posons $x_0 = -\infty$. Puisque $F$ et $\widehat F_n$ sont croissantes, pour tout $i=1,\ldots, k$ et pour tout $x \in [x_{i-1},x_i]$, on a, d'une part
%$$\widehat F_n(x)-F(x) \leq \widehat F_n(x_{i})-F(x_{i-1}) = \widehat F_n(x_i)-F(x_i)+\frac{1}{k},$$
%et d'autre part
%$$\widehat F_n(x)-F(x) \geq \widehat F_n(x_{i-1})-F(x_i) = \widehat F_n(x_{i-1})-F(x_i)-\frac{1}{k}.$$
%Donc, pour tout $x\in \R$,
%$$\big|\widehat F_n(x)-F(x)\big|\leq \max_{i = 1,\dots, k-1}\big|\widehat F_n(x_i)-F(x_i)\big|+\frac{1}{k}.$$
%On a $\widehat F_n(x)\stackrel{\mathrm{p.s.}}{\rightarrow} F(x)$ par la loi forte des grands nombres. Donc, sur le complémentaire d'un ensemble $\Omega_k$ de probabilité $0$, on  a
%$$\limsup_{n \rightarrow \infty}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| \leq \frac{1}{k}.$$
%Puis on fait tendre $k$ vers l'infini :
%$$\lim_{n \rightarrow \infty}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| = 0$$
%sur $\cup_{k \geq 1}\Omega_k$ qui est de probabilité $0$.
Soit $k \geq 1$ un entier, et pour tout $0 \leq k \leq m$,
$$x_k^m = \inf\{x \in \R,\;F(x)\geq \tfrac{k}{m}\}.$$
(Les points $x_k^m$ ne sont pas nécessairement distincts si $F$ n'est pas continue.) Par construction, pour $0 \leq k \leq m-1$,
$$F\big(x_k^m\big) \geq \frac{k}{m} \geq F\big(x_k^m-\big)$$
car $F$ est continue à droite, et donc
$$F\big(x_k^m\big)+\frac{1}{m} \geq F\big(x_{k+1}^m-\big).$$
Soit $x \in [x_k^m, x_k^{m+1})$. Puisque $F$ et $\widehat F_n$ sont croissantes, on a, pour tout $n \geq 1$,
$$\widehat F_n\big(x_k^m\big)-F\big(x_{k+1}^m-\big) \leq  \widehat F_n\big(x\big)-F\big(x\big) \leq \widehat F_n\big(x_{k+1}^m-\big)-F\big(x_k^m\big),$$
et aussi, d'après ce ce qui précède
$$\widehat F_n\big(x_k^m\big)-F\big(x_{k}^m\big)-\frac{1}{m} \leq \widehat F_n\big(x\big)-F\big(x\big) \leq \widehat F_n\big(x_{k+1}^m-\big)-F\big(x_{k+1}^m-\big)+\frac{1}{m}.$$
Il vient
\begin{align*}
&\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| \\
\leq\,& \max\left\{\max_{0 \leq k \leq m}\big|\widehat F_n\big(x_k^m\big)-F\big(x_k^m\big)\big|, \max_{0 \leq k \leq m}\big|\widehat F_n\big(x_k^m-\big)-F\big(x_k^m-\big)\big|\right\}+\frac{1}{m}.
\end{align*}
On a $\widehat F_n(x)\stackrel{\mathrm{p.s.}}{\rightarrow} F(x)$ par la loi forte des grands nombres. Il existe donc un ensemble négligeable ${\mathcal N}'(m)$
en dehors duquel
$$\max_{0 \leq k \leq m}\big|\widehat F_n\big(x_k^m\big)-F\big(x_k^m\big)\big| \rightarrow 0.$$
De même, en appliquant la loi des grands nombres aux variables $1_{\{X_i < x\}}$, il existe une ensemble négligeable ${\mathcal N}''(m)$ en dehors duquel
$$\max_{0 \leq k \leq m}\big|\widehat F_n\big(x_k^m-\big)-F\big(x_k^m-\big)\big| \rightarrow 0.$$
On en déduit qu'en dehors d'un ensemble négligeable ${\mathcal N}(m) = {\mathcal N}'(m) \cup {\mathcal N}''(m)$, on a
$$\limsup_{n \rightarrow \infty}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| \leq \frac{1}{m}.$$
Puis on fait tendre $m$ vers l'infini :
$$\lim_{n \rightarrow \infty}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| = 0$$
en dehors de $\bigcup_{m \geq 1}{\mathcal N}(m)$ qui est de probabilité $0$.
\end{proof}
\subsection{Vitesse d'estimation uniforme}
\begin{theoreme}[Kolmogorov-Smirnov] \label{kolmogorov smirnov} \index{Kolmogorov-Smirnov}
Si la fonction de répartition $F$ est continue, alors
$$\sqrt{n}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| \stackrel{(d)}{\longrightarrow} \mathbb{B}$$
où $\mathbb{B}$ est une variable aléatoire dont la loi ne dépend pas de $F$, de fonction de répartition
$$\PP\big[\mathbb{B} \leq x\big] = 1 + 2 \sum_{k=1}^\infty (-1)^k e^{-2k^2x},\;\;x \geq 0.$$
\end{theoreme}
\begin{remarque}
\emph{
La variable aléatoire se représente comme $\mathbb{B} = \sup_{t \in [0,1]}B_t$, où $(B_t, t \in [0,1])$ est un processus aléatoire appelé pont brownien. Ce résultat découle de la théorie des processus empiriques et sa preuve dépasse le cadre de ce cours\footnote{On pourra consulter, par exemple, le livre de van der Vaart \cite{VDW} pour les liens entre statistique et processus empiriques.}.
}
\end{remarque}
Nous admettons la convergence en loi de $\sqrt{n}\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big|$. Nous allons cependant démontrer que cette loi ne dépend pas de $F$, ce qui est très important en vue des applications statistiques.
\begin{lemme}
Soit $U_1,\ldots, U_n$ une suite de variables aléatoires indépendantes, uniformes sur $[0,1]$. On note $G_n$ leur fonction de répartition empirique. Si $F$ est continue, on a l'égalité en loi
$$\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| \stackrel{d}{=} \sup_{x \in \R}\big|G_n(x)-x\big|.$$
En particulier, la loi de $\mathbb{B}$ ne dépend pas de $F$.
\end{lemme}
\begin{proof}
Posons, $U_i = F(X_i)$. Alors les $U_i$ sont des variables aléatoires uniformes sur $[0,1]$, et il existe un ensemble négligeable ${\mathcal N}_i$ tel que, pour tout $x \in \R$ et pour tout  $\omega \notin {\mathcal N}_i$ on a
$$F\big(X_i(\omega)\big)\leq F(x)\;\;\;\text{si et seulement si}\;\;\;X_i(\omega)\leq x,$$
voir par exemple Méléard \cite{M}, paragraphe 4.2.4 p. 78. Donc, on peut écrire, pour tout $x \in \R$
$$\widehat F_n(t) = \frac{1}{n}\sum_{i = 1}^n 1_{\{X_i\leq x\}} = \frac{1}{n}\sum_{i  = 1}^n 1_{\{F(X_i)\leq F(x)\}}  = G_n\big(F(x)\big)$$
en dehors de ${\mathcal N} = \bigcup_i {\mathcal N}_i$ qui est encore négligeable. Il vient
$$\sup_{x \in \R}\big|\widehat F_n(x)-F(x)\big| = \sup_{x \in \R}\big|G_n\big(F(x)\big)-F(x)\big| = \sup_{x \in \R}\big|G_n(x)-x\big|.$$
\end{proof}
On en déduit un intervalle de confiance, uniforme en $x \in \R$ (une région de confiance) asymptotique. Pour tout $\alpha \in (0,1)$, désignons par $q_{1-\alpha}$ le quantile d'ordre $1-\alpha$ de la loi de $\mathbb{B}$, de sorte que
$$\PP\big[\mathbb{B} \leq q_{1-\alpha}\big] = 1-\alpha.$$
\begin{proposition} \label{reg conf asymp}
La région
$$\big\{{\mathcal J}_{n,\alpha}(x), x \in \R\big\} = \left\{\Big[\widehat F_n(x)\pm\frac{q_{1-\alpha}}{\sqrt{n}}\Big], x\in \R \right\}$$
est une région de confiance asymptotique :
$$\PP\Big[\forall x \in \R,\;F(x) \in {\mathcal J}_{n,\alpha}(x)\Big] \rightarrow 1-\alpha.$$
\end{proposition}
\begin{proof}
On applique le Théorème \ref{kolmogorov smirnov} :
\begin{align*}
\PP\Big[\forall x \in \R,\;F(x) \in {\mathcal J}_{n,\alpha}(x)\Big] & = \PP\Big[\sup_{x \in \R}\sqrt{n}\big|\widehat F_n(x)-F(x)\big| \leq q_{1-\alpha}\Big] \\
& \rightarrow \PP\big[\mathbb{B} \leq q_{1-\alpha}\big] = 1-\alpha.
\end{align*}
\end{proof}
\begin{remarque}
\emph{
Bien entendu, on a toujours $0 \leq F(x) \leq 1$, ce qui n'est pas forcément le cas de $\widehat F_n(x)\pm q_{1-\alpha}/\sqrt{n}$.
On peut \og réduire \fg{} la région $\big\{{\mathcal J}_{n,\alpha}(x), x \in \R\big\}$ en remplaçant ${\mathcal J}_{n,\alpha}(x)$ par
$$\overline{{\mathcal J}}_{n,\alpha}(x):={\mathcal J}_{n,\alpha}(x) \cap [0,1]$$
sans modifier la propriété de couverture asymptotique.
}
\end{remarque}
%\begin{remarque}
%\emph{
%{\tt comparaison non-unif}
%}
%\end{remarque}
\subsection{Précision uniforme non-asymptotique$^\star$}
De la même manière que l'inégalité de Hoeffding du Théorème \ref{hoeffding} nous a fourni une précision ponctuelle non-asymptotique, on a le résultat suivant :
\begin{theoreme}[Inégalité de Dvoretzky-Kiefer-Wolfowitz] \index{DKV, inégalité de}
Si la fonction de répartition $F$ est continue, pour $n \geq 1$ et $t > 0$, on a
$$\PP\big[\sup_x\big|\widehat F_n(x)-F(x)\big| \geq t\big] \leq 2 \exp(-2nt^2).$$
\end{theoreme}
La preuve utilise des résultats fins sur les processus empiriques et nous l'admettons. On en déduit, pour $\alpha \in (0,1)$, une région de confiance non-asymptotique uniforme
$$\big\{{\mathcal I}_{n,\alpha}(x), x\in \R\big\} = \big\{\big[\widehat F_n(x)\pm \sqrt{\tfrac{1}{2n}\log \tfrac{2}{\alpha}}\big], x\in \R\big\}$$
qui vérifie, pour tout $n \geq 1$
$$\PP\Big[\forall x \in \R,\;F(x)\in {\mathcal I}_{n,\alpha}(x)\Big] \geq 1-\alpha.$$
\begin{remarque}
\emph{
De le même manière que dans le cadre asymptotique, on peut modifier ${\mathcal I}_{n,\alpha}(x)$ en considérant ${\mathcal I}_{n,\alpha}(x) \cap [0,1]$.
}
\end{remarque}
\subsection{Test d'adéquation à une distribution donnée$^\star$}
Soit $F_0$ une distribution donnée. On souhaite maintenant décider, en vue des observations $X_1,\ldots, X_n$ distribuées selon la loi $F$ si
$F=F_0$ contre $F \neq F_0$ \og globalement\fg\;c'est-à-dire tester l'hypothèse nulle
$$H_0\;:\;\forall x \in \R,\;F(x) = F_0(x)$$
contre l'alternative
$$H_1\;:\;\exists\, x \in \R,\;F(x) \neq F_0(x).$$
Par rapport à la Section \ref{test ponctuel}, on doit modifier la traduction de l'hypothèse ${\mathcal F}_0 \subset \mathfrak{F}$. On pose
$$\mathfrak{F}_0 = \big\{F \in \mathfrak{F},\;\forall x \in \R, F(x)=F_0(x)\big\} = \{F_0\}$$
et on traduit l'hypothèse $H_0$ par la propriété $F \in \mathfrak{F}_0$.

De la même manière que dans la Section \ref{test ponctuel}, on peut construire un test de l'hypothèse $H_0$ contre $H_1$ à l'aide des régions de confiance $\big\{{\mathcal I}_{n,\alpha}(x), x \in \R\big\}$, ou $\big\{{\mathcal J}_{n,\alpha}(x), x \in \R\big\}$.

Pour simplifier, nous énonçons un résultat asymptotique.

\begin{proposition}[Test de Kolmogorov-Smirnov] \index{Kolmogorov-Smirnov, test}
Pour tout $\alpha \in (0,1)$, le test simple de l'hypothèse $H_0: F\in \mathfrak{F}_0$ contre l'alternative $H_1: F \in \mathfrak{F}\setminus \mathfrak{F}_0$, défini par la zone de rejet
$${\mathcal R}_{n,\alpha} = \Big\{\exists \,x\in \R,\;\;F_0(x) \notin {\mathcal J}_{n,\alpha}(x)\Big\}$$
est asymptotiquement de niveau $\alpha$.

De plus, pour tout point de l'alternative $F \in \mathfrak{F}\setminus \{F_0\}$, on a
$$\PP_F\big[(X_1,\ldots, X_n) \notin {\mathcal R}_{n,\alpha}\big] \rightarrow 0.$$
\end{proposition}
\begin{proof}
Sous l'hypothèse, on a $F = F_0$ et
$$\PP_{F_0}\big[(X_1,\ldots, X_n)\notin {\mathcal R}\big] = 1- \PP_{F_0}\big[\forall x\in \R,\;F_0(x) \in {\mathcal J}_{n,\alpha}(x)\big] \rightarrow \alpha$$
lorsque $n\rightarrow \infty$ par la Proposition \ref{reg conf asymp}. Donc le test de Kolmogorov-Smirnov est asymptotiquement de niveau $\alpha$. Pour tout point $F \in \mathfrak{F}\setminus \{F_0\}$ de l'alternative, il existe un point $x_0\in \R$ pour lequel $F(x_0)\neq F_0(x_0)$. On reprend alors point par point la fin de la démonstration de la Proposition \ref{convergence test ponctuel}.
\end{proof}

\section{Estimation de fonctionnelles}
Dans les Sections \ref{estimation ponctuelle} et \ref{estimation uniforme} nous avons rencontré deux situations opposées :
\begin{enumerate}
\item L'estimation \og locale \fg\;de $F$ en un point $x_0$. Nous nous sommes intéressé à la fonctionnelle linéaire
$$T_{x_0}(F) = F(x_0).$$
\item L'estimation \og globale \fg\; de $F$, c'est-à-dire l'estimation simultané des fonctionelles
$$\big\{T_{x}(F) = F(x),\;x \in \R\big\}.$$
\end{enumerate}

Plus généralement, on peut considérer l'estimation ou le problème de décision relative à des fonctionnelles plus générales. Par exemple

\begin{enumerate}
\item Une fonctionnelle linéaire, de la forme \index{fonctionnelle linéaire}
\begin{equation} \label{fonctionnelle lineaire}
T(F) = \int_{\R} g(x)dF(x),
\end{equation}
avec $g$ connue (choisie par le statisticien). L'exemple prototype étant le moment d'ordre $1$, pour le choix $g(x)=x$
$$m(F) = \int_{\R} x\,dF(x).$$
\item Une combinaison de fonctionelles linéaires : la variance
$$\sigma^2(F) = \int_{\R}\big(x-m(F)\big)^2dF(x),$$
le coefficient d'asymétrie
$$\alpha(F) = \frac{\int_{\R} \big(x-m(F)\big)^3dF(x)}{\sigma^2(F)^{3/2}},$$
le coefficient d'applatissement de $F$,
$$\kappa(F) = \frac{\int_{\R} \big(x-m(F)\big)^4dF(x)}{\sigma^2(F)^{2}}$$
parmi bien d'autres exemples.
\item Une fonctionelle non-linéaire, comme le quantile d'ordre $\alpha\in (0,1)$ :
$$T(F) = q_\alpha(F) = \tfrac{1}{2}\big(\inf\{t,\;F(t) >\alpha\}+\sup\{t,\;F(t)<\alpha\}\big).$$
\end{enumerate}
\subsection{Le cas régulier : méthode de substitution}
Un estimateur naturel de $T(F)$ est l'estimateur par substitution, où l'on remplace formellement $F$ par sa répartition empirique $\widehat F_n(\cdot)$.
\begin{definition} L'estimateur par substitution de $T(F)$
$$\widehat T_n = \widehat T_n(X_1,\ldots, X_n) = T(\widehat F_n)$$
est obtenu en remplaçant $F$ par sa fonction de répartition empirique $\widehat F_n$.
\end{definition}
\subsubsection{Convergence dans le cas régulier}
On a vu dans la Section \ref{estimation uniforme} que les fonctions $\widehat F_n(\cdot)$ et $F(\cdot)$ sont proches lorsque $n$ est grand. On imagine alors que $T(\widehat F_n)$ est proche de $T(F)$ dès lors que la fonction $F \leadsto T(F)$ est régulière.

\begin{proposition} \label{convergence substitution}
Si la fonctionnelle $T(F)$ admet la représentation
\begin{equation} \label{fonctionnelle reguliere}
T(F) = h\left(\int_{\R} g(x)dF(x)\right)
\end{equation}
où $\int_{\R} |g(x)|dF(x)<+\infty$ et $h:\R\rightarrow \R$ continue, alors
\begin{equation} \label{conv fonct reg}
T(\widehat F_n) \stackrel{\mathrm{p.s.}}{\longrightarrow} T(F).
\end{equation}
\end{proposition}
\begin{proof}
Remarquons que $T(\widehat F_n) = h\big(\tfrac{1}{n}\sum_{i = 1}^n g(X_i)\big)$. On a
$$
%\int_{\R} g(x)d\widehat F_n(x) =
\frac{1}{n}\sum_{i = 1}^ng(X_i)\stackrel{\mathrm{p.s.}}{\longrightarrow} \E\big[g(X)\big] = \int_{\R}g(x)dF(x)$$
par la loi forte des grands nombres. La convergence reste vraie en composant par $h$ qui est continue.
\end{proof}
\begin{exemple} \label{variance empirique}
\emph{
La variance $\sigma^2(F)$ de la distribution $F$ s'écrit
\begin{align*}
\sigma^2(F) & =\int_{\R}\big(x-m(F)\big)^2dF(x) \\
& = \int_{\R}x^2dF(x)-\Big(\int_{\R}xdF(x)\Big)^2 \\
& =h_1\left(\int_{\R} g_1(x)dF(x)\right)+h_2\left(\int_{\R} g_2(x)dF(x)\right),
\end{align*}
avec $h_1(x) = x$, $h_2(x)=x^2$, $g_1(x)=x^2$, $g_2(x)=x$. L'estimateur par substitution associé s'écrit
$$\widehat \sigma^2_n = \frac{1}{n}\sum_{i = 1}^n X_i^2 - \Xbar^2 = \frac{1}{n}\sum_{i = 1}^n \big(X_i-\Xbar)^2.$$
La convergence $\widehat \sigma^2_n \stackrel{\mathrm{p.s.}}{\rightarrow}\sigma^2(F)$ découle de la Proposition \ref{convergence substitution} appliquée à chacun des termes $ \tfrac{1}{n}\sum_{i = 1}^n X_i^2 $ et  $\Xbar^2$ respectivement. On peut faire des calculs analogues pour le coefficient d'asymétrie $\alpha(F)$ et pour le coefficient d'aplatissement $\kappa(F)$.
}
\end{exemple}
\begin{remarque}
\emph{
Plus généralement, si l'on munit $\mathfrak{F}$ de la métrique de la convergence uniforme, le Théorème \ref{glivenko cantelli} (Glivenko-Cantelli) assure que la convergence \eqref{conv fonct reg} aura lieu si l'application $T \leadsto T(F)$ est continue.
}
\end{remarque}
\subsubsection{Vitesse de convergence dans le cas régulier} \label{vitesse convergence cas regulier}
Pour les fonctionnelles de type \eqref{fonctionnelle reguliere}, on a une vitesse de convergence :
\begin{proposition} \label{vitesse substitution 1d}
Dans la situation de la Proposition \ref{convergence substitution}, si $h$ est continûment dérivable
et si $\E\big[g(X)^2\big] = \int_{\R} g(x)^2dF(x)<+\infty$, alors
$$
\sqrt{n}\big(T(\widehat F_n)-T(F)\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0, v(F)\big),
$$
où
$$v(F) = h'\big(\E\big[g(X)\big]\big)^2 \mathrm{Var}\big[g(X)\big].$$
\end{proposition}
\begin{proof}
Par le théorème central limite,
\begin{align*}
\sqrt{n}\left(\int_{\R} g(x)d\widehat F_n(x)-\int_{\R}g(x)dF(x)\right) =& \sqrt{n}\Big(\tfrac{1}{n}\sum_{i = 1}^ng(X_i)-\E\big[g(X)\big]\Big) \\
\stackrel{d}{\longrightarrow} & \mathcal{N}\big(0, \mathrm{Var}\big[g(X)\big]\big).
\end{align*}
On applique alors la Proposition \ref{methode delta} du Chapitre \ref{chapitre 1} (méthode delta) :
$$\sqrt{n}\Big(h\big(\tfrac{1}{n}\sum_{i = 1}^ng(X_i)\big)-h\big(\E\big[g(X)\big]\big)\Big) \stackrel{d}{\longrightarrow} \mathcal{N}\Big(0,h'\big(\E\big[g(X)\big]\big)^2 \mathrm{Var}\big[g(X)\big]\Big).$$
C'est précisément le résultat recherché, puisque $h\big(\E\big[g(X)\big]\big)=T(F)$.
\end{proof}
%{\tt la cas multidimensionnel}
\begin{exemple} \label{inv moment 4}
\emph{
Etudions le comportement de l'estimateur par substitution de
$$T(F)=\frac{1}{\E\big[X^4\big]}=\frac{1}{\int_{\R}x^4dF(x)}$$
sous l'hypothèse que $0 < \int_{\R}x^8dF(x)<+\infty$. On a
$$T(\widehat F_n) = \frac{1}{\tfrac{1}{n}\sum_{i = 1}^4X_i^4}$$
(en convenant par exemple $1/0=0$). On applique la Proposition \ref{vitesse substitution 1d}, avec $g(x)=x^4$ et $h(x)=x^{-1}$. (Il y a cependant une difficulté : en $x=0$ la fonction $h$ ne vérifie pas\footnote{Il s'agit en fait d'un faux problème : on a $\E\big[X^4] = \int_{\R}x^4dF(x)>0$ puisque sinon, $X=0$ presque-sûrement et donc $F=1_{\R_+}(x)$ ce qui contredirait l'hypothèse $\int_{\R}x^8dF(x)>0$. Ceci entraîne que $X$ est \og éloigné en moyenne \fg{} de la singularité $0$. On pourra alors montrer en exercice que la convergence en loi voulue a bien lieu.} les hypothèses de la Proposition \ref{vitesse substitution 1d} puisque $h$ a une singularité en $0$. En appliquant tout de même formellement de résultat de la proposition, on a
$$\sqrt{n}\big(T(\widehat F_n) - T(F)\big)\stackrel{d}{\longrightarrow} \mathcal{N}\big(0,v(F)\big),$$
avec
$$v(F) = h'\big(\E\big[g(X)\big]\big)^2\big(\E\big[g(X)^2\big]-\E\big[g(X)\big]^2\big) = \frac{\mu_8}{\mu_4^2}-1$$
où $\mu_i =\E[X^i] = \int_{\R}x^idF(x)$. On peut pousser un peu plus loin l'étude et déduire de ce résultat un intervalle de confiance asymptotique pour $T(F) = \mu_4^{-1}$ comme dans la Section \ref{precision asymptotique}. C'est l'objet de l'Exercice \ref{int asymp moment 4 inverse}.
}
\end{exemple}
La Proposition \ref{vitesse substitution 1d} ne donne qu'un résultat en dimension 1 : elle ne permet même pas de traiter immédiatement la vitesse de convergence dans l'Exemple \ref{variance empirique}, et une version multidimensionnelle de la \og méthode delta \fg{} s'avère nécessaire dans le cas général.

Considérons une fonctionnelle de la forme
\begin{equation} \label{fonctionnelle multidim}
T(F) = h\Big(\int_{\R}g_1(x)dF(x),\ldots, \int_{\R}g_k(x)dF(x)\Big),
\end{equation}
où  $h:\R^k\rightarrow \R$ est une fonction différentiable, de gradient
$$J_h(\bx) = \nabla h(\bx) = \big(\partial_1 h(\bx),\ldots, \partial_k h(\bx)\big),\;\;\;\bx \in \R^k.$$
En appliquant la Proposition \ref{methode delta multidimensionnelle}, on a le résultat suivant :

\begin{corollaire} \label{substitution multidim}
Si la fonctionnelle $T(F)$ admet la représentation \eqref{fonctionnelle multidim} avec une fonction $h$ continûment différentiable, et si
 $\int_{\R}g_i(x)^2 dF(x)<+\infty$ pour tout $i=1,\ldots, k$, alors
$$\sqrt{n}\big(T(\widehat F_n)-T(F)\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0, v(F)\big),$$
avec
$$v(F) = J_h({\bf g})\,\Sigma_{{\bf g}}\,J_h({\bf g})^T,$$
où
%$$J_h(\bx) = \nabla h(\bx) = \big(\partial_1 h(\bx),\ldots, \partial_k h(\bx)\big),\;\;\;\bx \in \R^k,$$
%est le gradient de $h$,
$${\bf g} = \big(\E\big[g_1(X)\big],\ldots, \E\big[g_k(X)\big]\big)$$
%est le vecteur des espérances des $g_i(X)$,
et $\Sigma_{{\bf g}}$
%$$\Sigma_{\bf g} = \E\big[\big(g_1(X)-\E[g_1(X)],\ldots, g_k(X)-\E[g_k(X)]\big)^T\big(g_1(X)-\E[g_1(X)],\ldots, g_k(X)-\E[g_k(X)]\big)\big]$$
est la matrice de variance-covariance
%du vecteur $\big(g_1(X),\ldots, g_k(X)\big)$,
des $g_i(X)$:
$$\big(\Sigma_{{\bf g}}\big)_{ij} = \E\big[\big(g_i(X)-\E[g_i(X)]\big)\big(g_j(X)-\E[g_j(X)]\big)\big],\;\;1\leq i,j\leq k.$$
\end{corollaire}

\begin{exemple} \label{variance empirique methode delta}
\emph{
Reprenons le problème du calcul de la loi limite de la variance empirique de l'exemple \ref{variance empirique}. On a
$$\widehat \sigma_n^2 = \frac{1}{n}\sum_{i = 1}^n X_i^2- \big(\Xbar\big)^2.$$
On applique le Corollaire \ref{substitution multidim} avec $h(x_1,x_2) = x_1-x_2^2$, $g_1(x) = x^2$ et $g_2(x) = x$. On a
$$\nabla h(x_1,x_2) = (1,\;-2x_2)\;\;\;\text{et}\;\;\;{\bf g} = (\E[X^2],\;\E[X]).$$
Notons $\mu_i = \E[X^i]$. Un calcul simple montre que
$$
\Sigma_{{\bf g}} =
\left(
\begin{array}{cc}
\mu_4 - \mu_2^2 & \mu_3 - \mu_1 \mu_2 \\
\mu_3 - \mu_1 \mu_2  & \mu_2 - \mu_1^2
\end{array}
\right).
$$
Alors
$$\sqrt{n}\big(\widehat \sigma_n^2-\sigma\big)\stackrel{d}{\longrightarrow} \mathcal{N}\big(0,v(F)\big),$$
avec
$$v(F) =(1,\;-2\mu_1)
\left(
\begin{array}{cc}
\mu_4 - \mu_2^2 & \mu_3 - \mu_1 \mu_2 \\
\mu_3 - \mu_1 \mu_2  & \mu_2 - \mu_1^2
\end{array}
\right)
(1,\;-2\mu_1)^T.
%\kappa-4\alpha \mu+4\mu^2 \sigma^2.
$$
On trouve
$$v^2 = \mu_4-\mu_2^2-4\mu_1(\mu_3+\mu_1^3-2\mu_1\mu_2).$$
Dans le cas précis de la variance empirique, on aurait pu aussi retrouver directement ce résultat par une autre méthode, voir l'Exercice \ref{variance empirique slutsky}.
}
\end{exemple}
Avec la même technique, on peut exhiber les lois limites du coefficient d'asymétrie empirique et du coefficient d'aplatissement empirique.
%, voir Exercice \ref{kurtosis empirique}.
\subsection{Le cas non-régulier$^\star$}  \label{le cas non regulier}
Les fonctionnelles régulières de type \eqref{fonctionnelle reguliere} sont insuffisantes pour les applications : par exemple, elles ne recouvrent pas le cas très utile de l'estimation des quantiles d'une distribution inconnue.

Plus généralement, supposons que l'on dispose de l'information supplémentaire suivante sur le modèle statistique :
$$F \in \mathfrak{F}^{\mathrm{ac}} \subset \mathfrak{F},$$
où $\mathfrak{F}^{\mathrm{ac}}$ désigne l'ensemble des distributions absolument continues, c'est-à-dire qui possèdent une densité $f$ par rapport à la mesure de Lebesgue. Alors, par exemple, la fonctionnelle
$$T(F) = \int_{\R}F'(x)^2dx = \int_{\R} f(x)^2dx$$
n'est pas régulière. Bien que l'on ait $f(x)=F'(x)$ presque-partout, on ne peut pas former d'estimateur par substitution en \og dérivant \fg\; $\widehat F_n(\cdot)$ qui est constante par morceaux. Plus généralement, dans le cas où le modèle statistique a pour ensemble de paramètres $\mathfrak{F}^{\mathrm{ac}}$, on peut s'intéresser à la constuction d'un estimateur $\widehat f_n(\cdot)$ qui soit une bonne approximation de la densité $f(\cdot)$ de $F$.

Dans le reste de cette section, nous étudions deux cas particuliers : l'estimation des quantiles, et le lissage de la distribution empirique.

\subsubsection{Estimation des quantiles \index{quantiles empiriques}}
On considère la statistique d'ordre associée à l'échantillon $(X_1,\ldots, X_n)$, c'est-à-dire le vecteur $(X_{(1)},\ldots, X_{(n)})$ obtenu par la permutation (aléatoire) qui fournit le réarrangement croissant des données
$$X_{(1)} \leq \cdots \leq X_{(i)} \leq \cdots \leq X_{(n)}.$$
Cette permutation n'est pas nécessairement unique (dans le cas discret, certaines valeurs des observations peuvent coïncider). Pour estimer le quantile\footnote{Voir la Section \ref{quantiles} du Chapitre \ref{chapitre 1}.} d'ordre $p$ de la loi $F$, c'est-à-dire
$$T(F) = \tfrac{1}{2}\big(\inf\{q,\,F(q)>p\}+\sup\{q,\,F(q)<p\}\big)$$
on peut choisir l'estimateur par substitution
$$\widehat q_{n,p} = T(\widehat F_n) =  \tfrac{1}{2}\big(\inf\{q,\,\widehat F_n(q)>p\}+\sup\{q,\,\widehat F_n(q)<p\}\big)$$
appelé quantile empirique d'ordre $p$. La difficulté de cette approche réside dans le fait que $x \leadsto \widehat F_n(x)$ est constante par morceaux, donc, pour $p\in [0,1]$ donné, l'équation
$$\widehat F_n(q)=p.$$
admet une infinité de solutions ou n'en admet aucune. On peut expliciter $\widehat q_{n,p} $ à l'aide de la statistique d'ordre. On pourra montrer que
%On a toujours
%$$\widehat F_n(\widehat q_{n,p}) = p$$
%et on a, plus précisément
$$\widehat q_{n,p} =
\left\{
\begin{array}{lll}
X_{(k)} & \text{si} & p \in \big((k-1)/n, k/n\big) \\
\tfrac{1}{2}\big(X_{(k)}+X_{(k+1)}\big) & \text{si} & p=k/n
\end{array}
\right.$$
pour $k = 1,\ldots, n$. Le comportement asymptotique de $\widehat q_{n,p}$ est étudié dans l'Exercice \ref{asymp quantile} à la fin du chapitre.
\subsubsection{Lissage de la distribution empirique$^\star$} \index{distribution empirique}
Etant donné l'observation $X_1,\ldots, X_n$, la fonction aléatoire
$$x\leadsto \widehat F_n(x) = \frac{1}{n}\sum_{i = 1}^n 1_{\{X_i(\omega)\leq x\}}$$
est constante par morceaux. On insiste ici sur l'aléa $\omega$, pour marquer le fait que $\widehat F_n(\cdot)$ dépend d'une réalisation $\big(X_1(\omega),\ldots, X_n(\omega)\big)$ du vecteur aléatoire $\big(X_1,\ldots, X_n\big)$. Si on prend formellement sa dérivée (au sens des distributions), on obtient
\begin{equation} \label{distribution empirique formelle}
\widehat F_n'(dx) = \frac{1}{n}\sum_{i = 1}^n \delta_{X_i(\omega)}(dx)
\end{equation}
où $\delta_a(dx)$ est la mesure de Dirac au point $a$. On obtient ainsi une mesure de probabilité\footnote{Celle-ci dépend de $\omega$ : il s'agit d'une distribution aléatoire.}, qui assigne à chaque point $X_i(\omega)$ la masse $1/n$.
\begin{definition}
Etant donnée une réalisation $\big(X_1(\omega),\ldots, X_n(\omega)\big)$ du vecteur aléatoire $\big(X_1,\ldots, X_n\big)$, on appelle distribution empirique la mesure de probabilité uniforme sur l'ensemble $\{X_1(\omega),\ldots, X_n(\omega)\}$ définie par \eqref{distribution empirique formelle}.
\end{definition}
Remarquons qu'en posant formellement
$$d\widehat F_n(x) = \widehat F_n'(dx),$$
les notations sont cohérentes avec les calculs : pour toute fonction test $\varphi$, on a
$$\int_{\R}\varphi(x)d\widehat F_n(x) = \frac{1}{n}\sum_{i=1}^n \varphi\big(X_i(\omega)\big) = \int_{\R}\varphi(x) \tfrac{1}{n}\sum_{i = 1}^n \delta_{X_i(\omega)}(dx).$$

\subsubsection{Estimateur à fenêtre mobile et à noyau$^\star$}
La densité $f$ est la dérivée de la fonction de répartition $x \leadsto F(x)$. Ecrivons l'approximation
$$f(x) = F'(x) \approx \frac{1}{h}\big(F(x+h/2)-F(x-h/2)\big)$$
lorsque $h$ est petit. On approche le membre de droite par substitution. Ceci fournit l'estimateur
$$\widehat f_n(x) =  \frac{1}{h}\big(\widehat F_n(x+h/2)-\widehat F_n(x-h/2)\big),$$
appelé estimateur par fenêtre mobile.

Posons $U_x^h = [x-h/2,x+h/2)$. Alors $\widehat f_n(x)$ compte le nombre d'observations $X_i$ qui \og tombent\fg\; dans la \og fenêtre\fg\; $U_x^h$ normalisé par $n$, puis on fait glisser la fenêtre $U_x^h$ avec $x$:
\begin{align*}
\frac{1}{h}\big(\widehat F_n(x+h/2)-\widehat F_n(x-h/2)\big)
 =\,& \frac{1}{nh}\sum_{i = 1}^n 1_{\{X_i \in U_x^h\}} \\
 =\,& \frac{1}{nh}\sum_{i = 1}^nK\left(\frac{x-X_i}{h}\right),
\end{align*}
où $K(x) = 1_{\{-1/2 < x \leq 1/2\}}$. La fonction aléatoire $x \leadsto \widehat f_n(x)$ est elle-même une densité de probabilité, constante par morceaux.

Une version plus lisse de l'estimateur à fenêtre mobile consiste à remplacer la fonction $K$ par une fonction régulière $K^{(r)}$, vérifiant $\int_{\R}K^{(r)}(x)dx=1$. On utilise souvent le noyau gaussien
$$K^{(r)}(x) = (2\pi)^{-1/2}\exp(-x^2/2).$$ L'estimateur à noyau
$$\widehat f_n^{(r)}(x) = \frac{1}{nh} \sum_{i=1}^n K^{(r)}\left(\frac{x-X_i}{h}\right)$$
est donc la moyenne arithmétique de $n$ \og fonctions cloches\fg\;
$$\frac{1}{h}K^{(r)}\left(\frac{\cdot-X_i}{h}\right),$$
chaque \og cloche \fg\; étant une densité de probabilité centrée en $X_i$ et d'échelle $h$. La fonction aléatoire $x \leadsto \widehat f_n^{(r)}(x)$ est une densité de probabilité : elle est positive, et
$$\int_{\R}\widehat f_n^{(r)}(x)dx = \int_{\R}K(x)dx=1.$$
L'étude des estimateurs à noyau pour l'estimation non-paramétrique de la densité est une théorie à part entière qui dépasse le cadre de ce cours. Elle est traitée de façon approfondie dans le cours de MAP 553, voir \cite{Tsyb2}.
\section{Exercices}
\begin{exercice} \label{precision int conf}
\emph{Soit $\Phi(x) = (2\pi)^{-1/2}\int_{-\infty}^xe^{-t^2/2}dt$ la fonction de répartition de la loi gaussienne standard.
\begin{itemize}
\item Montrer que $1-\Phi(x) \leq \frac{1}{2}e^{-x^2/2}$ et en déduire que pour $\alpha \in (0,1)$,
$$\alpha \leq \exp(-\frac{1}{2}\Phi^{-1}(1-\alpha/2)^2).$$
\item Montrer que $1-\Phi(x)  = \frac{x}{\sqrt{2\pi}} e^{-x^2/2} -x^2[1-\Phi(x)]$. En déduire
$$1-\Phi(x) \geq \frac{e^{-x^2/2}}{2x\sqrt{2\pi}}.$$
(On pourra utiliser l'inégalité : $x/(1+x^2)\geq 1/2x$ si $x \geq 1$.)
\item En déduire
$$\sqrt{2\log \frac{1}{\alpha r(\alpha)}} \leq \Phi^{-1}(1-\alpha/2),$$
où l'on a posé $r(\alpha):=2 \sqrt{\pi \log\frac{1}{\alpha}}$.
\end{itemize}
}
\end{exercice}
\begin{exercice} \label{variance empirique slutsky}
\emph{On a étudié le comportement asymptotique de la variance empirique par la méthode \og delta \fg{} dans l'exemple \ref{variance empirique methode delta}. On peut retrouver ce résultat de manière plus directe. On écrit
$$\sqrt{n}\big(\tfrac{1}{n}\sum_{i = 1}^n(X_i-\overline{X}_n)-\sigma^2\big) = \sqrt{n}\big(\tfrac{1}{n}\sum_{i = 1}^n (X_i-\mu)^2-\sigma^2\big)-\sqrt{n}(\overline{X}_n-\mu)^2.$$
Montrer que le second terme converge vers $0$ en probabilité. Montrer que le premier terme est asymptotiquement normal via le théorème central-limite. Conclure via la Proposition \ref{slutsky} (Slutsky).
}
\end{exercice}
\begin{exercice} \label{int asymp moment 4 inverse}
\emph{
On cherche un intervalle de confiance asymptotique pour la fonctionnelle
$$T(F)=\frac{1}{\E\big[X^4\big]}=\frac{1}{\int_{\R}x^4dF(x)}$$
sous l'hypothèse que $0 < \int_{\R}x^8dF(x)<+\infty$. On a vu dans l'Exemple \ref{inv moment 4} la Section \ref{vitesse convergence cas regulier} la convergence
$$\sqrt{n}\big(T(\widehat F_n) - T(F)\big)\stackrel{d}{\longrightarrow} \mathcal{N}\big(0,v(F)\big),$$
avec  $v(F) = \mu_8/\mu_4^2-1$. Montrer que $v(\widehat F_n) \stackrel{\PP}{\rightarrow} v(F)$ et en déduire un intervalle de confiance asymptotique pour $T(F)$ à l'aide de la Proposition \ref{slutsky} (Slutsky).
}
\end{exercice}
\begin{exercice}
\emph{
Soient $X_1,\ldots, X_n$ des variables aléatoires réelles indépendantes, de même densité $f$. On note
$X_{(1)},\ldots, X_{(n)}$ la statistique d'ordre associée (voir Section \ref{le cas non regulier}).
% leur réarrangement croissant, c'est-à-dire
%\begin{eqnarray*}
%&X_{(1)} = \min\{X_i, i=1,\ldots, n\}, \\
%&X_{(2)} =  \text{seconde plus petite valeur parmi}\;X_1,\ldots, X_n,\\
%&\ldots,  \\
%&X_{(n)} = \max\{X_i, 1,\leq i \leq n\}.
%\end{eqnarray*}
\begin{itemize}
\item Montrer que la densité de $(X_{(1)},\ldots, X_{(n)})$ est donnée par
$$f_{(X_{(1)},\ldots, X_{(n)})} = n! \prod_{i=1}^n f(x_i)1_{\{x_1 < x_2 < \ldots < x_n\}}.$$
\item Si $F$ désigne la fonction de répartition des $X_i$, montrer que $X_{(k)}$ a pour densité
$$f_{X_{(k)}}(x) = k\,C_{n}^k\, f(x)\big(1-F(x)\big)^{n-k}F(x)^{k-1}.$$
\end{itemize}
}
\end{exercice}

\begin{exercice}[Un test asymptotique de gaussianité] \label{test gaussianite japonais}
\emph{
Soient $X_1,\ldots, X_n$ un $n$-échantil\-lon de loi inconnue $F$ ayant au moins un moment d'ordre $4$ et de moyenne nulle et de variance non-nulle. \begin{itemize}
\item On pose, pour $k= 1, \ldots, 4$
$$T_n^{(k)} = \frac{\tfrac{1}{n}\sum_{i = 1}^n X_i^k}{\big(\tfrac{1}{n}\sum_{i = 1}^n X_i^2\big)^{k/2}}.$$
Montrer que
$$\frac{n}{15}\big(T_n^{(3)}\big)^2+\frac{n}{24}\big(T_n^{(4)}-3\big)^2 \stackrel{d}{\rightarrow} \chi^2(2),$$
où $\chi^2(2)$ désigne la loi du $\chi^2$ à 2 degrés de liberté.
\item En déduire un test de l'hypothèse nulle $H_0: F=\Phi$ contre l'alternative $H_1: F\neq \Phi$ où
$\Phi(x) = (2\pi)^{-1/2}\int_{-\infty}^x e^{-t^2/2}dt$ est la fonction de répartition de loi normale standard.
\item Le test est-il consistant ?
\end{itemize}
}
\end{exercice}
\begin{exercice}[Comportement asymptotique des quantiles empiriques] \label{asymp quantile}
\emph{
Soit $(\zeta_1,\dots,\zeta_{n+1})$ des variables aléatoires indépendantes et de même loi exponentielle de paramètre $1$. On pose
$$ V_i=\sum_{j=1}^i \zeta_j$$
\begin{itemize}
\item
Montrer que le vecteur $(V_1,\dots,V_{n+1})$ admet comme densité
$$ (v_1,\dots,v_{n+1}) \mapsto 1_{\{0<v_1<\dots<v_{n+1}\}} \exp(-v_{n+1}).$$
\item On considère une permutation aléatoire $\Gamma$ de $\{1,\dots,n\}$ de loi uniforme et indépendante
de $(\zeta_1,\dots,\zeta_{n+1})$. Montrer que les variables aléatoires
$$ \frac{V_{\Gamma(i)}}{V_{n+1}}, \quad i=1,\ldots n$$
sont indépendantes et de même loi uniforme sur $[0,1]$.
\item Soit $F$ une fonction de répartition sur $\R$. On pose
$$ F^{-}(u)=\inf\{t\in\R,\; F(t)\geq u\}, \quad 0<u<1.$$
Montrer que $F^{-}$ est bien définie et qu'on a l'équivalence
$u\le F(t) \Leftrightarrow F^{-}(u) \leq t$.
En déduire que si $(X_1,\dots,X_n)$ est un $n$-échantillon de loi $F$, alors
la statistique d'ordre $(X_{(1)},\dots,X_{(n)})$ a même loi que le vecteur
$$ \Big(F^{-}\big(\tfrac{V_{1}}{V_{n+1}}\big),\ldots, F^{-}\big(\tfrac{V_{n}}{V_{n+1}}\big)\Big).$$
\item Soit $p\in (0,1)$. Montrer que
$$ \sqrt{n} \Big(\frac{V_{[ np ]}}{n-p}, \frac{V_{n+1}}{n-1}\Big)$$
converge en loi vers un  vecteur gaussien centré $(Z_1,Z_2)$ avec  $\mathrm{Var}(Z_2)=1$ et $\mathrm{Var}[Z_1]=\mathrm{Cov}(Z_1,Z_2)=p$.
\item On suppose qu'il existe un voisinage $(a,b)$ de $F^-(p)$ et une fonction $f$ strictement positive sur $(a,b)$, continue en $F^-(p)$ tels que
$$ F(t)=F(t_1)+ \int_{t_1}^t f(s) ds \quad \text{pour $t\in(a,b)$.}$$
Montrer que $F^{-}(p)$ est l'unique solution de l'équation $F(t)=p$.
Montrer que $\sqrt{n}( X_{([np])}-F^-(p) )$ converge en loi vers la loi gaussienne ${\mathcal N}\Big(0, p(1-p)/f\big(F^{-}(p)\big)^2\Big)$. (Théorème de Mosteller).
\end{itemize}
}
\end{exercice}
\chapter[Méthodes d'estimation en densité]{Méthodes d'estimation pour le modèle de densité} \label{estimation densite}
On se place dans le modèle d'échantillonnage. L'hypothèse supplémentaire par rapport au Chapitre \ref{echantillonnage} est que la famille de probabilités associée à l'expérience statistique est \og paramétrique \fg{} : on peut la représenter à l'aide d'un sous-ensemble d'un espace de dimension finie.
\section{Introduction}
\subsection{Notations et hypothèses} \label{hypotheses domination etc}
\subsubsection{Situation}
On observe un $n$-échantillon
$$X_1,\ldots, X_n$$
d'une loi inconnue sur $\R$, que l'on notera aussi sous forme d'un vecteur colonne
$$\big(X_1,\ldots, X_n\big)^T,$$
où les $X_i$ sont des variables indépendantes et identiquement distribuées, et on suppose que leur loi commune appartient à une famille paramétrique de lois donnée
$$\big\{\PP_\vartheta, \vartheta \in \Theta\big\},\;\;\Theta \subset \R^d,$$
où $\vartheta$ est un paramètre de dimension $d$. L'expérience statistique sous-jacente au sens de la Définition \ref{def math exp stat} du Chapitre \ref{chapitre 2} s'écrit
$${\mathcal E}^n = \big(\R^n, {\mathcal B}^n, \{\PP_\vartheta^n, \vartheta \in \Theta\} \big)$$
où $\PP_\vartheta^n$ est la loi de $n$ variables aléatoires indépendantes de loi $\PP_\vartheta$. On écrit indifféremment $\PP_\vartheta$, ou $\PP_\vartheta^n$, voire $\PP$ lorsqu'il n'y a pas de confusion possible.
On note aussi ${\mathcal E} = {\mathcal E}^1$, l'expérience associée à une seule observation.

Dans ce contexte, on cherche à construire des estimateurs $\widehat \vartheta_n$ de $\vartheta$, ou plutôt des suites d'estimateurs, variant avec $n$. Un estimateur -- {\it cf.} la Définition \ref{procedure statistique} -- est une quantité mesurable par rapport aux observations :
$$\widehat \vartheta_n =  \widehat \vartheta_n(X_,\ldots, X_n)$$
à valeurs dans $\R^d$ (idéalement, à valeurs dans $\Theta$). Evidemment, un estimateur raisonnable $\widehat \vartheta_n$ \og approche\fg{} $\vartheta$ d'autant mieux que le nombre d'observations $n$ est grand. Nous allons développer des méthodes systématiques de construction d'estimateurs \og raisonnables\fg{}, en faisant des hypothèses adéquates sur la famille $\big\{\PP_{\vartheta}, \vartheta \in \Theta\big\}$.

\subsubsection{Identifiabilité}
\index{identifiabilité}
Nous supposons toujours que l'expérience est bien paramétrée, au sens où la fonction $\vartheta \in \Theta \leadsto \PP_\vartheta$ est injective, ce qui était déjà implicite dans nos notations : deux valeurs différentes $\vartheta_1\neq \vartheta_2$ donnent lieu à deux mesures de probabilités $\PP_{\vartheta_1}\neq \PP_{\vartheta_2}$ différentes.

Une expérience statistique ${\mathcal E}^n$ engendrée par l'observation d'un $n$-échantillon s'écrit ${\mathcal E}^n = {\mathcal E} \times \cdots \times {\mathcal E}$ ($n$ fois), où ${\mathcal E}$ est l'expérience statistique associée à une observation (${\mathcal E} = {\mathcal E}^1$). Alors ${\mathcal E}^n$ est identifiable si et seulement si ${\mathcal E}$ l'est.


Voici un exemple de mauvaise paramétrisation donnant lieu à un modèle qui n'est pas identifiable : $\PP_\vartheta$ est la loi sur $\R$ de densité par rapport à la mesure de Lebesgue
$$f(\vartheta,x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(x-\vartheta^2)^2},\;\;\vartheta \in \Theta = \R.$$
La donnée de $f(\vartheta,\cdot)$ ne permet par de distinguer $\vartheta$ et $-\vartheta$. Par contre, la même expérience associée à l'ensemble des paramètres
$\widetilde \vartheta = \R_+$ devient identifiable.

\subsubsection{Domination}
\index{domination}
Nous faisons une hypothèse essentielle de domination, qui permet, en un certain sens, de réduire la complexité de l'étude de ${\mathcal E}^n$ à celle d'une fonction de plusieurs variables.
\begin{hypothese} \label{domination}
L'expérience ${\mathcal E}$ est dominée : il existe une mesure $\sigma$-finie $\mu$ sur $\R$ telle que, pour tout $\vartheta \in \Theta$, $\mu$ domine $\PP_\vartheta$. On note
$$f(\vartheta, x) = \frac{d\PP_\vartheta}{d\mu}(x),\;\;x\in \R$$
la densité de $\PP_\vartheta$ par rapport à $\mu$.
\end{hypothese}

\begin{remarque}
\emph{
Pour un $n$-échantillon, ${\mathcal E}^n$ est dominée si et seulement si ${\mathcal E}$ l'est. L'expérience statistique ${\mathcal E}^n$ est dominée par la mesure produit $\mu^{n} = \mu \otimes \ldots \otimes \mu$ ($n$ fois) et
$$\frac{d\PP_\vartheta^n}{d\mu^{n}}(x_1,\ldots, x_n) = \prod_{i = 1}^n f(\vartheta, x_i),\;\;x_1,\ldots, x_n \in \R.$$
}
\end{remarque}
\begin{remarque}
\emph{
Se donner une expérience statistique satisfaisant l'Hypothèse \ref{domination} revient à spécifier une application $f:\Theta \times \R \rightarrow \R$. Nous verrons dans ce chapitre ainsi qu'au Chapitre \ref{theorie asymptotique} comment l'estimation de $\vartheta$ est intimement liée à la régularité de la fonction $(\vartheta,x) \leadsto f(\vartheta,x)$.
}
\end{remarque}

Dans presque toutes les situations que nous considérerons, la mesure $\mu$ est la mesure de Lebesgue sur $\R$ lorsque la loi des observations est absolument continue, ou bien $\mu$ est la mesure de comptage sur l'ensemble des valeurs possibles des observations lorsque la loi des observations est discrète.

\begin{exemple}
\emph{
\begin{enumerate}
\item Si l'expérience statistique ${\mathcal E}$ est engendrée par l'observation d'une variable exponentielle de paramètre $\vartheta, \vartheta >0$, alors $\PP_\vartheta(dx)$ est la loi exponentielle de paramètre $\vartheta$ et $\Theta = \R_+\setminus\{0\}$. Une mesure dominante est la mesure de Lebesgue $\mu(dx)=dx$ et on a
$$\PP_\vartheta(dx) = f(\vartheta,x) dx = \vartheta \exp(-\vartheta x) 1_{\{x \geq 0\}} dx.$$
\item Si ${\mathcal E}$ est engendrée par l'observation d'une variable de Poisson de paramètre $\vartheta >0$, alors $\PP_\vartheta(dx)$ est la loi de Poisson de paramètre $\vartheta$ et $\Theta = \R_+\setminus \{0\}$. Dans ce cas, on peut prendre pour $\mu$ la mesure de comptage sur $\mathbb{N}$ et on a
$$\PP_\vartheta(dx) = f(\vartheta, x)\mu(dx) = \exp(-\vartheta)\frac{\vartheta^x}{x!}\mu(dx),$$
et on a aussi
$$f(\vartheta,x) = \PP_\vartheta\big[X=x\big].$$
\item Si ${\mathcal E}$ est engendrée par l'observation d'une variable gaussienne, de moyenne $\mu$ et de variance $\sigma^2$, alors $\vartheta = (\mu,\sigma^2)$, $\Theta = \R \times \R_+\setminus \{0\}$ et $\PP_\vartheta(dx)$ est la loi ${\mathcal N}(\mu, \sigma^2)$. Dans ce cas, on peut prendre $\mu(dx) = dx$ et on a
$$f(\vartheta, x) = (2\pi\sigma^2)^{-1/2}\exp\big(-\tfrac{1}{2\sigma^2}(x-\mu)^2\big).$$
Attention : dans certaines situations, on suppose que l'on connaît l'une des valeurs $\mu$ ou $\sigma^2$. Dans ce cas, on doit changer de paramètre et d'ensemble de paramètres, même si, bien-sûr, la loi des observations reste la même. Par exemple, si l'on connaît $\sigma^2$, alors on prend $\vartheta = \mu$, $\Theta = \R$ et on écrit plutôt
$$f_{\sigma^2}(\vartheta, x) = (2\pi\sigma^2)^{-1/2}\exp\big(-\tfrac{1}{2\sigma^2}(x-\mu)^2\big).$$
\end{enumerate}
}
\end{exemple}


\subsubsection{Calcul de lois}
On note $\PP_\vartheta^n$ (ou $\PP_\vartheta$ lorsqu'il n'y a pas de confusion) la loi des observations, et $\E_\vartheta^n\big[\cdot\big]$ (ou $\E_\vartheta\big[\cdot\big]$) l'espérance associée.
Si $\widehat \vartheta_n$ est un estimateur de $\vartheta$ et $\varphi$ une fonction test, alors
\begin{align*}
\E_\vartheta\big[\varphi(\widehat \vartheta_n)\big] &= \E_\vartheta\big[\varphi\big(\widehat \vartheta_n(X_1,\ldots, X_n)\big)\big] \\
&= \int_{\R^n} \varphi\big(\widehat \vartheta_n(x_1,\ldots, x_n)\big) \PP_\vartheta(dx_1)\ldots \PP_\vartheta(dx_n) \\
& = \int_{\R^n} \varphi\big(\widehat \vartheta_n(x_1,\ldots, x_n)\big) \prod_{i = 1}^n f(\vartheta, x_i) \mu(dx_1)\ldots \mu(dx_n).
\end{align*}
Si $\mu$ est la mesure de Lebesgue, cette formule devient
$$\E_\vartheta\big[\varphi(\widehat \vartheta_n)\big] =\int_{\R^n} \varphi\big(\widehat \vartheta_n(x_1,\ldots, x_n)\big) \prod_{i = 1}^n f(\vartheta, x_i)dx_1\ldots dx_n.$$
Si $\mu$ est la mesure de comptage sur ${\mathcal M}\subset \R$ au plus dénombrable, la formule devient
$$\E_\vartheta\big[\varphi(\widehat \vartheta_n)\big] =\sum_{x_1,\ldots,\, x_n \in {\mathcal M}} \varphi\big(\widehat \vartheta_n(x_1,\ldots, x_n)\big) \prod_{i = 1}^n f(\vartheta, x_i).$$
Ces formules ne sont pas toujours \og praticables \fg{}: on choisit souvent des fonctions tests et des estimateurs très particuliers pour pouvoir conduire les calculs.
\subsection{Familles paramétriques classiques} \label{familles parametrees}
\begin{enumerate}
\item {\it Loi gaussienne réelle et vectorielle}, que nous avons déja rencontré au Chapitre \ref{chapitre 1}.
\item {\it Dérivées des lois gaussiennes}. Il s'agit de la loi du $\chi^2$ à $n$ degrés de liberté, la loi de Student à $n$ degrés de libertés, et la loi de Fisher ou Fisher-Snedecor à $(n_1,n_2)$ degrés de liberté, que nous avons déja rencontrées au Chapitre \ref{chapitre 1}.
\item {\it Loi Gamma.} Notée $\Gamma_{\lambda,\alpha}$ de paramètres $\alpha >0$ et $\lambda>0$, de densité $\gamma_{\lambda,\alpha}$ par rapport à la mesure de Lebesgue
\index{Gamma, loi}
$$\gamma_{\lambda,\alpha}(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}1_{\{x \geq 0\}}$$
où $\Gamma(x) = \int_0^{+\infty}u^{x-1}e^{-u}du$. Si $X \sim \Gamma_{\lambda,\alpha}$, alors
\begin{align*}
\E\big[X^k\big] & = \frac{\lambda^\alpha}{\Gamma(\alpha)}\int_{0}^{+\infty} x^{\alpha+k-1}e^{-\lambda x}dx\\
& =  \frac{\lambda^{-k}}{\Gamma(\alpha)}\int_{0}^{+\infty} x^{\alpha+k-1}e^{-x}dx\\
& = \frac{\lambda^{-k}\Gamma(\alpha+k)}{\Gamma(\alpha)}.
\end{align*}
En particulier, $\E\big[X\big] = \alpha/\lambda$ et $\var\big[X\big]=\alpha/\lambda^2$. Le paramètre $\lambda$ joue un rôle de facteur d'échelle : on montre de la même manière que si $X \sim \Gamma_{1,\alpha}$, alors $X/\lambda \sim \Gamma_{\lambda,\alpha}$. C'est donc le deuxième paramètre qui est important en modélisation. En particulier, la loi du $\chi^2$ à $n$ degrés de liberté est la loi $\Gamma_{1/2,n/2}$.
\item {\it Loi exponentielle}. C'est la loi $\Gamma_{\lambda,1}$, $\lambda >0$, de densité $\lambda e^{-\lambda x}1_{\{x \geq 0\}}$. En particulier, sa moyenne vaut $1/\lambda$ et sa variance $1/\lambda^2$.
\item {\it Loi Béta}. De paramètres $\lambda_1, \lambda_2 >-1$. C'est une loi sur $[0,1]$, de densité
$$x \leadsto \frac{\Gamma(\lambda_1+\lambda_2)}{\Gamma(\lambda_1)\Gamma(\lambda_2)}x^{\lambda_1-1}(1-x)^{\lambda_2-1}1_{\{x\in (0,1)\}}.$$
Son nom vient de la fonction Béta
\index{Béta, loi}
$$B(\lambda_1,\lambda_2) = \int_0^1 x^{\lambda_1-1}(1-x)^{\lambda_2-1}dx = \frac{\Gamma(\lambda_1)\Gamma(\lambda_2)}{\Gamma(\lambda_1+\lambda_2)}.$$
Si $X$ suit la loi Béta de paramètres $(\lambda_1,\lambda_2)$, ses moments -- s'ils existent -- sont donnés par la formule
$$\E\big[X^k\big] = \int_0^1 \frac{\Gamma(\lambda_1+\lambda_2)}{\Gamma(\lambda_1)\Gamma(\lambda_2)}x^{\lambda_1+k-1}(1-x)^{\lambda_2-1} = \frac{\Gamma(\lambda_1+\lambda_2)\Gamma(\lambda_1+k)}{\Gamma(\lambda_1)\Gamma(\lambda_1+\lambda_2+k)}.$$
En particulier, pour $k=1,2$ on obtient
$$\E\big[X\big] = \frac{\lambda_1}{\lambda_1+\lambda_2},\;\;\;\E\big[X^2\big] = \frac{\lambda_1(\lambda_1+1)}{(\lambda_1+\lambda_2)(\lambda_1+\lambda_2+1)}.$$
\item {\it Loi uniforme.} Sur $[0,1]$, on peut la voir comme un cas particulier de la loi Béta\footnote{Le lien entre loi uniforme et loi Béta intervient dans le calcul de la statistique de rang associé à des tirages uniformes, dont une application fondamentale est la loi limite d'estimation de quantiles, voir par exemple \cite{B}, p.46.} pour $\lambda_1=\lambda_2=1$.
%, voir l'Exercice \label{loi limite quantile empirique}.
\item {\it Loi de Cauchy.} \index{Cauchy, loi de}C'est la loi de paramètres $\alpha \in \R$ et $\sigma^2>0$ de densité
$$x \leadsto \frac{\sigma}{\pi\big(\sigma^2+(x-\alpha)\big)^2} = \frac{1}{\pi \sigma}\frac{1}{1+\big((x-\alpha)/\sigma^2\big)^2}$$
sur $\R$. Ce n'est rien d'autre que la famille de translations-dilatations associée à la loi de Cauchy standard de densité
$$x \leadsto \frac{1}{\pi(1+x^2)}$$
mais à la différence de la famille des lois normales, elle n'admet pas de moment d'ordre $1$ (et donc pas de variance non plus).
\item {\it Loi log-normale}
\index{log-normale, loi}On dit qu'un variable $Y$ est log-normale si elle peut s'écrire $Y =\exp(X)$, avec $X \sim {\mathcal N}(\mu,\sigma^2)$. La densité de la loi log-normale est
$$x \leadsto \frac{1}{x}g\big(\log(x)\big),$$
où $g(x) = (2\pi^{-1/2})\exp(-x^2/2)$ est la densité de la loi normale standard. De plus,
$$\E\big[Y\big] = e^{\mu+\sigma^2/2},\;\;\;\E\big[Y^2\big] = e^{2\mu+2\sigma^2}.$$
\item {\it Loi de Bernoulli.} Rencontrée au Chapitre \ref{chapitre 1}.
\item {\it Loi de Poisson.} Rencontrée au Chapitre \ref{chapitre 1}. Si $X$ suit une loi de Poisson de paramètre $\lambda>0$, alors $\E\big[X\big] = \var\big[X\big] = \lambda$.
%Cette propriété se révèle très importante dans les applications, voir l'Exercice \ref{Poisson important}.
\item {\it Loi multinomiale.} Soient $X_1,\ldots, X_n$ sont des variables aléatoires à valeurs dans $\{1,\ldots, d\}$, indépendantes et de même loi
\index{multinomiale}
$$\PP\big[X=\ell\big] = p_\ell,\;\;\ell=1,\ldots, d.$$
Si l'on note $N_\ell = \sum_{i=1}^n 1_{\{X_i = \ell\}}$ le nombre de tirages ayant donné la valeur $\ell$, alors le vecteur
$(N_1,\ldots, N_\ell)$ suit la loi multinomiale de paramètres $n$ et $(p_1,\ldots, p_d)$, donnée par
$$\PP\big[N_1 = n_1,\ldots, N_d = n_d\big] = \frac{n!}{n_1!\cdots n_d!}p_1^{n_1}\cdots p_d^{n_d},\;\;\;\sum_{\ell=1}^d n_\ell=1.$$
La loi multinomiale généralise la loi binomiale, qui correspond au cas $d=2$. Cette loi est fondamentale dans l'utilisation du test du $\chi^2$ du Chapitre \ref{tests asymptotiques}.
\end{enumerate}
\section{Méthode des moments} \label{la methode des moments}
\subsection{Le cas de la dimension 1}
\index{moments, méthode des}
On suppose $\vartheta \subset \R$. Supposons donnée une application $g: \R \rightarrow \R$ telle que
$$\vartheta \leadsto m(\vartheta) = \E_\vartheta\big[g(X)\big]$$
existe et soit strictement monotone et continue. Alors $m$ réalise une bijection de $\Theta$ sur son image $m(\Theta)$ et on a la représentation
$$\vartheta = m^{-1}\big(\E_\vartheta\big[g(X)\big]\big),\;\;\vartheta \in \Theta.$$
En remplaçant la moyenne théorique inconnue $m(\vartheta) = \E_\vartheta\big[g(X)\big]$ par sa version empirique $\tfrac{1}{n}\sum_{i = 1}^n g(X_i)$, observable, un estimateur naturel de $\vartheta$ est donc
\begin{equation} \label{est substitution}
\widehat \vartheta_n = m^{-1}\left(\frac{1}{n}\sum_{i = 1}^ng(X_i)\right).
\end{equation}
Une autre façon de voir cette approche est de remarquer que si $F_\vartheta$ désigne la fonction de répartition de la loi $\PP_\vartheta$, alors
$$\vartheta = T(F_\vartheta) = m^{-1}\left(\int_{\R}g(x)dF_\vartheta(x)\right),$$
où $T$ est une fonctionnelle de type \eqref{fonctionnelle lineaire} étudiée au chapitre précédent.
On a donc aussi
$$\widehat \vartheta_n = T(\widehat F_n) = m^{-1}\left(\frac{1}{n}\sum_{i=1}^n g(X_i)\right).$$
%\begin{remarque}
%\emph{
%Si $\tfrac{1}{n}\sum_{i = 1}^ng(X_i) \notin m(\Theta)$, on peut modifier $\widehat \vartheta_n$ de la manière suivante : on note $x \leadsto P_\Theta[x]$ la fonction qui réalise le minimum\footnote{Ce minimum n'est pas nécessairement unique. Mais dans la plupart des exemples, $m(\Theta)$ est un intervalle et le problème ne se pose pas.} de distance entre $x$ et l'adhérence de $\Theta$. Alors
%\begin{equation} \label{est moment proj}
%\widetilde \vartheta_n = P_\Theta\big[ m^{-1}\big(\tfrac{1}{n}\sum_{i = 1}^ng(X_i) \big)\big]
%\end{equation}
%est un autre estimateur de $\vartheta$ qui vérifie $|\widetilde \vartheta_n - \vartheta| \leq |\widehat \vartheta_n-\vartheta|$, $\PP_\vartheta$-presque-sûrement.
%}
%\end{remarque}
\begin{definition}
On appelle estimateur par méthode des moments \index{moment, estimateur}tout estimateur de la forme \eqref{est substitution} ou \eqref{est moment proj}.
\end{definition}
\begin{remarque}
\emph{
Dans la plupart des exemples, on choisit $g$ de la forme $g(x) = x^k$ avec $k \geq 1$, d'où la terminologie. Le choix $g$ est arbitraire pour le statisticien : il y a donc tout un ensemble de possibilités pour construire un estimateur par méthode des moments, mais sous la contrainte que l'application $\vartheta \leadsto m(\vartheta)$ soit régulière et inversible.
%, ce qui n'est pas toujours facile à obtenir.
% Nous verrons au Chapitre \ref{} des critères de sélection pour $g$.
}
\end{remarque}
Sous des hypothèses de régularité sur $m$ et d'intégrabilité sur $g$, on a le comportement asymptotique de $\widehat \vartheta$ suivant.
\begin{proposition} \label{comp asymptotique est moment}
Si $\E_\vartheta\big[|g(X)|\big]<+\infty$ et si $m^{-1}$ est continue, on a
$$\widehat \vartheta_n \stackrel{\mathrm{p.s.}}{\rightarrow}\vartheta.$$
%sous $\PP_\vartheta$.
De plus, si pour tout $\vartheta \in \Theta$, $\E_\vartheta\big[g(X)^2\big]<+\infty$  et si la fonction $m$ est dérivable, alors
\begin{equation} \label{conv loi est moment}
\sqrt{n}\big(\widehat \vartheta_n - \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\left(0,\frac{1}{m'(\vartheta)^2}\var_\vartheta\big[g(X_1)\big]\right)
\end{equation}
%en loi sous $\PP_\vartheta^n$.
\end{proposition}
%\begin{remarque}
\begin{proof}
%La première partie de la proposition est la loi forte des grands nombres : $\tfrac{1}{n}\sum_{i = 1}^ng(X_i)$ converge vers $\E_\vartheta\big[g(X_1)\big]$ presque-sûrement. L'inverse $m^{-1}$ de $m$ est continue, donc on a aussi
%$$\widehat \vartheta_n = m^{-1}\left(\frac{1}{n}\sum_{i = 1}^ng(X_i)\right) \rightarrow m^{-1}\big(\E_\vartheta\big[g(X_1)\big]\big) = \vartheta$$
%presque-sûrement. La seconde partie de la proposition est une application de la Proposition \ref{methode delta} (\og méthode delta \fg{}).
On applique simplement les Propositions \ref{convergence substitution} et \ref{vitesse substitution 1d} du Chapitre \ref{echantillonnage} à la fonctionnelle régulière $T(F_\vartheta)$.
\end{proof}
%\emph{
%La proposition \ref{comp asymptotique est moment} reste vraie si l'on remplace $\widehat \vartheta_n$ par $\widetilde \vartheta_n$, voir Exercice \ref{correction estimateur aux bords}.
%}
%\end{remarque}
\begin{exemple}[Loi exponentielle]
\emph{
On considère l'expérience ${\mathcal E}^n$ engendrée par l'observation d'un $n$-échantillon de variables exponentielles de paramètre $\vartheta >0$. Les fonctions les plus simples pour construire un estimateur sont par exemple $g(x) = x$ ou $\widetilde g(x)=x^2$. Ceci fournit deux estimateurs. On part de l'équation
$$m(\vartheta) = \E_\vartheta\big[g(X)\big] = \int_0^{+\infty}x\vartheta \exp(-\vartheta x)dx = \frac{1}{\vartheta}$$
ou bien
$$\widetilde m(\vartheta) = \E_\vartheta\big[\widetilde g(X)\big] = \int_0^{+\infty}x^2\vartheta \exp(-\vartheta x)dx = \frac{2}{\vartheta^2},$$
et on résout
$$m(\vartheta) = \tfrac{1}{n}\sum_{i = 1}^n X_i\;\;\;\text{ ou }\;\;\;\widetilde m(\vartheta) = \tfrac{1}{n}\sum_{i = 1}^n X_i^2.$$ On obtient deux estimateurs par substitution :
$$\widehat \vartheta_{n,1} = \frac{1}{\frac{1}{n}\sum_{i = 1}^nX_i},\;\;\;\;\text{et}\;\;\;\;\widehat \vartheta_{n,2}= \left(\frac{2}{\tfrac{1}{n}\sum_{i = 1}^nX_i^2}\right)^{1/2}.$$
La Proposition \ref{comp asymptotique est moment} s'applique, et, comme
$$\text{Var}_\vartheta\big[g(X)\big] = \frac{1}{\vartheta^2}\;\;\;\;\text{et}\;\;\;\;\text{Var}_\vartheta\big[\widetilde g(X)\big] = \frac{20}{\vartheta^4}$$
et
$$m'(\vartheta) =- \frac{1}{\vartheta^2}\;\;\;\;\text{et}\;\;\;\;\widetilde m'(\vartheta) = -\frac{4}{\vartheta^3}$$
on obtient la convergence en loi \eqref{conv loi est moment} de l'erreur renormalisée $\sqrt{n}(\widehat \vartheta_{n,i}- \vartheta)$ pour $i=1,2$ vers une gaussienne centrée de variance
$$v(\vartheta) = m'(\vartheta)^{-2}\text{Var}_\vartheta\big[g(X)\big] = \vartheta^2$$
et
$$\widetilde v(\vartheta) = \widetilde m'(\vartheta)^{-2}\text{Var}_\vartheta\big[\widetilde g(X)\big] = \frac{20}{\vartheta^4}\frac{\vartheta^6}{16} = \frac{5}{4}\vartheta^2$$
respectivement. L'erreur de l'estimateur $\widehat \vartheta_{n,1}$ est \og moins dispersée\fg\; que celle de $\widehat \vartheta_{n,2}$ et de ce point de vue, $\widehat \vartheta_{n,1}$ semble \og préférable\fg\; à $\widehat \vartheta_{n,2}$. Nous étudierons plus systématiquement la comparaison d'estimateurs au Chapitre \ref{theorie asymptotique}.
}
\end{exemple}
\begin{exemple}[Loi de Cauchy] \label{exemple modele de cauchy}
\emph{
On considère la famille de translation (voir \ref{familles parametrees}) associée à la loi de Cauchy sur $\R$.
%La famille de lois $\{\PP_\vartheta, \vartheta \in \Theta = \R\}$ est telle que
La loi $\PP_\vartheta$ a une densité par rapport à la mesure de Lebesgue sur $\R$
$$f(\vartheta, x) = \frac{1}{\pi\big(1+(x-\vartheta)^2\big)},\;\;x\in \R.$$
La densité $f(\vartheta,\cdot)$ n'a pas de moment d'ordre $k$ pour $k \geq 1$, et le choix $g(x)=x^k$ avec $k$ entier ne s'applique pas ici. Prenons $g(x) = \text{signe}(x)$, avec
$$\text{signe}(x) =
\left\{
\begin{array}{rll}
-1 & \text{si} & x \leq 0 \\
1 & \text{si} & x >0.
\end{array}
\right.$$
On a
$$\E_\vartheta\big[g(X_1)\big] = \int_{\R}\text{signe}(x)f(\vartheta,x)dx = 1-2F(-\vartheta),$$
où
$$F(t) = \frac{1}{\pi}\int_{-\infty}^t \frac{dt}{1+t^2} = \frac{1}{\pi}\text{Arctg}(t)+\frac{1}{2}.$$
On résout
$$\frac{2}{\pi}\text{Arctg}(\vartheta) = \frac{1}{n}\sum_{i = 1}^n \text{signe}(X_i),$$
d'où l'estimateur
$$\widehat \vartheta_{n} = \text{tg}\left(\frac{\pi}{2n}\sum_{i = 1}^n \text{signe}(X_i)\right).$$
Les propriétés asymptotiques de $\widehat \vartheta_{n}$ vers $\vartheta$ s'obtiennent en appliquant la Proposition \ref{comp asymptotique est moment}.
% voir Exercice \ref{fin cauchy}
%{\tt check continuite}.
}
\end{exemple}
%\begin{exemple}
%\emph{
%%{\tt modèle discret}
%\begin{center}
%{\tt INSERT HERE SUPPL. 6}
%\end{center}
%}
%\end{exemple}
\subsection{Le cas multidimensionnel}
Lorsque $\Theta \subset \R^d$ avec $d \geq 1$, il n'est plus possible en général d'identifier $\vartheta$ via une seule fonction $g$ via la représentation \eqref{fonctionnelle lineaire}. On étend la méthode précédente en identifiant $\vartheta$ à l'aide de $d$ applications $g_\ell:\R \rightarrow \R$, pour $\ell=1,\ldots,d$
$$x \leadsto \big(g_1(x),\ldots, g_d(x)\big),\;\;x\in \R,$$
de sorte que le système d'équations
\begin{equation} \label{systeme d equations moment}
m_\ell(\vartheta) = \E_\vartheta\big[g_\ell(X)\big] = \int_{\R}g_\ell(x)dF_\vartheta(x),\;\;\ell=1,\ldots, d
\end{equation}
admette une solution unique, lorsque cela est possible. Un estimateur par méthode des moments est alors tout estimateur $\widehat \vartheta_n$ satisfaisant
\begin{equation} \label{def est moment multidim}
m_\ell(\widehat \vartheta_n) = \frac{1}{n}\sum_{i = 1}^d g_\ell(X_i),\;\;\ell=1,\ldots, d.
\end{equation}
\begin{definition}
On appelle estimateur par substitution ou par méthode des moments associé à la fonction $\boldsymbol{g}$ tout estimateur $\widehat \vartheta_n$ solution de
\eqref{def est moment multidim}.
\end{definition}
On note
$$\boldsymbol{m}(\vartheta)=\E_\vartheta\big[\boldsymbol{g}(X)\big] = \big(\E_\vartheta\big[g_1(X)],\ldots, \E_\vartheta \big[g_d(X)\big]\big)$$
l'application de $\R^d\rightarrow \R^d$ définie composante par composante par \eqref{systeme d equations moment}. On utilise donc la représentation
$$\vartheta = \boldsymbol{m}^{-1}\left(m_1(\vartheta),\ldots, m_d(\vartheta)\right)$$
pour estimer $\vartheta$ par
$$\est = \boldsymbol{m}^{-1}\left(\frac{1}{n}\sum_{i = 1}^ng_1(X_i),\ldots, \frac{1}{n}\sum_{i = 1}^n g_d(X_i)\right)$$
\begin{proposition} \label{comp asympt moment multidim}
Si $\boldsymbol{m}$ est continue, inversible et d'inverse continue, alors l'estimateur par méthode des moments est bien défini et on a
$$\est \stackrel{\mathrm{p.s.}}{\rightarrow} \vartheta$$
sous $\PP_\vartheta$. De plus, si $\boldsymbol{m}^{-1}$ est différentiable et si $\E_\vartheta\big[g_\ell(X)^2\big]<+\infty$, on a la convergence
$$\sqrt{n}\big(\est-\vartheta\big) \stackrel{d}{\rightarrow} \mathcal{N}\big(0,V(\vartheta)\big),$$
où
\begin{equation} \label{formule variance asymptotique}
V(\vartheta) = J_{\boldsymbol{m}^{-1}}\Sigma_{\boldsymbol{m}}(\vartheta) \,J_{\boldsymbol{m}^{-1}}^T,
\end{equation}
avec $\Sigma_{\boldsymbol{m}}(\vartheta)$ la matrice de variance-covariance du vecteur $\big(g_1(X),\ldots, g_d(X)\big)^T$ définie par
\begin{equation} \label{def mat cov}
\big(\Sigma_{\boldsymbol{m}}(\vartheta)\big)_{\ell,\ell'}=
\E_\vartheta\big[g_\ell(X)g_{\ell'}(X)\big] - \E_\vartheta\big[g_\ell(X)\E_\vartheta\big[g'_\ell(X)\big]
\end{equation}
et $J_{\boldsymbol{m}^{-1}}$ désigne la matrice de la différentielle de $\boldsymbol{m}^{-1}$.
\end{proposition}
\begin{proof}
Par la loi des grands nombres, on a, composante par composante, la convergence
\begin{align*}
 \left(\frac{1}{n}\sum_{i = 1}^ng_1(X_i),\ldots, \frac{1}{n}\sum_{i = 1}^ng_d^{-1}(X_i)\right) & \stackrel{\mathrm{p.s.}}{\longrightarrow}\Big(\E_\vartheta\big[g_1(X)\big],\ldots, \E_\vartheta\big[g_d(X)\big]\Big) \\
& =\boldsymbol{m}(\vartheta)
\end{align*}
sous $\PP_\vartheta$. Par continuité de $\boldsymbol{m}^{-1}$, on en déduit
\begin{align*}
\est &  = {\boldsymbol m}^{-1}\left(\frac{1}{n}\sum_{i = 1}^ng_1(X_i),\ldots, \frac{1}{n}\sum_{i = 1}^ng_d^{-1}(X_i)\right) \\
& \stackrel{\mathrm{p.s.}}{\longrightarrow} {\boldsymbol{m}^{-1}}\Big(\E_\vartheta\big[g_1(X)\big],\ldots, \E_\vartheta\big[g_d(X)\big]\Big) \\
& =\boldsymbol{m}^{-1}\big(\boldsymbol{m}(\vartheta)\big) \\
& = \vartheta.
\end{align*}
 La deuxième partie de la proposition est  la méthode \og delta \fg{} multidimensionnelle. On applique d'abord le Théorème \ref{TCL vectoriel} (théorème central limite vectoriel): la suite de vecteurs
$$\left(\frac{1}{n}\sum_{i = 1}^n g_1(X_i),\ldots, \frac{1}{n}\sum_{i =1}^n g_d(X_i)\right)^T$$
est asymptotiquement gaussienne, et
$$\sqrt{n}\Big(\big(\tfrac{1}{n}\sum_{i = 1}^n g_1(X_i),\ldots, \tfrac{1}{n}\sum_{i =1}^n g_d(X_i)\big)^T-\boldsymbol{m}(\vartheta)\Big)\stackrel{d}{\rightarrow} {\mathcal N}\big(0,\Sigma_m(\vartheta)\big),$$
sous $\PP_\vartheta$, de matrice de variance-covariance $\Sigma_m(\vartheta)$ donnée par \eqref{def mat cov}. Puis, on applique la Proposition \ref{methode delta multidimensionnelle} (méthode delta) avec $\boldsymbol{g}=\boldsymbol{m}^{-1}$.
\end{proof}
\begin{remarque}
\emph{
Ce résultat est très proche du Corollaire \ref{substitution multidim} du Chapitre \ref{echantillonnage} (la fonction $\boldsymbol{m}^{-1}$ jouant le rôle de
$\boldsymbol{g}$ dans le Corollaire \ref{substitution multidim}).
}
\end{remarque}
\begin{exemple}
\emph{
Si $\vartheta = (\mu,\sigma^2) \in \Theta = \R \times \R_+\setminus\{0\}$ et $\PP_\vartheta$ est la loi ${\mathcal N}(\mu,\sigma^2)$, alors $d=2$ et les fonctions $g_1(x)=x$ et $g_2(x)=x^2$ fournissent le système d'équations
$$\mu = \Xbar,\;\;\;\sigma^2+\mu^2 = \frac{1}{n}\sum_{i=1}^n X_i^2,$$
dont la solution est
\begin{equation} \label{sol rep}
\est = \big(\widehat \mu_n, \widehat \sigma^2_n \big)^T =\big(\Xbar, \tfrac{1}{n}\sum_{i = 1}^nX_i^2-\Xbar^2\big)^T.
\end{equation}
On retrouve l'estimation de fonctionnelles du Chapitre \ref{echantillonnage}. L'estimateur $\widehat \vartheta_n$ est asymptotiquement normal.  On peut calculer sa variance asymptotique en appliquant la formule \eqref{formule variance asymptotique} de la Proposition \ref{comp asympt moment multidim} ci-dessus ou bien en partant directement de la représentation \eqref{sol rep} et en appliquant alors le Corollaire \ref{substitution multidim} du Chapitre \ref{echantillonnage}. En notant $\mu_i = \E\big[X^i\big]$, on obtient finalement
$$
V(\vartheta) = \left(
\begin{array}{cc}
\mu_2-\mu_1^2 & -3 \mu_1\mu_2+2\mu_1^3+\mu_3 \\
-3 \mu_1\mu_2+2\mu_1^3+\mu_3 & 2\mu_1(4\mu_1\mu_2-2\mu_1^3-2\mu_3)+\mu_4-\mu_2^2
\end{array}
\right).
$$
En particulier, dans le cas d'une distribution centrée, lorsque $\mu_1=0$, on retrouve la forme particulièrement simple
$$
V(\vartheta) = \left(
\begin{array}{cc}
\mu_2& \mu_3 \\
\mu_3 & \mu_4-\mu_2^2
\end{array}
\right).
$$
}
\end{exemple}
\section{Moments généralisés. $Z$- et $M$-estimation} \label{M estimation densite}
\index{GMM, estimateur}
\index{moments généralisés, estimateur des}
\index{$Z$-estimateur}
\subsubsection{Insuffisance de la méthode des moments}
La méthode des moments repose sur l'existence d'une fonction $m$ (réelle ou vectorielle) inversible qui n'est pas toujours facile à déterminer ou à mettre en œuvre numériquement. On présente une extension naturelle qui fournit une nouvelle classe d'estimateurs  que l'on va pouvoir étudier de manière systématique.

En particulier, sous des hypothèses de régularité suffisantes, on pourra construire une méthode \og automatique \fg{} de sélection d'un estimateur asymptotiquement optimal, dans un sens que nous discuterons au Chapitre \ref{theorie asymptotique}.
\subsection{$Z$-estimateurs}
\subsubsection{Construction en dimension 1}
Lorsque le paramètre $\vartheta$ est de dimension 1, c'est-à-dire $\Theta \subset \R$, la méthode des moments de la section précédente repose sur de bonnes propriétés -- régularité, inversibilité -- de l'application
\begin{equation} \label{eq base moment}
m(\vartheta) = m_g(\vartheta)= \int_{\R}g(x)\PP_\vartheta(dx)
\end{equation}
pour un certain choix de fonction
%\footnote{en remplaçant \eqref{eq base moment} par un système d'équations basé sur une fonction vectorielle $g = (g_1,\ldots g_d)$ dans le cas multidimenseionnel.}
$g$. Autrement dit, on a, pour tout $\vartheta \in \Theta$
\begin{equation} \label{eq substitution}
\int_{\R} \big(m_g(\vartheta)-g(x)\big)\PP_\vartheta(dx) = 0,
\end{equation}
où $g$ est à choisir. Considérons de manière générale pour $\Theta \subset \R^d$ et $d \geq 1$ une application
$$\phi:\Theta \times \R \rightarrow \R$$
telle que pour tout $\vartheta \in \Theta$
\begin{equation} \label{moment generalise}
\int_{\R} \phi(\vartheta,x)\PP_\vartheta(dx) = 0
\end{equation}
dont \eqref{eq substitution} est un cas particulier avec $\phi(\vartheta,x) = m_g(\vartheta)-g(x)$. Pour construire un estimateur, on peut  se donner une application $\phi$ satisfaisant l'équation \eqref{moment generalise} pour tout $\vartheta \in \Theta$ et résoudre sa version empirique, c'est-à-dire chercher un estimateur $\widehat \vartheta_n$ satisfaisant
\begin{equation} \label{moment generalise empirique}
\frac{1}{n}\sum_{i = 1}^n \phi(\widehat \vartheta_n,X_i) = 0.
\end{equation}

\begin{definition}[$Z$-Estimateur ou estimateur GMM\footnote{$Z$ pour zéro et GMM pour Generalized Method of Moments.}] Etant donnée une application $\phi:\Theta \times \R \rightarrow \R$ satisfaisant \eqref{moment generalise}, on appelle $Z$-estimateur associé à $\phi$ tout estimateur $\widehat \vartheta_n$ satisfaisant \eqref{moment generalise empirique}.
\end{definition}
%{\tt remarque existence unicite}
%{\tt version multidimensionelle}
\subsubsection{Le cas multidimensionnel}
L'extension au cas multi-dimensionnel $\Theta \subset \R^d$, avec $d \geq 1$ est immédiate. La fonction $\phi$ est remplacée par une application
$$\Phi  = (\phi_1,\ldots, \phi_d): \Theta \times \R \rightarrow \R^d$$
où chaque composante $\phi_\ell:\Theta \times \R \rightarrow \R$ joue le même rôle qu'en dimension 1. Pour que la méthode ait un sens, il faut que,
comme pour l'équation \eqref{moment generalise}, le paramètre inconnu $\vartheta$ soit  solution du  système d'équations
\begin{equation} \label{moment generalise multidim}
\int_{\R} \phi_\ell(\vartheta, x)\PP_\vartheta(dx)=0,\;\;\;\ell = 1,\ldots, d
\end{equation}
et construire un $Z$-estimateur revient à résoudre une version empirique de \eqref{moment generalise multidim}.
\begin{definition}[$Z$-estimateur, cas multidimensionnel]
Etant donné une application $\Phi:\Theta \times \R \rightarrow \R^d$, on appelle $Z$-estimateur associé à $\Phi$ tout estimateur $\est$ satisfaisant
$$\frac{1}{n}\sum_{i=1}^n \Phi(\est,X_i)=0,\;\;\;\ell=1,\ldots, d.$$
\end{definition}
%\subsubsection{Exemples}
%\begin{center}
%{\tt INSERT HERE SUPPL. 9}
%\end{center}
%\subsubsection{Converence et propriétés asymptotiques}
\subsection{$M$-estimateurs} \label{def M estimateur}
\index{$M$-estimateur}
\index{contraste, estimateur de}
%\subsubsection{Construction}
Soit $\psi: \Theta \times \R \rightarrow \R$ une application telle que, pour tout $\vartheta \in \Theta \subset \R^d$, avec $d\geq 1$, la fonction
\begin{equation} \label{eq contraste}
a \leadsto \E_\vartheta\big[\psi(a,X)\big] = \int_{\R}\psi(a,x)\PP_\vartheta(dx)
\end{equation}
admette un maximum en $a=\vartheta$. Une procédure naturelle pour estimer $\vartheta$ consiste à maximiser une version empirique de \eqref{eq contraste}.
\begin{definition}
On appelle $M$-estimateur\footnote{Il y a peut-être un problème de mesurabilité à régler pour garantir que l'on obtient effectivement un estimateur. Nous ignorons ce problème éventuel.} associé au contraste $\psi$ tout estimateur $\widehat \vartheta_n$ qui satisfait
$$\frac{1}{n}\sum_{i = 1}^n \psi(\widehat \vartheta_n, X_i) = \max_{a \in \Theta} \frac{1}{n}\sum_{i = 1}^n \psi(a, X_i).$$
\end{definition}
Si le paramètre $\vartheta$ est de dimension $d=1$ et si l'on suppose, pour tout $x\in \R$ que la fonction $a\leadsto \psi(a,x)$ est régulière, en posant
$$\phi(a,x)=\partial_1\psi(a,x),$$
on a
$$\sum_{i = 1}^n \partial_1\psi(\widehat \vartheta_n,X_i) = \sum_{i = 1}^n\phi(\widehat \vartheta_n,X_i)=0$$
ce qui permet -- dans ce cas -- d'interpréter un $M$-estimateur comme un $Z$-estimateur. Cette interprétation s'étend immédiatement au cas multidimensionnel.
%\subsubsection{Exemples}
\begin{exemple}
\emph{
On considère les lois $\{\PP_\vartheta, \vartheta \in \Theta = \R\}$ qui est la famille de translations $\big\{F(\cdot-\vartheta),\,\vartheta \in \R\big\}$ associée à une distribution donnée $F$ centrée et ayant un moment d'ordre 1. On a
$$\vartheta = \int_{\R} x\PP_\vartheta(dx) = \int_{\R}(x+\vartheta)dF(x).$$
Alors $m(\vartheta) = \E_\vartheta\big[X\big]$ minimise la fonction
$$a \leadsto \int_{\R}(x-a)^2\PP_\vartheta(dx) = \E_\vartheta\big[(X-a)^2\big]$$
d'après la Proposition \ref{caracterisation moyenne}. En prenant $\psi(a,x) = -(x-a)^2$, le $M$-estimateur associé à $\psi$ satisfait
$$\sum_{i = 1}^n \psi(\est,X_i) = \max_{a \in \R}\sum_{i = 1}^n\psi(a,X_i)$$
ou encore
$$\sum_{i = 1}^n \phi(\widehat \vartheta_n,X_i) = 0$$
avec $\phi(a,x)=\partial_1\psi(a,x)=-2(x-a)$, ce qui implique $\sum_{i = 1}^n (X_i-\widehat \vartheta_n) = 0$, d'où l'estimateur $\widehat \vartheta_n = \overline{X}_n = \tfrac{1}{n}\sum_{i = 1}^n X_i$. Dans cet exemple simple, tous les points de vue coïncident.
}
\end{exemple}
\subsection{Convergence des $Z$- et des $M$-estimateurs} \label{proprietes de convergence}
Dans cette section, nous donnons des critères simples sur la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ et la fonction $\phi$ -- pour les $Z$-estimateurs -- ou $\psi$ -- pour les $M$-estimateurs -- qui garantissent la convergence de l'estimateur correspondant.
%ainsi qu'une vitesse de convergence.
Nos conditions sont classiques et sous-optimales. La recherche de conditions minimales est un problème délicat qui dépasse le cadre de ce cours. On pourra consulter van der Vaart \cite{VDW} pour une discussion accessible sur le sujet. Pour des raisons techniques, nous commençons par traiter la convergence des $M$-estimateurs, dont nous déduirons celle des $Z$-estimateurs.
% et Ibragimov et Hasminskii pour un traitement

\subsubsection{Convergence des $M$-estimateurs} \label{convergence des m estimateurs}
Pour une fonction de contraste $\psi :\Theta \times \R \rightarrow \R$ donnée, on définit
$$M_n(a) = \frac{1}{n}\sum_{i = 1}^n \psi(a,X_i),\;\;a \in \Theta$$
et, pour $\vartheta \in \Theta$,
$$M(a, \vartheta) =\E_\vartheta\big[\psi(a,X)\big].$$
\begin{proposition}[Convergence des $M$-estimateurs] \label{convergence des m estimateurs}
On suppose $\Theta \subset \R^d$, avec $d \geq 1$, que le $M$-estimateur $\est$ associé à la fonction $\psi$ est bien défini, et qu'on \vspace{1mm}a
\begin{itemize}
\item[(i)] $\sup_{a \in \Theta}\big|M_n(a)-M(a,\vartheta)\big| \stackrel{\PP_\vartheta}{\rightarrow} 0,\vspace{2mm}$
\item[(ii)] $\forall \varepsilon  >0,\;\;\sup_{|a-\vartheta|\geq \varepsilon}M(a,\vartheta) < M(\vartheta, \vartheta),\vspace{1mm}$ (condition de maximum)
\item[(iii)] $M_n(\est) \geq M_n(\vartheta)-\varepsilon_n,$
où  $\varepsilon_n \stackrel{\PP_\vartheta}{\longrightarrow} 0\vspace{3mm}$.
\end{itemize}
Alors le $M$-estimateur $\est$ est convergent (ou consistant) :
$$\est \stackrel{\PP_\vartheta}{\longrightarrow} \vartheta.$$
\end{proposition}
\begin{proof}
On écrit
%\begin{align*}
$$M(\vartheta,\vartheta)-M(\est,\vartheta)  = T_{n,1}+T_{n,2}+T_{n,3},$$
avec
\begin{align*}
T_{n,1} &= M(\vartheta,\vartheta)-M_n(\vartheta),\\
T_{n,2} & = M_n(\vartheta)-M_n(\est),\\
T_{n,3} & = M_n(\est) - M(\est,\vartheta).
\end{align*}
Les termes $T_{n,1}$ et $T_{n,3}$ tendent vers $0$ en probabilité sous $\PP_\vartheta$ grâce à l'hypothèse (i).
% Le terme $T_{n,2}$ vérifie
%$T_{n,2}\leq \varepsilon_n \stackrel{\PP_\vartheta}{\rightarrow} 0$ grâce à l'hypothèse (iii).

Soit $\varepsilon >0$. D'après la condition (ii), il existe $\eta >0$ tel que $M(a,\vartheta) \leq M(\vartheta,\vartheta)-\eta$ dès lors que $|a-\vartheta| \geq \varepsilon$. On a donc l'inclusion
\begin{equation} \label{inclusion convergence}
\big\{|\est-\vartheta| \geq \varepsilon\big\} \subset \big\{M(\est,\vartheta) \leq  M(\vartheta,\vartheta)-\eta\big\}
\end{equation}
en prenant $a=\est$. Il vient
\begin{align*}
\PP_\vartheta\big[|\est-\vartheta| \geq \varepsilon\big]  & \leq \PP_\vartheta\big[M(\est,\vartheta) < M(\vartheta,\vartheta)-\eta\big] \\
& = \PP_\vartheta\big[M(\vartheta,\vartheta)-M(\est,\vartheta) > \eta\big] \\
& \leq \PP_\vartheta\big[T_{n,1}+\varepsilon_n+ T_{n,3}\geq \eta\big]\\
& \stackrel{\PP_\vartheta}{\longrightarrow} 0
\end{align*}
où l'on utilise successivement l'inclusion \eqref{inclusion convergence}, l'hypothèse (iii) et le fait que chacun des termes $T_{n,1}$, $\varepsilon_n$ et $T_{n,3}$ tend vers $0$ en probabilité sous $\PP_\vartheta$.
\end{proof}
\subsubsection{Convergence des $Z$-estimateurs}
On suppose d'abord $\Theta \subset \R$. Pour une fonction $\phi$ donnée, on définit
$$Z_n(a) = \frac{1}{n}\sum_{i = 1}^n \phi(a,X_i),\;\;a \in \Theta$$
et, pour $\vartheta \in \Theta$,
$$Z(a, \vartheta) =\E_\vartheta\big[\phi(a,X)\big]\;\;a \in \Theta.$$
\begin{proposition}[Convergence des $Z$-estimateurs] \label{convergence des z estimateurs}
On suppose que le $Z$-estimateur $\est$ associé à la fonction $\phi$ est bien défini, et qu'on \vspace{1mm}a
\begin{itemize}
\item[(i)] $\sup_{a \in \Theta}\big|Z_n(a)-Z(a,\vartheta)\big| \stackrel{\PP_\vartheta}{\rightarrow} 0,\vspace{1mm}$
\item[(ii)] $\forall \varepsilon  >0,\;\;\inf_{|a-\vartheta|\geq \varepsilon}|Z(a,\vartheta)| >0 =  |Z(\vartheta, \vartheta)|,\vspace{1mm}$
\item[(iii)] $Z_n(\est) \stackrel{\PP_\vartheta}{\rightarrow} \vspace{3mm}0$.
%où $\varepsilon_n$ est une suite de variables aléatoires telle que $\varepsilon_n \stackrel{\PP_\vartheta}{\longrightarrow} 0$.
\end{itemize}
Alors le $Z$-estimateur $\est$ est convergent (ou consistant) :
$$\est \stackrel{\PP_\vartheta}{\longrightarrow} \vartheta.$$
\end{proposition}
\begin{proof} ll suffit de reprendre point par point la preuve de la Proposition \ref{convergence des m estimateurs} en remplaçant $M_n(a)$ par $-|Z_n(a)|$ et $M(a,\vartheta)$ par $Z(a,\vartheta)$.
\end{proof}
Le cas multidimensionnel où $\Theta \subset \R^d$ avec $d \geq 1$ se traite de la même manière, en remplaçant la fonction $\phi$ par une fonction vectorielle $\Phi = (\phi_1,\ldots, \phi_d)$ et les valeurs absolues dans les conditions (i)--(ii)--(iii) par la norme euclidienne sur $\R^d$.
\subsection{Loi limite des $Z$- et $M$-estimateurs}
Nous précisons les résultats de la section précédente, en cherchant une vitesse de convergence $\alpha_n\rightarrow \infty$ de sorte que l'erreur normalisée
$$\alpha_n(\est-\vartheta)$$
converge vers une limite non-dégénérée. Nous donnons des hypothèses suffisantes  sur les fonctions $\phi$ -- pour les $Z$-estimateurs -- et $\psi$ -- pour les $M$-estimateurs -- de sorte qu'on ait une convergence en loi vers une gaussienne avec la normalisation $\alpha_n = \sqrt{n}$. Ces conditions ne sont pas optimales (voir van deer Vaart \cite{VDW}). A l'inverse de la section précédente, nous partons d'un résultat sur les $Z$-estimateurs pour en déduire un résultat sur les $M$-estimateurs.
\subsubsection{Loi limite des $Z$-estimateurs}
Nous donnons les résultats dans le cas  $\Theta \subset \R$, lorsque le paramètre $\vartheta$ est de dimension $d=1$, pour simplifier\footnote{Le passage au cas multidimensionnel ne présente essentiellement qu'une difficulté d'écriture.}. Etant données, d'une part une fonction $\phi:\Theta \times \R \rightarrow \R$ définissant un $Z$-estimateur, et d'autre part la famille $\big\{\PP_\vartheta,\,\vartheta\in \Theta\big\}$, on fait le jeu d'hypothèses suivant :
\begin{hypothese}[Hypothèse loi limite $Z$-estimateurs] \label{hyp conv z est} On \vspace{1mm}a
\begin{itemize}
%\item[(i)] La famille $\big\{\PP_\vartheta,\,\vartheta\in \Theta\big\}$ est dominée par une mesure $\sigma$-finie $\mu$ sur\vspace{1mm}$\;\R$.
\item[(i)] Pour tout point $\vartheta \in \Theta$, il existe un voisinage ouvert ${\mathcal V}(\vartheta)$ tel que, pour tout $a \in {\mathcal V}(\vartheta)$
$$\big|\partial^2_a \phi(a, x)\big| \leq g(x),\;\;\text{où}\;\;\E_\vartheta\big[g(X)\big]<+\infty.$$
\item[(ii)] Pour tout $\vartheta \in \Theta$, on a
$$\E_\vartheta\big[\phi(\vartheta,X)\big] = 0,\;\;\;\;\E_\vartheta\big[\phi(\vartheta,X)^2\big]<+\infty,\;\;\;\;\E_\vartheta\big[\partial_\vartheta \phi(\vartheta,X)\big]\neq 0.$$
\end{itemize}
\end{hypothese}
\begin{remarque}
\emph{Le jeu d'hypothèse \ref{hyp conv z est} peut paraître un peu \og repoussant \fg{} à première vue. Nous verrons que la méthode de preuve est très simple, et que ces hypothèses apparaissent naturellement lors du contrôle des différents termes d'un dévelop\-pement asymptotique\footnote{On peut \og presque \fg{} les oublier et ne retenir que la méthode de preuve où elles réapparaîtront de façon évidente.}.
}
\end{remarque}
\begin{remarque}
\emph{
Le jeu d'hypothèse \ref{hyp conv z est} est local : comme le suggère l'hypothèse (i), on doit pouvoir contrôler le comportement de la famille $\big\{\PP_\vartheta,\,\vartheta\in \Theta\big\}$ dans un voisinage de $\vartheta$, pour tout $\vartheta$. Ceci exclut les paramètres de la frontière de $\Theta$ dans le cas où $\Theta$ n'est pas un ouvert. En restreignant l'espace des paramètres (donc en considérant une expérience statistique \og plus petite \fg{}), on pourra souvent se ramener au jeu d'hypothèses \ref{hyp conv z est} à condition que $\Theta$ soit d'intérieur non vide au départ.
}
\end{remarque}
Sous ce jeu d'hypothèses, on a le comportement asymptotique suivant pour les $Z$-estimateurs
\begin{proposition}[Loi limite des $Z$-estimateurs] \label{loi limite z est}
Si la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ et la fonction $\phi$ vérifient l'Hypothèse \ref{hyp conv z est}, alors, si $\est$ est un $Z$-estimateur associé à $\phi$ tel que $\est \stackrel{\PP_\vartheta}{\rightarrow} \vartheta$, on a
$$\sqrt{n}\big(\est-\vartheta\big) \stackrel{d}{\rightarrow} {\mathcal N}\big(0,v_\phi(\vartheta)\big)$$
en loi sous $\PP_\vartheta$, où
$$v_\phi(\vartheta) = \frac{\E_\vartheta\big[\phi(\vartheta,X)^2\big]}{\Big(\E_\vartheta\big[\partial_\vartheta\phi(\vartheta,X)\big]\Big)^2}.$$
\end{proposition}
\begin{proof}
Notons $Z_n(a) = \tfrac{1}{n}\sum_{i = 1}^n \phi(a,X_i)$, $a \in \Theta$ comme dans la preuve de la Proposition \ref{convergence des z estimateurs}, et introduisons les notations $Z'_n(a) = \partial_a Z_n(a)$, $Z''_n(a) = \partial^2_aZ_n(a)$. Ecrivons un développement de Taylor de la fonction $Z_n$ au voisinage de $\vartheta$. On a
$$0 = Z_n(\est) = Z_n(\vartheta)+(\est-\vartheta)Z'_n(\vartheta)+\frac{1}{2}(\est-\vartheta)^2Z_n''(\widetilde \vartheta_n),$$
où $\widetilde \vartheta_n$ est un point (aléatoire) entre $\est$ et $\vartheta$, ce que l'on réécrit sous la forme
\begin{equation} \label{ecriture}
\sqrt{n}\big(\est-\vartheta\big) = \frac{ -\sqrt{n}Z_n(\vartheta)}{Z'_n(\vartheta)+\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)}.
\end{equation}
%avec
%$$\varepsilon_n = -\frac{1}{2}\frac{\sqrt{n}(\est-\vartheta)^2Z_n''(\widetilde \vartheta_n)}{Z'_n(\vartheta)},$$
sur l'événement $\{Z'_n(\vartheta) +\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)\neq 0\}$.

Sous $\PP_\vartheta$, les variables $\phi(\vartheta,X_i)$ sont indépendantes, identiquement distribuées, de moyenne nulle et de variance finie $\E_\vartheta\big[\phi(\vartheta,X)^2\big]$ d'après l'Hypothèse \ref{hyp conv z est} (ii). En appliquant le théorème central-limite
$$-\sqrt{n}Z_n(\vartheta) \stackrel{d}{\rightarrow} {\mathcal N}\big(0, \E_\vartheta\big[\phi(\vartheta,X)^2\big]\big)$$
en loi sous $\PP_\vartheta$.

Considérons maintenant le dénominateur. On a $Z'_n(\vartheta) = \tfrac{1}{n}\sum_{i = 1}^n \partial_\vartheta \phi(\vartheta,X_i)$ et les variables $\partial_\vartheta \phi(\vartheta,X_i)$ sont intégrables d'après  l'Hypothèse \ref{hyp conv z est} (ii). En appliquant la loi des grands nombres, on obtient
$$Z_n'(\vartheta) \stackrel{\PP_\vartheta}{\longrightarrow} \E_\vartheta\big[\partial_\vartheta\phi(\vartheta,X)\big]\neq 0.$$
La seule réelle difficulté de la preuve de la proposition consiste à démontrer que
\begin{equation} \label{remainder}
\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)\stackrel{\PP_\vartheta}{\rightarrow}0.
\end{equation}
En effet, dans ce cas, le dénominateur dans \eqref{ecriture} tend vers $\E_\vartheta\big[\partial_\vartheta\phi(\vartheta,X)\big]\neq 0$ en $\PP_\vartheta$ probabilité, et on en déduit\footnote{Il y a une petite difficulté : on doit se placer sur l'événement $\{Z'_n(\vartheta)+\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)\neq 0\}$, mais la $\PP_\vartheta$-probabilité de cet événement tend vers 1. Nous omettons les détails.}, en appliquant la Proposition \ref{slutsky} (Slutsky) que
$$\frac{ -\sqrt{n}Z_n(\vartheta)}{Z'_n(\vartheta)+\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)} \stackrel{d}{\longrightarrow}{\mathcal N}\left(0, \frac{\E_\vartheta\big[\phi(\vartheta,X)^2\big]}{\big(\E_\vartheta\big[\partial_\vartheta\phi(\vartheta,X)\big]\big)^2}\right),$$
qui est la limite recherchée.

Il reste à montrer \eqref{remainder}. D'après l'hypothèse \ref{hyp conv z est} (ii), il existe un voisinage ${\mathcal V}(\vartheta)$ de $\vartheta$ tel que
$|\partial^2_a\phi(a,x)| \leq g(x)$ si $a \in {\mathcal V}(\vartheta)$. L'hypothèse $\est \stackrel{\PP_\vartheta}{\rightarrow} \vartheta$ implique que
$$\PP_\vartheta\big[\est \in {\mathcal V}(\vartheta)\big]\rightarrow 1.$$
Posons ${\mathcal C}_n = \{\est \in {\mathcal V}(\vartheta)\}$. On a
\begin{align*}
\E_\vartheta\Big[\big|Z''_n(\widetilde \vartheta_n)\big|1_{{\mathcal C}_n} \Big]& \leq \E_\vartheta\Big[\frac{1}{n}\sum_{i = 1}^n \big|\partial^2_\vartheta\phi(\widetilde \vartheta_n,X_i)\big|1_{{\mathcal C}_n} \Big] \\
 & \leq \E_\vartheta\Big[\frac{1}{n}\sum_{i = 1}^n g(X_i)\Big]\\
 &  = \E_\vartheta \Big[g(X)\Big]<+\infty
 \end{align*}
en appliquant l'hypothèse \ref{hyp conv z est} (i). On en déduit
$$\sup_n\E_\vartheta\big[Z''_n(\widetilde \vartheta_n)1_{{\mathcal C}_n}\big]<+\infty.$$
Ceci entraîne $(\est-\vartheta)Z''_n(\widetilde \vartheta_n)1_{{\mathcal C}_n}\stackrel{\PP_\vartheta}{\rightarrow}0$, puisque $\est \stackrel{\PP_\vartheta}{\rightarrow}\vartheta$, voir par exemple l'Exercice \ref{convproba et l1} du Chapitre \ref{chapitre 1}.
Finalement, on écrit, pour tout $\varepsilon >0$
$$
\PP_\vartheta\big[\big|\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)\big|\geq \varepsilon\big] \leq \PP_\vartheta\big[\big|\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)1_{{\mathcal C}_n} \big|\geq \varepsilon\big] +\PP_\vartheta\big[{\mathcal C}_n^c\big],
$$
et chacun des deux termes du membre de droite tend vers $0$ lorsque $n \rightarrow \infty$.
%\tfrac{1}{2}(\est-\vartheta)Z_n''(\widetilde \vartheta_n)1_{{\mathcal C}}
\end{proof}
\subsubsection{Loi limite des $M$-estimateurs}
Nous nous restreignons encore au cas où $\Theta \subset \R$. Nous traduisons l'Hypothèse \ref{hyp conv z est} pour une fonction de contraste $\psi$ en posant $\phi(a,x)=\partial_a\psi(a,x)$.
\begin{hypothese}[Hypothèse loi limite $M$-estimateurs] \label{hyp conv m est}On \vspace{1mm}a
\begin{itemize}
%\item[(i)] La famille $\big\{\PP_\vartheta,\,\vartheta\in \Theta\big\}$ est dominée par une mesure $\sigma$-finie $\mu$ sur\vspace{1mm} $\R$.
\item[(i)] Pour tout point $\vartheta \in \Theta$, il existe un voisinage ouvert ${\mathcal V}(\vartheta)$ tel que, pour tout $a \in {\mathcal V}(\vartheta)$
$$\big|\partial^3_a \psi(a, x)\big| \leq g(x),\;\;\text{où}\;\;\E_\vartheta\big[g(X)\big]<+\infty.$$
\item[(ii)] Pour tout $\vartheta \in \Theta$, on a
$$\E_\vartheta\big[\partial_\vartheta\psi(\vartheta,X)\big] = 0,\;\;\;\;\E_\vartheta\big[\big(\partial_\vartheta\psi(\vartheta,X)\big)^2\big]<+\infty,\;\;\;\;\E_\vartheta\big[\partial_\vartheta^2 \psi(\vartheta,X)\big]\neq 0.\vspace{3mm}$$
\end{itemize}
\end{hypothese}
\begin{proposition}[Loi limite des $M$-estimateurs] \label{loi limite m est}
Si la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ et la fonction $\phi$ vérifient l'Hypothèse \ref{hyp conv m est}, alors, si $\est$ est un $M$-estimateur associé à $\psi$ tel que $\est \stackrel{\PP_\vartheta}{\rightarrow} \vartheta$, on a
$$\sqrt{n}\big(\est-\vartheta\big) \stackrel{d}{\rightarrow} {\mathcal N}\big(0,v_\psi(\vartheta)\big)$$
en loi sous $\PP_\vartheta$, où
$$v_\phi(\vartheta) = \frac{\E_\vartheta\big[\big(\partial_\vartheta \psi(\vartheta,X)\big)^2\big]}{\Big(\E_\vartheta\big[\partial_\vartheta^2\phi(\vartheta,X)\big]\Big)^2}.$$
\end{proposition}
\begin{proof} Comme indiqué plus haut, on applique la Proposition \ref{loi limite z est} à la fonction $\phi(a,x) = \partial_a\psi(a,x)$.
\end{proof}
\section{Maximum de vraisemblance}
\subsection{Principe du maximum de vraisemblance}
\index{vraisemblance, fonction de}
\index{vraisemblance, estimateur du maximum de}
\subsubsection{Fonction de vraisemblance}
On se place sous l'Hypothèse de domination \ref{domination} présentée dans la Section \ref{hypotheses domination etc} : l'expérience ${\mathcal E}$ est dominée par une mesure $\mu$ sur $\R$, et on note
\begin{equation} \label{parametrisation}
\left\{f(\vartheta,\cdot),\vartheta \in \Theta\right\}
\end{equation}
la famille de densités par rapport à $\mu$, indicée par l'ensemble des paramètres $\Theta \subset \R^d$, avec $d \geq 1$. Pour toute fonction test $\varphi$
$$\int_{\R}\varphi(x)\PP_\vartheta(dx) = \int_{\R}\varphi(x)\frac{d\PP_\vartheta}{d\mu}(x)\mu(dx) = \int_{\R}\varphi(x)f(\vartheta,x)\mu(dx).$$
%\subsection{Equi-invariance}
\begin{definition}
On appelle fonction de vraisemblance associée à l'expérience produit ${\mathcal E}^n$ l'application
$$\vartheta \in \Theta \leadsto {\mathcal L}_n(\vartheta,X_1,\ldots, X_n) = \prod_{i = 1}^nf(\vartheta,X_i).$$
\end{definition}
La fonction de vraisemblance\footnote{La fonction $x \leadsto f(\vartheta,x)$ est définie à un ensemble $\mu$-négligeable près, donc on devrait en toute rigueur parler d'une (classe d'équivalence de) fonction de vraisemblance.} est une fonction aléatoire, observable. On la note parfois simplement ${\mathcal L}_n(\vartheta)$ lorsqu'il n'y a pas d'ambiguité.\begin{exemple}[cas discret]
\emph{
Si la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ est la famille des lois de Poisson de paramètre $\vartheta  \in \Theta = \R_+\setminus \{0\}$, alors une mesure dominante est la mesure de comptage $\mu$ sur $\N$ définie par $\mu(dx) = \sum_{k \in \N}\delta_k(dx)$ et on a
$$\PP_\vartheta(dx) = f(\vartheta, x) \mu(dx)= e^{-\vartheta}\frac{\vartheta^x}{x!}\mu(dx).$$
La mesure $\mu(dx)$ est portée par $\N$, donc on peut prendre $f(\vartheta, x) = e^{-\lambda}\frac{\vartheta^x}{x!}$ pour $x \in \N$ et $0$ sinon. La vraisemblance s'écrit alors, pour tout $\vartheta >0$
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \prod_{i = 1}^n e^{-\vartheta}\frac{\vartheta^{X_i}}{X_i!} = \frac{1}{\prod_{i = 1}^nX_i!}e^{-n\vartheta}\vartheta^{\sum_{i = 1}^n X_i}.$$
}
 \end{exemple}
\begin{exemple}[cas continu]
\emph{
Si la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ est la famille des lois de Cauchy de paramètre $\vartheta =(\alpha,\sigma^2) \in \Theta = \R\times \R_+\setminus\{0\}$, -- voir la Section \ref{familles parametrees} -- alors une mesure dominante est la mesure de Lebesgue sur $\R$ et on a
$$\PP_\vartheta(dx) = f(\vartheta, x)dx = \frac{\sigma}{\pi\big(\sigma^2+(x-\alpha)^2\big)}dx.$$
La vraisemblance s'écrit alors, pour tout $\vartheta >0$
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \frac{\sigma^n}{\pi^n}\prod_{i = 1}^n\big(\sigma^2+(X_i-\alpha)^2\big)^{-1}$$
}
\end{exemple}
\begin{exemple}[cas mélange]
\emph{
Dans les exemples emblématiques du Chapitre \ref{chapitre 2}, nous avons mentionné l'expérience engendrée par l'observation de
$$X_i^\star = \min\{X_i,T\},\;\;i=1,\ldots, n$$
où les $X_i$ sont des variables exponentielles indépendantes, de paramètre $\vartheta >0$ que l'on n'observe pas, et $T>0$ est un instant de censure. Les lois $\big\{\PP_\vartheta^\star,\,\vartheta \in \Theta\big\}$ de $X^\star$ ne sont ni discrètes, ni continues. La famille est dominée par $\mu(dx) = dx + \delta_{T}(dx)$, où $\delta_T(dx)$ est la mesure de Dirac au point $T$. On a
$$\PP_\vartheta^\star(dx) = f(\vartheta, x)\mu(dx),$$
où $$f(\vartheta,x) =  \vartheta e^{-\vartheta x}1_{\{x < T\}} +c(\vartheta)1_{\{x=T\}},$$
avec $c(\vartheta) = \int_{T}^{+\infty}\vartheta e^{-\vartheta t}dt= e^{-\vartheta T}$. La vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1^\star,\ldots, X_n^\star) & = \prod_{i = 1}^n f(\vartheta, X_i^\star) \\
& = \vartheta^{\,\mathrm{card}\, N_n^-} \exp\big(-\vartheta \sum_{i \in N_n^-} X_i^\star \big)c(\vartheta)^{\mathrm{card}\,N_n^+},
\end{align*}
où $N_n^- = \{i \leq n,\,X_i^\star < T\}$ et $N_n^+ = \{i \leq n,\, X_i^\star = T\}$. Elle est à comparer avec la vraisemblance du modèle sans censure, où l'on observe les $X_i$ directement. Dans ce cas
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \vartheta^n \exp\big(-\vartheta \sum_{i =1}^n X_i \big).$$
Nous verrons au Chapitre \ref{theorie asymptotique} comment quantifier la perte d'information liée à la censure.
%, et on a $\mathrm{card}\,N_n^-+\mathrm{card}\,N_n^+=n$.
%really ?
}
\end{exemple}
\index{vraisemblance, log}
\subsubsection{Définition de l'estimateur du maximum de vraisemblance}
\begin{definition} \label{est max de vrais}
On appelle estimateur du maximum de vraisemblance tout estimateur $\estMV$ satisfaisant
$${\mathcal L}_n(\widehat \vartheta_n^{\,\tt mv},X_1,\ldots,X_n) = \max_{\vartheta \in \Theta} {\mathcal L}_n(\vartheta,X_1,\ldots,X_n),$$
autrement dit
\begin{equation} \label{def emv}
\widehat \vartheta_n^{\,\tt mv} \in \mathrm{arg}\max_{\vartheta \in \Theta}{\mathcal L}_n(\vartheta,X_1,\ldots, X_n).
\end{equation}
\end{definition}
L'estimateur du maximum de vraisemblance peut ne pas exister. Il n'est pas non plus nécessairement unique.
%Dans \eqref{def emv}, on devrait plutôt écrire
%$$\widehat \vartheta_n^{\,\tt mv} \in \mathrm{argmax}_{\vartheta \in \Theta}{\mathcal L}_n(\vartheta,X_1,\ldots, X_n).$$
\begin{definition}
L'application
\begin{align*}
\vartheta \in \Theta \leadsto \ell_n(\vartheta, X_1,\ldots, X_n) &= \frac{1}{n}\log {\mathcal L}_n(\vartheta,X_1,\ldots,X_n) \\
&= \frac{1}{n}\sum_{i = 1}^n \log f(\vartheta,X_i),
\end{align*}
bien définie si $f(\vartheta,\cdot) > 0$ est appelée fonction de log-vraisemblance. En posant $\log 0 = 0$, on pourra parler de log-vraisemblance en toute généralité.
\end{definition}
%\begin{remarque}
%\emph{
%On a pour tout $\vartheta \in \Theta$,
%$$\PP_\vartheta\big[f(\vartheta,X)=0\big] = \int_{x,\,f(\vartheta, x)=0}f(\vartheta,x)\mu(dx) = 0,$$
%donc le problème de la définition de la log-vraisemblance est
%}
%\end{remarque}
On a aussi
$$\widehat \vartheta_n^{\,\tt mv} \in \mathrm{arg}\max_{\vartheta \in \Theta}\ell_n(\vartheta,X_1,\ldots, X_n).$$
Avant de donner des exemples de calcul effectif d'estimateurs du maximum de vraisemblance, nous allons justifier la définition \eqref{def emv}.
\subsubsection{Principe de maximum de vraisemblance à deux points}
Considérons une famille de lois à deux points
$$\Theta = \{\vartheta_1,\vartheta_1\} \subset \R,$$
où $\PP_{\vartheta_1}$ et $\PP_{\vartheta_2}$ sont deux lois discrètes portées par un sous-ensemble ${\mathcal M} \subset \R$ au plus dénombrable. On choisit pour mesure dominante $\mu$ la mesure de comptage sur ${\mathcal M}$, et la densité $f(\vartheta,\cdot)$ est donnée par
\begin{equation} \label{les probas}
f(\vartheta, x) = \PP_\vartheta\big[X = x\big],\;\;x\in {\mathcal M},\;\;\vartheta \in \{\vartheta_1,\vartheta_2\}.
\end{equation}
{\it A priori} -- avant l'expérience aléatoire -- si les observations $(X_1,\ldots, X_n)$ suivent la loi $\PP_\vartheta$ (avec $\vartheta = \vartheta_1$ ou $\vartheta_2$) la probabilité d'observer\footnote{C'est-à-dire la probabilité de réalisation de l'événement $\{X_1 = x_1,\ldots, X_n = x_n\}$} $(X_1 = x_1,\ldots, X_n = x_n)$ est exactement
$$\PP_\vartheta\big[X_1 = x_1,\ldots, X_n = x_n\big] = \prod_{i = 1}^n \PP_\vartheta\big[X_i = x_i\big] = \prod_{i = 1}^n f(\vartheta, x_i).$$
{\it A posteriori} on dispose d'une réalisation de $(X_1,\ldots, X_n)$. Supposons que, pour cette réalisation, on observe
$$\Big\{\prod_{i = 1}^nf(\vartheta_1, X_i) > \prod_{i = 1}^nf(\vartheta_2,X_i)\Big\},$$
c'est-à-dire
$$\Big\{{\mathcal L}_n(\vartheta_1,X_1,\ldots, X_n) >  {\mathcal L}_n(\vartheta_2,X_1,\ldots, X_n)\Big\}.$$
D'après \eqref{les probas}, nous pouvons faire l'interprétation suivante :

{\it A posteriori}, la probabilité d'avoir observé $(X_1,\ldots, X_n)$ est plus grande sous $\PP_{\vartheta_1}$ que sous $\PP_{\vartheta_2}$. Ceci nous suggère de \og suspecter \fg{} que la loi des observations est $\PP_{\vartheta_1}$ plutôt que $\PP_{\vartheta_2}$ : la valeur $\vartheta_1$ est \og plus vraisemblable\fg{} que $\vartheta_2$.

Si, pour la réalisation de l'observation $(X_1,\ldots, X_n)$ on a ${\mathcal L}_n(\vartheta_2) > {\mathcal L}_n(\vartheta_1)$, alors on fera la conclusion opposée : $\vartheta_2$ est plus \og vraisemblable \fg{} que $\vartheta_1$. On a donc maximisé la fonction de vraisemblance $\vartheta \leadsto {\mathcal L}_n(\vartheta,X_1,\ldots, X_n)$ dans le cas très simple où $\vartheta$ ne peut prendre que deux valeurs :
$$\widehat \vartheta_n^{\,\tt mv} = \vartheta_11_{\big\{ {\mathcal L}_n(\vartheta_1,X_1,\ldots, X_n) >  {\mathcal L}_n(\vartheta_2,X_1,\ldots, X_n)\big\}}+\vartheta_2  1_{\big\{{\mathcal L}_n(\vartheta_1,X_1,\ldots, X_n) <{\mathcal L}_n(\vartheta_2,X_1,\ldots, X_n)\big\}}.$$
Si enfin ${\mathcal L}_n(\vartheta_2) = {\mathcal L}_n(\vartheta_1)$, alors il n'y a pas unicité de la procédure et on ne peut pas conclure.
\subsubsection{Passage de deux paramètres et une famille de lois quelconque}
De manière générale, si $\Theta \subset \R^d$ avec $d\geq 1$ est un ensemble arbitraire, la valeur, si elle est bien définie,
$$\widehat \vartheta_n^{\,\,\tt mv} = \text{arg} \max_{\vartheta \in \Theta}{\mathcal L}_n(\vartheta,X_1,\ldots, X_n)$$
est la plus vraisemblable.
\subsubsection{Passage à une famille de lois continues}
Le passage aux lois continues, où les $\{\PP_\vartheta, \vartheta \in \Theta\}$ sont absolument continues par rapport à la mesure de Lebesgue se faite de la même manière. On peut reproduire -- heuristiquement -- le raisonnement du paragraphe précédent. On remplace
$$\PP_\vartheta\big[X_1 = x_1,\ldots, X_n = x_n\big] = \prod_{i = 1}^n \PP_\vartheta\big[X_i = x_i\big] = \prod_{i = 1}^n f(\vartheta, x_i),$$
par
$$\PP_\vartheta\big[X_1 \in {\mathcal V}(x_1),\ldots, X_n \in {\mathcal V}(x_n)\big] = \prod_{i = 1}^n \PP_\vartheta\big[X_i \in {\mathcal V}(x_i)\big]$$
% = \prod_{i = 1}^n f(\vartheta, x_i).$$
où ${\mathcal V}(x)$ est un \og petit \fg{} voisinage de $x$. Alors
$$\PP_\vartheta\big[X\in {\mathcal V}(x)\big]=\int_{{\mathcal V}(x)}f(\vartheta,u)du \approx f(\vartheta,x) \big|{\mathcal V}(x)\big|$$
dans la limite $\big|{\mathcal V}(x)\big| \rightarrow 0$, où $\big|{\mathcal V}(x)\big|$ désigne le mesure de Lebesgue de ${\mathcal V}(x)$. Donc la probabilité de l'événement
$$\Big\{X_1 \in {\mathcal V}(x_1),\ldots, X_n \in {\mathcal V}(x_n)\Big\}$$
est \og essentiellement \fg{} proportionnelle à $\prod_{i = 1}^nf(\vartheta, x_i)$, et ceci indépendamment de $\vartheta$ (si on accepte l'approximation précédente).

\subsubsection{Equations de vraisemblance} \index{vraisemblance, équations de}
Si le maximum de $\vartheta \leadsto {\mathcal L}_n(\vartheta)$, ou encore le maximum de $\vartheta \leadsto \ell_n(\vartheta)$ n'est pas atteint sur la frontière de $\Theta$, et si l'application $\vartheta \leadsto {\mathcal L}_n(\vartheta)$ est continûment différentiable, alors une condition nécessaire que doit satisfaire l'estimateur du maximum de vraisemblance $\widehat \vartheta_n^{\,\tt mv}$ est l'annulation du gradient
$$\nabla_\vartheta\, {\mathcal L}_n(\vartheta,X_1,\ldots, X_n)\arrowvert_{\vartheta = \widehat \vartheta_n^{\,\tt mv}} = 0$$
ce qui fournit un système de $d$ équations si $\Theta \subset \R^d$ avec $d\geq 1$. De la même manière, une condition nécessaire sur la log-vraisemblance est
\begin{equation} \label{eq vrais}
\nabla_\vartheta\, \ell_n(\vartheta,X_1,\ldots, X_n)\arrowvert_{\vartheta = \widehat \vartheta_n^{\,\tt mv}} = 0
\end{equation}
\begin{definition}[Equations de vraisemblance]
L'équation \eqref{eq vrais} est appelée équation de vraisemblance si $d = 1$ et système d'équations de vraisembance si $d>1$.
\end{definition}
En résolvant \eqref{eq vrais}, on obtient tous les points critiques de $\vartheta \leadsto \ell_n(\vartheta)$, en particulier, tous ses maxima et minima locaux.
\begin{definition} On appelle racine de l'équation de vraisemblance tout (estimateur) $\widehat \vartheta_n^{\,{\tt rv}}$ solution de \eqref{eq vrais}, c'est-à-dire tel que
$$\nabla_\vartheta\,\ell_n(\widehat \vartheta_n^{\,{\tt rv}},X_1,\ldots, X_n) = 0.$$
\end{definition}
\begin{remarque}
\emph{
Supposons que pour tout $\vartheta \in \Theta$, on a $f(\vartheta,x)>0\;\mu(dx)$ presque-partout et $\vartheta \leadsto f(\vartheta, x)$ est différentiable, $\mu(dx)$ presque-partout. Alors, si
$\vartheta \leadsto \ell_n(\vartheta)$ atteint son maximum global pour tous les $\vartheta$ tels que $\nabla_\vartheta\ell_n(\vartheta) = 0$,
alors les ensembles qui définissent les solutions $\estMV$ et $\widehat \vartheta_n^{\,{\tt rv}}$ coïncident.
 }
 \end{remarque}
\subsubsection{Invariance du maximum de vraisemblance vis-à-vis de la mesure dominante}
Sous l'Hypothèse \ref{domination}, il existe une mesure positive $\sigma$-finie sur $\R$ qui domine la famille $\big\{\PP_\vartheta$, $\vartheta \in \Theta\big\}$.

C'est le choix de $\mu$ qui spécifie la famille de densités $f(\vartheta, \cdot)$ sur laquelle est construite la vraisemblance, et par suite l'estimateur du maximum de vraisemblance.
\begin{proposition} L'estimateur du maximum de vraisemblance ne dépend pas du choix de la mesure dominante $\mu$ dans le calcul de la vraisemblance.
\end{proposition}
\begin{proof}
Soit $\nu$ une autre mesure dominante.  Les mesures $\mu$ et $\nu$ sont elles-mêmes dominées par la mesure $\mu+\nu$, donc, pour toute
fonction test $\varphi$,
\begin{align*}
\int_{\R}\varphi(x)\PP_\vartheta(dx) &= \int_{\R}\varphi(x)\frac{d\PP_\vartheta}{d(\mu+\nu)}(x)(\mu+\nu)(dx) \\
&=\int_{\R}\varphi(x)\frac{d\PP_\vartheta}{d\mu}(x)\frac{d\mu}{d(\mu+\nu)}(x)(\mu+\nu)(dx) \\
& = \int_{\R}\varphi(x)\frac{d\PP_\vartheta}{d\nu}(x)\frac{d\nu}{d(\mu+\nu)}(x)(\mu+\nu)(dx).
\end{align*}
Les densités $\frac{d\PP_\vartheta}{d\mu}(x)$ et $\frac{d\PP_\vartheta}{d\nu}(x)$ ne différent que d'un facteur multiplicatif qui ne dépend pas de $\vartheta$ (sauf éventuellement sur un ensemble $(\mu+\nu)$-négligeable). Donc, presque-sûrement,
$$\prod_{i = 1}^n \frac{d\PP_\vartheta}{d\mu}(X_i)\;\;\;\text{et}\;\;\;\prod_{i = 1}^n \frac{d\PP_\vartheta}{d\nu}(X_i)$$
ne diffèrent que d'une fonction de $X_1,\ldots, X_n$ qui ne dépend pas de $\vartheta$.
On ne modifie pas $\widehat \vartheta_n^{\,\tt mv}$ selon que l'on maximise la vraisemblance formée sur l'une ou l'autre des mesures dominantes.
%ne dépend pas du choix de a mesure dominante.
\end{proof}
\subsubsection{Equi-invariance} \index{équi-invariance}
L'estimateur du maximum de vraisemblance n'est pas modifié par changement de (bonne) paramétrisation. Cela signifie que si $\estMV$ est l'estimateur du maximum de vraisemblance pour $\vartheta$, alors $G(\estMV)$ est l'estimateur du maximum de vraisemblance du paramètre $G(\vartheta)$ pour toute fonction $G$ \og raisonnable\fg{}.

Plus précisément, si $\big\{\PP_\vartheta, \,\vartheta \in \Theta\big\}$ est une famille de probabilités associée à une expérience statistique, et si $$G :\Theta \rightarrow G(\Theta)$$ est une bijection de $\Theta$ sur son image $G(\Theta)$, on construit une nouvelle famille de probabilités $\big\{\mathbb{Q}_{\tau}, \tau \in G(\Theta)\big\}$ en posant
$$\mathbb{Q}_{\tau} = \PP_{G^{-1}(\tau)}.$$
\begin{proposition}
Si $G:\Theta \rightarrow \widetilde \Theta$ est une bijection et si $\widehat \vartheta_n^{\,\tt mv}$ désigne l'estimateur du maximum de vraisemblance pour l'expérience statistique associée à la famille de lois $\big\{\PP_\vartheta, \vartheta \in \Theta \big\}$, alors $G(\widehat \vartheta_n^{\,\tt mv})$ est l'estimateur du maximum de vraisemblance de $G(\vartheta)$, c'est-à-dire pour l'expérience statistique associée à la famille de lois $\big\{\PP_{G^{-1}(\tau)}, \tau \in G(\Theta)\big\} = \big\{\mathbb{Q}_{\tau}, \tau \in G(\Theta)\big\}$.
\end{proposition}
\begin{proof}
Posons $\widehat \tau_n = G(\estMV)$. Alors $\estMV = G^{-1}(\widehat \tau_n)$. Pour tout $\tau \in G(\Theta)$, la vraisemblance $\widetilde {\mathcal L}_n(\tau, X_1,\ldots, X_n)$ associée à la famille $\big\{\PP_{G^{-1}(\tau)}, \tau \in G(\Theta)\big\}$ s'écrit
\begin{align*}
\widetilde {\mathcal L}_n(\tau, X_1,\ldots, X_n) & = {\mathcal L}_n(G^{-1}(\tau), X_1,\ldots, X_n) \\
& = {\mathcal L}_n(\vartheta,X_1,\ldots,X_n) \\
& \leq {\mathcal L}_n(\estMV,X_1,\ldots,X_n) \\
& = \widetilde {\mathcal L}_n(\widehat \tau_n, X_1,\ldots, X_n).
\end{align*}
\end{proof}
\begin{exemple}
\emph{Si $X_1,\ldots, X_n$ est un $n$-échantillon de loi exponentielle de paramètre $\vartheta \in \Theta  = \R_+\setminus \{0\}$, alors la loi $\PP_\vartheta$ a une densité par rapport à la mesure de Lebesgue donnée par $f(\vartheta, x) = \vartheta e^{-\vartheta x}1_{\{x \geq 0\}}$. La log-vraisemblance
s'écrit\footnote{Noter que tous les $X_i$ sont positifs $\PP_\vartheta$ p.s., simultanément pour tous les $\vartheta \in \Theta$, donc il est inutile de faire apparaître la condition $1_{\{X_i\geq 0\}}$ dans la formule de la vraisemblance.}
$$\ell_n(\vartheta,X_1,\ldots, X_n) = n \log \vartheta - \vartheta \sum_{i = 1}^n X_i,$$
donc $\partial_\vartheta \ell_n(\vartheta, X_1,\ldots, X_n) = 0$ si et seulement si $\vartheta = \frac{1}{\Xbar}$. On vérifie que c'est un maximum global, donc
$\estMV =  \frac{1}{\Xbar}$. Par équi-invariance, on en déduit sans calcul que l'estimateur du maximum de vraisemblance pour un $n$-échantillon de loi exponentielle de paramètre $\tau = 1/\vartheta$, $\vartheta \in \Theta = \R_+\setminus \{0\}$ est $\widehat \tau_n = \Xbar$.
}
\end{exemple}
\begin{exemple}
\emph{
Si $X_1,\ldots, X_n$ est un $n$-échantillon de loi log-normale de moyenne $a \in \R$ et de variance $d^2 >0$, alors, par la représentation $Y_i = \log X_i \sim {\mathcal N}(\mu,\sigma^2)$ avec
$$a = e^{\mu+\sigma^2/2},\;\;\;d^2 = a^2(e^{\sigma^2}-1)$$
(voir Section \ref{familles parametrees}), en étudiant la fonction $$(\mu,\sigma^2) \leadsto (a,d^2) =\big(e^{\mu+\sigma^2/2},a^2(e^{\sigma^2}-1)\big)$$
qui établit une bijection de $\R\times \R_+\setminus \{0\}$, on en déduit par équi-invariance du cas gaussien que l'estimateur du maximum de vraisemblance pour $(a,d^2)$
est
$$\big(\widehat a_n^{\,{\tt mv}},(\widehat d_n^2)^{\,{\tt mv}}\big) = \big(e^{\overline{Y}_n+s_n^2/2},(\widehat a_n^{\,{\tt mv}})^2(e^{s_n^2}-1)\big),$$
où $\overline{Y}_n = \tfrac{1}{n}\sum_{i = 1}^nY_i = \tfrac{1}{n}\sum_{i = 1}^n \log X_i$ et $s_n^2 = \tfrac{1}{n}(Y_i - \overline{Y}_n)^2$.
}
\end{exemple}
\subsection{Exemples de calcul }
\begin{exemple}[modèle gaussien standard]
\emph{L'expérience statistique est engendrée par un $n$-échantillon de loi ${\mathcal N}(\mu,\sigma^2)$, le paramètre est $\vartheta = (\mu,\sigma^2)\in \Theta = \R\times \R_+\setminus\{0\}$. Une mesure dominante est la mesure de Lebesgue sur $\R$ et on a alors
$$f(\vartheta, x) = (2\pi\sigma^2)^{-1/2}\exp\big(-\tfrac{1}{2\sigma^2}(x-\mu)^2\big)$$
La log-vraisemblance associée s'écrit
$$\ell_n\big((\mu,\sigma^2),X_1,\ldots, X_n\big) = -\frac{n}{2}\log(2\pi \sigma^2)-\frac{1}{2\sigma^2}\sum_{i = 1}^n (X_i-\mu)^2.$$
L'équation de vraisemblance s'écrit
$$
\left\{
\begin{array}{lll}
\partial_\mu\ell_n \big((\mu,\sigma^2),X_1,\ldots, X_n\big) & = &\displaystyle  \frac{1}{\sigma^2}\sum_{i = 1}^n (X_i-\mu) \\ \\
\partial_{\sigma^2}\ell_n \big((\mu,\sigma^2),X_1,\ldots, X_n\big)&  = &\displaystyle-\frac{n}{2\sigma^2}+\frac{1}{2\sigma^4}\sum_{i = 1}^n (X_i-\mu)^2,
\end{array}
\right.
$$
Pour $n \geq 2$, ceci nous fournit le point critique
$$\est = \big(\overline{X}_n,\frac{1}{n}\sum_{i = 1}^n(X_i-\overline{X}_n)^2\big).$$
On vérifie ensuite que le point critique est l'unique maximum global et donc $\widehat \vartheta_n^{\,{\tt rv}} = \estMV$.
}
\end{exemple}
\begin{exemple}[modèle de Bernoulli]
\emph{L'expérience statistique est engendrée par un $n$-échantillon de loi de Bernoulli de paramètre $\vartheta \in \Theta = (0,1)$. Donc
$$\PP_\vartheta\big[X = x\big] = \vartheta^x(1-\vartheta)^{1-x},\;\;\;x\in \{0,1\}.$$
On peut prendre comme mesure dominante $\mu$ la mesure de comptage sur $\{0,1\}$ et dans ce cas $f(\vartheta,x) = \vartheta^x(1-\vartheta)^{1-x}$.
La vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = \prod_{i = 1}^n\vartheta^{X_i}(1-\vartheta)^{1-X_i} \\
& =  \vartheta^{\sum_{i = 1}^n X_i}(1-\vartheta)^{n-\sum_{i = 1}^nX_i}
\end{align*}
et la log-vraisemblance vaut
$$\ell_n(\vartheta, X_1,\ldots, X_n) = n\Xbar \log \vartheta + n(1-\Xbar)\log(1-\vartheta).$$
On a $\partial_\vartheta \ell_n(\vartheta, X_1,\ldots, X_n) = n\Xbar \vartheta^{-1}-(n-\Xbar)(1-\vartheta)^{-1} = 0$ si et seulement si $\vartheta = \Xbar$. On vérifie que $\vartheta = \Xbar$ est un maximum global et donc $\estMV = \Xbar$.
}
\end{exemple}
\begin{exemple}[modèle de Laplace]
\emph{L'expérience statistique est engendrée par un $n$-échantillon de loi de Laplace de paramètre $\vartheta \in \Theta = \R$, dont la densité par rapport à la mesure de Lebesgue est donnée par
$$f(\vartheta,x) = \frac{1}{2\sigma}\exp\big(-\frac{|x-\vartheta|}{\sigma}\big),$$
où $\sigma >0$ est connu. La fonction de vraisemblance s'écrit
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = (2\sigma)^{-n}\exp\big(-\frac{1}{\sigma}\sum_{i = 1}^n \big|X_i-\vartheta\big|\big)$$
et la log-vraisemblance vaut
$$\ell_n(\vartheta,X_1,\ldots, X_n) = - n \log(2\sigma)-\frac{1}{\sigma}\sum_{i = 1}^n \big|X_i-\vartheta\big|.$$
Maximiser ${\mathcal L}_n(\vartheta, X_1,\ldots, X_n)$ revient à minimiser la fonction $\vartheta \leadsto \sum_{i = 1}^n \big|X_i-\vartheta\big|$. Cette fonction est dérivable presque partout, de dérivée
$$-\sum_{i = 1}^n \text{sign}(X_i-\vartheta).$$
La dérivée (définie presque partout) est constante par morceaux.
Si $n$ est impair, elle s'annule en un point unique $X_{\big(\tfrac{n+1}{2}\big)}$, où $X_{(1)}\leq \ldots \leq X_{(n)}$ désigne la statistique d'ordre associée à l'échantillon (voir Section \ref{le cas non regulier} du Chapitre \ref{echantillonnage}).
Si $n$ est pair, il y a une infinité de solutions : tout point de l'intervalle $\big(X_{\big(\tfrac{n}{2}\big)},X_{\big(\tfrac{n}{2}+1\big)} \big)$ est un estimateur du maximum de vraisemblance. On retrouve la médiane empirique (voir Section \ref{le cas non regulier} du Chapitre \ref{echantillonnage}).
}
\end{exemple}
\begin{exemple}[modèle uniforme]
\emph{L'expérience statistique est engendrée par un $n$-échantillon de loi uniforme sur $[0,\vartheta]$, où $\vartheta \in \Theta = \R_+\setminus \{0\}$
est le paramètre. Une mesure dominante est la mesure de Lebesgue et la densité de la loi uniforme est donnée par
$$f(\vartheta, x) = \frac{1}{\vartheta}1_{[0,\vartheta]}(x).$$
La fonction de vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = \frac{1}{\vartheta^n}\prod_{i = 1}^n 1_{0 \leq X_i \leq \vartheta} \\
& = \vartheta^{-n}1_{\{X_{(n)} \leq \vartheta\}},
\end{align*}
où $X_{(n)} = \max_{i = 1,\ldots, n}X_i$. La valeur maximale de ${\mathcal L}_n(\vartheta, X_1,\ldots, X_n)$ est obtenue pour $\vartheta = X_{(n)}$ et donc
$\estMV = X_{(n)}$. Par contre, la fonction de log-vraisemblance n'est pas définie pour toutes les valeurs de $\vartheta$ et n'est pas dérivable.
}
\end{exemple}
\begin{exemple}[modèle de Cauchy]
\emph{L'expérience statistique est engendrée par un $n$-échantillon de loi de Cauchy de paramètre $\vartheta \in \Theta = \R$, dont la densité par rapport à la mesure de Lebesgue sur $\R$ est donnée par
$$f(\vartheta,x) = \frac{1}{\pi\big(1+(x-\vartheta)^2\big)}.$$
La fonction de vraisemblance s'écrit
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n)  = \pi^{-n}\prod_{i = 1}^n\frac{1}{1+(X_i-\vartheta)^2},$$
et la log-vraisemblance vaut
$$\ell_n(\vartheta, X_1,\ldots, X_n) = -n\log \pi-\frac{1}{n}\sum_{i = 1}^n \log\big(1+(X_i-\vartheta)^2\big),$$
et l'équation de vraisemblance équivaut à résoudre
\begin{equation} \label{eq vrais cauchy}
\sum_{i = 1}^n \frac{X_i-\vartheta}{1+(X_i-\vartheta)^2}=0.
\end{equation}
Cette équation n'admet pas de solution explicite et admet en général plusieurs solutions. Nous verrons plus tard comment traiter le comportement asymptotique d'une solution de \eqref{eq vrais cauchy} de façon indirecte.}
\end{exemple}
\begin{exemple}[absence d'estimateur du maximum de vraisemblance]
\emph{
Considérons le modèle de translation par rapport à la densité
$$f_0(x) = \frac{e^{-\frac{|x|}{2}}}{2\sqrt{2\pi|x|}},\;\;x\in \R,$$
c'est-à-dire le modèle dominé par la mesure de Lebesgue sur $\R$ de densités
$$f_0(x-\vartheta),\;\;x\in \R, \vartheta \in \Theta = \R.$$
La fonction de vraisemblance s'écrit
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \prod_{i = 1}^n f_0(X_i-\vartheta).$$
On a $\lim_{\vartheta \rightarrow X_i}{\mathcal L}_n(\vartheta, X_1,\ldots, X_n)=+\infty$ pour tout $i=1,\ldots, n$. Pour cette expérience statistique, il n'existe pas d'estimateur du maximum de vraisemblance.
}
\end{exemple}
\subsection{Maximum de vraisemblance et $M$-estimation}
\subsubsection{Préliminaire : une inégalité de convexité}
\begin{lemme}[Inégalité d'entropie] \label{entropie}
Soit $\mu$ une mesure $\sigma$-finie sur $(\R, {\mathcal B})$. Soient deux densités de probabilité  $f,g:\R \rightarrow \R_+$ par rapport à $\mu$, c'est-à-dire vérifiant
$$\int_{\R}f(x)\mu(dx) = \int_{\R}g(x)\mu(dx)=1.$$
Alors\footnote{Avec la convention $\int_{\{x,f(x)=0\}}f(x)\log g(x)\mu(dx)=0$ pour toute fonction $g$.}
$$\int_{\R}f(x)\log f(x)\mu(dx) \geq \int_{\R} f(x) \log g(x)\mu(dx)$$
si les deux intégrales sont finies, et l'égalité a lieu si et seulement si $f=g$ $\mu$-presque partout.
\end{lemme}
\begin{proof}
On doit montrer
\begin{equation} \label{a montrer}
\int_{\R} f(x)\log \frac{g(x)}{f(x)}\mu(dx) \leq 0.
\end{equation}
Pour $x \geq -1$, on a $\log(1+x) \leq x$ avec égalité si et seulement si $x=0$, donc
$$
\log \frac{g(x)}{f(x)} = \log\left(1+\big(\frac{g(x)}{f(x)}-1\big)\right) \leq \frac{g(x)}{f(x)}-1,
$$
avec égalité si et seulement si $f(x) = g(x)$. Il vient
\begin{align*}
\int_{\R} f(x)\log \frac{g(x)}{f(x)}\mu(dx) & \leq \int_{\R} f(x)\left(\frac{g(x)}{f(x)}-1\right)\mu(dx) \\
& = \int_{\R}g(x)\mu(dx)-\int_{\R}f(x)\mu(dx)=0.
\end{align*}
Si on n'a pas $f=g$ $\mu$-presque partout, alors l'inégalité est stricte.
\end{proof}
\subsubsection{Le maximum de vraisemblance est un $M$-estimateur}
Replaçons-nous dans le contexte de la Section \ref{def M estimateur}. Posons
$$\psi(a,x) = \log f(a, x),\;\;a\in \Theta,\;x \in \R.$$
Alors l'estimateur du maximum de vraisemblance $\widehat \vartheta_n^{\,\tt mv}$, s'il existe, satisfait
$$\widehat \vartheta_n^{\,\tt mv} \in \mathrm{arg} \max_{a \in \Theta}\sum_{i = 1}^n\psi(a,X_i)$$
et peut s'interpréter comme le $M$-estimateur associé à la fonction $\psi$. En effet, d'après le Lemme \ref{entropie}, la valeur $a= \vartheta$ maximise
$$a \leadsto \int_{\R}\psi(a, x)\PP_\vartheta(dx) = \int_{\R}\log f(a, x) f(\vartheta, x)\mu(dx).$$
\index{vraisemblance, contraste de}
Ceci justifie {\it a posteriori} le principe du maximum de vraisemblance. Nous verrons au Chapitre \ref{theorie asymptotique} qu'il y a beaucoup plus encore : le contraste $\psi(a,x) =  \log f(\vartheta, x)$ est optimal dans un certain sens.

Si pour tout $\vartheta \in \Theta$
%check l ordre de \forall \vartheta et \forall x
la fonction $\vartheta \leadsto \log f(\vartheta, x)$ est différentiable $\mu$-presque partout, alors on a aussi l'interprétation du maximum de vraisemblance comme $Z$-estimateur associé à la fonction
$$\phi(\vartheta,x) = \partial_\vartheta \log f(\vartheta, x) = \frac{\partial_\vartheta f(\vartheta,x)}{f(\vartheta,x)},\;\;\vartheta \in \Theta, x \in \R$$
lorsque $\Theta \subset \R$, avec une généralisation immédiate en dimension plus grande que 1.

En particulier, le comportement asymptotique de l'estimateur du maximum de vraisemblance peut se déduire des Propositions \ref{loi limite z est} ou \ref{loi limite m est} si l'on dispose de conditions de régularité suffisantes. Nous reviendrons plus spécifiquement sur la convergence de l'estimateur du maximum de vraisemblance dans le Chapitre \ref{theorie asymptotique}.

%une note sur la convergence de l emv (comme contraste)

%Nous verrons au Chapitre \ref{theorie asymptotique%} comment ces dernières quantités interviennent de manière profonde pour caractériser l'optimalité des estimateurs sous des hypothèses adéquates de régularité {\tt bof cette phrase}.
%\subsection{Propriétés asymptotiques}
%{\tt qqch de court via constrastes ; à opposer au chapitre "théorie asymptotique"}
%\subsection{Calcul numérique du maximum de vraisemblance}
%\begin{center}
%{\tt INSERT HERE SUPPL. 16}
%\end{center}
%\section{Exercices}
%\begin{exercice}[Modèle non-dominé] \label{exercice absence domination}
%\emph{
%Soit ${\mathcal E}$ l'expérience engendrée par l'observation de $\vartheta X$, où $X$ suit une loi de Poisson de paramètre $1$, et $\vartheta \in \Theta = \R_+\setminus \{0\}$ est le paramètre. Montrer que ${\mathcal E}$ n'est pas dominée.
%}
%\end{exercice}
%\begin{exercice} \label{statistique de rang}
%\begin{center}
%{\tt INSERT HERE SUPPL. 18}
%\end{center}
%\end{exercice}
%\begin{exercice} \label{loi limite quantile empirique}
%\begin{center}
%{\tt INSERT HERE SUPPL. 19}
%\end{center}
%\end{exercice}
%\begin{exercice} \label{correction estimateur aux bords}
%\begin{center}
%{\tt INSERT HERE SUPPL. 20}
%\end{center}
%\end{exercice}
%\begin{exercice} \label{fin cauchy}
%\begin{center}
%{\tt INSERT HERE SUPPL. 21}
%\end{center}
%\end{exercice}
\chapter[Méthodes d'estimation en régression]{Méthodes d'estimation pour le modèle de régression} \label{regression}
\section{Modèles de régression}
%\subsection{Notations et hypothèses}
Déjà rencontré dans les exemples 2, 4 et 6 du Chapitre \ref{chapitre 2}, la régression -- tout comme l'échantillonnage -- est incontournable en statistique. Presque tous les modèles utilisés dans les applications peuvent se ramener à des généralisations plus ou moins sophistiquées de la régression. Dans ce chapitre, nous présentons brièvement les résultats essentiels de l'estimation paramétrique et en particulier, la méthode des moindres carrés.
\subsection{Modèle de régression à \og design \fg{} aléatoire} \label{regression a design aleatoire}
\index{modèle de régression}
\index{\og design \fg{} aléatoire}
On part de l'expérience statistique engendrée par l'observation
$$(\bX_1,Y_1),\ldots,(\bX_n,Y_n)$$
où
\begin{equation} \label{eq regression}
Y_i = r(\vartheta, \bX_i)+\xi_i\vspace{4mm},
\end{equation}
pour $i=1,\ldots, n$. Les variables aléatoires $({\bX}_i, Y_i)$ sont indépendantes, de même loi, à valeurs dans $\R^k \times \R$, et
$\vartheta \in \Theta\subset \R^d$ est le paramètre inconnu.

\begin{definition} Le vecteur $\bX_i$ est appelé vecteur de covariables (ou de variables explicatives\footnote{L'emploi de termes différents -- et non synonymes -- pour désigner les même objets provient des utilisations très différentes du modèle de régression dans les applications (économétrie, signal, biostatistique, etc.).}
) associé à l'observation $Y_i$.
La matrice $\big(\bX_1 \cdots \bX_n\big)$ est appelée \og design \fg{} ou plan d'expérience associé au modèle.

La fonction $x \leadsto r(\vartheta, x)$, connue au paramètre $\vartheta \in \Theta$ près, est appelée fonction de régression.

Les variables aléatoires $\xi_i$ sont appelées \og bruits\fg{} ou innovations.
\index{\og bruit\fg, innovation}
\end{definition}
On note $\PP_\vartheta = \PP_\vartheta(d{\bf x}\,dy)$ la loi jointe des $(\bX_i,Y_i)$ définie sur $\R^k \times \R$ et le but est d'inférer sur le paramètre $\vartheta$. L'expérience statistique associée à l'observation s'écrit :
$${\mathcal E}_{\text{{\tt design-aléa}}}^n = \left(\R^{(k+1)n}, {\mathcal B}^{(k+1)n},\big\{\PP_\vartheta^n, \vartheta \in \Theta\big\}\right)$$
où $\PP_{\vartheta}^n$ désigne le produit des lois $\PP_\vartheta$ effectué $n$-fois. Notons que puisque les $(\bX_i, Y_i)$ sont indépendantes et équidistribuées, les $\xi_i$ le sont aussi.

\begin{remarque}
\emph{
Les variables $\xi_i$ \og polluent \fg{} l'observation de la fonction d'intérêt $r(\vartheta,\cdot)$ aux points $(\bX_i,Y_i)$. En l'absence des $\xi_i$ reconstruire $r(\vartheta,\cdot)$ et donc $\vartheta$ se ramènerait à un problème d'interpolation numérique.
}
\end{remarque}

%Nous faisons une hypothèse d'identifiabilité \fg{}, sans lesquelles le problème statistique n'est pas vraiment bien posé.
% première hypothèse fondamentale sur la structure de l'expérience ${\mathcal E}^n$.
\begin{hypothese}[Identifiabilité, \og design aléatoire\fg{}] \label{identif ft de reg}
L'application $\vartheta \in \Theta \leadsto r(\vartheta,\cdot)$ est injective. De plus, la loi des $\xi_i$ admet un moment d'ordre $1$ et les variables $\xi_i$ vérifient
\begin{equation} \label{bruit zero}
\E_\vartheta\big[\xi_i\,|\,\bX_i\big]=0.
\end{equation}
\end{hypothese}

\begin{remarque}
\emph{
L'Hypothèse \ref{identif ft de reg} garantit une bonne paramétrisation de la fonction de régression $r(\vartheta,\cdot)$. Sans \eqref{bruit zero}, on pourrait écrire
$$Y_i = r(\vartheta,\bX_i)+ g(\vartheta, \bX_i) +\widetilde \xi_i,$$
avec $g(\vartheta, \bX_i)  = \E_\vartheta\big[\xi_i\,|\,\bX_i\big]$ et $\widetilde \xi_i = \xi_i- \E_\vartheta\big[\xi_i\,|\,\bX_i\big]$ qui vérifie bien $\E\big[\widetilde \xi_i\,|\,\bX_i\big] = 0$ et $g \neq 0$, ce qui empêche de pouvoir identifier la fonction $r(\vartheta,\cdot)$, même lorsqu'elle est réduite à une constante.
}
\end{remarque}
\begin{remarque}
\emph{
Une manière naturelle d'obtenir la représentation \eqref{eq regression} si la loi des $Y_i$ admet un moment d'ordre $1$ est de définir, pour chaque $\vartheta \in \Theta$, la fonction de régression
$$r(\vartheta,\cdot):\R^k \rightarrow \R$$
en posant
$$r(\vartheta, \bx) = \E_\vartheta\big[Y_i\,|\,\bX_i = \bx\big],\;\;\bx \in \R^k.$$
Alors, on a
$$Y_i = r(\vartheta, \bX_i) +\xi_i,\;\;\text{avec}\;\;\xi_i = Y_i - \E_\vartheta\big[Y_i\,|\,\bX_i \big]$$
et on vérifie immédiatement que l'on a bien l'Hypothèse \ref{bruit zero}.
}
\end{remarque}
\subsection{Réduction au cas d'un \og design \fg{} déterministe} \label{regression design deterministe}
Nous avons déjà discuté du caractère aléatoire du \og design \fg{}, selon que le statisticien choisit  ou non le plan d'expérience ou le \og design \fg{}. Nous allons faire dans ce cours une hypothèse qui va nous permettre de nous ramener systématiquement au cas où le \og design\fg{} est déterministe.


\begin{hypothese}[Ancillarité des covariables] \label{ancillarity}
La loi $\PP^{\bX}$ des covariables ne dépend pas de $\vartheta$.
\end{hypothese}
\index{\og design \fg{} déterministe}
Sous l'Hypothèse \ref{ancillarity}, la loi des covariables $\bX_i$ ne contient pas d'information sur le paramètre $\vartheta$. On  \og gèle\fg{} les $\bX_i$ dont le caractère aléatoire est ignoré.

Mathéma\-tiquement, cela consiste à étudier les propriétés statistiques des estimateurs conditionnellement aux $\bX_i$, et donc, de remplacer formellement les  $(\bX_i,Y_i)$ par $(\bx_i,Y_i)$ où les $\bx_i$ sont données, sans perdre de généralité.

On remplace désormais le modèle de régression à \og design aléatoire \fg{} de la Section \ref{regression a design aleatoire} par le modèle de régression à \og design déterministe\fg{} : on observe l'expérience engendrée par
$$(\bx_1,Y_1),\ldots, (\bx_n, Y_n),$$
où
\begin{equation} \label{equation reg deterministe}
Y_i = r(\vartheta, \bx_i)+\xi_i
\end{equation}
pour $i=1,\ldots, n$. Les vecteurs $\bx_i \in \R^k$ sont donnés, et les variables $Y_i$ sont indépendantes mais pas identiquement distribuées : la loi de $Y_i$ dépend maintenant de $\bx_i$ qui est fixé et les $\xi_i$ sont des bruits. L'expérience statistique s'écrit ici
$${\mathcal E}^n_{\text{{\tt design-déter}}} = \Big(\R^n, {\mathcal B}^n, \big\{\PP_\vartheta^{\,n},\vartheta \in \Theta\big\}\Big),$$
où $\PP_\vartheta^{\,n}$ est la loi des $Y_i$ données par \eqref{equation reg deterministe}. L'hypothèse  d'identifiabilité devient
\begin{hypothese}[Identifiabilité, \og design déterministe \fg{}] \label{identif reg det}
L'application $\vartheta \in \Theta \leadsto r(\vartheta,\cdot)$ est injective. De plus, pour tout $i=1,\ldots, n$, les variables aléatoires $\xi_i$ sont intégrables et
$$\E_\vartheta^n\big[\xi_i\big]=0.$$
\end{hypothese}


\subsection{Calcul de la vraisemblance}

On se place dans toute la suite du chapitre dans le modèle de régression à \og design \fg{} déterministe, c'est-à-dire nous considérons l'expérience ${\mathcal E}_{\text{{\tt design-déter}}}^n$.

\subsubsection{Calcul de la loi de $Y_i$}

Nous faisons ici une hypothèse technique :
\begin{hypothese} \label{technique noise}
Les \og bruits \fg{} $\xi_i$ sont indépendants, identiquement distribués, et leur loi commune $\PP^{\,\xi}$ ne dépend pas des $\bx_i$ et du paramètre $\vartheta$.
\end{hypothese}

Cette hypothèse est un peu superflue et nous nous en affranchirons dans certains exemples. Elle a néanmoins l'avantage de présenter des formules de calcul très simples.

\begin{proposition}[Loi des observations] \label{loi des observations}
Sous les Hypothèses \ref{identif reg det} et \ref{technique noise},  on a, pour toute fonction test $\varphi$, et pour $i=1,\ldots, n$
$$\E_{\vartheta}\big[\varphi(Y_i)\big] = \int_{\R}\varphi\big(z+r(\vartheta,\bx_i)\big)\PP^{\,\xi}(dz).$$

Si, de plus, la loi $\PP^{\,\xi}$ des \og bruits\fg{} admet une densité $z \leadsto g(z)$ par rapport à la mesure de Lebesgue, on a, pour $i=1,\ldots, n$
$$\E_\vartheta\big[\varphi(Y_i)\big] = \int_{\R}\varphi(z)g\big(z-r(\vartheta,\bx_i)\big)dz.$$
%La densité conditionnelle de $Y_i$ sachant $\bX_i = \bx_i$ est la fonction\footnote{définie presque-partout}
%$$y \leadsto g\big(y-f(\vartheta,\bx_i)\big),$$
%et la densité (inconditionnelle) de $Y_i$ est la fonction
%$$y \leadsto \int_{\R^k} g\big(y-f(\vartheta,\bx)\big) \PP^{\bX}(d\bx).$$
En particulier, $Y_i$ admet une densité donnée par $z \leadsto g\big(z-r(\vartheta,\bx_i)\big).$
\end{proposition}
\begin{proof}
Les deux points de la proposition sont évidents : on a
\begin{align*}
\E_\vartheta\big[\varphi(Y_i)\big] & = \E_\vartheta\big[\varphi\big(r(\vartheta,\bx_i)+\xi_i\big)\big]\\
& = \int_{\R} \varphi\big(z+r(\vartheta,\bx_i)\big)\PP^{\,\xi}(dz),
\end{align*}
en appliquant la formule de la mesure image \eqref{formule mesure image}. Si, de plus, $\PP^{\,\xi}$ admet une densité $g$, cette dernière quantité s'écrit
$$\int_{\R} \varphi\big(z+r(\vartheta,\bx_i)\big)g(z)dz = \int_{\R}\varphi(z)g\big(z-r(\vartheta,\bx_i)\big)dz.$$
\end{proof}
\begin{remarque}
\emph{
L'Hypothèse \ref{technique noise} est superflue. Dans le cas général, si on note $\PP^\xi_{\vartheta, \bx_i}$ la loi de $\xi$, dépendante de $\bx_i$ et $\vartheta$, et si cette loi admet une densité $z \leadsto g(\vartheta, \bx_i, z)$ par rapport à la mesure de Lebesgue, alors $Y_i$ aussi et sa densité est donnée par :
$$z \leadsto g\big(\vartheta, \bx_i, z-r(\vartheta,\bx_i)\big)$$
}
\end{remarque}

%Sous l'Hypothèse \ref{ancillarity}, la loi des variables explicatives $\bX_i$ n'apporte pas d'information sur le paramètre $\vartheta$ : on dit que les $\bX_i$ sont ancillaires. Nous pouvons considérer deux situations sans perdre d'information :
%\begin{itemize}
%\item Nous placer dans le modèle où les variables $\bX_i$ sont \og gelées\fg{}. Conditionellement à $\big(\bX_1 = \bx1,\ldots \bX_n=\bx_n\big)$, les variables aléatoires $Y_i$ sont indépendantes, mais pas de meme loi : on a
%$$Y_i = r(\vartheta, \bx_i)+\xi_i, \;\;i=1,\ldots,n$$
%et les $\bx_i$ sont \og gelés\fg{} une bonne fois pour toute.
%\item Laisser les variables aléatoires $\bX_i$ \og fluctuer\fg{} selon leur loi $\PP^{\bX}$ : on a alors
%$$Y_i = r(\bX_i) +\xi_i\;\;i=1,\ldots, n$$
%\end{itemize}
%ll faut bien comprendre que cela ne change rien en pratique. Mais, d'un point de vue mathématique, ce n'est pas la même chose de faire intervenir ou non l'{\it alea} des $\bX_i$ dans les propriétés des estimateurs. En particulier, on a deux points de vue pour la vraisemblance :
\subsubsection{Formule de vraisemblance}

Les variables $Y_i$ étant indépendantes le calcul de leur loi jointe est immédiat.
\begin{proposition} \label{prelim vraisemblance}
Sous les Hypothèses \ref{identif reg det}, et \ref{technique noise}, si la loi $\PP^{\,\xi}$ des \og bruits \fg{} admet une densité $z \leadsto g(z)$ par rapport à la mesure de Lebesgue sur $\R$, alors
 la loi de $(Y_1,\ldots, Y_n)$  admet une densité
 par rapport à la mesure de Lebesgue sur $\R^n$ donnée par
$$(z_1,\ldots, z_n) \leadsto \prod_{i = 1}^n g\big(z_i- r(\vartheta, \bx_i)\big).$$
\end{proposition}
\begin{proof}
Par construction, les variables aléatoires $Y_1, \ldots, Y_n$ sont indépen\-dantes, de densité $z_i \leadsto g\big(z_i- r(\vartheta, \bx_i)\big)$ par rapport à la mesure de Lebesgue.
% On applique alors la Proposition \ref{prelim vraisemblance}.
\end{proof}
On en déduit que si $\PP^{\,\xi}$ admet une densité par rapport à la mesure de Lebesgue, alors l'expérience statistique
${\mathcal E}^n_{\text{{\tt design-déter}}}$ est dominée par la mesure de Lebesgue $dz_1\cdots dz_n$ sur $\R_n$, et on a
$$\frac{d\PP_{\vartheta}^n}{dz_1\cdots dz_n}(z_1,\ldots, z_n) = \prod_{i = 1}^n g\big(z_i- r(\vartheta, \bx_i)\big).$$
\begin{corollaire}[formule de vraisemblance] \label{formule de vraisemblance}
Sous les Hypothèses \ref{identif reg det}, et \ref{technique noise}, si la loi $\PP^{\,\xi}$ des \og bruits \fg{} admet une densité $z \leadsto g(z)$ par rapport à la mesure de Lebesgue sur $\R$, alors la vraisemblance par rapport à la mesure de Lebesgue sur $\R^n$ est donnée par
$$
{\mathcal L}_n\big(\vartheta,Y_1,\ldots, Y_n\big) = \prod_{i = 1}^n g\big(Y_i - r(\vartheta, \bx_i)\big).
$$
\end{corollaire}
%\item La vraisemblance inconditionnelle des observations $(Y_1,\ldots, Y_n)$
%\begin{equation} \label{vrais incond}
%\vartheta \leadsto {\mathcal L}_n\big(\vartheta,Y_1,\ldots, Y_n\big) = \prod_{i = 1}^n\int_{\R^k}g\big(Y_i - r(\vartheta, \bx_i)\big)\PP^{\bX}(d\bx_i).
%\end{equation}
%\end{itemize}
%\end{definition}
%\subsubsection{Vraisemblance conditionnelle ou inconditionnelle ?}
%Avec quelle vraisemblance travailler \og en pratique \fg{}? Les deux formules ont leurs avantages et leurs inconvénients : le poitn de vue inconditionnel à le grand avantage que les variables aléatoires $(\bX_i, Y_i)$ sont indépendantes et identiquement distribuées. On pourrait être tenté d'appliquer alors les résultats du chapitres précédent. Mais cela ne marche pas tout à fait : les observations $(\bX_i, Y_i)$ sont certes indépendantes et identiquement distribuées, mais sur $\R^{k+1}$, un \og espace d'état\fg{} inutilement \og gros \fg{} alors que la dépendance en $\vartheta$ n'apparaît qu'au travers des $Y_i$ à valeurs dans $\R$.

%Cela se voir immédiatement dans les formules de vraisemblance : la vraisemblance inconditionnelle est plsu difficile à manipuler. Même si l'on considère la log-vraisemblance, on obtient
%$$\ell_n(\vartheta,Y_1,\ldots, Y_n) =\sum_{i = 1}^n \log\int_{\R^k}g\big(Y_i - r(\vartheta, \bx_i)\big)\PP^{\bX}(d\bx_i)$$
%et même si on fait apparaître une somme de variables aléatoires indépendantes identiquement distribuées, la présence de l'intégrale $k$-uple rend les calculs plus délicats.

%Finalement, on verra au Chapitre \ref{theorie asymptotique} que l'on ne perd jamais d'information en prenant la vraisemblance conditionnelle à des variables dont la loi ne dépend pas du paramètre : c'est le principe d'ancillarité de Fisher, voir \ref{} qui nous fera opter systématiquement en faveur de la formule \eqref{vrais cond} plutôt que \eqref{vrais incond}.

%\begin{remarque}
%\emph{
%Dans les Propositions \ref{prelim vraisemblance}, \ref{} et dans la Définition \ref{formule vraisemblance}, nous avons supposé poru simplifier que la loi $\PP^\xi$ des innovation est dominée par la mesure de Lebesgue. On peut remplacer la mesure de Lebesgue par n'importe quelle mesure $\sigma$-finie, en particulier la mesure de comptages sur le sous-ensemble ${\mathcal M}\subset \R$ au plus dénombrable des valeurs de $\PP^\xi$. Dans ce cas, les formules \eqref{vrais cond} et \eqref{vrais incond} deviennent
%$$\vartheta \leadsto {\mathcal L}_n\big(\vartheta,Y_1,\ldots, Y_n|\bX_1=\bx_1,\ldots, \bX_n = \bx_n\big) = \prod_{i = 1}^ng\big(Y_i - r(\vartheta, \bx_i)\big)$$
%et
%$$\vartheta \leadsto {\mathcal L}_n\big(\vartheta,Y_1,\ldots, Y_n\big) = \prod_{i = 1}^n\int_{\R^k}g\big(Y_i - r(\vartheta, \bx_i)\big)\PP^{\bX}(d\bx_i)$$
%respectivement.
%}
%\end{remarque}

\section{Régression linéaire simple} \label{regression lineaire simple}
\index{régression linéaire simple}
Pour les raisons invoquées plus haut, on se place désormais dans le modèle de régression à \og design \fg{} déterministe.
% et on fait les Hypothèses \ref{identif reg det}.
\subsection{Droite de régression}
%Sous les Hypothèse \ref{} et \ref{}. {\tt more comments here}
\begin{definition} On appelle modèle linéaire simple l'expérience statistique engendrée par les variables aléatoires $Y_i$ à valeurs dans $\R$ (et par le \og design \fg{} $(x_1,\ldots, x_n)$), où
$$Y_i = \vartheta_0+\vartheta_1x_i+\xi_i,\;\;i=1,\ldots,n$$
et
\begin{itemize}
\item Le paramètre inconnu est $\vartheta = (\vartheta_0,\vartheta_1)^T\in \Theta = \R^2$.
\item Les \og bruits \fg{} $\xi_i$ satisfont
$$\E_\vartheta\big[\xi_i\big]=0,\;\;\mathrm{Var}_\vartheta\big[\xi_i^2\big]=\sigma^2>0.$$
\end{itemize}
\end{definition}
Dans ce contexte, l'Hypothèse \ref{identif reg det} est automatiquement vérifiée. La variance $\sigma^2$ des \og bruits \fg{} peut elle-même être inconnue et être considérée comme un paramètre du modèle. On parle de modèle de régression simple à variance connue ou inconnue. Les paramètres $\vartheta_0$ et $\vartheta_1$ s'appellent respectivement  \og ordonnée à l'origine \fg{} et \og coefficient directeur\fg{} de la droite d'équation
$$y = r(\vartheta, x) = \vartheta_0+\vartheta_1 x.$$
Si $\widehat \vartheta_n$ est un estimateur de $\vartheta$, on note $x\leadsto r(\widehat \vartheta_n, x)$ l'estimateur de la fonction de régression (ici, une droite) associée au modèle linéaire simple.
\begin{definition}
Si $\widehat \vartheta_n$ est un estimateur de $\vartheta$ dans le modèle linéaire simple, on appelle $\widehat Y_i = r(\widehat \vartheta_n, x_i)$ la valeur de $Y_i$ prédite par l'estimateur et $\widehat \xi_i = Y_i - \widehat Y_i$ son résidu. On appelle
$$\|\widehat \xi\|^2 = \sum_{i = 1}^n \widehat \xi_i^2 = \sum_{i = 1}^n(\widehat Y_i - Y_i)^2$$
la somme résiduelle des carrés (RSS, Residual Sum of Squares)
\index{résidus}
\end{definition}
La somme résiduelle des carrés mesure l'erreur (au sens de la norme euclidienne) entre les observations $Y_i$ et les observations prédites par l'estimateur
$r(\widehat \vartheta_n, x_i)$.
\begin{definition}
%[Moindres carrés dans le modèle linéaire simple]
L'estimateur des moindres carrés dans le modèle linéaire simple (à variance connue) est l'estimateur $\estMC$ qui minimise la somme résiduelle des carrés :
$$\sum_{i = 1}^n\big(Y_i - r(\estMC, x_i)\big)^2 = \min_{\vartheta \in \R^2}\sum_{i = 1}^n\big(Y_i - r(\vartheta,x_i)\big)^2,$$
où l'infimum est pris sur l'ensemble des estimateurs possibles de $\vartheta$ construits à partir des observations $Y_i$, $i=1,\ldots, n$.
\end{definition}
\begin{proposition} \label{MC}
On a  $\estMC = \big(\widehat \vartheta_{n,0}^{\,{\tt mc}}, \widehat \vartheta_{n,1}^{\,{\tt mc}}\big)^T$, avec
$$\widehat \vartheta_{n,0}^{\,{\tt mc}} = \overline{Y}_n - \widehat \vartheta_{n,1}^{\,{\tt mc}} \overline{x}_n,$$
et
\begin{align*}
\widehat \vartheta_{n,1}^{\,{\tt mc}} & = \frac{\sum_{i = 1}^n(x_i-\overline{x}_n)(Y_i-\overline{Y}_n)}{\sum_{i = 1}^n(x_i - \overline{x}_n)^2}\\
& = \frac{\sum_{i = 1}^n x_i(Y_i-\overline{Y}_n)}{\sum_{i = 1}^n(x_i-\overline{x}_n)^2} = \frac{\sum_{i = 1}^n(x_i-\overline{x}_n)Y_i}{\sum_{i = 1}^n(x_i-\overline{x}_n)^2},
\end{align*}

où $\overline{x}_n = \tfrac{1}{n}\sum_{i = 1}^n x_i$ et $\overline{Y}_n = \tfrac{1}{n}\sum_{i = 1}^n Y_i$.
\end{proposition}
\begin{proof}
En anticipant, on peut appliquer la Proposition \ref{emc multiple} ou bien retrouver directement le résultat : on cherche les points critiques de la fonction $$(\vartheta_0,\vartheta_1)\leadsto L_n(\vartheta_0,\vartheta_1) = \sum_{i = 1}^n\big(Y_i - \vartheta_0-\vartheta_1 x_i \big)^2.$$
On a
$$
\left\{
\begin{array}{lll}
\partial_{\vartheta_0} L_n(\vartheta_0,\vartheta_1) & = & -2\sum_{i = 1}^n (Y_i-\vartheta_0-\vartheta_1 x_i)  \\
\partial_{\vartheta_1} L_n(\vartheta_0,\vartheta_1) & = &  -2\sum_{i = 1}^n x_i(Y_i-\vartheta_0-\vartheta_1 x_i),
\end{array}
\right.
$$
et donc $\nabla L_n(\vartheta_0,\vartheta_1)=0$ si et seulement si
$$
\left\{
\begin{array}{lll}
-\sum_{i = 1}^n Y_i + n\vartheta_0+\vartheta_1\sum_{i =1}^n x_i & = & 0 \\
-\sum_{i = 1}^n x_iY_i+\vartheta_0\sum_{i = 1}^n x_i +\vartheta_1\sum_{i = 1}^nx_i^2 &= & 0,
\end{array}
\right.
$$
ce qui fournit $\vartheta_0 = \overline{Y}_n-\vartheta_1\overline{x}_n$ en isolant $\vartheta_0$, puis $(\vartheta_0,\vartheta_1)=\big(\widehat \vartheta_{n,0}^{\,{\tt mc}}, \widehat \vartheta_{n,1}^{\,{\tt mc}}\big)$ par substitution. La fonction $L_n$ est quadratique et tend vers $+\infty$ en l'infini, l'unique point critique est bien un minimum global.

%\begin{center}
%{\tt INSERT HERE SUPPL. 22}
%\end{center}
\end{proof}
%\begin{remarque}
%\emph{
Cette preuve élémentaire s'affranchit d'hypothèses probabilistes sur le modèle : le résultat de la Propostion \ref{MC} ne nécessite aucune propriété sur les $\xi_i$.
\index{moindres carrés, estimateur des}
L'estimation de $\sigma^2$ est en revanche plus subtile. On peut penser à prendre la moyenne empirique du carré des résidus
$$\widehat \sigma^2_n = \frac{1}{n}\sum_{i = 1}^n \widehat \xi_n^2 = \frac{1}{n}\sum_{i = 1}^n \big(Y_i - r(\widehat \vartheta_n^{\,\tt mc},x_i)\big)^2,$$
mais les variables aléatoires $\widehat \xi_n^2 $ ne sont pas indépendantes, puisque $\estMC$ fait intervenir toutes les variables $Y_i$.

Le résultat suivant donne le comportement de la moyenne et de la variance de $\widehat \vartheta_{n}^{\,{\tt mc}}$.
\begin{proposition}
%Sous les Hypothèse \ref{},
Dans le modèle de régression linéaire simple, l'estimateur des moindres carrés $\widehat \vartheta_{n}^{\,{\tt mc}}$ vérifie
$$\E_\vartheta\big[\widehat \vartheta_{n}^{\,{\tt mc}}\big] = \big(\vartheta_0,\vartheta_1\big)^T,$$
et la matrice de variance-covariance de $\estMC$ est donnée par
$$
%\mathrm{Var}_\vartheta\big[\widehat \vartheta_{n}^{\,{\tt mc}}\big]
\Sigma\big[\estMC\big]  = \E_\vartheta\big[(\estMC-\vartheta)(\estMC-\vartheta)^T\big]
 = \frac{\sigma^2}{n s_n^2}
\left(
\begin{array}{cc}
\displaystyle \frac{1}{n}\sum_{i = 1}^n x_i^2 & -\overline{x}_n\\ \\
\displaystyle -\overline{x}_n & 1\\
 \end{array}
\right),
 $$
 où
 $$s_n^2 = \frac{1}{n}\sum_{i = 1}^n(x_i - \overline{x}_n)^2.$$
\end{proposition}
\begin{proof}
Comme pour la preuve de la Proposition \ref{MC} on peut appliquer en anticipant la Proposition \ref{proprietes moindres carres} ou bien démontrer le résultat directement.
\end{proof}
\begin{remarque}
\emph{
Sans hypothèse supplémentaire sur la loi des innovations, il est difficile de préciser ces résultats.
%{\t more comments here}
}
\end{remarque}


\subsection{Moindres carrés et maximum de vraisemblance}
Nous allons faire une hypothèse supplémentaire sur la distribution des \og bruits \fg{} $\xi_i$ qui nous permettra de construire un estimateur de $\sigma^2$.
\begin{hypothese} \label{MC is MLE}
Les \og bruits \fg{} $\xi_i$ sont indépendants, de même loi ${\mathcal N}(0,\sigma^2)$.
\end{hypothese}
Sous cette hypothèse forte qui renforce l'Hypothèse \ref{technique noise}, l'estimateur du maximum de vraisemblance  fournit un estimateur du paramètre
$(\vartheta_0,\vartheta_1,\sigma^2)$ dont les deux premières composantes coïncident avec l'estimateur des moindres carrés de la Proposition \ref{MC}.
\begin{proposition} \label{MC is MLE simple}
Sous l'Hypothèse \ref{MC is MLE}, l'estimateur du maximum de vraisemblance
$$\widehat \vartheta_n^{\,\tt mv} = \big(\widehat \vartheta_{n,0}^{\,{\tt mv}}, \widehat \vartheta_{n,1}^{\,{\tt mv}}, \widehat \sigma_n^2\big)$$
est bien défini. On a
$$\big(\widehat \vartheta_{n,0}^{\,{\tt mv}}, \widehat \vartheta_{n,1}^{\,{\tt mv}} \big)=  \big(\widehat \vartheta_{n,0}^{\,{\tt mc}}, \widehat \vartheta_{n,1}^{\,{\tt mc}}\big),$$
et
$$\widehat \sigma_n^2 = \frac{1}{n}\sum_{i = 1}^n\big(\widehat \xi_i\big)^2,\;\;\text{où}\;\;\; \widehat \xi_i = Y_i - r(\widehat \vartheta_n^{\,\tt mc},x_i).$$
\end{proposition}
\begin{proof}
D'après le Corollaire \ref{formule de vraisemblance}, si $g_\sigma(x)=(2\pi\sigma^2)^{-1/2}\exp(-x^2/2\sigma^2)$ désigne la densité de la loi ${\mathcal N}(0,\sigma^2)$, la vraisemblance de l'expérience statistique est donnée par
$$
{\mathcal L}_n\big(\vartheta_0,\vartheta_1,\sigma^2, Y_1,\ldots, Y_n\big) = \prod_{i = 1}^ng_\sigma\big(Y_i - r(\vartheta, x_i)\big),
$$
et la log-vraisemblance vaut alors
$$\ell_n(\vartheta_0,\vartheta_1,\sigma^2, Y_1,\ldots, Y_n) = -\frac{n}{2}\log \sigma^2-\frac{1}{2\sigma^2}\sum_{i = 1}^n(Y_i-\vartheta_0-\vartheta_1 x_i)^2.$$
On a
$$\partial_{\sigma^2}\ell_n(\vartheta_0,\vartheta_1,\sigma^2, Y_1,\ldots, Y_n) = -\frac{n}{2\sigma^2}+\frac{1}{2\sigma^4}\sum_{i = 1}^n (Y_i-\vartheta_0-\vartheta_1x_i)^2$$
et ce terme est nul si et seulement si
$$\sigma^2 = \frac{1}{n} \sum_{i = 1}^n (Y_i-\vartheta_0-\vartheta_1x_i)^2.$$
Par ailleurs, le calcul de $\partial_{\vartheta_0}\ell_n(\vartheta_0,\vartheta_1,\sigma^2, Y_1,\ldots, Y_n)$ et $\partial_{\vartheta_1}\ell_n(\vartheta_0,\vartheta_1,\sigma^2, Y_1,\ldots, Y_n)$ mène à une constante multiplicative près à celui des fonctions  $\partial_{\vartheta_i} L_n(\vartheta_0,\vartheta_1,Y_1,\ldots, Y_n)$, pour $i=0,1$ de la preuve de la Proposition \ref{MC}. On en déduit le point annoncé $\estMV$ comme l'unique point critique de la fonction de vraisemblance, et on vérifie que c'est bien un maximum global.
%\begin{center}
%{\tt INSERT HERE SUPPL. 24}
%\end{center}
\end{proof}
%\begin{remarque}
%\begin{center}
%{\tt INSERT HERE SUPPL. 25}
%\end{center}
%%le cas gaussien hyper standard
%\end{remarque}
\section{Régression linéaire multiple}
\subsection{Modèle linéaire}
\index{régression linéaire multiple}
On généralise le modèle de régression linéaire simple en autorisant des points de \og design\fg{} vectoriels. On considère l'expérience statistique engendrée par l'observation de
$$(\bx_1,Y_1),\ldots, (\bx_n,Y_n)$$
avec
\begin{equation} \label{modele lineaire standard}
Y_i = \vartheta^T \bx_i + \xi_i,\;\;i=1,\ldots, n
\end{equation}
où les $Y_i$ sont à valeurs dans $\R$, les variables explicatives $\bx_i$ sont à valeurs dans $\R^k$, et le paramètre $\vartheta \in \Theta = \R^d$ est $k$-dimensionnel, c'est-à-dire $d=k$. Matriciellement, si l'on désigne par $\mathbb{M}$ la matrice dont les colonnes sont les composantes des vecteurs ${\bx_i}$, c'est-à-dire, si l'on note $\bx_i = (x_{i,1},\ldots, x_{i,k})^T$,
%$$
%\mathfrak{X} =
%\left(
%\begin{array}{cccc}
%X_{1,1} & X_{1,2} & \ldots & X_{1,k} \\
%\cdots & \cdots & \cdots &\cdots \\
%X_{i,1} & X_{i,2} & \ldots & X_{i,k} \\
%\cdots & \cdots & \cdots &\cdots \\
%X_{n,1} & X_{n,2} & \ldots & X_{n,k} \\
%\end{array}
%\right)
%$$
$$
\design =
\left(
\begin{array}{cccc}
x_{1,1} & x_{1,2} & \ldots & x_{1,k} \\
\cdots & \cdots & \cdots &\cdots \\
x_{i,1} & x_{i,2} & \ldots & x_{i,k} \\
\cdots & \cdots & \cdots &\cdots \\
x_{n,1} & x_{n,2} & \ldots & x_{n,k} \\
\end{array}
\right)
$$
et la représentation \eqref{modele lineaire standard} s'écrit de la même manière
\begin{equation} \label{representation matricielle}
{\bf Y} = \mathbb{M}\,\vartheta + \boldsymbol{\xi},
\end{equation}
où ${\bf Y} = (Y_1,\ldots, Y_n)^T$ et $\boldsymbol{\xi} = (\xi_1,\ldots, \xi_n)^T$. Comme pour le modèle de régression linéaire simple, nous faisons une hypothèse sur le \og bruit\fg{} $\boldsymbol{\xi}$ :
\begin{equation} \label{hyp bruit minimale}
\E\big[\boldsymbol{\xi}\big]=0,\;\;\;\E\big[\boldsymbol{\xi}\boldsymbol{\xi}^T\big]=\sigma^2\mathrm{Id}_n.
\end{equation}
%la suivante : pour tous $1,\leq i,j\leq n$,
%$$\E_\vartheta\big[\xi_i\big]=0,\;\;\;\text{et}\;\;\;\E\big[\xi_i\xi_j\big] = \sigma^2 \delta_{ij},$$
%où $\delta_{ij}$ est le symbole de Kronecker.
%On suppose les Hypothèses \ref{ancillary} et \ref{identif reg}, vérifiées, et on suppose de plus comme dans la Section \ref{} {\tt more here}.
%\begin{hypothese} On a
%$$\mathrm{Var}_\vartheta\big[\xi_i\,|\,\bX_i\big] = \sigma^2 >0.$$
%\end{hypothese}
%Sous l'Hypothèse \ref{ancillarity}, on peut raisonner conditionnellement à
%$$(\bX_1 = \bx_1,\ldots, \bX_n = \bx_n),$$
%ce que l'on fait à partir de maintenant. On note de la même manière que dans la représentation matricielle \eqref{representation matricielle}
%$$
%\design =
%\left(
%\begin{array}{cccc}
%x_{1,1} & x_{1,2} & \ldots & x_{1,k} \\
%\cdots & \cdots & \cdots &\cdots \\
%x_{i,1} & x_{i,2} & \ldots & x_{i,k} \\
%\cdots & \cdots & \cdots &\cdots \\
%x_{n,1} & x_{n,2} & \ldots & x_{n,k} \\
%\end{array}
%\right)
%$$
%pour la matrice des variables explicatives conditionellement aux $\bX_i = \bx_i$, avec
%$\bx_i = (x_{i,1},\ldots, x_{i,k})^T$.

%En termes matriciels, cela signifie simplement que l'on raisonne conditionnellement à $\mathfrak{X} = \design$, c'est-à-dire on travaille avec $(\design, {\bf Y})$, où
%$${\bf Y} = \design \vartheta + \boldsymbol{\xi}.$$

\subsection{Estimateur des moindres carrés}

Dans ce contexte, on cherche l'estimateur des moindres carrés pour $\vartheta$, c'est-à-dire l'estimateur $\widehat \vartheta_n^{\,\,{\tt mc}}$ qui minimise la somme du carré des résidus :
$$
\sum_{i = 1}^n \big(Y_i - (\estMC)^T\bx_i \big)^2 = \min_{\vartheta \in \R^k}\sum_{i =1}^n \big(Y_i - \vartheta^T \bx_i\big)^2.
$$
Il existe toujours une solution à ce problème de minimisation
%{\tt check ce que l'on veut dire},
mais elle n'est pas nécessairement unique.
\index{moindres carrés, estimateur des}
\begin{definition} On appelle estimateur des moindres carrés tout estimateur $\estMC$ satisfaisant
$$\estMC \in \mathrm{arg} \min_{\vartheta \in \R^k}\sum_{i = 1}^n\big(Y_i - \vartheta^T\bx_i\big)^2.$$
\end{definition}
Une condition suffisante d'unicité de l'estimateur des moindres carrés est la suivante :
\begin{proposition} \label{emc multiple}
On suppose la matrice $\design^T\design$ inversible. Alors l'estimateur des moindres carrés est unique et s'écrit
$$\estMC = \big(\design^T\design\big)^{-1}\design^T {\bf Y}.$$
\end{proposition}
Nous donnons deux preuves et deux interprétations de ce résultat :
\subsubsection{Méthode analytique}
\begin{proof}
Le point $\estMC$ est nécessairement un point critique de l'application
$$\vartheta \leadsto h(\vartheta) = \sum_{i = 1}^n \big(Y_i-\vartheta^T\bx_i\big)^2,$$
c'est-à-dire il est solution du système de $k$ équations
$$\partial_{\vartheta_j}h\big(\estMC\big) = 0,\;\;\;j=1,\ldots,k,$$
ce qui s'écrit
$$2 \sum_{i = 1}^n \bx_i\big(Y_i - \big(\estMC \big)^T\bx_i\big) = 0$$
ou encore, sous forme matricielle :
\begin{equation} \label{eq normales}
\design^T\design \estMC = \design^T {\bf Y}.
\end{equation}
L'équation \eqref{eq normales} est un système de $k$ équations qui a une solution unique dès lors que $\design^T\design$ est inversible, donnée par
$$\estMC = \big(\design^T\design\big)^{-1}\design^T {\bf Y}.$$
La fonction $\vartheta \leadsto h(\vartheta)$ est convexe et positive, donc la solution $\estMC$ est un minimum global. %{\tt check}.
\end{proof}
\begin{definition}
L'équation \eqref{eq normales} est appelée système d'équations normales pour la méthode des moindres carrés.
\end{definition}
\begin{proposition} \label{rem rang}
La matrice $\design^T\design$ est (symétrique) positive. Elle est définie positive si et seulement si $\mathrm{rang}(\design) = k$.
\begin{proof}
On a, pour $v \in \R^k$
$$v^T\big(\design^T\design\big)v = w^Tw \geq 0$$
où l'on a posé implicitement $w = \design v$. Le cas d'égalité est vérifié si et seulement si $w = 0$, c'est-à-dire, $\design v = 0$. Si $\mathrm{rang}(\design)<k$, alors il existe $v \neq 0$ tel que $\design v =0$ et dans ce cas, $\design^T \design$ n'est pas strictement positive. Réciproquement, si $\design^T \design $ n'est pas strictement positive, alors il existe  $v \neq 0$ tel que $v^T\big(\design^T\design\big)v =0$, et donc $\design v=0$ d'où $\mathrm{rang}(\design)<k$.
\end{proof}
\end{proposition}
\begin{remarque}
\emph{
En conséquence, si la taille de l'échantillon est plus petite que la dimension du paramètre $\vartheta$, c'est-à-dire si $n < k$, la matrice $\design^T\design$ est dégénérée.
%{\tt mais...}
}
\end{remarque}
\subsubsection{Méthode géométrique}
\begin{proof}[Deuxième démonstration de la Proposition \ref{emc multiple}] Soit $V$ l'image de $\R^n$ par l'application linéaire de $\R^n$ dans $\R^k$ de matrice $\design$, c'est-à-dire
$$V = \big\{v \in \R^n,\;\;v=\design\vartheta,\, \vartheta \in \R^k\big\}.$$
Alors, pour tout $y\in \R^n$,
$$\min_{\vartheta \in \R^k}\|y- \design\vartheta\|^2 = \min_{v \in V}\|y-v\|^2,$$
où $\|v\|^2 = v^Tv$ désigne le carré de la norme euclidienne. Notons que $\design$ est de rang $k$ si et seulement si la dimension de $V$ est $k$.
D'après la Proposition \ref{rem rang}, puisque $\design^T\design$ est supposée inversible, on a bien $\dim V = k$. Alors, si $P_V$ désigne la matrice du projecteur orthogonal sur $V$ dans $\R^n$, on a $\mathrm{rang}(P_V) = k$ et l'estimateur des moindres carrés vérifie
\begin{equation} \label{projection}
\design\estMC = P_V{\bf Y},
\end{equation}
ce qui se traduit par
$$\langle {\bf Y}-P_V{\bf Y},v\rangle = 0,\;\;\text{pour tout}\;\;v \in V,$$
où, pour $u,v \in \R^n$, on note $\langle u,v\rangle = u^Tv$ le produit scalaire euclidien. En appliquant \eqref{projection}, l'équation précédente s'écrit encore pour tout $v \in V$
$$\langle \design\estMC,v\rangle = \langle {\bf Y},v\rangle,$$
c'est-à-dire, pour tout $\vartheta \in \R^k$
$$\langle \design\estMC,\design\vartheta\rangle = \langle {\bf Y},\design\vartheta\rangle,$$
soit, pour tout $\vartheta \in \R^k$
$$\langle \design^T\design\estMC, \vartheta\rangle = \langle \design^T{\bf Y},\vartheta\rangle.$$
Puisque $\design^T\design$ est inversible, on en déduit $\estMC =  \big(\design^T\design\big)^{-1}\design^T {\bf Y}$.
\end{proof}
\begin{remarque}
\emph{
A ce stade de l'étude, comme pour le cas de la régression linéaire simple, on n'a pas besoin de faire d'hypothèse probabiliste sur le modèle. La méthode des moindres carrés dépasse le cadre de l'estimation statistique et apparaît plus généralement comme une méthode de \og régularisation \fg{} en analyse numérique.
%Cependant, des hypothèses probabilistes sur le \og bruit \fg{} $\boldsymbol{\xi}$ permettent d'affiner significativement ses propriétés.
}
\end{remarque}
\subsection{Propriétés de la méthode des moindres carrés}
%On suppose que le \og bruit \fg{} $\boldsymbol{\xi}$ satisfait \eqref{hyp bruit minimale}.
\begin{proposition} \label{proprietes moindres carres}
Supposons la matrice $\design^T\design$ inversible, et que le \og $\boldsymbol{\xi}$ \fg{} satisfait \eqref{hyp bruit minimale}.
On a
$$\E_\vartheta\big[\estMC\big] = \vartheta,$$
et la matrice de variance-covariance de $\estMC$ est donnée par
%\begin{align*}
$$\Sigma\big[\estMC\big]  = \E_\vartheta\big[(\estMC-\vartheta)(\estMC-\vartheta)^T\big]
 = \sigma^2 \big(\design^T\design\big)^{-1}.
%\end{align*}
$$
\end{proposition}
\begin{proof}
On a
$$\estMC = \big(\design^T\design\big)^{-1}\design^T{\bf Y} = \big(\design^T\design\big)^{-1}\design^T\big(\design\vartheta+\boldsymbol{\xi}\big) = \vartheta + \big(\design^T\design\big)^{-1}\design^T \boldsymbol{\xi},$$
d'où la première partie de la proposition, puisque $\E_\vartheta\big[\boldsymbol{\xi}\big] = 0$. Puis,
\begin{align*}
&  \E_\vartheta\big[(\estMC-\vartheta)(\estMC-\vartheta)^T\big] \\
 =&   \E_\vartheta\big[\big(\design^T\design\big)^{-1}\design^T \boldsymbol{\xi}\big(\boldsymbol{\xi}^T\design \big(\design^T\design\big)^{-1}\big)\big] \\
   = & \big(\design^T\design\big)^{-1}\design^T \E_\vartheta\big[\boldsymbol{\xi}\boldsymbol{\xi}^T\big]\design  \big(\design^T\design\big)^{-1}.
\end{align*}
Puisque $\E_\vartheta\big[\boldsymbol{\xi}\boldsymbol{\xi}^T\big] = \sigma^2 \mathrm{Id}_n$, le dernier terme devient
$$\big(\design^T\design\big)^{-1}\design^T\sigma^2\design  \big(\design^T\design\big)^{-1} = \sigma^2 \big(\design^T\design\big)^{-1}.$$
\end{proof}
\begin{proposition}[Estimation de la variance $\sigma^2$] \label{estimation de la variance sigma}
On suppose la matrice $\design^T\design$ inversible, et que le \og bruit \fg{} $\boldsymbol{\xi}$ satisfait \eqref{hyp bruit minimale}. Alors l'estimateur
$$\widehat \sigma_n^2 = \frac{\|{\bf Y}-\design\estMC\|^2}{n-k} = \frac{1}{n-k}\sum_{i = 1}^n\big(Y_i - \big(\estMC\big)^T\bx_i\big)^2$$
vérifie
$$\E\big[\widehat \sigma_n^2\big] = \sigma^2.$$
\end{proposition}
%\begin{remarque}
%{\tt sur le fait de diviser par $n-k$ et non par $n$}
%\end{remarque}
\begin{proof}
On a la décomposition
\begin{align*}
{\bf Y}-\design\estMC & = \design(\vartheta - \estMC)+\boldsymbol{\xi} \\
 & = -\design \big(\design^T \design\big)^{-1} \design^T \boldsymbol{\xi} + \boldsymbol{\xi} \\
 & = (\mathrm{I}_n-P_V)\boldsymbol{\xi},
 \end{align*}
où $V \subset \R^n$ est l'image de $\R^k$ par l'application linéaire de matrice $\design$
comme précédemment. Par conséquent
\begin{align*}
\E_\vartheta\big[\|{\bf Y}-\design \estMC\|^2\big] & = \E_\vartheta\big[\boldsymbol{\xi}^T\big(\mathrm{I}_n-P_V\big)^T\big(\mathrm{I}_n-P_V\big)\boldsymbol{\xi}\big] \\
& = \E_\vartheta\big[\boldsymbol{\xi}^T\big(\mathrm{I}_n-P_V\big)^2\boldsymbol{\xi}\big] \\
& =  \E_\vartheta\big[\boldsymbol{\xi}^T\big(\mathrm{I}_n-P_V\big)\boldsymbol{\xi}\big],
\end{align*}
où l'on utilise le fait que la matrice $\mathrm{I}_n-P_V$ est symétrique et idempotente.
%Notons $(v_{i,j})_{1 \leq i,j \leq n}$ les éléments de la matrice $P_V$.
Il vient
\begin{align*}
\E_\vartheta\big[\boldsymbol{\xi}^T\big(\mathrm{I}_n-P_V\big)\boldsymbol{\xi}\big] & = \E_\vartheta\big[\mathrm{trace}\big(\boldsymbol{\xi}^T\big(\mathrm{I}_n-P_V\big)\boldsymbol{\xi}\big)\big] \\
& = \E_\vartheta\big[\mathrm{trace}\big(\mathrm{I}_n-P_V\big)\boldsymbol{\xi}\boldsymbol{\xi}^T\big] \\
& = \mathrm{trace}\Big(\big(\mathrm{I}_n-P_V\big)\E_\vartheta\big[\boldsymbol{\xi}\boldsymbol{\xi}^T\big]\Big) \\
& = \sigma^2 (n-k).
%\sum_{i,j=1}^n(\delta_{i,j}- v_{i,j})\E_{\vartheta}\big[\xi_i \xi_j\big] \\
%& = \sigma^2 \sum_{i,j=1}^n (1-v_{i,i}) = \sigma^2 \big(n - \mathrm{Tr}(P_V)\big)
\end{align*}
%où $\delta_{i,j}$ est le symbole de Kronecker.
\end{proof}
%\begin{remarque}
%{\tt par de gaussianité ici}
%\end{remarque}
\subsection{Régression linéaire multiple gaussienne}
\index{régression linéaire gaussienne}
\subsubsection{Loi des estimateurs}
On fait l'hypothèse supplémentaire que  $\boldsymbol{\xi}$ est un vecteur gaussien, dont les composantes sont indépendantes, ce qui revient exactement à l'Hypothèse \ref{MC is MLE}. On a alors la loi explicite de l'estimateur des moindres carrés.
%une généralisation de la Proposition \ref{MC is MLE simple}
%\begin{hypothese}[Gaussianité du \og bruit\fg{}] \label{gaussianite}
%On a
%$$\boldsymbol{\xi} \sim \mathcal{N}\big(0,\sigma^2\mathrm{I}_n\big).$$
%\end{hypothese}
\begin{proposition} \label{application cochran}
On se place sous l'Hypothèse \ref{MC is MLE} et on suppose que la matrice $\design^T\design$ inversible.
\begin{itemize}
\item[(i)] l'estimateur des moindres carrés $\estMC$ est un vecteur gaussien $k$-dimensionnel  de moyenne $\vartheta$ et de matrice de variance-covariance $\sigma^2 \big(\design^T \design\big)^{-1}\vspace{2mm}$,
\item[(ii)] les vecteurs aléatoires $\estMC$ et ${\bf Y}-\design \estMC$ sont indépendants (et de même, les vecteurs aléatoires $\design (\estMC-\vartheta)$ et ${\bf Y} - \design \estMC$ sont indépendants){\vspace{2mm}},
\item[(iii)] la variable aléatoire $\sigma^{-2}\|{\bf Y}-\design \estMC\|^2$ suit la loi $\chi^2(n-k)$ du $\chi^2$ à $n-k$ degrés de liberté, et  $\sigma^{-2}\|\design(\estMC-\vartheta)\|^2$ suit la loi $\chi^2(k)$ du $\chi^2$ à $k$ degrés de liberté.
\end{itemize}
\end{proposition}
\begin{proof}
On écrit, comme pour la preuve de la Proposition \ref{proprietes moindres carres}
$$\estMC = \vartheta + \big(\design^T\design\big)^{-1}\design^T \boldsymbol{\xi},$$
et on en déduit immédiatement  le point (i): $\estMC$ est un vecteur gaussien comme transformation affine de $\boldsymbol{\xi}$ qui est un vecteur gaussien ; la moyenne de $\estMC$ est $\vartheta$ et sa matrice de variance-covariance $\sigma^2 \big(\design^T \design\big)^{-1}$ d'après la Proposition \ref{proprietes moindres carres}.

On a aussi
$${\bf Y}-\design \estMC = (\mathrm{Id}_n-P_V)\boldsymbol{\xi}$$
avec les notations de la preuve de la Proposition \ref{estimation de la variance sigma}. Donc $(\estMC, {\bf Y}-\design \estMC)$ est un vecteur gaussien de $\R^{k+n}$ comme transformation affine du vecteur gaussien $\boldsymbol{\xi}$. Pour montrer l'indépendance dans (ii), on applique la Proposition \ref{correlation=independance en gaussien}. Il vient
\begin{align*}
\Sigma\big[\estMC,{\bf Y}-\design \estMC\big] & = \E_\vartheta\big[(\estMC-\vartheta)({\bf Y}-\design \estMC)^T\big] \\
& = \E_\vartheta\big[(\design^T\design)^{-1}\design^T{\boldsymbol \xi}{\boldsymbol \xi}^T(\mathrm{Id}_n-P_V)\big] \\
& = 0,\\
\end{align*}
car $P_V$ s'écrit $P_V = \design\big(\design^T \design \big)^{-1}\design^T$. Donc $\estMC$ et ${\bf Y}-\design \estMC$ sont indépendants, et par suite  $\design(\estMC-\vartheta)$ et  ${\bf Y}-\design \estMC$ sont indépendants.

Le point (iii) est une application de la Proposition \ref{cochran} (Cochran) : le vecteur  ${\boldsymbol \xi}' = \sigma^{-1}{\boldsymbol \xi}$ est gaussien de matrice de variance-covariance l'identité sur $\R^n$. De plus
$${\bf Y}-\design \estMC = \sigma(\mathrm{Id}_n-P_V){\boldsymbol \xi}',\;\;\;\;
\design(\estMC-\vartheta) = \sigma P_V {\boldsymbol \xi}'$$
et les matrices $P_V$ et $\mathrm{Id}_n-P_V$ sont idempotentes, voir la preuve de la Proposition \ref{proprietes moindres carres}, et on a $(\mathrm{Id}_n-P_V)P_V=0$, avec $\text{Rang}(P_V)=k$ et  $\text{Rang}(\mathrm{Id}_n-P_V)=n-k$.
\end{proof}
\subsubsection{Remarque sur la loi des estimateurs et l'approche asymptotique}
Dans le cas où $\boldsymbol{\xi}$ est un vecteur gaussien, les lois de $\estMC$ et $\widehat \sigma_n^2$ sont explicites, à $n$ fixé. Il s'agit d'un résultat exact sur les lois des estimateurs dans un cadre non-asymptotique\footnote{On dit parfois \og à distance finie\fg{}.}. Ceci n'est plus vrai si la loi des innovations n'est pas gaussienne. Dans ce cas, on essaye de se ramener au cas gaussien par des arguments asymptotiques.
% si les innovations ont un moment d'ordre 2.

Par exemple, dans le cas le plus simple où l'on observe
$$Y_i = \vartheta + \xi_i,\;\;i=1,\ldots, m$$
où les innovations $\xi_i$ sont indépendantes, identiquement distribuées -- mais pas nécessairement gaussiennes -- de moyenne $0$ et de variance $\tau^2 >0$ et $\vartheta \in \Theta = \R$. Alors, on observe aussi
$$\overline{Y}_m = \vartheta + \frac{1}{\sqrt{m}}\,\widetilde \xi^{(m)},$$
où $\widetilde \xi^{(m)}  = \tfrac{1}{\sqrt{m}}\sum_{i = 1}^m \xi_i$ est une variable \og asymptotiquement gaussienne \fg{} par le théorème central limite, dans le sens où $\widetilde \xi^{(m)} \stackrel{d}{\rightarrow} {\mathcal N}(0,\tau^2)$ dans la limite $m\rightarrow \infty$. On est donc ramené au cas de la régression gaussienne, mais dans un cadre dégénéré : ici, on a $k=d=1$, $\design = 1$ et $\sigma^2 = \tfrac{\tau^2}{m}$ et $n=1$ (une seule observation). Le cas d'une dimension plus grande et d'un \og design \fg{} non-dégénéré est plus délicat à traiter : on peut chercher à \og regrouper \fg{} les observations en faisant des moyennes, de sorte de se ramener au cas gaussien via le théorème central-limite. Nous ne développons pas ce point.

En conclusion, l'obtention de lois explicites pour l'estimateur des moindres carrés dans un cadre non-asymptotique est un fait remarquable, mais à considérer avec précaution du point de vue de la modélisation : l'hypothèse de gaussianité sur les innovations est en fait elle-même de nature asymptotique.

\section{Régression non-linéaire}
\index{régression non-linéaire}
\subsection{Moindres carrés non-linéaires et $M$-estimation}
\subsubsection{Situation}
On se place dans le contexte général de la Section \ref{regression design deterministe}. On fait l'Hypothèse \ref{identif reg det} et on observe
$$(\bx_1, Y_1,\ldots, \bx_n, Y_n),$$
où
\begin{equation} \label{regression nonlineaire}
Y_i = r(\vartheta, \bx_i)+\xi_i,\;\;i=1,\ldots, n,
\end{equation}
%On peut donc considérer les modèle conditionellement à $(\bX_1 = \bx_1,\ldots, \bX_n = \bx_n)$, et donc \og ignorer\fg{} le caractère aléatoire des $\bX_i$. On supposera donc sans perdre de généralités que l'on observe
%\begin{equation} \label{regression nonlineaire} Y_i = r(\vartheta,\bx_i)+\xi_i,\;\;i=1,\ldots, n
%\end{equation}
où les $\bx_i \in \R^k$ sont donnés et $\vartheta \in \Theta \subset \R^d$ est le paramètre inconnu. Contrairement à la section précédente, on ne suppose plus $r(\vartheta,\cdot)$ linéaire, et il n'y a donc plus de raison de supposer $d = k$.
\subsubsection{Vraisemblance et moindres carrés}
Imposons pour simplifier l'hypothèse de gaussianité \ref{MC is MLE} sur les innovations $\xi_i$, qui sont donc indépendantes, de même loi ${\mathcal N}(0,\sigma^2)$. Dans ce cas, la log-vraisemblance
s'écrit
$$\ell_n(\vartheta, Y_1,\ldots, Y_n) = -\frac{n}{2}\log(2\pi \sigma^2)-\frac{1}{2\sigma^2}\sum_{i = 1}^n \big(Y_i - r(\vartheta,\bx_i)\big)^2.$$
Le calcul de l'estimateur du maximum de vraisemblance $\estMV$ de $\vartheta$ consiste à minimiser la fonction
$$\vartheta \leadsto \sum_{i = 1}\big(Y_i - r(\vartheta, \bx_i)\big)^2.$$
Dans le cas du modèle linéaire de la Section \ref{regression lineaire simple}, si l'on postule la forme $r(\vartheta,\bx) = \vartheta^T \bx$ avec $d=k$, on retrouve aussi l'estimateur des moindres carrés. De manière générale, sans hypothèse particulière sur les innovations $\xi$, on peut poser la définition
\begin{definition}[Estimateur des moindres carrés non-linéaires]
Etant donné le modèle de régression non-linéaire \eqref{regression nonlineaire}, on appelle estimateur des moindres carrés non-linéaires, s'il existe,  tout estimateur
$\estMCNL$ satisfaisant
$$\sum_{i = 1}^n \big(Y_i - r(\estMCNL, \bx_i)\big)^2 = \inf_{\vartheta \in \Theta}\sum_{i = 1}^n \big(Y_i - r(\vartheta, \bx_i)\big)^2.$$
\end{definition}

Cette définition se généralise très naturellement à une notion de $M$-estimateur de la façon suivante. On se donne une application
$$\psi : \Theta \times \R^k \times \R \rightarrow \R$$
jouant le même rôle que l'application $\psi(\cdot,\cdot)$ de la Section \ref{M estimation densite} du Chapitre \ref{estimation densite} pour l'estimation dans le modèle de densité, à ceci près qu'on l'autorise désormais à dépendre de  $\bx_i$.
\begin{definition}
On appelle $M$-estimateur associé à la fonction de contraste $\psi$ tout estimateur $\widehat \vartheta_n$ satisfaisant
$$\sum_{i = 1}^n \psi(\widehat \vartheta_n, \bx_i, Y_i) = \max_{\vartheta \in \Theta}\sum_{i=1}^n \psi(\vartheta, \bx_i, Y_i).$$
\end{definition}
Dans ce contexte, l'estimateur des moindres carrés non-linéaires apparaît comme le $M$-estimateur associé à la fonction de contraste
$$a \leadsto \psi(a,\bx,y) = -\big(y-r(a,\bx)\big)^2,\;\;\;a \in \Theta.$$
%\subsection{Propriétés des $M$-estimateurs en régression}
Une étude systématique des propriétés asymptotiques des $M$-estimateurs pour le modèle de la régression se fait essentiellement de la même manière que pour le modèle de densité du Chapitre \ref{estimation densite}, mais les aspects techniques sont plus développés. Nous développons -- sans entrer dans les détails -- quelques exemples.

\subsection{Reconstruction d'un signal échantillonné}
On considère l'expérience statistique engendrée par
$$Y_i = r(\vartheta,i/n)+\xi_i,\;\;\;i=1,\ldots,n$$
où les $\xi_i = \sigma \varepsilon_i$ sont indépendants et identiquement distribués, centrés et $\E_\vartheta\big[\varepsilon_i^2\big]=1$. La fonction $r(\vartheta,\cdot)$ est connue au paramètre $\vartheta \in \Theta \subset \R^d$ près. Ici, le \og design\fg{} est donc $\big(1/n,\ldots, (n-1)/n,1\big)$.

On suppose que la fonction $(\vartheta,x) \leadsto r(\vartheta,x)$ est régulière. En particulier,  $x\leadsto r(\vartheta, x)$ est au moins continue. L'estimateur des moindres carrés non-linéaires, s'il est bien défini, vérifie
$$\widehat \vartheta_n^{\,{\tt mcnl}} = \mathrm{arg} \min_{\vartheta \in \Theta} \sum_{i = 1}^n \big(Y_i - r(\vartheta, i/n)\big)^2.$$
Indiquons brièvement comment généraliser les résultats de la Section \ref{proprietes de convergence} sans faire d'hypothèses précises.
\subsubsection{Consistance}
Posons, pour $a \in \Theta \subset \R$ (traitons le cas unidimensionnel pour simplifier),
$$M_n(a) = \frac{1}{n}\sum_{i = 1}^n \big(Y_i-r(a,i/n)\big)^2.$$
On écrit
\begin{align*}
M_n(a) & = \frac{1}{n}\sum_{i = 1}^n \big(\sigma\varepsilon_i + r(\vartheta,i/n)-r(a,i/n)\big)^2 \\
& = \frac{1}{n}\sum_{i = 1}^n\big(r(\vartheta, i/n)-r(a,i/n)\big)^2+\frac{\sigma^2}{n}\sum_{i = 1}^n \varepsilon_i^2 - \frac{2\sigma}{n}\sum_{i  = 1}^n \big(r(\vartheta, i/n)-r(a,i/n)\big)\varepsilon_i,
\end{align*}
où la loi des $\varepsilon_i$ sous $\PP_\vartheta$ est centrée et réduite. Par continuité de $x\leadsto r(\vartheta,x)$, on a la convergence
$$\frac{1}{n}\sum_{i = 1}^n \big(r(\vartheta, i/n)-r(a,i/n)\big)^2 \rightarrow \int_0^1 \big(r(\vartheta, x)-r(a,x)\big)^2dx.$$
Par la loi des grands nombres, on a
$$\frac{\sigma^2}{n}\sum_{i = 1}^n \varepsilon_i^2\stackrel{\PP_\vartheta}{\longrightarrow}\sigma^2,$$
et, par un simple calcul de variance,
$$ \frac{2\sigma}{n}\sum_{i  = 1}^n \big(r(\vartheta, i/n)-r(a,i/n)\big) \varepsilon_i \stackrel{\PP_\vartheta}{\longrightarrow} 0.$$
Donc
%\begin{align*}
$$
M_n(a)  \stackrel{\PP_\vartheta}{\longrightarrow} M(a,\vartheta)  = \int_0^1 \big(r(\vartheta,x)-r(a,x)\big)^2dx+\sigma^2.
$$
La suite de l'étude consiste à faire des hypothèses d'identifiabilité adéquates sur la fonction $(\vartheta,x)\leadsto r(\vartheta,x)$, de sorte que $a\leadsto M(a,\vartheta)$ admette un minimum unique en $a=\vartheta$, et on peut alors généraliser la Proposition \ref{convergence des m estimateurs}, mais une telle étude dépasse un peu le cadre du cours.
\subsubsection{Loi limite et normalité asymptotique}
Avec suffisamment de régularité, on peut faire un développement de $M'_n(a)$ au voisinage de $\estMC$. On a
\begin{equation} \label{approximation constraste regression}
M'_n(\widehat \vartheta_n^{\,{\tt mcnl}}) = 0 \approx M'_n(\vartheta)+(\vartheta - \widehat \vartheta_n^{\,{\tt mcnl}})M_n''(\vartheta),
\end{equation}
d'où
$$\sqrt{n}(\widehat \vartheta^{\,{\tt mcnl}}_n-\vartheta)\approx -\frac{\sqrt{n}M_n'(\vartheta)}{M_n''(\vartheta)}.$$
On a
\begin{align*}
\sqrt{n}M_n'(\vartheta) & = \frac{2}{\sqrt{n}}\sum_{i = 1}^n \big(Y_i-r(\vartheta,i/n)\big)\partial_\vartheta r(\vartheta,i/n) \\
& = \frac{2\sigma}{\sqrt{n}}\sum_{i = 1}^n \varepsilon_i\,\partial_\vartheta r(\vartheta,i/n),
\end{align*}
d'où
$$\E_\vartheta\big[\sqrt{n}M_n'(\vartheta)\big]=0,$$
et
\begin{align*}
\E_\vartheta\big[nM_n'(\vartheta)^2\big] & = \frac{4\sigma^2}{n}\sum_{i = 1}^n \partial_\vartheta r(\vartheta,i/n)^2\\
& \rightarrow 4\sigma^2 \int_0^1 \partial_\vartheta r(\vartheta,x)^2dx.
\end{align*}
En ré-écrivant $\sqrt{n}M_n'(\vartheta) = \big(\E_\vartheta\big[nM_n'(\vartheta)^2\big]\big)^{1/2} \xi^{(n)}$, on peut montrer\footnote{Il faut disposer d'un théorème central-limite pour des variables aléatoires indépendantes non-équidistribuées.} que $\xi^{(n)} \stackrel{d}{\rightarrow} {\mathcal N}(0,1)$ en loi sous $\PP_\vartheta$. On a aussi
\begin{align*}
M_n''(\vartheta) & = \frac{2}{n}\sum_{i = 1}^n\big(-\partial_\vartheta r(\vartheta, i/n)^2+\sigma\varepsilon_i \,\partial_\vartheta^2 r(\vartheta, i/n)\big) \\
& \stackrel{\PP_\vartheta}{\longrightarrow} -2 \int_0^1 \partial_\vartheta r(\vartheta, x)^2dx.
\end{align*}
On en déduit, avec suffisamment de régularité et en contrôlant le reste dans l'approximation \eqref{approximation constraste regression},
$$\sqrt{n}\big(\widehat \vartheta_n^{\,{\tt mcnl}}-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\Big(0,\frac{\sigma^2}{\int_0^1 \partial_\vartheta r(\vartheta, x)^2dx}\Big).$$
\subsection{Modèle de Poisson conditionnel}
On observe
$$(\bx_1,Y_1),\ldots, (\bx_n,Y_n)$$
où les $\bx_i\in \R^k$ sont donnés et les $Y_i$ à valeurs entières. On suppose que $Y_i$ suit la loi de Poisson de paramètre
$$\lambda_i(\vartheta) = \exp\big(\bx_i^T\vartheta\big),\;\;i=1,\ldots, n$$
où $\vartheta \in \Theta = \R^k$ est le paramètre inconnu.

Si l'on considère le modèle de régression à \og design \fg{} aléatoire associé, alors on observe un $n$-échantillon
$$(\bX_1,Y_1),\ldots, (\bX_n,Y_n)$$
où les $(\bX_i,Y_i)$ ont la même loi que $(\bX,Y) \in \R^k\times \R$. La loi de $(\bX,Y)$ est décrite de la façon suivante : conditionnellement\footnote{D'où la terminologie de modèle de Poisson conditionnel.
} à $\bX=\bx$, la variable $Y$ suit une loi de Poisson de paramètre $\exp\big(\bx^T\vartheta\big)$. Puis, on doit spécifier\footnote{Ce que nous ne ferons jamais ; nous supposerons simplement que la loi de $\bX$ ne dépend pas de $\vartheta$.} la loi de $\bX$.
En écrivant
$$Y_i = \exp\big(\bx_i^T\vartheta\big) +\Big(Y_i-\exp\big(\bx_i^T\vartheta\big)\Big),$$
on obtient bien la représentation $Y_i = r(\vartheta,\bx_i)+\xi_i$, avec
$$ r(\vartheta,\bx_i) = \exp\big(\bx_i^T\vartheta\big)$$
et
$$\xi_i = Y_i-\exp\big(\bx_i^T\vartheta\big).$$
On a bien $\E_\vartheta\big[\xi_i\big] =0$ en utilisant que l'espérance d'une variable aléatoire de Poisson de paramètre $\lambda$ est égale à $\lambda$. La vraisemblance du modèle s'écrit
$$
{\mathcal L}_n(\vartheta, Y_1,\ldots, Y_n)  = \prod_{i = 1}^n e^{-\lambda_i(\vartheta)}\frac{\lambda_i(\vartheta)^{Y_i}}{Y_i!}
$$
d'où
$$\log {\mathcal L}_n(\vartheta, Y_1,\ldots, Y_n) = -\sum_{i = 1}^n \exp\big(\bx_i^T \vartheta\big)+\sum_{i=1}^nY_i \bx_i^T\vartheta-\sum_{i = 1}^n \log(Y_i!), $$
et les équations de vraisemblance s'écrivent
$$-\sum_{i = 1}^n x_{ij}\exp\big(\bx_i^T\vartheta\big)+\sum_{i = 1}^n Y_i x_{ij}=0,\;\;\;j = 1,\ldots, k.$$
\subsection{Modèles à réponse binaire}
\subsubsection{Contexte général}
Très utilisés en pratique, les modèles binaires correspondent à l'observation de
$$(\bx_1,Y_1),\ldots, (\bx_n, Y_n)$$
où $\bx_i \in \R^k$ est un ensemble de caractéristiques de l'individu $i$ qui est de type $Y_i \in \{0,1\}$.

Par souci d'homogénéité avec la littérature, on se place -- sans perdre de généralité -- dans le modèle à \og design \fg{} aléatoire correspondant, c'est-à-dire que l'on considère les $\bx_i$ comme des réalisations de variables aléatoires $\bX_i$. En écrivant
$$Y_i = p_{\bx_i}(\vartheta)+\big(Y_i-p_{\bx_i}(\vartheta)\big),$$
avec
$$p_{\bx_i}(\vartheta) = \E_\vartheta\big[Y_i\,|\,\bX_i=\bx_i\big] = \PP_\vartheta\big[Y_i=1\,|\,\bX_i = \bx_i\big],$$
on obtient la représentation
$$Y_i = r(\vartheta,\bx_i)+\xi_i,$$ avec
$$r(\vartheta,\bx_i) = p_{\bx_i}(\vartheta)$$
et
$$\xi_i = Y_i- p_{\bx_i}(\vartheta),$$
et on a bien $\E_\vartheta\big[\xi_i\,|\,\bX_i = \bx_i\big] =0$.
\subsubsection{Régression logistique}
La régression logistique correspond à la modélisation
$$p_{\bx_i}(\vartheta) = \frac{\exp\big(\bx_i^T\vartheta\big)}{1+\exp\big(\bx_i^T\vartheta\big)} = \psi\big(\bx_i^T\vartheta\big),$$
où $\psi(x) = e^x/(1+e^x)$ est la fonction logistique.

En particulier, on peut expliciter la vraisemblance du modèle
$${\mathcal L}_n(\vartheta, Y_1,\ldots, Y_n) = \prod_{i = 1}^n p_{\bx_i}(\vartheta)^{Y_i}\big(1-p_{\bx_i}(\vartheta)\big)^{1-Y_i},$$
que l'on peut maximiser numériquement.

Une représentation équivalente est celle des modèles dits latents, où l'on observe
\begin{equation} \label{rep modele latent}
Y_i = 1_{\big\{Y_i^\star >0\big\}},\;\;Y_i^\star = \bx_i^T\vartheta + U_i,
\end{equation}
où les $Y_i$ sont des variables {\it latentes}, c'est-à-dire que l'on n'observe pas, et $U_i$ est une variable ayant pour fonction de répartition
$$F(x) = \frac{1}{1+e^{-x}}.$$
En effet,
\begin{align*}
\PP_\vartheta\big[Y_i^\star >0\,|\,\bX_i=\bx_i\big] & = \PP_\vartheta\big[\bx_i^T\vartheta +U_i >0\,|\,\bX_i=\bx_i\big] \\
& =1- \PP_\vartheta\big[U_i \leq -\bx_i^T\vartheta\big] \\
& = 1-F\big(-\bx_i^T\vartheta\big) \\
& = \frac{\exp\big(\bx_i^T\vartheta\big)}{1+\exp\big(\bx_i^T\vartheta\big)}.
\end{align*}
\subsubsection{Modèles Probit}
Le modèle probit est proche de la régression logistique. Il s'agit simplement de remplacer dans la représentation \eqref{rep modele latent} la variable $U_i$ qui a pour fonction de répartition $F(x) = 1/(1+e^{-x})$ par une variable aléatoire $U_i$ gaussienne, centrée.

%Le modèle Tobit généralise la modèle probit dans le sens suivant, on observe
%$$Y_i = Y_{i^\star}1_{\big\{Y_i^\star >0\big\}},\;\;\;Y_i^\star = \bx_i^T\vartheta + U_i,\;\;U_i \sim {\mathcal N}(0,1).$$

\subsubsection{Loi logistique et \og odd-ratios\fg{}$^\star$}
La loi logistique de fonction de répartition $F(x) = 1/(1+e^{-x})$ possède des queues de distribution plus épaisses que la loi gaussienne, et sa fonction de répartition est plus simple à manipuler numériquement.

Une spécificité du modèle logistique est l'interprétation du modèle en terme de risque. Imaginons que $Y_i=1$ signifie la présence d'une maladie chez l'individu $i$ (et $Y_i=0$ signifie l'absence de la maladie). Les $\bx_i$ sont un ensemble de facteurs (qualitatifs ou marqueurs biologiques) susceptibles \og d'expliquer \fg{} $Y_i$. Le risque (odd-ratio) de l'individu $i$ est défini comme
$${\mathcal R}_i = \frac{\PP_\vartheta\big[Y_i = 1\,|\,\bX_i = \bx_i\big]}{\PP_\vartheta\big[Y_i = 0\,|\,\bX_i = \bx_i\big]}$$
et ${\mathcal R}_i$ est proche de $\PP_\vartheta\big[Y_i = 1\,|\,\bX_i = \bx_i\big]$ (à l'ordre 1) lorsque la probabilité de présence de la maladie est faible.
Dans le cas de la régression logistique, on a
\begin{align*}\frac{\PP_\vartheta\big[Y_i = 1\,|\,\bX_i = \bx_i\big]}{\PP_\vartheta\big[Y_i = 0\,|\,\bX_i = \bx_i\big]}&  = \frac{\big(1+\exp(-\bx_i^T\vartheta)\big)^{-1}}{\exp\big(-\bx_i^T\vartheta\big)\big(1+\exp(-\bx_i^T\vartheta)\big)} \\
& = \exp\big(\bx_i^T\vartheta\big).
\end{align*}
Si une des variables explicatives $x_{ij}$ est qualitative, pour un $j \in \{1,\ldots, k\}$ c'est-à-dire à valeurs dans $\{0,1\}$ (par exemple, une réponse de type \og oui ou non \fg{} à un questionnaire concernant le patient),
on note
$$\bx_i^{(-j)} = (x_{i1},\ldots, x_{i,j-1},x_{i,j+1},\ldots, x_{ik})^T,$$
c'est-à-dire $\bx_i$ privé de sa $j$-ième composante.
Posons
$${\mathcal R}_i(X_j=1) = \frac{\PP_\vartheta\big[Y_i = 1\,|\,\bX_i^{(-j)} = \bx_i^{(-j)},X_j=1\big]}{\PP_\vartheta\big[Y_i = 0\,|\,\bX_i^{(-j)} = \bx_i^{(-j)},X_j=1\big]}$$
et
$$
{\mathcal R}_i(X_j=0) =
\frac{\PP_\vartheta\big[Y_i = 1\,|\,\bX_i^{(-j)} = \bx_i^{(-j)},X_j = 0\big]}{\PP_\vartheta\big[Y_i = 0\,|\,\bX_i^{(-j)} = \bx_i^{(-j)},X_j=0\big]}.$$
Alors, on a
$$\exp\big(\vartheta_j x_{ij}\big) =\frac{{\mathcal R}_i(X_j=1)}{{\mathcal R}_i(X_j=0)}.$$
Cette identité peut s'interpréter de la manière suivante : le coefficient $\exp\big(\vartheta_j x_{ij}\big)$ est égal au rapport des risques correspondant à $X_j=1$ et $X_j = 0$. Ce rapport est indépendant de la valeur de $\bx_i^{(-j)}$.
%\section{Exercices}

\chapter[Information statistique et théorie asymptotique]{Information et théorie asymptotique} \label{theorie asymptotique}

\section{Introduction}
\subsubsection{Situation}
Nous nous plaçons dans le contexte des deux chapitres précédents : on cherche à estimer un paramètre $d$ -dimensionnel $\vartheta \in \Theta \subset \R^d$ dans les deux situations suivantes
\begin{enumerate}
\item Pour le modèle de la densité, on observe un $n$-échantillon
$$(X_1,\ldots, X_n)$$
de variables aléatoires réelles. Les $X_i$ suivent la loi $\PP_\vartheta$ parmi une famille de probabilités $\big\{\PP_\vartheta, \vartheta \in \Theta\big\}$ données.
\item Pour le modèle de régression à \og design déterministe\fg{}, on observe $n$ vecteurs de données
$$(\bx_1,Y_1),\ldots, (\bx_n, Y_n)$$
admettant la représentation
$$Y_i = r(\vartheta, \bx_i)+\xi_i,\;\;i=1,\ldots, n.$$
La forme de la fonction de régression $r(\vartheta,\cdot)$ est connue au paramètre $\vartheta$ près, et les $\xi_i$ sont des innovations ou des \og bruits\fg{} centrés sur lesquels on fait un jeu d'hypothèses.
\end{enumerate}

En forçant un peu le trait, nous pouvons résumer les méthodes d'estimation des chapitres précédents à la construction d'estimateurs basés sur la maximisation d'un critère : pour la densité,
$$\widehat \vartheta_n \in \mathrm{arg} \max_{\vartheta \in \Theta} \sum_{i = 1}^n \psi(\vartheta, X_i),$$
où
$$\psi: \Theta \times \R \rightarrow \R$$
est la fonction de constraste définissant l'estimateur. Elle est choisie par le statisticien.
Pour la régression à \og design \fg{} déterministe,
$$\widehat \vartheta_n \in \mathrm{arg} \max_{\vartheta \in \Theta} \sum_{i = 1}^n \psi(\vartheta, \bx_i, Y_i),$$
où maintenant la fonction de contraste
$$\psi: \Theta \times \R^k \times \R \rightarrow \R$$
prend aussi comme argument les valeurs des points du \og design \fg{} observés $\bx_i$.
\subsubsection{Loi limite d'un estimateur}
Sous des hypothèses de régularité, le comportement asymptotique de $\widehat \vartheta_n$ prend la forme (en dimension $d=1$)
\begin{equation} \label{loi limite dim1}
\sqrt{n}\big(\est - \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0, v_\Psi(\vartheta)\big)
\end{equation}
où $v_\psi(\vartheta) >0$ est la variance asymptotique de l'estimateur, qui dépend en général de $\vartheta$ et bien sûr du choix de la fonction de contraste $\psi$.

La version multidimensionnelle de \eqref{loi limite dim1} s'écrit
\begin{equation} \label{loi limite dim d}
\sqrt{n}\big(\est - \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0, V_\Psi(\vartheta)\big)
\end{equation}
avec $V_\psi(\vartheta)$ une matrice symétrique, et doit se comprendre comme la convergence du vecteur aléatoire $\sqrt{n}\big(\est - \vartheta\big)$ en loi vers un vecteur gaussien de $\R^d$, centré, de matrice de variance covariance $V_\psi(\vartheta)$ définie positive.
%, la condition de positivité sur matrice de variance-covariance voulant dire que la $V_\Psi(\vartheta) >0$ est définie positive.

%{\tt more on the delta methode here ?}

Un résultat de type \eqref{loi limite dim1} ou \eqref{loi limite dim d} nous apprend deux choses :
\begin{enumerate}
\item Le \og bon\fg{} ordre de grandeur de l'erreur $\est - \vartheta$ est $\frac{1}{\sqrt{n}}$. En effet, la convergence vers une loi non-dégénérée\footnote{C'est-à-dire une loi gaussienne de variance finie $v_\psi(\vartheta)$ non nulle ou de matrice de variance-covariance $V_\psi(\vartheta)$ non singulière.} avec la normalisation $\sqrt{n}$ implique que si l'on choisit une autre normalisation $\alpha_n \rightarrow \infty$, alors l'erreur normalisée
$$\alpha_n(\est - \vartheta)$$
 tend vers $0$ en probabilité si $\alpha_n/\sqrt{n} \rightarrow 0$ et \og explose\footnote{Dans le sens suivant : $\forall M>0,\;\liminf_{n \rightarrow \infty}\PP_\vartheta\big[|\alpha_n(\est - \vartheta)|\geq M\big]>0.$} \fg{} si $\alpha_n/\sqrt{n} \rightarrow \infty$.
\item La dispersion de l'erreur normalisée dans la bonne échelle $\sqrt{n}$ est gaussienne, de variance $v_\psi(\vartheta)$ (ou $V_\psi(\vartheta)$).
\end{enumerate}
Ces deux informations apparaissent à deux niveaux complètement différents, mais sont de même importance et guideront les questions que nous aborderons dans ce chapitre :

\begin{itemize}

\item la vitesse d'estimation $\alpha_n = \sqrt{n}$ est-elle optimale ? Dans quel sens ? Quelles conditions simples sur la famille de lois $\{\PP_\vartheta, \vartheta \in \Theta\}$ garantissent cette optimalité ? Sinon, quelles vitesses peut-on trouver en général \vspace{3mm}?

\item au sein d'une classe d'estimateurs satisfaisant \eqref{loi limite dim1} (ou \eqref{loi limite dim d} dans le cas où le paramètre $\vartheta$ est multidimensionnel), comment choisir un membre optimal, et dans quel sens ? Par exemple, comment choisir la \og meilleure\fg{} fonction $\psi$
%Suffit-il de chercher la fonction $\psi$ qui minimise\footnote{Un problème immédiat étant que, quand bien même le sens de cette approche serait justifié, la fonction $\psi$ qui minimise $v_\psi(\vartheta)$ dépend {\it a priori} de la valeur $\vartheta$ inconnue.} $v_\psi(\vartheta)$ ou $V_\psi(\vartheta)$
\vspace{3mm} ?
\end{itemize}

Un programme ainsi énoncé est trop ambitieux. Nous donnerons néanmoins des éléments de réponse à chacune des questions énoncées ci-dessus. Sous des hypothèses de régularité sur la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$, on peut définir une quantité d'information -- l'information de Fisher -- associée à l'expérience statistique. L'estimateur du maximum de vraisemblance est asymptotiquement normal de variance l'inverse de l'information de Fisher. Cette variance est minimale parmi la classe des $Z$-estimateurs (ou $M$-estimateurs réguliers) et ce résultat nous fournira une notion d'optimalité associée aux modèles réguliers.

Ce n'est que le premier pas vers une théorie plus générale de l'estimation optimale dans les modèles dits réguliers, qui dépasse le cadre de ce cours. Pour des développements plus complets, on pourra consulter V. Genon-Catalot et D. Picard \cite{GCP} ou van der Vaart \cite{VDW}.
%{\tt mot sur a notion d'information}.
\section{Comparaison d'estimateurs}
Pour $n \geq 1$, on se donne ${\mathcal E}^n$ une suite d'expériences associée à la famille de probabilités $\big\{\PP_\vartheta^n,\vartheta \in \Theta\big\}$.
%Par exemple ${\mathcal E}^n$ est l'expérience engendrée par un $n$-échantillon de loi $\PP_\vartheta$, où $\vartheta \in \Theta$.

Plaçons-nous en dimension 1 pour simplifier. Etant données deux (suites d') estimateurs
$$\widehat \vartheta_{n,1}\;\;\;\text{et}\;\;\;\widehat \vartheta_{n,2}$$
lequel est préférable ? Si l'on dispose d'un résultat asymptotique de type \eqref{loi limite dim1} de la forme
$$\sqrt{n}\big(\widehat \vartheta_{n,j}-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,v_j(\vartheta)\big)\;\;\;j = 1,2$$
alors on a le développement asymptotique
$$\widehat \vartheta_{n,j} = \vartheta + \sqrt{\frac{v_j(\vartheta)}{n}}\xi_{n,j},$$
où
$$\xi_{n,j} \stackrel{d}{\longrightarrow} {\mathcal N}(0,1).$$
De ce point de vue, il est préférable de choisir $\widehat \vartheta_{n,1}$ à $\widehat \vartheta_{n,2}$ si
\begin{equation} \label{ineq variance}
v_1(\vartheta) \leq v_2(\vartheta).
\end{equation}
Mais cela pose deux problèmes :

\begin{itemize}
\item le sens de l'inégalité \eqref{ineq variance} peut varier selon la valeur de $\vartheta$ qui est inconnue.
\item cette représentation ne se justifie que dans la limite $n \rightarrow \infty$.
\end{itemize}
\subsection{Risque quadratique en dimension 1}
Cette approche est non-asymptotique.  On suppose ici $d=1$, c'est-à-dire $\Theta \subset \R$.
\begin{definition}
Le risque quadratique d'un estimateur $\est$ au point $\vartheta \in \Theta$ est
$${\mathcal R}(\est, \vartheta) = \E_\vartheta\big[(\est-\vartheta)^2\big].$$
\end{definition}
Le risque quadratique mesure l'erreur moyenne quadratique lorsque l'on estime $\vartheta$ par $\est$. Le choix de l'erreur quadratique est un peu arbitraire. On pourrait tout aussi bien considérer le risque
$$\E_\vartheta\big[|\est - \vartheta|\big],$$
ou plus généralement un risque associé à une fonction de perte $(x,y)\leadsto \ell(x,y)$ arbitraire
$$\E_\vartheta\big[\ell(\est,\vartheta)\big]$$
satisfaisant $\ell(x,y)\geq 0$ avec égalité si et seulement si $x=y$.
On a déja rencontré les avantages de considérer comme mesure d'erreur la différence au carré au Chapitre \ref{regression}, en particulier, le fait que $\vartheta \leadsto {\mathcal R}(\est,\vartheta)$ est dérivable sous des hypothèses relativement faibles.

Remarquons aussi que l'inégalité de Tchebychev \eqref{tchebychev} entraîne, pour tout $\varepsilon >0$
$$\PP_\vartheta\big[|\est - \vartheta| > \varepsilon\big] \leq \frac{1}{\varepsilon^2}{\mathcal R}(\est, \vartheta)$$
et donc le risque quadratique permet de  contrôler -- au moins grossièrement -- la probabilité que la précision de $\est$ soit inférieure ou égale à un niveau  $\varepsilon >0$ donné. En particulier, si
$${\mathcal R}(\est, \vartheta) \rightarrow 0$$
alors
%alors\footnote{au sens où
%$\forall \varepsilon >0,\;\;\lim_{n \rightarrow \infty} \PP_\vartheta^n\big[|\est-\vartheta| >\varepsilon\big] = 0$.}
$$\est \stackrel{\PP_\vartheta^n}{\longrightarrow}\vartheta.$$
On en déduit la règle de sélection suivante :
\begin{definition} \label{comp risque quad}
L'estimateur $\widehat \vartheta_{n,1}$ est préférable à l'estimateur $\widehat \vartheta_{n,2}$ au sens du risque quadratique au point $\vartheta$ si
$${\mathcal R}(\widehat \vartheta_{n,1}, \vartheta) \leq {\mathcal R}(\widehat \vartheta_{n,2}, \vartheta).$$
\end{definition}
\subsubsection{Notion d'admissibilité}
\index{admissible, estimateur}
Etant donné une (suite d') expérience(s) ${\mathcal E}^n$, existe-t-il un estimateur $\widehat \vartheta_n^\star$ optimal au sens de la Définition \ref{comp risque quad}, c'est-à-dire vérifiant
\begin{equation} \label{naive optimalite}
\forall \vartheta \in \Theta,\;\;\;{\mathcal R}(\widehat \vartheta_{n}^\star, \vartheta) \leq \inf_{\est}{\mathcal R}(\widehat \vartheta_{n}, \vartheta)\;?
\end{equation}
La réponse est négative : prenons par exemple l'expérience engendrée par l'observation d'un $n$-échantillon de loi ${\mathcal N}(\vartheta, \sigma^2)$, avec $\vartheta \in \Theta = \R$ et $\sigma^2$ connu. L'estimateur du maximum de vraisemblance est
$$\estMV = \overline{X}_n.$$
Considérons par ailleurs l'estimateur artificiel
$$\widehat \vartheta_n = 0$$
qui prend toujours la valeur $0$ sans tenir compte des observations. Alors, pour tout $\vartheta \in \Theta$,
$${\mathcal R}(\estMV,\vartheta) = \frac{\sigma^2}{n}\;\;\text{et}\;\;\;{\mathcal R}(\est,\vartheta) = \vartheta^2.$$
Il est clair que selon les valeurs de $n$ et $\sigma$ il existe des valeurs de $\vartheta$ où l'estimateur absurde $\est =0$ est préférable à $\estMV$ pour le risque quadratique.

La situation générale est pire ! Même si $\Theta$ se réduit à deux points distincts, quelle que soit l'expérience statistique, on ne peut pas construire d'estimateur optimal au sens de \eqref{naive optimalite}. Voir pour cela l'Exercice \ref{no optimality}. La notion d'optimalité au sens naïf de \eqref{naive optimalite} est impossible à réaliser.

On peut néanmoins aborder la notion de comparaison sous un angle plus faible : c'est la notion d'efficacité et d'admissibilité.
\index{efficace, estimateur}
\begin{definition}[Efficacité]
Si $\widehat \vartheta_{n,1}$ est préférable à $\widehat \vartheta_{n,2}$ pour le risque quadratique en tout point $\vartheta \in \Theta$
et s'il existe un point $\widetilde \vartheta \in \Theta$ pour lequel on a
$${\mathcal R}(\widehat \vartheta_{n,1}, \widetilde \vartheta) < {\mathcal R}(\widehat \vartheta_{n,2}, \widetilde \vartheta),$$
on dit que $\widehat \vartheta_{n,1}$ est plus efficace que $\widehat \vartheta_{n,2}$ et que $\widehat \vartheta_{n,2}$ est inadmissible.
\end{definition}
On en déduit une notion (faible) d'optimalité :
\begin{definition}[Admissibilité] \label{def admissibilite}
L'estimateur $\est$ est admissible s'il n'existe pas d'estimateur plus efficace que $\est$.
\end{definition}
\subsubsection{Optimalité sur une classe d'estimateurs}
Une autre manière de contourner le problème de l'absence d'optimalité au sens \eqref{naive optimalite} consiste à restreindre la classe des estimateurs, de sorte que des estimateurs absurdes soient éliminés d'office. Pour cela, on part de la constatation suivante :
\begin{proposition}[Structure du risque quadratique]
Pour tout estimateur $\est$ et tout $\vartheta \in \Theta$, on a la décomposition
$${\mathcal R}(\est, \vartheta) = \big(\E_\vartheta\big[\est\big]-\vartheta\big)^2+\mathrm{Var}_\vartheta\big[\est\big] = \mathrm{biais}^2+\mathrm{variance}.$$
\end{proposition}
\begin{definition}
On dit que $\est$ est sans biais, respectivement asymptotiquement sans biais, si
$$\forall \vartheta \in \Theta,\;\;\E_\vartheta\big[\est\big] = \vartheta,$$
respectivement $\lim_{n \rightarrow \infty}\E_\vartheta\big[\widehat \vartheta_n\big]=\vartheta$.
\end{definition}
%FAUX SI PAS D HYP SUPPL\begin{remarque}
%\emph{
%Un estimateur ne peut pas être asymptotiquement sans biais et de variance nulle, sauf si $\Theta$ est réduit à un point.
%voir Exercice \ref{sans biais variance nulle}.
%}
%\end{remarque}
Une approche classique de la littérature statistique (un peu dépassée aujourd'hui) consiste à réaliser le programme suivant : parmi les estimateurs sans biais, chercher ceux de variance minimale. Un fait remarquable est que dans certaines situations, un tel programme est réalisable, voir l'Exercice \ref{cramerrao}. Cependant, cette approche reste limitée et nous ne la développerons pas dans ce cours car :
\index{biais--variance d'un estimateur}
\begin{itemize}
\item les estimateurs sans biais n'apparaissent que dans des situations assez particulières.
%\item si l'on \og perturbe\fg{}, même légèrement le modèle, on perd la notion de biais {\tt more here}
\item même pour les expériences statistiques admettant des estimateurs sans biais, on peut presque toujours construire des estimateurs biaisés plus efficaces, comme le montre l'exemple suivant dans un cas simple.
\end{itemize}

\begin{exemple} \label{inadmissibilite}
\emph{
Dans le modèle engendré par l'observation d'un $n$-échantillon de loi ${\mathcal N}(\mu,\sigma^2)$, avec $(\mu,\sigma^2) \in \R \times \R_+\setminus\{0\} $, on s'intéresse au paramètre $\vartheta = \sigma^2$. On suppose $n \geq 2$. Considérons les estimateurs
$$\widehat \vartheta_{n,1} = \frac{1}{n}\sum_{i = 1}^n \big(X_i - \overline{X}_n\big)^2,\;\;\text{et}\;\;
\widehat \vartheta_{n,2} = \frac{1}{n-1}\sum_{i = 1}^n \big(X_i-\overline{X}_n\big)^2.$$
Alors $\E_\vartheta\big[\widehat \vartheta_{n,1}\big] = \frac{n-1}{n}\vartheta = \vartheta-n^{-1}\sigma^2$.
En conséquence, le biais de $\widehat \vartheta_{n,1}$ vaut $-\sigma^2n^{-1}$ et $\widehat \vartheta_{n,1}$ est biaisé.
Par contre, $\E_\vartheta\big[\widehat \vartheta_{n,2}\big] = \sigma^2 = \vartheta$ et $\widehat \vartheta_{n,2}$ est sans biais. Par ailleurs,
$$\mathrm{Var}_\vartheta\big[\widehat \vartheta_{n,2}\big] = \left(\frac{n}{n-1}\right)^2,\;\;\;\mathrm{Var}_\vartheta\big[\widehat \vartheta_{n,1}\big] = \frac{2\sigma^4}{n-1}.$$
On en déduit
$${\mathcal R}(\widehat \vartheta_{n,1},\vartheta) = \left(\frac{\sigma^2}{n}\right)^2+2\frac{n-1}{n^2}\sigma^4 = \frac{2n-1}{n^2}\sigma^4$$
et
$${\mathcal R}(\widehat \vartheta_{n,2},\vartheta) = \frac{2\sigma^4}{n-1} > {\mathcal R}(\widehat \vartheta_{n,1},\vartheta)$$
pour tout $\vartheta \in \Theta$. Donc $\widehat \vartheta_{n,1}$ est plus efficace que $\widehat \vartheta_{n,2}$. L'estimateur sans biais est inadmissible.
}
\end{exemple}
Cependant, l'Exemple \ref{inadmissibilite} n'est pas tout à fait honnête : la différence entre $\widehat \vartheta_{n,1}$ et $\widehat \vartheta_{n,2}$ s'estompe lorsque $n$ grandit, au sens où
$$\lim_{n \rightarrow \infty}\frac{{\mathcal R}_n(\widehat \vartheta_{n,1}, \vartheta)}{{\mathcal R}(\widehat \vartheta_{n,2},\vartheta)} = 1.$$
Cette remarque met plutôt en relief un défaut de la notion d'admissibilité et suggère une approche asymptotique.
Nous verrons plus loin comment l'approche asymptotique élimine naturellement certains estimateurs artificiels.
Nous concluons cette section avec la régle de comparaison suivante :
\begin{definition} L'estimateur $\widehat \vartheta_{n,1}$ est asymptotiquement préférable à l'estimateur $\widehat \vartheta_{n,2}$ au point $\vartheta \in \Theta$ si
$$\limsup_{n \rightarrow \infty}\frac{{\mathcal R}_n(\widehat \vartheta_{n,1}, \vartheta)}{{\mathcal R}(\widehat \vartheta_{n,2},\vartheta)} \leq 1.$$
\end{definition}
On pourrait en définir une notion d'efficacité asymptotique analogue à la Définition \ref{def admissibilite} non-asymptotique. Nous reviendrons plus tard sur ce point.
%{\tt quand ?}
 \subsection{Risque quadratique et normalité asymptotique}
 On suppose toujours $\Theta \subset \R$ pour simplifier. On a vu aux Chapitres \ref{estimation densite} et \ref{regression} des résultats de type
 \begin{equation} \label{one more norm asympt}
 \sqrt{n}\big(\widehat \vartheta_{n}- \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0, v(\vartheta)\big)
 \end{equation}
%lorsque $n \rightarrow \infty$.
Supposons que la convergence ait aussi lieu en passant au carré et en prenant l'espérance, c'est-à-dire
\begin{equation} \label{convergence moment}
\lim_{n \rightarrow \infty} n {\mathcal R}(\widehat \vartheta_{n},\vartheta) = v(\vartheta).
\end{equation}
Alors, l'estimateur $\widehat \vartheta_{n,1}$ sera asymptotiquement préférable à l'estimateur $\widehat \vartheta_{n,2}$ pour le risque quadratique au point $\vartheta$ si
\begin{equation} \label{ordering variance}
v_1(\vartheta) \leq v_2(\vartheta)
\end{equation}
dès lors que $\widehat \vartheta_{n,1}$ et $\widehat \vartheta_{n,2}$ vérifient des convergences de type \eqref{one more norm asympt} et \eqref{convergence moment}.

Malheureusement, on n'a pas en général une inégalité de type \eqref{ordering variance} {\it simultanément pour tout} $\vartheta \in \Theta$. Une solution conservatrice consiste alors à préférer asymptotiquement $\widehat \vartheta_{n,1}$ à  $\widehat \vartheta_{n,2}$ si
$$\sup_{\vartheta \in \Theta} v_1(\vartheta) \leq \sup_{\vartheta \in \Theta}v_2(\vartheta).$$
Ceci nous conduit à une notion faible mais très robuste de la notion d'optimalité asymptotique pour le risque quadratique.
\begin{definition}[Risque minimax]
Le risque d'un estimateur $\est$ sur l'ensemble des paramètres $\Theta$ est
$${\mathcal R}(\est\,|\, \Theta)=\sup_{\vartheta \in \Theta}{\mathcal R}(\est, \vartheta).$$
Un estimateur $\widehat \vartheta_n^\star$ est asymptotiquement optimal au sens minimax pour le risque quadratique si
$$\limsup_{n \rightarrow \infty}\frac{{\mathcal R}(\widehat \vartheta_n^\star\,|\, \Theta)}{\inf_{\est}{\mathcal R}(\est\,|\, \Theta)}\leq 1,$$
où l'infimum est pris sur l'ensemble de tous les estimateurs.
\end{definition}
\index{minimax, optimalité}
\begin{remarque}
\emph{
L'optimalité asymptotique au sens minimax se généralise im\-médiate\-ment à d'autres fonctions de perte que la perte quadratique. Elle est couramment utilisée lorsque l'ensemble des paramètres est de grande dimension, et en particulier en estimation non-paramétrique.
}
\end{remarque}
Nous terminons cette section en présentant des conditions simples qui permettent de passer de \eqref{one more norm asympt} à \eqref{convergence moment}. A quelle condition simple la convergence en loi \eqref{one more norm asympt} entraîne-t-elle une convergence de type \eqref{convergence moment} ? Plus généralement si $Z_n$ est une suite de variables aléatoires réelles telle que
$$Z_n\stackrel{d}{\rightarrow} Z,$$
peut-on avoir
$$\lim_{n \rightarrow \infty}\E\big[g(Z_n)\big] = \E\big[g(Z)\big]$$
pour une fonction $g$ continue non-bornée ? Si $g$ est bornée, c'est la définition même de la convergence en loi. Dans le cas où $g$ est non-bornée, il faut invoquer une propriété d'uniforme intégrabilité sur la suite $Z_n$.
\begin{proposition}
%[Théorème de continuité pour les moments]
Soit $Z_n$ une suite de vecteurs aléatoires de $\R^d$ telle que $Z_n \stackrel{d}{\rightarrow} Z$.
Alors, si $g:\R^d \rightarrow \R$ est une application continue et si l'une au moins des trois conditions suivantes est vérifiée :

\begin{itemize}

\item[(i)] $\lim_{t \rightarrow \infty} \sup_{n} \int_{t}^{+\infty}\PP\big[|g(Z_n)|> x\big]dx = 0$,

\item[(ii)] $\PP\big[|g(Z_n)|>x\big] \leq h(x)$, avec $\int_0^{+\infty} h(x)dx<+\infty$,

\item[(iii)] il existe $\varepsilon >0$ tel que $\sup_{n} \E\big[|g(Z_n)|^{1+\varepsilon}\big]<+\infty$,

\end{itemize}

on a
$$\lim_{n \rightarrow \infty}\E\big[g(Z_n)\big] = \E\big[g(Z)\big].$$
\end{proposition}
\begin{proof}
Par l'inégalité de Tchebychev, on a, pour $x>0$,
$$\PP\big[|g(Z_n)| > x\big] \leq \frac{\E\big[|g(Z_n)|^{1+\varepsilon}\big]}{x^{1+\varepsilon}},$$
donc (iii) implique (i). De même, la condition (ii) entraîne clairement la condition (i). Supposons (i). Alors, on écrit
$$\E\big[|g(Z_n)|\big] = \int_0^{+\infty}\PP\big[|g(Z_n)|\geq x\big]dx.$$
Par hypothèse, la convergence en loi $Z_n \stackrel{d}{\rightarrow} Z$ entraîne $|g(Z_n)| \stackrel{d}{\rightarrow} |g(Z)|$ par continuité de $|g(\cdot)|$, et donc
$$\PP\big[|g(Z_n)|\geq x\big] \rightarrow \PP\big[|g(Z)|\geq x\big]$$
pour presque tout $x$. Donc, pour tout $t >0$, par convergence dominée,
$$\lim_{n \rightarrow \infty} \int_0^t \PP\big[|g(Z_n)|\geq x\big] dx \rightarrow \int_0^t \PP\big[|g(Z)|\geq x\big]dx.$$
L'hypothèse (i) rend légitime le passage à la limite $t \rightarrow \infty$ dans la convergence précédente. Finalement
\begin{align*}
\lim_{n \rightarrow \infty} \E\big[|g(Z_n)|\big] & = \lim_{n \rightarrow \infty} \int_0^{+\infty} \PP\big[|g(Z_n)|\geq x\big]dx \\
& = \int_0^{+\infty} \PP\big[|g(Z)|\geq x\big]dx \\
& = \E\big[|g(Z)|\big].
\end{align*}
\end{proof}
\subsection{Risque quadratique : le cas multidimensionnel$^\star$}
\index{risque quadratique, cas multidimensionnel}
Si $\vartheta \in \Theta \subset \R^d$ avec $d \geq 1$, un estimateur $\est$ de $\vartheta = (\vartheta_1,\ldots, \vartheta_d)^T$ s'écrit sous forme vectorielle
$$\est =(\widehat \vartheta_n^{(1)},\ldots, \widehat \vartheta_n^{(d)})^T,$$
où $\widehat \vartheta_n^{(j)}$ est la $j$-ème composante de $\est$. Considérons dans un premier temps le risque quadratique de $\est$ au point $\vartheta$ composante par composante, c'est-à-dire ${\mathcal R}(\widehat \vartheta_n^{(j)},\vartheta_j)$, pour $j=1,\ldots, d$, ou plus généralement une combinaison linéaire
$$\sum_{j = 1}^d \alpha_j {\mathcal R}(\widehat \vartheta_n^{(j)},\vartheta_j)$$
de sorte que tous les $\alpha_j$ soient positifs. En particulier, pour $\alpha_j = 1$ pour tout $j$, on a
$$\sum_{j = 1}^d \alpha_j {\mathcal R}(\widehat \vartheta_n^{(j)},\vartheta_j) = \E_\vartheta\big[\|\est- \vartheta\|^2\big],$$
où $\|\cdot\|$ désigne la norme euclidienne sur $\R^d$.
%Plus généralement, on peut vouloir comparer les performances relatives des estimateurs pour l'estimation de combinaisons linéaires de composantes $\vartheta_j$ de $\vartheta$, c'est-à-dire considérer
%$${\mathcal R}\Big(\sum_{j = 1}^d \alpha_j \widehat \vartheta_n^{(j)}, \sum_{j = 1}^d \alpha_j \vartheta_{j}\Big) = \sum_{j,k=1}^d\alpha_j\alpha_k\,
%\E_\vartheta\Big[\big(\widehat \vartheta_n^{(j)}-\vartheta_j\big)\big(\widehat \vartheta_n^{(k)}-\vartheta_k\big)\Big].$$
Pour cela, on a besoin d'une notion de dispersion dans $\R^d$.
\begin{definition}
Si $Z_1$ et $Z_2$ sont deux vecteurs aléatoires à valeurs dans $\R^d$ ayant des moments d'ordre deux (c'est-à-dire $\E\big[\|Z_i\|^2\big]<+\infty$ pour $i=1,2$), on dit que la dispersion de $Z_1$ autour de $\alpha \in \R^d$ est plus petite que la dispersion de $Z_2$ si, pour tout $v \in \R^d$, on a
\begin{equation} \label{dispersion multidim}
\E\big[\langle Z_1-\alpha, v\rangle^2\big] \leq \E\big[\langle Z_2-\alpha, v\rangle^2\big],
\end{equation}
où $\langle u,v\rangle = \sum_{i=1}^d u_iv_i$ désigne le produit scalaire euclidien sur $\R^d$.
\end{definition}
Si $\alpha = \E\big[Z_1\big] = \E\big[Z_2\big]$, l'inégalité \eqref{dispersion multidim} exprime le fait que la variance de $Z_1$ dans n'importe quelle direction $v$ est plus grande que la variance de $Z_2$ dans cette même direction.

Si $\Sigma(Z_i)$ désigne la matrice de variance-covariance de $Z_i$ pour $i=1,2$, la relation \eqref{dispersion multidim} se traduit pour $\alpha = 0$ par
$$\sum_{j,k=1}^d \Sigma({Z_1})_{jk} v_j v_k \leq \sum_{j,k=1}^d \Sigma({Z_2})_{jk} v_j v_k,\;\;v \in \R^d,$$
c'est-à-dire la matrice $\Sigma(Z_2)-\Sigma(Z_1)$ est positive. Ceci nous fournit, de la même façon qu'en dimension 1, une règle de sélection non-asymptotique.
\begin{definition}
Un estimateur $\widehat \vartheta_{n,1}$ du paramètre $\vartheta \in \Theta \subset \R^d$ est préférable à $\widehat \vartheta_{n,2}$ pour le risque quadratique au point $\vartheta$ si la dispersion de $\widehat \vartheta_{n,1}$ autour de $\vartheta$ est plus petite que celle de $\widehat \vartheta_{n,2}$.
\end{definition}
En conséquence, si $\Sigma_i(\vartheta) = \Sigma(\widehat \vartheta_{n,i}-\vartheta)$ est la matrice de variance-covariance du vecteur $\widehat \vartheta_{n,i}-\vartheta$ pour $i=1,2$, dire que $\widehat \vartheta_{n,1}$ est préférable à $\widehat \vartheta_{n,2}$ implique que la matrice $\Sigma_1(\vartheta) - \Sigma_2(\vartheta)$ est positive.

On peut de même donner la règle de comparaison asymptotique suivante
\begin{definition} Soit  $v_n >0$ une suite telle que $\lim_{n \rightarrow \infty}=+\infty$. Si $\widehat \vartheta_{n,1}$ et $\widehat \vartheta_{n,1}$ sont deux suites d'estimateurs tels que
$$v_n\big(\widehat \vartheta_{n,i}-\vartheta\big) \stackrel{d}{\longrightarrow} Z_i,$$
pour $i=1,2$, où les variables $Z_i$ sont centrées et de carré intégrable, on dit que $\widehat \vartheta_{n,1}$ est asymptotiquement préférable à $\widehat \vartheta_{n,2}$ au point $\vartheta$ si la dispersion de $Z_1$ autour de $0$ est plus petite que celle de $Z_2$.
\end{definition}
%{\tt check!}
\begin{remarque}
\emph{
En particulier, dans le cas classique où $v_n = \sqrt{n}$ et $Z_i \sim {\mathcal N}\big(0,\Sigma_i(\vartheta)\big)$, dire que $\widehat \vartheta_{n,1}$ est asymptotiquement préférable à $\widehat \vartheta_{n,2}$ au point $\vartheta$ implique que la matrice $\Sigma_2(\vartheta)-\Sigma_1(\vartheta)$ est positive.
%{\tt check!}
}
\end{remarque}
\section{Modèles réguliers}
\subsection{Information de Fisher} \label{information de fisher}
\index{Fisher, information de}
\subsubsection{Situation}
Dans toute la suite, on se placera dans le modèle de la densité : on considère une suite d'expérience ${\mathcal E}^n$ engendrée par l'observation d'un $n$-échantillon
$$(X_1,\ldots, X_n)$$
où la loi  $\PP_\vartheta$ des  variables aléatoires $X_i$ appartient à une famille donnée de probabilités sur $\R$
$$\{\PP_\vartheta,\;\vartheta \in \Theta\}$$
dominée par une mesure $\sigma$-finie\footnote{Dans presque tous les cas, $\mu$ sera la mesure de Lebesgue lorsque les $\PP_\vartheta$ sont absolument continues, ou bien la mesure de comptage sur un ensemble ${\mathcal M} \subset \R$ au plus dénombrable lorsque les $X_i$ sont discrètes, à valeurs dans ${\mathcal M}$.
} $\mu$ sur $\R$. On note
$$f(\vartheta, x) = \frac{d\PP_\vartheta}{d\mu}(x),\;\;\;\vartheta \in \Theta, \;\;x \in \R$$
la densité de $\PP_\vartheta$ par rapport à $\mu$. C'est une fonction positive, définie $\mu$-presque partout,  $\mu$-intégrable, et si $X \sim \PP_\vartheta$, on a la formule d'intégration (c'est la formule \eqref{formule mesure image} de la mesure image, voir Chapitre \ref{chapitre 1})
$$\E_\vartheta\big[\varphi(X)\big] = \int_{\R} \varphi(x)\PP_\vartheta(dx) = \int_{\R}\varphi(x)f(\vartheta, x)\mu(dx)$$
pour toute fonction test $\varphi$. On introduit aussi la notation suivante :
\begin{definition} On pose, lorsque cela a un sens
$$\ell(\vartheta, x) = \log f(\vartheta, x),\;\;x\in \R, \vartheta \in \Theta.$$
(En convenant $\log 0 = 0$ par exemple, on pourra toujours parler de $\ell(\vartheta, x)$). La dérivée de la fonction $\vartheta \leadsto \ell(\vartheta,x)$, lorsqu'elle existe, s'appelle \og fonction score \fg{} du modèle $\big\{\PP_\vartheta,\,\vartheta \in \Theta \big\}$.\index{score, fonction}
\end{definition}
\subsubsection{Information de Fisher d'une famille de densités} \label{fisher premiere interpretation}
Restreignons nous dans un premier temps au cas où $\Theta \subset \R$ pour simplifier.
\begin{definition}[Information de Fisher] \label{information de fisher definition}
Si $\vartheta \leadsto \ell(\vartheta, x)$ est dérivable $\mu(dx)$-presque partout, on appelle information de Fisher de la famille $\{\PP_\vartheta,\;\vartheta \in \Theta\}$ au point $\vartheta \in \Theta$ la quantité
$$\mathbb{I}(\vartheta) = \int_{\R}\big(\partial_\vartheta\, \ell(\vartheta, x)\big)^2f(\vartheta, x)\mu(dx) = \E_\vartheta\big[\big(\partial_\vartheta \,\ell(\vartheta, X)\big)^2\big].$$
\end{definition}
On a, pour tout $\vartheta \in \Theta$,
$$\mathbb{I}(\vartheta) = \int_{\{x,\,f(\vartheta,x)>0\}}\frac{\big(\partial_\vartheta f(\vartheta,x)\big)^2}{f(\vartheta, x)}\mu(dx),$$
et aussi
$$0 \leq \mathbb{I}(\vartheta) \leq +\infty,$$
les cas intéressants étant ceux pour lesquels on a
$$0 < \mathbb{I}(\vartheta) < +\infty.$$
%\begin{remarque}
%\emph{
%L'information de Fisher ne dépend pas du choix de la mesure dominante.
%}
%\end{remarque}
\subsubsection{Origine de l'information de Fisher}
L'information de Fisher apparaît naturellement comme la variance limite de l'estimateur du maximum de vraisemblance, sous des hypothèses suffisantes de régularité sur  $\{f(\vartheta,\cdot),\vartheta \in \Theta\}$. Cela signifie que l'on a
\begin{equation} \label{first Fisher}
\sqrt{n}\big(\estMV - \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\left(0,\frac{1}{\mathbb{I}(\vartheta)}\right).
\end{equation}
Donnons immédiatement l'heuristique de ce résultat, sans nous soucier des hypothèses, que nous préciserons plus loin. Nous allons essentiellement répéter la preuve de la Proposition \ref{loi limite z est} du Chapitre \ref{estimation densite} dans ce contexte particulier. D'après l'équation \eqref{eq vrais} du Chapitre \ref{estimation densite}, l'estimateur $\estMV$ satisfait
$$\partial_\vartheta \ell_n(\vartheta)_{|\vartheta = \estMV} = 0,$$
où
$$\ell_n(\vartheta) = \sum_{i = 1}^n \ell(\vartheta, X_i) = \sum_{i = 1}^n \log f(\vartheta, X_i)$$
 est la log-vraisemblance associée à la famille $\big\{\PP_\vartheta, \vartheta \in \Theta \big\}$. Au voisinage de $\estMV$, on a, à l'ordre 1,
$$0 = \partial_\vartheta \ell_n(\vartheta)_{|\vartheta = \estMV} \approx \partial_\vartheta \ell_n(\vartheta) + \big(\estMV - \vartheta\big)\partial_\vartheta^2 \ell_n(\vartheta).$$
En divisant par $ \partial^2_\vartheta \ell_n(\vartheta)$ et en multipliant par $\frac{1}{\sqrt{n}}$, on obtient l'approximation
$$
%\sqrt{n}\big(\estMV - \vartheta\big) \approx \frac{\tfrac{1}{\sqrt{n}}\partial_\vartheta \ell_n(\vartheta)}{-\tfrac{1}{n}\partial_\vartheta^2 \ell_n(\vartheta)}.
\sqrt{n}\big(\estMV - \vartheta\big) \approx \frac{n^{-1/2}\partial_\vartheta \,\ell_n(\vartheta)}{-n^{-1}\partial_\vartheta^2\, \ell_n(\vartheta)}.
$$
C'est l'étude asymptotique du numérateur et du dénominateur respectivement qui va faire apparaître $\mathbb{I}(\vartheta)$. Notons que
$$n^{-1/2}\,\partial_\vartheta \,\ell_n(\vartheta) = \frac{1}{\sqrt{n}}\sum_{i = 1}^n  \partial_\vartheta \log f(\vartheta, X_i).$$
et
$$-n^{-1}\,\partial_\vartheta^2\, \ell_n(\vartheta) = -\frac{1}{n}\sum_{i = 1}^n \partial^2_\vartheta\log f(\vartheta, X_i).$$
Sous des conditions d'intégrabilité suffisantes, le dénominateur converge  par la loi des grands nombres vers
$$-\E_\vartheta\big[ \partial^2_\vartheta \log f (\vartheta, X)\big]$$
en probabilité. Le comportement du numérateur $\tfrac{1}{\sqrt{n}}\partial_\vartheta \ell_n(\vartheta)$ est moins évident. Nous allons d'abord énoncer un lemme fondamental sur lequel nous reviendrons plus tard.
\begin{lemme} Sous des hypothèses de régularité adéquates, on a
$$\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, X)\big] =0.$$
\end{lemme} \label{centrage score}
\begin{proof} Justifions formellement ce résultat : on a
\begin{align*}
\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, X)\big] &= \int_{\R} \partial_\vartheta\log f(\vartheta,x)\,f(\vartheta,x) \mu(dx) \\
& = \displaystyle \int_{\R} \frac{\partial_\vartheta f(\vartheta,x)}{f(\vartheta,x)} f(\vartheta,x) \mu(dx) \\
& = \int_{\R} \partial_\vartheta f(\vartheta,x)\mu(dx) \\
& = \partial_\vartheta \int_{\R} f(\vartheta,x) \mu(dx) = \partial_\vartheta 1 = 0.
\end{align*}
\end{proof}
On a aussi $\int_{\R}\partial^2_\vartheta f(\vartheta, x)\mu(dx)=0$, ce qui permet de déduire la relation très utile pour les calculs

\begin{equation} \label{formule utile}
\mathbb{I}(\vartheta) = \E_\vartheta\big[\big(\partial_\vartheta \log f(\vartheta, X)\big)^2\big] = -\E_\vartheta\big[\partial^2_\vartheta \log f(\vartheta, X\big].
\end{equation}

Revenons à l'étude du numérateur $\tfrac{1}{\sqrt{n}}\partial_\vartheta \ell_n(\vartheta)$. D'après le Lemme \ref{centrage score}, les variables aléatoires $\partial_\vartheta \log f(\vartheta, X_i)$ sont indépendantes, centrées, de variance $\mathbb{I}(\vartheta)$. D'après le théorème central-limite, on a la convergence
$$ \frac{1}{\sqrt{n}}\sum_{i = 1}^n  \partial_\vartheta \log f(\vartheta, X_i) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,\mathbb{I}(\vartheta)\big).$$
On a déja vu que le dénominateur $-\tfrac{1}{n}\partial_\vartheta^2 \ell_n(\vartheta)$ converge en probabilité vers
$$-\E_\vartheta\big[ \partial^2_\vartheta \log f(\vartheta, X)\big] = \mathbb{I}(\vartheta)$$
d'après la formule \eqref{formule utile}. On en déduit par la Proposition \ref{slutsky} (Slutsky) que le quotient converge en loi vers une gaussienne centrée de variance $\mathbb{I}(\vartheta)^{-1}$, c'est-à-dire
$$\sqrt{n}\big(\estMV - \vartheta\big) \approx \mathcal{N}\left(0,\frac{1}{\mathbb{I}(\vartheta)}\right),$$
et nous pouvons donc interpréter $\mathbb{I}(\vartheta)$ comme l'inverse de la variance asymptotique de l'estimateur du maximum de vraisemblance.

La suite de cette section consiste à rendre rigoureux ce raisonnement, à le générali\-ser au cas où $\vartheta$ est de dimension $d \geq 1$ et à montrer que $\mathbb{I}(\vartheta)$ est une caractéristique \og géométrique\fg{} de la famille $\{\PP_\vartheta, \vartheta \in \Theta\}$, apparentée à une notion d'information intrinsèque de l'expérience statistique associée. Ce sera un premier pas vers une notion de comparaison des expériences statistiques d'une part, et de la meilleure estimation possible d'autre part.

%\subsubsection{Exemples de calcul de l'information de Fisher}
\subsubsection{Information de Fisher d'une (suite d') expérience(s) statistique(s)}
L'information de Fisher introduite dans la Définition \ref{information de fisher definition} de la Section \ref{information de fisher} porte sur une famille $\big\{ f(\vartheta, \cdot),\,\vartheta \in \Theta\big\}$ de densités $(\vartheta,x) \in \Theta \times \R \rightarrow \R_+$ avec $\Theta \subset \R$. L'extension de cette notion pour une expérience statistique dominée arbitraire -- en se restreignant toujours au cas $\Theta \subset \R$ -- est immédiate :
\begin{definition} Si ${\mathcal E}^n = \big(\mathfrak{Z}_n, {\mathcal Z}_n, \big\{\PP_\vartheta^n,\,\vartheta \in \Theta\big\}\big)$ est une suite d'expériences statistiques dominée par une mesure $\mu_n(dz)$ $\sigma$-finie sur $(\mathfrak{Z}_n, {\mathcal Z}_n)$ et si $\Theta \subset \R$, alors l'information de Fisher de l'expérience au point $\vartheta \in \Theta$ est définie par
\begin{equation} \label{def vrais cas general}
\mathbb{I}(\vartheta\,|\,{\mathcal E}^n) = \int_{\mathfrak{Z}_n} \Big(\partial_\vartheta \log f_n(\vartheta, z)\Big)^2 \PP_\vartheta^n(dz),
\end{equation}
où $f_n(\vartheta,z)=\frac{d\PP_\vartheta^n}{d\mu}(z)$ pour peu que l'expression ci-dessus soit bien définie.
\end{definition}

En particulier, si l'expérience statistique considérée est engendrée par un $n$-échantillon de loi $\{\PP_\vartheta,\,\vartheta \in \Theta\}$ sur $\R$ dominée par une mesure $\mu$ sur $\R$, alors on a
$${\mathcal E}^n = \big(\R^n,{\mathcal B}^n,\{\PP_\vartheta^n,\,\vartheta \in \Theta\}\big),$$
avec $\PP_\vartheta^n = \PP_\vartheta \otimes \cdots \otimes \PP_\vartheta$ ($n$-fois), $\mu_n = \mu \otimes \cdots \otimes \mu$ ($n$-fois), et
$$f_n(z) = f_n(x_1,\ldots, x_n) = \prod_{i = 1}^n f(\vartheta,x_i),\;\;z=(x_1,\ldots, x_n) \in \mathfrak{Z}=\R^n,$$
où $f(\vartheta,x) = \frac{d\PP_\vartheta}{d\mu}(x)$ est la densité pour la famille de lois de probabilités sur $\R$. On déduit immédiatement de la formule
\eqref{def vrais cas general} l'identité :
\begin{equation} \label{def info fisher n ech}
\mathbb{I}(\vartheta\,|\,{\mathcal E}^n) = n\, \mathbb{I}(\vartheta) = n \,\mathbb{I}(\vartheta\,|\,{\mathcal E}^1),
\end{equation}
où $\mathbb{I}(\vartheta)$ est l'information de Fisher pour la famille $\big\{f(\vartheta, \cdot),\,\vartheta \in \Theta\big\}$ de la Définition \ref{information de fisher definition}.
\begin{remarque}
\emph{
La formule \eqref{def info fisher n ech} s'interprète de la manière suivante : pour un $n$-échantillon, chaque donnée $X_i$ contribue à l'information totale du modèle au point $\vartheta$ pour une quantité $\mathbb{I}(\vartheta)$. L'information totale, après $n$ observations, est $n$ fois l'information qu'apporte chaque donnée. Voir la Section \ref{proprietes info fisher}.
}
\end{remarque}
\index{régulier, modèle, expérience statistique}
\subsection{Modèle régulier en dimension 1} \label{modele regulier, def}
Nous avons vu dans la Section \ref{M estimation densite} du Chapitre \ref{estimation densite} que l'estimateur du maximum de vraisemblance est un $M$-estimateur associé au constraste
$\psi(a,x) = \log f(a,x)$ ou bien un $Z$-estimateur associé au \og score \fg{}
$$\phi(a,x) = \partial_a \psi(a,x) = \frac{\partial_a f(a,x)}{f(a,x)},$$
pour peu que ces quantités soient bien définies et régulières\footnote{Et on suppose toujours implicitement que la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ est dominée par une mesure $\sigma$-finie $\mu$ sur $\R$, de sorte que l'on puisse parler de la famille des densités $\big\{f(\vartheta, \cdot),\,\vartheta \in \Theta\big\}$.}.

Nous allons donner un jeu d'hypothèses le plus simple possible, de sorte que les calculs de la Section \ref{information de fisher}  développés précédemment soient justifiés, en particulier le Lemme \ref{centrage score}, et que l'on puisse appliquer les Propositions \ref{loi limite z est} ou \ref{loi limite m est} qui fournissent le comportement asymptotique des $Z$- ou $M$-estimateurs.

\begin{hypothese}[Régularité d'un modèle (ou d'une famille)] \label{regularite} On \vspace{1mm}a
\begin{itemize}
\item[(i)] L'ensemble des paramètres $\Theta \subset \R$ est un intervalle ouvert et pour tous $\vartheta, \vartheta' \in \Theta$, les ensembles
$\{f(\vartheta, \cdot)>0\}$ et $\{f(\vartheta',\cdot)>0\}$ coïncident\vspace{2mm}.

 \item[(ii)] $\mu$-presque partout, les fonctions $\vartheta \leadsto f(\vartheta,\cdot)$ et $\vartheta \leadsto \ell(\vartheta,\cdot)$ sont deux fois continûment différenti\-ables sur $\Theta${\vspace{1mm}}.

\item[(iii)] Pour tout $\vartheta \in \Theta$, il existe un voisinage de ${\mathcal V}(\vartheta) \subset \Theta$ tel que
pour tout $a \in {\mathcal V}(\vartheta)$:
$$|\partial_a^{2}\ell(a,x)|+|\partial_a \ell(a,x)|+\big(\partial_a\ell(a,x)\big)^2\leq g(x),$$
où
$$\int_{\mathbb{R}}g(x)\sup_{a \in {\mathcal V}(\vartheta)}f(a, x)\mu(dx)<+\infty.{\vspace{1mm}}$$

\item[(iv)] L'information de Fisher est non-dégénérée :
$$\forall \vartheta \in \Theta,\;\;\mathbb{I}(\vartheta) >0.$$
\end{itemize}
\end{hypothese}
Les hypothèses (ii) et (iii) sont les plus restrictives. On peut significativement les améliorer. Une référence accessible est van der Waart \cite{VDW}. Noter aussi que l'hypothèse (iii) est un renforcement des conditions
$$\E_\vartheta\big[\big|\partial^2_\vartheta\ell(\vartheta,X)\big|\big]<+\infty, \;\;\text{et}\;\;\E_\vartheta\big[\big(\partial_\vartheta\ell(\vartheta, X)\big)^2\big] = \mathbb{I}(\vartheta) <\infty.$$
\begin{definition} \label{famille reguliere} On dit que la famille de densités $\{f(\vartheta, \cdot), \vartheta \in \Theta\}$ est régulière si l'Hypothèse  \ref{regularite} est vérifiée. Par extension, l'expérience statistique ${\mathcal E}$ (ou ${\mathcal E}^n$) est régulière si elle est dominée et que la famille de densités associées est régulière.
\end{definition}
\subsection{Propriétés de l'information de Fisher}
\subsubsection{Information de Fisher et maximum de vraisemblance} \label{proprietes info fisher}
L'estimateur du maximum de vraisemblance est un $M$-estimateur, associé à la fonction
$$a \leadsto {\mathcal F}(a,\vartheta)=\E_\vartheta\big[\psi(a,X)\big],$$
où $\psi$ est la fonction de contraste :
%$$\psi(a,x) = \partial_\vartheta \ell(\vartheta,x)_{\big|\,\vartheta = a} = \partial_\vartheta \log f(\vartheta, x)_{\big|\,\vartheta = a}.$$
$$\psi(a,x) = \log f(a, x).$$
\begin{proposition} \label{Fisher et emv}Si la famille $\{f(\vartheta,\cdot), \vartheta \in \Theta\}$ est régulière et si
$$\forall \vartheta, \in \Theta,\;\;\;\int_{\R}\big|\log f(\vartheta,x)\big|f(\vartheta,x)\mu(dx)<+\infty,$$
alors, pour tout $\vartheta \in \Theta$, la fonction $a \leadsto {\mathcal F}(\vartheta,a)$ est deux fois continûment dérivable et on a
$$ \partial_a{\mathcal F}(a,\vartheta)_{\big|\,a=\vartheta}  = 0,$$
et
$$\partial_a^2{\mathcal F}(a,\vartheta)_{\big|\,a=\vartheta}  = \E_\vartheta\big[\partial_\vartheta^2\,\ell(\vartheta,X)\big] = - {\mathbb I}(\vartheta).$$
\end{proposition}
Le lemme technique suivant permet de justifier la dérivation sous le signe somme :
\begin{lemme} \label{derivation}
Soit $g:\Theta \times \R \rightarrow \R$ telle que $a \leadsto g(a,x)$ soit continûment différentiable $\mu(dx)$ presque-partout. Si, de plus, pour un ouvert ${\mathcal U}$ de $\Theta$,  et pour tout $a \in {\mathcal U}$
$$\int_{\R} \big|g(a,x)\big|\mu(dx) <+\infty,\;\;\text{et}\;\;\int_{\R}\sup_{a \in {\mathcal U}}\big|\partial_a\,g(a,x)\big|\mu(dx) <+\infty$$
%et, pour tout $a \in {\mathcal U}$,
%$$\int_{\R} \big|g(a,x)\big|\mu(dx) <+\infty,$$
alors  la fonction $a\leadsto G(a) = \int_{\R} g(a,x)\mu(dx)$
est continûment différentiable sur ${\mathcal U}$ et
% on peut dériver sous le signe somme :
$$G'(a) = \frac{d}{da}\int_{\R} g(a,x)\mu(dx) = \int_{\R} \partial_a \,g(a,x)\mu(dx).$$
\end{lemme}
\begin{proof} C'est une application répétée du théorème de convergence dominée.
\end{proof}

\begin{proof}[Démonstration de la Proposition \ref{Fisher et emv}]
L'application $a \leadsto {\mathcal F}(a,\vartheta)$ est dérivable en appliquant le Lemme \ref{derivation} avec $g(a,x) = f(\vartheta,x)\log f(a,x)$.
%ainsi que {\tt more here}.
On obtient :
$$ \partial_a{\mathcal F}(a,\vartheta)_{\big|a=\vartheta}   = \int_{\R} \partial_\vartheta \ell(\vartheta,x) f(\vartheta,x)\mu(dx).$$
On sait déja par le Lemme \ref{entropie} du Chapitre \ref{estimation densite} que le maximum de ${\mathcal F}(\cdot, \vartheta)$ est atteint en $a=\vartheta$, donc $\partial_a{\mathcal F}(a,\vartheta)_{\big|a=\vartheta} = 0$. Pour la deuxième égalité, on applique le Lemme \ref{derivation} à $G(a) = \partial_a{\mathcal F}(a,\vartheta)$ en posant cette fois-ci
$g(a,x) = \partial_a^2\ell(a,x)f(\vartheta,x)$.
\end{proof}
Nous allons maintenant démontrer rigoureusement l'identité \ref{formule utile} de la Section \ref{fisher premiere interpretation}.
\begin{lemme} \label{formule rigoureuse}
Si la famille $\{f(\vartheta, \cdot), \vartheta \in \Theta\}$ est régulière, alors, pour tout $\vartheta \in \Theta$, on a
$$\mathbb{I}(\vartheta) = -\E_\vartheta\big[\partial^2_\vartheta\,\ell(\vartheta,X)\big] =-\int_{\R} \partial^2_\vartheta \,\ell(\vartheta, x)f(\vartheta,x)\mu(dx).$$
\end{lemme}
En particulier, on en déduit, sous les hypothèses de la Proposition \ref{Fisher et emv}
$$\partial^2_a{\mathcal F}(a,\vartheta)_{\big|a=\vartheta} = -\mathbb{I}(\vartheta).$$
\begin{proof}
On dérive deux fois sous le signe somme l'égalité
$$\int_{\R}f(\vartheta,x)\mu(dx)=1.$$
On applique d'abord le Lemme \ref{derivation} avec $g(\vartheta,x) = f(\vartheta,x)$. On en déduit, pour tout $\vartheta \in \Theta$,
$$\int_{\R} \partial_\vartheta f(\vartheta,x)\mu(dx) = 0,$$
ou encore
$$\int_{\R} \partial_\vartheta\ell(\vartheta,x) f(\vartheta,x)\mu(dx) = 0.$$
On applique le Lemme \ref{derivation} une seconde fois, avec $g(\vartheta,x) = \partial_\vartheta f(\vartheta,x) = \partial_\vartheta\ell(\vartheta,x)f(\vartheta,x)$. Alors
$$\partial_\vartheta g(\vartheta,x) = \partial^2_\vartheta \ell(\vartheta,x)f(\vartheta, x)+\big(\partial_\vartheta\,\ell(\vartheta,x)\big)^2f(\vartheta,x).$$
Cette identité
%avec l'Hypothèse \ref{} {\tt more here}
permet de conclure
$$0 = \int_{\R} \partial_\vartheta g(\vartheta,x)\mu(dx) = \int_{\R}\partial_\vartheta^2\ell(\vartheta,x)f(\vartheta,x)\mu(dx)+\mathbb{I}(\vartheta),$$
d'où le résultat.
\end{proof}
\subsection{Interprétation géométrique de l'information de Fisher}
Pour une expérience statistique régulière, la Proposition \ref{Fisher et emv} et le Lemme \ref{formule rigoureuse} donnent la représentation
$$\mathbb{I}(\vartheta) = -\partial^2_a{\mathcal F}(a,\vartheta)_{\big|a=\vartheta} \geq 0,$$
et la fonction $a \leadsto {\mathcal F}(a,\vartheta)$ atteint son maximum au point $a=\vartheta$.

Si $\mathbb{I}(\vartheta)$ est petite, le rayon de courbure de la courbe représentative de $a \leadsto {\mathcal F}(a,\vartheta)$ est grand dans un voisinage de $\vartheta$, et ${\mathcal F}(\cdot,\vartheta)$ est \og plate\fg{} dans ce voisinage, et le comportement typique de $a \leadsto \ell_n(a)$ sera oscillant, rendant moins précis l'estimateur du maximum de vraisemblance.
\index{maximum de vraisemblance}
Par contre, si $\mathbb{I}(\vartheta)$ est grande, ${\mathcal F}(\cdot, \vartheta)$ est \og pointue\fg{} dans un voisinage de $\vartheta$.
\subsubsection{Lien avec l'entropie}
Si $\PP$ et $\mathbb{Q}$ sont deux mesures de probabilités définies sur un même espace mesurable $(\Omega, {\mathcal A})$, on définit la divergence de Kullback-Leibler de $\PP$ relativement à $\mathbb{Q}$ comme
$$K(\PP, \mathbb{Q}) = \int_{\Omega} \log \frac{d\PP}{d\mathbb{Q}}(\omega)\PP(d\omega)$$
si $\PP \ll \mathbb{Q}$ ($\mathbb{Q}$ domine $\PP$) et on pose $K(\PP, \mathbb{Q})=+\infty$ sinon. On parle improprement de \og distance \fg{} de Kullback-Leibler entre $\PP$ et $\mathbb{Q}$ pour la raison suivante :
\begin{lemme}
\index{Kullback-Leibler, divergence}
%\index{Maximum de vraisemblance}
On a toujours
$$0 \leq K(\PP,\mathbb{Q}) \leq +\infty,$$
et
$$K(\PP,\mathbb{Q}) = 0\;\;\;\text{si et seulement si}\;\;\; \PP = \mathbb{Q}.$$
\end{lemme}
\begin{proof}
%Supposons $\PP \ll \mathbb{Q}$. Alors il existe une densité $q(x) = \frac{d\PP}{d\mathbb{Q}}(x)$ définie $\mathbb{Q}$ presque-sûrement, et la fonction $x \leadsto \log q(x)$ est définie $\mathbb{Q}$ presque-sûrement en convenant $\log(x/0)=+\infty$ si $0 < x < +\infty$. De même pour $x \leadsto $
Introduisons la fonction définie sur $\R_+$ par
$$h(x)=x\log(x).$$
Si $Z$ est une variable aléatoire positive telle que $\E_{\mathbb{Q}}\big[Z\big]<+\infty$ (espérance de $Z$ par rapport à la mesure de probabilité $\mathbb{Q}$), on peut toujours définir la quantité
$${\mathcal E}\big[Z\big] = \E_{\mathbb{Q}}\big[h(Z)\big]-h\big(\E_{\mathbb{Q}}\big[Z\big]\big),$$
En effet, $h$ est minorée par $-1/e$, donc $\E_{\mathbb{Q}}\big[h(Z)\big]$ a un sens, même si $h(Z)$ n'est pas $\mathbb{Q}$-intégrable.
Puisque $h$ est convexe, l'inégalité de Jensen assure que ${\mathcal E}_{\mathbb{Q}}[Z] \geq 0$ (éventuellement $+\infty$). Enfin, ${\mathcal E}\big[Z\big]$ est finie si et seulement si $h(Z)$ est $\mathbb{Q}$-intégrable.

Supposons maintenant $\PP \ll \mathbb{Q}$, et posons $Z = \frac{d\PP}{d\mathbb{Q}}$, la densité de Radon-Nikodym\footnote{Voir, par exemple, Jacod et Protter \cite{JP}, Chapitre 28.} de $\PP$ par rapport à $\mathbb{Q}$. Alors $Z$ est $\mathbb{Q}$-intégrable et $\E_{\mathbb{Q}}\big[Z\big]=1$. Il vient
$${\mathcal E}\big[Z\big] = \E_{\mathbb{Q}}\big[h(Z)\big] = \int \frac{d\PP}{d\mathbb{Q}}\log\frac{d\PP}{d\mathbb{Q}}d\mathbb{Q} = K(\PP,\mathbb{Q}),$$
d'où la première partie du lemme.

La seconde partie du lemme est une conséquence immédiate du Lemme \ref{entropie} :
on pose $\mu = \mathbb{Q}$, $f=\frac{d\PP}{d\mathbb{Q}}$ et $g=1$. Alors $f$ et $g$ sont deux densités de probabilité par rapport à $\mu$ et on a
$$K(\PP,\mathbb{Q}) = \int \log \frac{f}{g} f d\mu \geq 0$$
%la mesure $\mu = \PP+\mathbb{Q}$ domine simultanément $\PP$ et $\mathbb{Q}$ et, en posant $f=\frac{d\PP}{d\mu}$ et $g = \frac{d\mathbb{Q}}{d\mu}$, on a $\frac{d\PP}{d\mathbb{Q}} = f/g$ $\mu$-presque partout. On a alors
%$$K(\PP,\mathbb{Q}) = \int \log \frac{f}{g}f d\mu \leq 0$$
d'après le Lemme \ref{entropie}, avec égalité si et seulement $f=g$ $\mu$-presque partout, ce qui entraîne $\PP=\mathbb{Q}$.
%est la cas d'égalité dans l'inégalité de Jensen : puisque $h$ est strictement convexe et ${\mathcal E}[Z]\geq 0$, si $K(\PP,\mathbb{Q})=0$, alors $Z=1$ $\mathbb{Q}$ presque-sûrement et ceci entraîne $\PP = \mathbb{Q}$.
\end{proof}
Dans le contexte d'un modèle régulier, entropie et information de Fisher sont reliés par la fonction ${\mathcal F}$ : on a, pour $\vartheta_1, \vartheta_2 \in \Theta$,
$$K\big(\PP_{\vartheta_1}, \PP_{\vartheta_2}\big) = {\mathcal F}(\vartheta_2, \vartheta_2) - {\mathcal F}(\vartheta_1, \vartheta_2)
=\int_{\R} \log \frac{f(\vartheta_2, x)}{f(\vartheta_1, x)} f(\vartheta_2,x) \mu(dx).
$$
C'est une mesure de divergence disymétrique entre $\PP_{\vartheta_1}$ et $\PP_{\vartheta_2}$. Son interprétation est similaire à celle de l'information de Fisher, comme le montre la représentation ci-dessus. L'avantage immédiat de la divergence de Kullback-Leibler sur l'information de Fisher est qu'elle est toujours définie, sans hypothèse de régularité sur la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ sous-jacente.
\begin{definition}
La valeur
$$-{\mathcal F}(\vartheta,\vartheta) = - \int_{\R}f(\vartheta,x) \log f(\vartheta,x) \mu(dx)$$
est appelée entropie de Shannon associée à la densité $f(\vartheta,\cdot)$.
\end{definition}
\index{Shannon, entropie de}
L'entropie de Shannon peut être utilisée comme mesure de dispersion lorsque, par exemple, la variance par rapport à la loi $f(\vartheta,x)\mu(dx)$ n'existe pas. Elle a un lien avec la théorie de l'information.
\subsection{Le cas multidimensionnel} \label{passage fisher multidimensionnel}
Si $\Theta \subset \R^d$ avec $ d >1$, tous les résultats de la Section précédente s'étendent de manière naturelle en remplaçant dérivation par rapport à $\vartheta$ par différentiabilité dans $\R^d$. L'information de Fisher devient la matrice d'information de Fisher.
\begin{definition} La matrice d'information de Fisher $\mathbb{I}(\vartheta) = \big(\mathbb{I}(\vartheta)_{\ell,\ell'}\big)_{1 \leq \ell,\ell' \leq d}$ associée à la famille de densités $\{f(\vartheta),\,\vartheta \in \Theta\}$ avec $\vartheta \in \Theta \subset \R^d$ est définie au point $\vartheta$ par
$$\mathbb{I}(\vartheta)_{\ell,\ell'} = \E_\vartheta\big[\partial_{\vartheta_\ell}\log f(\vartheta, X) \partial_{\vartheta_{\ell'}} \log f(\vartheta, X)\big],\;\;\;1 \leq \ell,\ell' \leq d,$$
pour peu que cette quantité soit bien définie, avec $\vartheta  = (\vartheta_1,\ldots, \vartheta_d)^T$. C'est une matrice symétrique positive.
\end{definition}
Nous ne développerons pas la théorie en dimension plus grande que 1. Une référence avec des exemples détaillés est Borovkov \cite{B}.
\section{Théorie asymptotique}
\subsection{Normalité asymptotique du maximum de vraisemblance}
\subsubsection{Le cas de la dimension 1}
On considère l'expérience statistique ${\mathcal E}^n$ engendrée par un $n$-échantillon de loi $\PP_\vartheta$, où la famille $\big\{\PP_\vartheta,\,\vartheta\in \Theta\big\}$ est dominée par une mesure $\mu$ sur $\R$ $\sigma$-finie, et on suppose $\Theta \subset \R$. Le résultat suivant donne le comportement asymptotique de l'estimateur du maximum de vraisemblance.
% Le jeu d'hypothèses très fort que nous faisons permet de se ramener aux résultats du Chapitre \ref{estimation densite} pour les $Z$- et $M$-estimateurs.
\begin{proposition}[Normalité asymptotique de l'EMV] \label{normalite asymptotique de l emv}
Si l'expérience ${\mathcal E}^n$ est régu\-lière au sens de la Définition \ref{famille reguliere}, alors l'estimateur du maximum de vraisemblance $\estMV$ est bien défini et asymptotiquement normal, et on a
$$\sqrt{n}\big(\estMV-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\Big(0,\frac{1}{\mathbb{I}(\vartheta)}\Big)$$
en loi sous $\PP_\vartheta$, et $0 < \mathbb{I}(\vartheta) <+\infty$ est l'information de Fisher du modèle au point $\vartheta$.
\end{proposition}
\begin{proof}[Esquisse de démonstration]
En interprétant l'estimateur du maximum de vraisemblance comme un $M$-estimateur, on applique la Proposition \ref{loi limite m est} du Chapitre \ref{estimation densite} pour la fonction de constraste $\psi(a,x) = \log f(a,x)$. Ceci nous conduit en fait à vérifier les conditions de l'Hypothèse \ref{hyp conv z est} en vue d'appliquer la Proposition \ref{loi limite z est} à la fonction $\phi(a,x) = \partial_a \log f(a,x)$.

Cependant, les conditions de l'Hypothèse \ref{regularite} sont en partie plus faibles que l'Hypothèse \ref{hyp conv z est}. En reprenant la preuve de la Proposition \ref{loi limite z est}, on vérifie alos que seul le terme de reste \eqref{remainder} pose une difficulté. On pourra montrer en exercice qu'en appliquant pour ce terme la formule de Taylor avec reste intégral, alors les conditions de régularité de l'Hypothèse \ref{regularite} permettent de conclure.
\end{proof}

\subsubsection{Le cas multidimensionnel}
La Proposition \ref{normalite asymptotique de l emv} s'étend au cas multidimensionnel, en remplaçant l'information de Fisher par la matrice d'information de Fisher définie dans la Section \ref{passage fisher multidimensionnel}, en étendant l'Hypothèse \ref{regularite} par une version multidimensionelle (la dérivée première par rapport à $\vartheta$ de la fonction $\vartheta \leadsto f(\vartheta,\cdot)$ devenant le gradient et la dérivée seconde la matrice hessienne). Nous ne développerons pas la théorie en dimension plus grande que 1. Une référence avec des exemples détaillés est Borovkov \cite{B}.

\subsection{Comparaison d'estimateurs : efficacité asymptotique}
\index{efficacité asymptotique}
Nous nous plaçons dans cette section dans le cas de la dimension 1, avec $\Theta \subset \R$ pour simplifier. Les extensions au cas multidimensionnel se font de la même manière que pour la Section \ref{passage fisher multidimensionnel}. On se restreint ici à la classe des estimateurs asymptotiquement normaux, c'est-à-dire les estimateurs $\est$ pour lesquels
$$\sqrt{n}\big(\est - \vartheta\big)\stackrel{d}{\longrightarrow} {\mathcal N}\big(0,v(\vartheta)\big)$$
pour $\vartheta \in \Theta$. On suppose de plus :
\begin{hypothese} \label{reg variance asymp}
L'application $\vartheta \leadsto v(\vartheta)$ est continue et strictement positive sur $\Theta$.
\end{hypothese}
Sous des hypothèses de régularité, on a vu que les $M$-estimateurs sont asymptotiquement normaux et vérifient \eqref{reg variance asymp}. En particulier, pour l'estimateur du maximum de vraisemblance,
$$v(\vartheta) = \frac{1}{\mathbb{I}(\vartheta)}.$$
On a la règle de comparaison suivante :
\begin{definition} Si $\widehat \vartheta_{n,1}$ et $\widehat \vartheta_{n,2}$ sont deux (suites d')estimateurs asymptotiquement normaux de variances asymptotiques respectives $v_1(\vartheta)$ et $v_2(\vartheta)$ et vérifiant l'Hypothèse \ref{reg variance asymp}, on dit que $\widehat \vartheta_{n,1}$ est plus efficace que $\widehat \vartheta_{n,2}$ si
$$\forall \vartheta \in \Theta,\;\;v_1(\vartheta) \leq v_2(\vartheta)$$
et si de plus, il existe un point $\widetilde \vartheta \in \Theta$ tel que
$$v_1(\widetilde \vartheta) < v_2(\widetilde \vartheta).$$
Une suite d'estimateurs $\est$ est asymptotiquement efficace s'il n'existe pas d'autre estimateurs (dans la classe considérée) plus efficace que $\est$.
\end{definition}
\begin{remarque}
\emph{L'hypothèse de normalité asymptotique en tout point $\vartheta \in \Theta$ permet en particulier d'exclure les estimateurs artificiels de la forme $\est = \vartheta_0$ pour un point $\vartheta_0 \in \Theta$ arbitraire, qui sont catastrophiques pour le risque quadratique en dehors d'un \og petit \fg{} voisinage de $\vartheta_0$ mais qui ont un risque nul en $\vartheta_0$.
}
\end{remarque}
\subsubsection{Efficacité asymptotique du maximum de vraisemblance}
Dans cette section, on considère une expérience statistique régulière et on suppose l'espace des paramètres $\Theta \subset \R$ pour simplifier. On se restreint en fait à la classe des $Z$-estimateurs, qui contient en particulier les $M$-estimateurs réguliers.

Un tel estimateur $\est$ est obtenu comme solution d'une équation de type
\begin{equation} \label{eq GMM}
\sum_{i = 1}^n \phi(\est, X_i) = 0
\end{equation}
où $\phi: \Theta \times \R$ est une fonction  choisie par le statisticien, qui détermine la méthode. En particulier, si
$$\phi(\vartheta,x) = \partial_\vartheta\log f(\vartheta,x) = \partial_\vartheta \ell(\vartheta,x)$$
dans le cas d'une famille de probabilités $\{\PP_\vartheta(dx) = f(\vartheta,x)\mu(dx), \vartheta\in \Theta\}$ dominée par une mesure $\sigma$-finie $\mu$, on retrouve l'estimateur du maximum de vraisemblance.

On considère une expérience statistique régulière engendrée par l'observation d'un $n$-échantillon.
% {\tt more here}
\begin{theoreme}[Efficacité asymptotique du maximum de vraisemblance parmi la classe des $Z$-estimateurs]
Si $\est$ est un $Z$-estimateur régulier\footnote{Nous appelons informellement $Z$-estimateur régulier un $Z$-estimateur pour lequel la Proposition \ref{loi limite z est} est vérifiée.} associé à la fonction $\phi$ via \eqref{eq GMM}, alors $\est$ est asymptotiquement normal de variance asymptotique
$$v_\phi(\vartheta) = \frac{\E_\vartheta\big[\phi(\vartheta,X)^2\big]}{\Big(\E_\vartheta\big[\partial_\vartheta \phi(\vartheta,X)\big]\Big)^2}.$$
%def $Z$estimateur regulier
De plus, pour tout choix de fonction $\phi$, on a
 \begin{equation} \label{Cramer Rao}
 v_\phi(\vartheta) \geq \frac{1}{\mathbb{I}(\vartheta)}.
 \end{equation}
 \end{theoreme}
 \begin{corollaire}
 Dans un modèle régulier, l'estimateur du maximum de vraisemblance est asymptotiquement efficace parmi les
 $Z$-estimateurs réguliers.
 %{\tt more here}.
 \end{corollaire}
 \begin{proof}
La première partie du théorème a déjà été montrée dans la Proposition \ref{loi limite z est}. Montrons \eqref{Cramer Rao}. On note $\phi'(\vartheta,x) = \partial_\vartheta\phi(\vartheta,x)$. Par construction,
 % {\tt ameliorer},
la fonction $\phi$ vérifie
$$\partial_a \E_\vartheta\big[\phi(a,X)\big]_{\big| a = \vartheta}=0,$$
ce qui s'écrit encore
\begin{align*}
0& = \int_{\R} \phi'(\vartheta,x)f(\vartheta,x)\mu(dx)+\int_{\R}\phi(\vartheta,x)\partial_\vartheta f(\vartheta,x)\mu(dx) \\
& = \int_{\R} \phi'(\vartheta,x)f(\vartheta,x)\mu(dx)+\int_{\R}\phi(\vartheta,x)\partial_\vartheta\,\ell(\vartheta,x) f(\vartheta,x)\mu(dx),
\end{align*}
c'est-à-dire
$$\E_\vartheta\big[\phi'(\vartheta,X)\big] = -\E_\vartheta\big[\phi(\vartheta,X)\partial_\vartheta\ell(\vartheta,X)\big].$$
En appliquant l'inégalité de Cauchy-Schwarz, on obtient
$$\Big(\E_\vartheta\big[\phi'(\vartheta,X)\big]\Big)^2 \leq \E_\vartheta\big[\phi(\vartheta,X)^2\big] \E_\vartheta\big[\big(\partial_\vartheta\ell(\vartheta,X)\big)^2\big],$$
c'est-à-dire
$$v_\phi(\vartheta)^{-1} = \frac{\big(\E_\vartheta\big[\partial_\vartheta \phi(\vartheta,X)\big]\big)^2}{\E_\vartheta\big[\phi(\vartheta,X)^2\big]} \leq \E_\vartheta\big[\big(\partial_\vartheta\,\ell(\vartheta,X)\big)^2\big] = \mathbb{I}(\vartheta).$$
 \end{proof}
\subsubsection{Efficacité à un pas$^\ast$}
Dans un modèle régulier, l'estimateur du maximum de vraisemblance est \og meilleur \fg{} que n'importe quel autre $Z$-estimateur au sens de l'efficacité asymptotique. Pourtant, il est parfois plus facile de mettre en œuvre un $Z$-estimateur donné (ou d'ailleurs un $M$-estimateur) plutôt que l'estimateur du maximum de vraisemblance, voir l'Exemple \ref{exemple modele de cauchy} du modèle de Cauchy.

On peut modifier un estimateur $\est$ consistant et asymptotiquement normal de sorte qu'il ait asymptotiquement le même comportement que l'estimateur du maximum de vraisemblance.
%Etant donné une fonction de constraste $(a,x)\leadsto \psi(a,x)$, $a\in \Theta, x\in \R$,
On note $\ell_n(\vartheta) = \frac{1}{n}\sum_{i = 1}^n \log f(\vartheta,X_i).$
\begin{proposition}[Efficacité à un pas]
Si le modèle est régulier et si $\est$ est un estimateur asymptotiquement normal, alors l'estimateur modifié\footnote{Il faut bien sûr que le dénominateur du terme de correction soit non nul. L'événement sur lequel il est bien défini a une $\PP_\vartheta$-probabilité qui tend vers $1$ si le modèle est régulier. Nous omettons ces aspects techniques.}
$$\widetilde \vartheta_n = \est - \frac{\ell_n'(\est)}{\ell_n^{''}(\est)}$$
vérifie
$$\sqrt{n}\big(\widetilde \vartheta_n - \vartheta\big)\stackrel{d}{\longrightarrow} {\mathcal N}\Big(0,\frac{1}{\mathbb{I}(\vartheta)}\Big)$$
en loi sous $\PP_\vartheta$ et est donc asymptotiquement efficace.
\end{proposition}
Le choix initial pourra donc être un $M$- ou $Z$-estimateur consistant et asymptotiquement normal, sans que l'on ait besoin de se soucier (asymptotiquement) de sa variance asymptotique.
\begin{proof}[Esquisse de démonstration]
On écrit
\begin{align*}
\sqrt{n}\big(\widetilde \vartheta_n - \vartheta\big) & = \sqrt{n}\big(\est -\vartheta\big) - \frac{\sqrt{n}\ell_n'(\est)}{\ell''_n(\est)} \\
& = \sqrt{n}\big(\est -\vartheta\big) - \frac{\sqrt{n}\ell'_n(\vartheta)+\sqrt{n}\big(\ell'_n(\est)-\ell'_n(\vartheta)\big)}{\ell_n''(\vartheta) + \big(\ell_n''(\est)-\ell_n''(\vartheta)\big)} \\
& =  \sqrt{n}\big(\est -\vartheta\big) - \frac{\sqrt{n}\ell'_n(\vartheta)+\sqrt{n}(\est-\vartheta)\ell''_n(\vartheta)+u_n}{\ell_n''(\vartheta)+v_n}.
\end{align*}
La seule difficulté consiste à montrer que $u_n \stackrel{\PP_\vartheta}{\longrightarrow} 0$ et $v_n \stackrel{\PP_\vartheta}{\longrightarrow} 0$. Cela se fait de la même manière que pour la preuve de la Proposition \ref{loi limite z est} ou \ref{loi limite m est}. Alors $\sqrt{n}\big(\widetilde \vartheta_n - \vartheta\big)$ a le même comportement asymptotique que
$$\sqrt{n}\big(\est -\vartheta\big) - \frac{\sqrt{n}\ell'_n(\vartheta)+\sqrt{n}(\est-\vartheta)\ell_n''(\vartheta)}{\ell_n''(\vartheta)} = \sqrt{n}\frac{\ell'(\vartheta)}{\ell_n''(\vartheta)}$$
qui converge en loi sous $\PP_\vartheta$ vers la loi ${\mathcal N}\big(0,\tfrac{1}{\mathbb{I}(\vartheta)}\big)$ de la même manière qu'à la Section \ref{information de fisher}.
\end{proof}
\begin{exemple}
\emph{
Une source émet des particules de type $A$ avec probabilité $\vartheta$ et de type $B$ avec probabilité $1-\vartheta$, où $\vartheta \in \Theta = (0,1)$. On mesure l'énergie des particules, qui est distribuée selon une densité $f_1$ connue pour les particules de type $A$ et $f_2$ pour les particules de type $B$.
Si l'on détecte $n$ particules avec des énergies $X_1,\ldots, X_n$, quelle est la valeur de $\vartheta$ ?
En postulant que l'observation est un $n$-échantillon, la fonction de vraisemblance de l'expérience statistique engendrée par l'observation s'écrit
$${\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \prod_{i = 1}^n \big(\vartheta f_1(X_i)+(1-\vartheta)f_2(X_i)\big),$$
de sorte que
$$\partial_\vartheta \log {\mathcal L}_n(\vartheta, X_1,\ldots, X_n) = \sum_{i = 1}^n \frac{f_1(X_i)-f_2(X_i)}{\vartheta f_1(X_i)+(1-\vartheta)f_2(X_i)}.$$
La résolution de l'équation de vraisemblance associée est d'autant plus difficile que $n$ est grand. Supposons que $\int_{\R} \big(F_1(x)-F_2(x)\big)^2dx<+\infty$, où $F_i(x) = \int_{-\infty}^x f_i(t)dt$, $i=1,2$. Soit $\est$ l'estimateur qui minimise
$$a \leadsto \int_{\R}\big(\widehat F_n(x)-F_a(x)\big)^2dx,$$
avec
$$F_a(x)=a F_1(x)+(1-a)F_2(x),$$
et $\widehat F_n(x) = \tfrac{1}{n}\sum_{i = 1}^n 1_{X_i \leq x}$ désigne la fonction de répartition empirique de $F$ étudiée au Chapitre \ref{echantillonnage}.
En dérivant par rapport à la variable $a$, on obtient
$$\int_{\R}\big(\widehat F_n(x)-F_a(x)\big)\big(F_1(x)-F_2(x)\big)dx=0,$$ d'où
$$\est = \frac{\int_{\R}\big(\widehat F_n(x)-F_2(x)\big)\big(F_1(x)-F_2(x)\big)dx}{\int_{\R}\big(F_1(x)-F_2(x)\big)^2dx}.$$
En s'appuyant sur le Chapitre \ref{echantillonnage}, on peut montrer que $\est$ est asymptotiquement normal. Alors l'estimateur modifié
$$\widetilde \vartheta_n = \est -\frac{\partial_\vartheta \log {\mathcal L}_n(\est, X_1,\ldots, X_n)}{\partial_\vartheta^2 \log {\mathcal L}_n(\est, X_1,\ldots, X_n)}$$
où
$$\partial_\vartheta^2 \log {\mathcal L}_n(\est, X_1,\ldots, X_n) = -\sum_{i = 1}^n\frac{\big(f_1(X_i)-f_2(X_i)\big)^2}{\big(\vartheta f_1(X_i)+(1-\vartheta)f_2(X_i)\big)^2}$$
est asymptotiquement efficace, et sa variance asymptotique est l'information de Fisher du modèle
$$\mathbb{I}(\vartheta) = \int_{\R}\frac{\big(f_1(x)-f_2(x)\big)^2}{\vartheta f_1(x)+(1-\vartheta)f_2(x)}dx.$$
}
\end{exemple}
\begin{remarque}
\emph{
Il existe une extension multimensionnelle lorsque $\Theta \subset \R^d$ avec $d\geq 1$, obtenue de la même manière par un développement de Taylor à l'ordre 2. La dérivée de $\vartheta \leadsto \ell_n(\vartheta)$ est remplacée par son gradient, et la dérivée seconde par sa matrice hessienne, supposée définie positive.
}
\end{remarque}

\subsection{Le programme de Fisher et ses limites}
En 1922, Fisher conjectura que pour un modèle régulier (dans un sens comparable avec celui de la Section \ref{modele regulier, def}),
\begin{itemize}
\item[(i)] l'estimateur du maximum de vraisemblance converge et a pour variance asymptotique $\tfrac{1}{\mathbb{I}(\vartheta)}$.
\item[(ii)] si, pour une suite d'estimateurs $\widehat \vartheta_n$, on a
$$\sqrt{n}\big(\est - \vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,v(\vartheta)\big),$$
alors, nécessairement
$$v(\vartheta) \geq \frac{1}{\mathbb{I}(\vartheta)}.$$
\end{itemize}
\index{Fisher, programme de}
Le programme de Fisher aurait permis, parmi une classe d'estimateurs raisonnables, de clore le débat sur l'optimalité asymptotique. On a vu que le point (i) de la conjecture de Fisher est vrai. On a montré que le point (ii) est vrai parmi la classe restreinte des $Z$-estimateurs réguliers.

Mais la conjecture de Fisher est fausse en général :  pour tout estimateur asymptotiquement normal, on peut construire un estimateur modifié plus efficace. Une construction classique, le contre-exemple de Hodge-Lehmann, est étudiée par exemple dans Genon-Catalot et Picard \cite{GCP}.
%l'Exercice \ref{hodge lehmann}.
\subsubsection{Conclusion}
\begin{enumerate}
\item  Concernant la notion de modèle régulier, par souci de simplicité, nous nous sommes restreints à un jeu d'hypothèses assez fortes. On peut étendre significativement les hypothèses de régularité.
\item La comparaison asymptotique d'estimateurs reste une notion fragile et {\it ad-hoc}. Un point de vue alternatif est la recherche d'uniformité en le paramètre (approche minimax).
\end{enumerate}
\subsection{Modèles non-réguliers}
Nous traitons le cas des modèles non-réguliers sur un exemple incontournable : la loi uniforme.
%\subsubsection{Calcul de la vraisemblance}
Considérons l'expérience engendrée par un $n$-échantillon de loi uniforme sur $[0,\vartheta]$, où $\vartheta \in \Theta  = \R_+\setminus\{0\}$. La famille de lois $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$ associée est dominée par la mesure de Lebesgue sur $\R_+$, et la densité $f(\vartheta,x)$ s'écrit :
$$f(\vartheta,x)=\vartheta^{-1}1_{[0,\vartheta]}(x).$$
La fonction $\vartheta \leadsto f(\vartheta,x)$ n'est pas régulière au sens de la Définition \ref{famille reguliere}, puisqu'elle est discontinue en $\vartheta = x$.
On ne peut pas définir d'information de Fisher, et la théorie asymptotique ne s'applique pas.
%Pourtant, la formule \eqref{la bonne representation} permet d'exhiber \og un candidat \fg{} pour une statistique exhaustive, même en l'absence d'information de Fisher. Cette statistique exahustive dans un sens étendu est d'ailleurs l'estimateur du maximum de vraisemblance, ce qui suggère -- au moins dans ce cas particulier -- que l'on doit pouvoir étendre la théorie sous des conditions plus faibles.
La vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = \prod_{i = 1}^nf(\vartheta, X_i) \\
& = \vartheta^{-n}\prod_{i = 1}^n1_{[0,\vartheta]}(X_i)\\
& = \vartheta^{-n}1_{\{\max_{i = 1,\ldots, n}X_i \leq \vartheta\}}.
\end{align*}
%La représentation \eqref{la bonne representation} suggère que $T(X_1,\ldots, X_n) = \max_{i = 1,\ldots, n}X_i$ est une statistique exhaustive. Par ailleurs,
La fonction
$$\vartheta \leadsto \vartheta^{-n}1_{\big\{\max_{i = 1,\ldots, n}X_i \leq \vartheta\big\}}$$
atteint son maximum unique en $\vartheta = \max_{i = 1,\ldots, n}X_i$ qui est donc l'estimateur du maximum de vraisemblance $\estMV$.
\subsubsection{Comportement asymptotique du maximum de vraisemblance}
L'estimateur du maximum de vraisemblance n'est pas asymptotiquement normal, et la précision d'estimation de $\estMV$ est meilleure que la vitesse $1/\sqrt{n}$ des modèles réguliers.

On peut préciser son comportement asymptotique. Pour $t\in \R $, on a
\begin{align*}
\PP_\vartheta\big[\estMV  \leq t]  & = \PP_\vartheta\big[\bigcap_{i = 1}^n (X_i\leq t)\big] \\
& =\prod_{i = 1}^n \PP_\vartheta\big[X_i \leq t\big] \\
& = (\vartheta^{-1}t)^n 1_{[0,\vartheta]}(t)+1_{\{t >\vartheta\}}
\end{align*}
par indépendance des $X_i$. Il vient
\begin{align*}
\PP_\vartheta\big[n(\estMV-\vartheta)\leq t\big] & = \PP_\vartheta\big[\est \leq \vartheta +\tfrac{t}{n}\big] \\
& = \big(1+\vartheta^{-1}\frac{t}{n}\big)^n1_{[-n\vartheta, 0]}(t)+1_{\{t >0\}} \\
&\rightarrow e^{\vartheta^{-1}t}1_{\{t \leq 0\}} + 1_{\{t >0\}}.
\end{align*}
Donc $n(\estMV-\vartheta)$ converge en loi sous $\PP_\vartheta$ vers une loi de fonction de répartition
$$F(t)=e^{\vartheta^{-1}t}1_{\{t \leq 0\}} + 1_{\{t >0\}},$$
dérivable presque-partout, et de densité
$t \leadsto \vartheta^{-1}e^{-\vartheta t}1_{\{t \leq 0\}}$, qui peut s'écrire comme $-Z$, où $Z$ est une variable aléatoire exponentielle de paramètre $\vartheta^{-1}$. On notera que dans ce modèle, la vitesse d'estimation est $1/n$ et non $1/\sqrt{n}$ comme dans les modèles réguliers.
\section{Perte d'information$^\star$}
\index{perte d'information}
\index{exhaustivité}
\subsection{Sous-expérience statistique}
On considère une expérience statistique ${\mathcal E}$ arbitraire, engendrée par une observation $Z$ à valeurs dans $(\mathfrak{Z}, {\mathcal Z})$.

Dans l'expérience ${\mathcal E}$, un estimateur $\est$ est la donnée d'une fonction mesurable
$$\varphi : \mathfrak{Z} \rightarrow \Theta$$ appliquée à l'observation, c'est-à-dire
$$\widehat \vartheta = \varphi(Z).$$
Considérons maintenant une application mesurable
$$T:(\mathfrak{Z},{\mathcal Z}) \longrightarrow (\mathfrak{Y}, {\mathcal Y})$$
où $(\mathfrak{Y}, {\mathcal Y})$ est un espace mesurable donné, et posons $Y = T(Z)$. Alors $Y$ apparaît comme une \og sous-observation\fg{} de $Z$ et un estimateur de la forme $\widetilde \vartheta = \varphi(Y) = \varphi\big(T(Z)\big)$ sera en général moins performant qu'un estimateur de la forme $\est = \varphi(Z)$.

A l'application $T$ est attachée une notion de perte d'information, ou de compression d'information, que nous allons un peu formaliser.
\begin{definition}
%Si ${\mathcal E}^n$ est l'expérience statistique engendrée par l'observation $X^n$ à valeurs dans $\R^n$ et si $T^n:\R^n \rightarrow \R^n$ est mesurable,
On appelle sous-expérience de ${\mathcal E}$ associée à $T$ est on note ${\mathcal E}^{T}$ l'expérience engendrée par l'observation $T(Z)$.
\end{definition}
Si
$${\mathcal E} = \big(\R^n, {\mathcal B}^n, (\PP_\vartheta, \vartheta \in \Theta)\big),$$
on a
$${\mathcal E}^{T} = \big(T(\R^n), {\mathcal Y}, (\PP_\vartheta^T, \vartheta \in \Theta)\big),$$
où $\PP_\vartheta^{T}$ est la mesure image de $\PP_\vartheta$ par $T$. C'est une mesure de probabilité définie sur  $\big(T(\R^n), {\mathcal Y}\big)$ par
%sur la sous-tribu $({\mathcal B}^n)^T= \big\{T^{-1}(A),\,A\in {\mathcal Y}\big\}$ de ${\mathcal Y}$ définie par
$$\PP_\vartheta^{T}\big[A\big] = \PP_\vartheta\big[T^{-1}(A)\big],\;\;A\in {\mathcal Y}.$$
Un premier résultat  très intuitif est que l'on perd de l'information en passant de ${\mathcal E}$ à ${\mathcal E}^{T}$.
\begin{proposition} \label{perte info}
Si ${\mathcal E}$ et ${\mathcal E}^{T}$ sont régulières, alors, pour tout $\vartheta \in \Theta$
$$\mathbb{I}\big(\vartheta\,\big|{\mathcal E}^{T}\big) \leq \mathbb{I}\big(\vartheta\,|{\mathcal E}\big),$$
où $\mathbb{I}(\vartheta\,|{\mathcal E})$ désigne l'information de Fisher pour l'expérience statistique ${\mathcal E}$ au point $\vartheta$.
\end{proposition}
Notons tout d'abord que si $\mu$ domine ${\mathcal E}$, alors la mesure image $\mu^T$ de $\mu$ par $T$ domine\footnote{En effet, si $\PP_\vartheta^T\big[A\big] >0 $, alors $\PP_\vartheta\big[T^{-1}(A)\big]>0$ et donc $0 < \mu\big[T^{-1}(A)\big] = \mu^T\big[A\big]$.} ${\mathcal E}^T$. Posons
$$f^T(\vartheta,z) = \frac{d\PP_\vartheta^T}{d\mu^T}(z),\;\;\;z\in \mathfrak{Z},\;\vartheta \in \Theta.$$
On démontre cette proposition en deux étapes.
Une première étape est un résultat intéressant en lui-même que nous énonçons sous forme de lemme.
\begin{lemme} \label{restrict info utile}
On a, pour tout $\vartheta \in \Theta$,
$$\E_\vartheta\big[\partial_\vartheta \log f(\vartheta,Z)\,|\,T(Z)\big] = \partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\;\;\;\PP_\vartheta-\text{presque sûrement}.$$
\end{lemme}
\begin{proof}
Soit $A \in {\mathcal Y}$. D'une part, par caractérisation de l'espérance condition\-nelle s'écrit
$$\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)1_{T(Z) \in A}\big] = \E_\vartheta\left[\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)\,|T\big]1_{T(Z)\in A}\right].$$
D'autre part, puisque $\PP_\vartheta$ est la loi de $Z$, on a par la formule de la mesure image \eqref{formule mesure image}

$$\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)1_{T(Z) \in A}\big]
=\int_{T^{-1}(A)}\partial_\vartheta \log f(\vartheta, z)\PP_\vartheta(dz).
$$
Puisque ${\mathcal E}$ est régulière, il vient
\begin{align*}
&\int_{T^{-1}(A)}\partial_\vartheta \log f(\vartheta, z)\PP_\vartheta(dz)\\
= &\int_{T^{-1}(A)}\partial_\vartheta f(\vartheta,z)\mu(dz) \\
= &\,  \partial_\vartheta \int_{T^{-1}(A)} f(\vartheta,z)\mu(dz) \\
= &\,  \partial_\vartheta \int_{T^{-1}(A)} \PP_\vartheta(dz) \\
= &\, \partial_\vartheta \int_{A} \PP_\vartheta^T(dz) \;\;\text{(formule de la mesure image \eqref{formule mesure image})}\\
= &\,  \partial_{\vartheta} \int_A f^T(\vartheta, z) \mu^T(dz)  \\
= & \int_{A} \partial_\vartheta f^T(\vartheta,z) \mu^T(dz) \\
= &  \int_A \partial_\vartheta \log f^T(\vartheta,z) \PP_\vartheta^T(dz) \\
= &  \E_\vartheta\big[\partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)1_{T(Z)\in A}\big]\;\;\text{(formule de la mesure image \eqref{formule mesure image})}.
\end{align*}
Comme $A$ est arbitraire, on conclut par identification.
\end{proof}
Passons à la preuve de la Proposition \ref{perte info} proprement dite.
On a :
$$\E_\vartheta\left[\left(\partial_\vartheta \log f(\vartheta, Z) - \partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\right)^2\right] \geq 0.$$
En développant le carré, on obtient :
$$ \mathbb{I}\big(\vartheta\,|{\mathcal E}\big)+\mathbb{I}\big(\vartheta\,\big|{\mathcal E}^{T}\big)-2\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)\partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\big]\geq 0.$$
D'autre part,
\begin{align*}
& \E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)\partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\big] \\
= & \E_\vartheta\left[\E_\vartheta\big[\partial_\vartheta \log f(\vartheta, Z)\,|T\big]\partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\right] \\
= & \E_\vartheta \left[\left( \partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\right)^2\right],
\end{align*}
la dernière égalité étant obtenue en appliquant le Lemme \ref{restrict info utile}. Cette dernière quantité est précisément $\mathbb{I}\big(\vartheta\,\big|{\mathcal E}^{T}\big)$, ce qui achève la démonstration de la Proposition \ref{perte info}.

\subsection{Statistique exhaustive}
\subsubsection{Absence de perte d'information}
Nous nous intéressons à une classe particulière de fonctions $T$, qui ne font pas perdre d'information. Ecrites sous la forme $Y = T(Z)$ on appelle ces fonctions des \og statistiques exhaustives\fg{}.
\begin{definition}[Statistique exhaustive] \label{stat exhaustive}
On dit que la statistique $T$ est exhaustive (ou plutôt $Y = T(Z)$) pour l'expérience régulière ${\mathcal E}$ si ${\mathcal E}^T$ est régulière et
$$\mathbb{I}\big(\vartheta\,\big|{\mathcal E}^{T}\big) = \mathbb{I}\big(\vartheta\,|{\mathcal E}\big).$$
\end{definition}
Pour de telles sous-expériences, il n'y a pas de perte d'information, et la théorie de l'efficacité asymptotique reste inchangée.
\begin{remarque} \label{remarque factorisation}
\emph{
Il existe une définition plus large qui permet de définir l'exhaustivité (l'absence de perte d'information), même lorsque l'information de Fisher n'est pas définie, que nous ne donnons pas ici. Nous utiliserons la notion d'exhaustivité au Chapitre \ref{tests} dans le cadre de modèles réguliers, et nous pouvons nous contenter de la Définition \ref{stat exhaustive} dans ce cours.
}
\end{remarque}
\begin{remarque}
\emph{
Nous avons traité le cas d'un paramètre unidimensionnel $\vartheta \in \Theta \subset \R$ par souci de simplicité. On a des résultats analogues pour un paramètre $\vartheta \in \Theta \subset \R^d$ avec $d >1$ en remplaçant l'information de Fisher par la matrice d'information de Fisher, pour des hypothèses de régularité suffisantes. Nous ne développerons pas ces aspects ici (voir tout de même l'Exemple \ref{stat exhaustive gaussienne}).
}
\end{remarque}
\index{factorisation, critère de}
\subsubsection{Critère de factorisation}
La notion d'exhaustivité, c'est-à-dire d'absence de perte d'information pour une sous-expérience n'est pas facile à manipuler à partir de la Définition \ref{stat exhaustive}. Nous donnons un critère très simple pour montrer qu'une statistique est exhaustive.

\begin{theoreme}[Critère de Factorisation] Si l'expérience ${\mathcal E}$ est dominée par $\mu$, une statistique $T$ est exhaustive si et seulement si la vraisemblance $f(\vartheta, Z) = \tfrac{d\PP_\vartheta}{d\mu}(Z)$ s'écrit
\begin{equation} \label{la bonne representation}
f(\vartheta,Z) = p\big(T(Z),\vartheta\big)h(Z)\;\;\;\;\mu\;\text{presque-partout},
\end{equation}
où les fonctions $z \leadsto p(\cdot,z)$ et $z \leadsto h(z)$ sont mesurables et positives.
\end{theoreme}
%Nous admettons ce résultat,
%{\tt exhaustivite et MLE}.
Nous donnons une preuve très simple dans notre cadre où nous supposons les expérien\-ces statistiques ${\mathcal E}$ et ${\mathcal E}^T$ régulières, et nous supposons de plus que $f(\vartheta,\cdot)$ et strictement positive pour tout $\vartheta \in \Theta$ pour simplifier. Pour le cas général évoqué dans la Remarque \ref{remarque factorisation}, on trouvera une démonstation du théorème de factorisation dans Borovkov, \cite{B}, pp. 117--120.
\begin{proof}
Si $f(\vartheta,Z) = p\big(T(Z),\vartheta\big)h(Z)$ $\mu$ presque-partout, alors la mesure
$$\widetilde \mu(dz) = h(z)\mu(dz)$$
domine la famille $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$. Puisque $h$ est strictement positive, les ensembles de $\mu$- ou $\widetilde \mu$-mesure nulle coïncident. D'après l'Exercice \ref{invariance fisher dominante}, l'information de Fisher ne dépend pas du choix de la mesure dominante, que l'on calcule avec $\widetilde f(\vartheta,z) = \frac{d\PP_\vartheta}{d\widetilde \mu}(z)$. On a d'une part,
$$\E_\vartheta \big[\partial_\vartheta \log \widetilde f(\vartheta, Z)\,|\,T(Z) \big] = \partial_\vartheta \log \widetilde f(\vartheta,Z)$$
$\widetilde \mu$-presque partout,
puisque $\widetilde f(\vartheta,Z) = p\big(T(Z),\vartheta \big)$ est une fonction mesurable de $T(Z)$. D'autre part,
d'après le Lemme \ref{restrict info utile} et avec les mêmes notations, on a
$$\E_\vartheta \big[\partial_\vartheta \log \widetilde f(\vartheta, Z)\,|\,T(Z) \big] = \partial_\vartheta \log \widetilde f^T(\vartheta,Z)$$
$\widetilde \mu$-presque partout.
On en déduit
$$\partial_\vartheta \log \widetilde f(\vartheta,Z) = \partial_\vartheta \log \widetilde f^T(\vartheta,Z)$$
à un ensemble de $\widetilde \mu$-mesure nulle près. Le résultat en découle en passant au carré et en intégrant par rapport à $\PP_\vartheta$.

Réciproquement, on a montré dans la Proposition \ref{perte info} que
$$\E_\vartheta\left[\left(\partial_\vartheta \log f(\vartheta, Z) - \partial_\vartheta \log f^T\big(\vartheta, T(Z)\big)\right)^2\right] = \mathbb{I}\big(\vartheta\,|\,{\mathcal E}\big)-\mathbb{I}\big(\vartheta\,|\,{\mathcal E}^T\big) \geq 0.$$
En conséquence, si $\mathbb{I}\big(\vartheta\,|\,{\mathcal E}\big)=\mathbb{I}\big(\vartheta\,|\,{\mathcal E}^T\big)$, alors
\begin{equation} \label{fundamental egalite}
\partial_\vartheta \log f(\vartheta, Z)=\partial_\vartheta \log f^T\big(\vartheta, T(Z)\big),
\end{equation}
l'égalité ayant lieu $\PP_\vartheta$ presque-sûrement, et aussi $\mu$ presque-partout en utilisant le fait que $f(\vartheta,\cdot)$ est strictement positive.
En intégrant \eqref{fundamental egalite}, on obtient la représentation \eqref{la bonne representation}.
\end{proof}
\subsection{Exemples de statistiques exhaustives}
\begin{exemple}[Modèle de Bernoulli]
\emph{
Dans l'exemple 1 du Chapitre \ref{chapitre 2}, nous avons introduit deux expériences statistiques pour traiter le problème du sondage. D'une part, l'expérience ${\mathcal E}^n$, engendrée par l'observation d'un $n$-échantillon $X_1,\ldots, X_n$ de variables aléatoires de Bernoulli de paramètre $\vartheta \in \Theta = [0,1]$, qui s'écrit
$${\mathcal E}^n= \Big(\{0,1\}^n,\text{parties de}\big(\{0,1\}^n\big),\,\big\{\PP_\vartheta^n,\,\vartheta \in \Theta\big\}\Big),$$
où $\PP_\vartheta^n = \PP_\vartheta \otimes \ldots \otimes \PP_\vartheta$ ($n$-fois), avec
$$\PP_\vartheta\big[X=1\big] = \vartheta = 1-\PP_\vartheta\big[X=0\big],$$
et qui correspond à l'observation du résultat de chaque votant. D'autre part, l'expérience $\widetilde {\mathcal E}^n$ engendrée par l'observation de la somme\footnote{Notée $n_A$ dans l'exemple du Chapitre \ref{chapitre 2}.} $\sum_{i = 1}^nX_i$, notée
$$\widetilde {\mathcal E}^n = \Big(\{0,\ldots, n\},\text{parties de}\big(\{0,\ldots, n\}\big),\,\big\{\mathbb{Q}_\vartheta^n,\vartheta \in \Theta\big\}\Big),$$
où $\mathbb{Q}_\vartheta^n$ est la loi binomiale de paramètres $(n,\vartheta)$, et qui correspond à l'observation du nombre total de voix pour le candidat $A$. Intuitivement, les deux points de vue contiennent la même information sur le paramètre $\vartheta$. La notion d'exhaustivité permet de formaliser cette intuition. L'expérience $\widetilde {\mathcal E}^n =  ({\mathcal E}^n\big)^T$ est une sous-expérience de ${\mathcal E}^n$ pour l'application
\begin{align*}
T  : \{0,1\}^n & \rightarrow \{0,\ldots, n\} \\
(x_1,\ldots, x_n) & \leadsto T(x_1,\ldots, x_n) = \sum_{i = 1}^n x_i.
\end{align*}
Ecrivons maintenant la vraisemblance dans ${\mathcal E}^n$ en prenant comme mesure dominante la mesure de comptage sur $\{0,1\}^n$ : on a
\begin{align*}
{\mathcal L}\big(\vartheta,X_1,\ldots, X_n\big) & = \prod_{i =1}^n \vartheta^{X_i}(1-\vartheta)^{1-X_i} \\
& = \vartheta^{T(X_1,\ldots, X_n)} (1-\vartheta)^{n-T(X_1,\ldots, X_n)},
\end{align*}
et le critère de factorisation nous dit que la statistique $T(X_1,\ldots, X_n)$ est exhaustive. Il n'y a donc pas de perte d'information si l'on considère $\widetilde {\mathcal E}^n$ plutôt que ${\mathcal E}^n$.
}
\end{exemple}
\begin{exemple}[Loi exponentielle]
\emph{
On considère l'expérience statistique engendrée par un $n$-échantillon de loi exponentielle de paramètre $\vartheta \in \Theta = \R_+\setminus\{0\}$. La vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = \vartheta^{n}\exp\Big(-\vartheta \sum_{i = 1}^n X_i\Big) \\
& = \vartheta^{n}\exp\big(-\vartheta n\Xbar \big) \\
& = p\big(T(X_1,\ldots, X_n),\vartheta\big)h(X_1,\ldots, X_n)
\end{align*}
avec $p(x,\vartheta) = \vartheta^n \exp\big(-\vartheta x\big)$ et $h=1$. Donc $T(X_1,\ldots, X_n) = \Xbar$ est une statistique exhaustive d'après le théorème de factorisation.
}
\end{exemple}
\begin{exemple}[Un exemple en dimension $d=2$] \label{stat exhaustive gaussienne}
\emph{
On considère l'expérience statistique engendrée par un $n$-échantillon de loi ${\mathcal N}(\mu,\sigma^2)$, avec comme paramètre $\vartheta = (\mu,\sigma^2)\in \Theta  = \R \times \R_+\setminus\{0\}$. La vraisemblance s'écrit
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = (2\pi \sigma^2)^{-n/2}\exp\Big(-\frac{1}{2\sigma^2}\sum_{i = 1}^n(X_i-\mu)^2\Big) \\
& = (2\pi \sigma^2)^{-n/2}\exp\Big(-\frac{n}{2\sigma^2}(\tfrac{1}{n}\sum_{i = 1}^nX_i^2-2\Xbar+\mu^2\Big),
\end{align*}
ce qui montre que la statistique $T(X_1,\ldots, X_n) = (\Xbar,\tfrac{1}{n}\sum_{i = 1}^nX_i^2)$ est exhaustive d'après le théorème de factorisation. Si l'on suppose $\sigma^2=1$ connu, alors le paramètre devient $\vartheta = \mu$ et la vraisemblance s'écrit :
\begin{align*}
{\mathcal L}_n(\vartheta, X_1,\ldots, X_n) & = (2\pi)^{-n/2}\exp\Big(-\frac{1}{2}\sum_{i = 1}^n(X_i-\mu)^2\Big) \\
& = (2\pi)^{-n/2}\exp\big(n\Xbar-\tfrac{n\mu^2}{2}\big) \exp\big(-\tfrac{1}{2}\sum_{i = 1}^n X_i^2\big)
\end{align*}
et on conclut que dans ce cas $T(X_1,\ldots, X_n) = \Xbar$ est exhaustive d'après le critère de factorisation.
}
\end{exemple}

%\subsection{Modèle de régression et variables explicatives$^\ast$}
%Nous terminons cette section en justifiant le principe d'ancillarité, traduit pat l'Hypothèse \ref{ancillarity} qui nous a permis de ramener le traitement du modèle de régression à \og design \fg{} aléatoire au modèle de régression à \og design \fg{} déterministe dans le Chapitre \ref{estimation regression}.

%Rappelons que le modèle de régression avec covariables, on observe
%$$(\bX_1,Y_1),\ldots, (\bX_n,Y_n),$$
%où les vecteurs aléatoires $(\bX_i,Y_i)$ à valeurs dans $\R^k\times \R$ sont indépendants et identiquement distribués, et s'écrivent
%$$Y_i = r(\vartheta, \bX_i)+\xi_i,\;\;i=1,\ldots, n,$$
%où la fonction de régression $r(\vartheta,\cdot)$ est connue au paramètre $\vartheta$ près. Supposons pour simplifier que la loi des $\xi_i$ admette une densité $g$ connue. L'hypothèse d'ancillarité (Hypothèse \ref{ancillarity}) signifie que la loi $\PP^{\bX}$ des $\bX_i$ ne dépend pas de $\vartheta$. Dans ce cas, la famille de lois $\big{\PP_\vartheta(d\bx dy),\,\vartheta \in \Theta\big\}$ de $(\bX,Y)$ est dominée par la mesure
%$$\mu(d\bx dy) = \PP^{\bX}dy$$
%sur $\R^k\times \R$ et on a
%$$\frac{d\PP_\vartheta}{d\mu}(\bx,y) = g\big(y-r(\vartheta,\bx)\big)$$

%\subsection{Erreur de modèle et robustesse}
\section{Exercices}
\begin{exercice} \label{no optimality}
\emph{
On suppose que $\Theta = \{\vartheta_0,\vartheta\}\subset \R$, avec $\vartheta_0\neq \vartheta_1$, est réduit à deux points et que les mesures $\PP_{\vartheta_0}$ et $\PP_{\vartheta_1}$ sont mutuellement absolument continues (c'est-à-dire $\PP_{\vartheta_0} \ll \PP_{\vartheta_1}$ et $\PP_{\vartheta_1} \ll \PP_{\vartheta_0}$). Montrer qu'il n'existe pas d'estimateur $\vartheta^\star$ tel que
$$\forall \vartheta \in \Theta,\;\;{\mathcal R}(\vartheta^\star,\vartheta) \leq \inf_{\est}{\mathcal R}(\est,\vartheta),$$
où l'infimum est pris sur l'ensemble de tous les estimateurs, où ${\mathcal R}(\est,\vartheta) = \E_\vartheta\big[(\est-\vartheta)^2\big]$ désigne le risque quadratique de l'estimateur $\est$ au point $\vartheta$.
}
\end{exercice}
%\begin{exercice} \label{sans biais variance nulle}
%\begin{center}
%{\tt INSERT HERE SUPPL. 41}
%\end{center}
%\end{exercice}
\begin{exercice} \label{invariance fisher dominante}
\emph{
Soit $\big\{ \PP_\vartheta,\,\vartheta \in \Theta \big\}$, avec $\Theta \subset \R$ une famille de probabilités sur $\R$ régulière au sens de la Définition \ref{famille reguliere}. On suppose que pour tout $\vartheta \in \Theta$, on a
$$f(\vartheta,x)>0,\;\;\;\;\mu(dx)-\text{presque partout},$$
où $\mu$ est une mesure dominante. Montrer que l'information de Fisher $\mathbb{I}(\vartheta)$ ne dépend pas du choix de $\mu$.
}
\end{exercice}
\begin{exercice}[Inégalité de Cramer-Rao] \label{cramerrao}
\emph{
On considère l'expérience engendrée par un $n$-échantillon de loi appartenant à la famille régulière $\{\PP_\vartheta,\,\vartheta \in \Theta\}$, où $\Theta \subset \R$. Si $\est$ est un estimateur de $\vartheta$ (de carré intégrable), on a, pour tout $\vartheta \in \Theta$
\begin{equation} \label{cramer rao}\E_\vartheta\big[(\est-\vartheta)^2\big] \geq \frac{1+b'(\vartheta)}{n\mathbb{I}(\vartheta)}+b(\vartheta)^2,
\end{equation}
où $b(\vartheta) = \E_\vartheta\big[\est\big]-\vartheta$ est le biais de l'estimateur $\est$.
\begin{itemize}
\item En partant de l'identité $1 = \int_{\R} f(\vartheta,x)\mu(dx)$, montrer que
$$0 = \int_{\R}\partial_\vartheta f(\vartheta,x)\mu(dx).$$
\item En déduire
$$\E_\vartheta\big[(\est-\vartheta)\partial_\vartheta f(\vartheta,X)\big] = 1,$$
et par l'inégalité de Cauchy-Schwarz, montrer l'inégalité de Cramer-Rao \eqref{cramer rao}.
\end{itemize}
}
\end{exercice}
%\begin{exercice}[Super-efficacité et contre-exemple de Hodge-Lehmann$^\star$] \label{hodge lehmann}
%\emph{
%Dans un mo\-dèle régulier, soit $\est$ un estimateur asymptotiquement normal, de variance $v(\vartheta)$, pour $\vartheta \in \Theta \subset \R$.
%On suppose de plus que pour un point $\vartheta_0 \in \Theta$, il existe $\varepsilon >0$ tel que
%\begin{equation} \label{cond hodge lehmann}
%\sup_n\E_{\vartheta_0}\big[n^2(\est-\vartheta_0)^{2+\varepsilon}\big]<+\infty.
%\end{equation}
%\begin{enumerate}
%\item Donner un exemple de modèle vérifiant \eqref{cond hodge lehmann}
%\item On pose
%$$\widetilde \vartheta_n = \est1_{\big\{|\est-\vartheta_0|>n^{-1/4}\big\}}+\vartheta_0 1_{\big\{|\est-\vartheta_0| \leq n^{-1/4}\big\}}.$$
%Montrer que si $\vartheta \neq \vartheta_0$, on a
%$$\sqrt{n}(\widetilde \vartheta_n - \vartheta)\stackrel{d}{\longrightarrow} \mathcal{N}\Big(0,\frac{1}{v(\vartheta)}\Big).$$
%%$$\PP_\vartheta\big[\sqrt{n}\big(\widetilde T_n-\vartheta\big) \in [a,b]\big]\rightarrow \PP\big[v(\vartheta)\xi \in [a,b]\big],$$
%%où $\xi \sim {\mathcal N}(0,1)$.
%\item Montrer que $n\E_{\vartheta_0}\big[(\widetilde \vartheta_n-\vartheta_0)^2\big]\rightarrow 0$.
%\end{enumerate}
%En conclusion, on a construit un estimateur $\widetilde \vartheta_n$ asymptotiquement normal en tout point $\vartheta \neq \vartheta_0$, de même variance asymptotique que $\est$, et strictement meilleur que $\est$ en $\vartheta_0$. En déduire que cet estimateur infirme la seconde conjecture de Fisher.
%}
%\end{exercice}

\part{Tests d'hypothèses}
\chapter{Tests et régions de confiance} \label{tests}
Nous avons déja rencontré la notion de test statistique dans le Chapitre \ref{echantillonnage}. Dans ce chapitre, nous systématisons cette approche. Nous donnons quelques résultats incontournables de construction de test et nous abordons la notion d'optimalité. Nous allons voir que si on accepte de hiérarchiser les erreurs de décision lorsque l'on procède à un test -- le principe de Neyman -- alors il est possible de définir une notion d'optimalité plus satisfaisante que pour l'estimation.

\section{Problématique des tests d'hypothèse}
\subsection{Test et erreur de test}
\subsubsection{Situation}
On considère une expérience statistique engendrée par une observation $Z$ à valeurs dans $\big(\mathfrak{Z}, {\mathcal Z}\big)$
et associée à la famille de lois de probabilités
$$\big\{\PP_\vartheta,\;\vartheta \in \Theta\big\}.$$
L'ensemble des paramètres $\Theta$ est un sous-ensemble de $\R^d$, avec $d \geq 1$.

Dans le modèle de la densité, $Z = (X_1,\ldots, X_n)$ est un $n$-échantilllon où les variables aléatoires réelles $X_i$ sont indépendantes et de même loi, et $\PP_\vartheta$ est la loi du $n$-échantillon définie sur $(\mathfrak{Z}, {\mathcal Z}) = (\R^n, {\mathcal B}^n)$.

Dans le modèle de la régression à \og design \fg{} déterministe,
%, si on travaille conditionnellement aux variables explicatives $(\bX_1=\bx_1, \ldots, \bX_n = \bx_n)$, où $\bx_i \in \R^k$, alors
%le \og design\fg{} $(\bx1,\ldots, \bx_n)$ est fixé une bonne fois pour toutes, et
on peut écrire l'observation comme $Z = (Y_1,\ldots, Y_n)$, où les $Y_i = f(\vartheta,\bx_i)+\xi_i$ sont indépendantes et le \og design\fg{} $(\bx_1,\ldots, \bx_n)$ est donné une fois pour toutes. Dans ce cas, $\PP_\vartheta$ est la loi jointe des $Y_i$ définie sur $(\mathfrak{Z}, {\mathcal Z}) = (\R^n, {\mathcal B}^n)$.

%Dans le modèle de régression, si on ne travaille pas conditionnellement au design, alors $Z = \big((\bX_1,Y_1),\ldots, (\bX_n,Y_n)\big)$ où les variables $(\bX_i,Y_i)$ sont indépendantes et de même loi, et $\PP_\vartheta$ est la loi du $n$-échantillon définie sur $(\mathfrak{Z}, {\mathcal Z}) = \big(\R^{(k+1)n}, {\mathcal B}^{(k+1)n}\big)$.

\subsubsection{Principe du test statistique}

On veut \og décider\fg{} à partir de l'observation de $Z$ si une propriété de la loi de $Z$ est vérifiée ou non. Cette propriété se traduit mathématiquement par un sous-ensemble $\Theta_0 \subset \Theta$ de l'ensemble des paramètres, et la propriété signifie que $\vartheta \in \Theta_0$.


%PD de DEF est ce que la zone de rejet est aleatoire ou PAS ??????
\begin{definition}[Terminologie de test] \label{terminologie test}On teste \og l'hypothèse nulle \fg{}
$$H_0\;:\;\; \vartheta \in \Theta_0 \subset \Theta$$
contre \og l'alternative \fg{}
$$H_1\;:\;\vartheta \in \Theta_1 \subset \Theta,$$
avec $\Theta_0 \cap \Theta_1 = \emptyset$. Construire un test signifie construire une procédure $\varphi = \varphi(Z)$ de la forme
\begin{equation} \label{def test simple}
\varphi(Z) = 1_{\{Z \in {\mathcal R}\}}  =
\left\{
\begin{array}{lll}
0 & \;\;\; \text{si}\; Z \notin {\mathcal R}.\;\;\; \text{\og on accepte l'hypothèse nulle \fg{}} \\ \\
1 & \;\;\; \text{si}\; Z \in {\mathcal R}.\;\;\; \text{\og on rejette l'hypothèse nulle \fg{}} \\
\end{array}
\right.
\end{equation}
On dit que $\varphi$ est un test simple.
\index{test simple}
\end{definition}
 Il est naturel de prendre $\Theta_1 = \Theta \setminus \Theta_0$ et c'est ce que l'on fera la plupart du temps. On verra toutefois que ce choix ne s'impose pas toujours et dépend des propriétés que l'on souhaite obtenir pour $\varphi$. Pour le moment, on suppose $\Theta_1 = \Theta \setminus \Theta_0$.
\begin{definition} Toute procédure statistique de la forme \eqref{def test simple} est appelée test simple. On désigne indifféremment l'ensemble ${\mathcal R} \subset \mathfrak{Z}$ ou bien l'événement $\big\{Z \in {\mathcal R}\big\}$ comme zone de rejet ou encore zone critique du test $\varphi$.
\end{definition}
\begin{remarque}
%{\tt test randomisé}.
\emph{
Dans la définition \ref{terminologie test}, on parle de test simple car on n'autorise que deux réponses (accepter ou rejeter). On pourrait imaginer des situations plus générales, où l'on se refuse à décider, ou bien où l'on renvoie une valeur entre $0$ et $1$ qui indique un \og degré de suspicion \fg{} de l'hypothèse.
}
\end{remarque}
\subsubsection{Erreur de test}
\index{test, erreur de}
Lorsque l'on effectue un test simple, il y a quatre possibilités. Deux sont anecdotiques et correspondent à une bonne décision :

\begin{itemize}

\item Accepter l'hypothèse $H_0$ alors que $\vartheta \in \Theta_0$ (c'est-à-dire l'hypothèse $H_0$ est vraie).

\item Rejeter l'hypothèse $H_0$ alors que $\vartheta \in \Theta_1$ (c'est-à-dire l'hypothèse $H_0$ est fausse).

\end{itemize}

Les deux autres possibilités sont celles qui vont nous occuper, et correspondent à une erreur de décision :

\begin{itemize}

\item Rejeter l'hypothèse $H_0$ alors que $\vartheta \in \Theta_0$ (c'est-à-dire l'hypothèse $H_0$ est vraie).

\item Accepter l'hypothèse $H_0$ alors que $\vartheta \in \Theta_1$ (c'est-à-dire l'hypothèse $H_0$ est fausse).

\end{itemize}

\begin{definition}[Erreur de première et seconde espèce] L'erreur de première espèce correspond à la probabilité maximale de rejeter l'hypothèse alors qu'elle est vraie :
$$\sup_{\vartheta \in \Theta_0} \E_\vartheta\big[\varphi(Z)\big] = \sup_{\vartheta \in \Theta_0}\PP_\vartheta\big[Z \in {\mathcal R}\big].$$
L'erreur de seconde espèce correspond à la probabilité maximale d'accepter l'hypothèse alors qu'elle est fausse :
\begin{equation} \label{erreur 2nd espece}
\sup_{\vartheta \in \Theta_1} \E_\vartheta\big[1-\varphi(Z)\big] = \sup_{\vartheta \in \Theta_1}\PP_\vartheta\big[Z \notin {\mathcal R}\big].
\end{equation}
\end{definition}
\begin{remarque}
\emph{
D'après cette terminologie, l'erreur de première espèce mesure la probabilité (maximale) de rejeter à tort, et l'erreur de seconde espèce d'accepter à tort. Dans le langage courant, commettre une erreur de première espèce revient à faire un \og faux négatif \fg{}, et commettre une erreur de seconde espèce revient à faire un \og faux positif \fg{}.
}
\end{remarque}
Dans la plupart des situations, $\Theta_0$ est \og plus petit \fg{} que $\Theta_1$ et le contrôle de l'erreur de seconde espèce \eqref{erreur 2nd espece} est difficile, surtout si  $\Theta_1$ contient des points \og très proches \fg{} de $\Theta_0$. C'est pour cela que l'on introduit la fonction de fonction de puissance d'un test, qui mesure sa performance locale sur l'alternative.
\begin{definition} La fonction de puissance du test simple $\varphi$ est l'application
$$\pi_\cdot(\varphi):\Theta_1 \rightarrow [0,1]$$ définie par
$$\vartheta \in \Theta_1 \leadsto \pi_\vartheta(\varphi) = \PP_\vartheta\big[Z \in {\mathcal R}\big].$$
\end{definition}
\index{composite, hypothèse}
\index{simple, hypothèse}
\subsubsection{Hypothèse simple, hypothèse composite}
On utilise souvent la terminologie suivante dans le cas réel, où  $\Theta \subset \R$. Soit $\vartheta_0 \in \Theta$.
\begin{itemize}
\item Tester $H_0:\vartheta = \vartheta_0$ contre $H_1:\vartheta = \vartheta_1$ avec $\vartheta_1 \neq \vartheta_0$. On parle de test d'une hypothèse simple contre une alternative simple.
\item Tester $H_0:\vartheta = \vartheta_0$ contre $H_1:\vartheta \neq \vartheta_0$. On parle de test d'une hypothèse simple contre une alternative composite.
\item Tester $H_0:\vartheta > \vartheta_0$ contre $H_1:\vartheta \leq \vartheta_0$. On parle de test d'une hypothèse composite contre une alternative composite.
\item Tester $H_0:\vartheta > \vartheta_0$ contre $H_1:\vartheta = \vartheta_0$. On parle de test d'une hypothèse composite contre une alternative simple.
\end{itemize}

\subsection{Comparaison de test, principe de Neyman}
\index{Neyman, principe de}
Idéalement, on souhaite que l'erreur de première espèce et l'erreur de seconde espèce soient toutes deux simultanément petites. Les deux tests triviaux
$$\varphi_1 = 1_\emptyset,\;\;\;\text{et}\;\;\;\varphi_2 = 1_{\mathfrak{Z}}$$
qui consistent respectivement à accepter systématiquement l'hypothèse et à la rejeter systématiquement, sans utiliser l'observation $Z$, ont respectivement une erreur de première espèce nulle et une erreur de seconde espèce nulle. Malheureusement la  puissance de  $\varphi_1$ est catastrophique : $\pi_\vartheta(\varphi_1) = 0$ en tout point $\vartheta$ de toute alternative $\Theta_1$. De même l'erreur de première espèce de $\varphi_2$ est égale à 1, même si l'hypothèse est réduite à un point, quelle que soit l'hypothèse.

Une méthodologie, proposée historiquement par Neyman, consiste à imposer une disymétrie dans la problématique de test : on décide que le contrôle de l'erreur de première espèce est crucial. La démarche de construction de test sera alors, parmi les tests qui ont une erreur de première espèce contrôlée, de choisir le (ou les) test(s) le(s) plus puissant()s, c'est-à-dire ayant une erreur de seconde espèce la plus petite possible.

\begin{definition} Soit $\alpha \in [0,1]$ un niveau de risque. Un test simple $\varphi$ est de niveau $\alpha$ si son erreur de première espèce est inférieure ou égale à $\alpha$.
\end{definition}

\begin{definition}[Principe de Neyman] Soit $\alpha \in [0,1]$ un niveau de risque. Le test $\varphi^\star$ est optimal (uniformément plus puissant, ou UPP) pour tester
$$H_0 : \vartheta \in \Theta_0\;\;\;\;\text{ contre}\;\;\;\; H_1: \vartheta \in \Theta_1$$
si $\varphi^\star$ est de niveau $\alpha$ et, pour tout test $\varphi$ de niveau $\alpha$, on a
$$\forall \vartheta \in \Theta_1,\;\;\pi_\vartheta(\varphi) \leq \pi_\vartheta(\varphi^\star).$$
\end{definition}
%\begin{remarque}
%{\tt rejeter l hypothese ne veut pas dire accepter l alternative.}
%\end{remarque}
%\begin{remarque}
%{\tt en pratique puissance ; en theorie, d abord regler err 1 puis err 2.}
%\end{remarque}

\section{Hypothèse simple contre alternative simple}
\index{Neyman-Pearson, lemme de}
\subsection{Principe de Neyman et décision à deux points}
Dans le cas d'une hypothèse simple contre une alternative simple, on sait résoudre de façon optimale le principe de Neyman. Il s'agit d'une situation remarquable, qui ne se généralise pas facilement -- hormis des cas particuliers comme les familles à rapport de vraisemblance monotone, voir Section
\ref{rapport de vraisemblance monotone} -- dans un cadre non-asymptotique.

On suppose l'ensemble des paramètres réduit à deux points : $\Theta = \{\vartheta_0, \vartheta_1\}$. A partir de l'observation $Z$, on teste
$$H_0:\vartheta =\vartheta_0\;\;\;\text{contre}\;\;\;H_1:\;\vartheta = \vartheta_1.$$
\begin{definition}[Optimalité]
Soit $\alpha \in [0,1]$ un niveau de risque. Un test $\varphi^\star$ de niveau $\alpha$ est optimal ou PP (Plus Puissant) si
$$\pi(\varphi^\star)  = \sup_\varphi \pi(\varphi)$$
où le supremum est pris parmi tous les tests de niveau $\alpha$.
\end{definition}

Dans le cas d'une hypothèse simple contre une alternative simple, estimation et test se confondent. En effet, un estimateur \og raisonnable\footnote{C'est-à-dire contraint à prendre des valeurs dans l'espace des paramètres $\Theta = \{\vartheta_0,\vartheta_1\}$ ici.} \fg{} se représente sous la forme
$$\est = \vartheta_0 1_{Z \in {\mathcal A}}+\vartheta_1 1_{Z \notin {\mathcal A}}$$
pour un certain ensemble ${\mathcal A}\subset {\mathcal Z}$, et peut se mettre en correspondance avec le test simple de l'hypothèse $H_0:\vartheta = \vartheta_0$ contre $H_1:\vartheta = \vartheta_1$ défini par
$$\varphi_n = 1_{\big\{Z \notin {\mathcal A}\big\}}.$$
Si $(\vartheta, \widetilde \vartheta) \leadsto \ell(\vartheta, \widetilde \vartheta)$ est une fonction de perte\footnote{C'est-à-dire vérifiant les hypothèses minimales $\ell(\vartheta,\widetilde \vartheta) \geq 0$ pour tous $\vartheta, \widetilde \vartheta$ et $\ell(\vartheta,\widetilde \vartheta) = 0$ si et seulement si $\vartheta = \widetilde \vartheta$.}
donnée, et si ${\mathcal R}\big(\est,\vartheta\big) = \E_\vartheta\big[\ell(\est,\vartheta)\big]$ désigne le risque de l'estimateur $\est$ pour la perte $\ell(\cdot,\cdot)$ au point $\vartheta$, on a
\begin{align*}
{\mathcal R}\big(\est,\vartheta\big) & = \E_\vartheta\big[\ell(\vartheta_0,\vartheta)1_{Z \in {\mathcal A}}+\ell(\vartheta_1,\vartheta)1_{Z \notin {\mathcal A}}\big] \\
& = \ell(\vartheta_0,\vartheta) \PP_\vartheta\big[\varphi = 0\big] + \ell(\vartheta_1,\vartheta)\PP_\vartheta\big[\varphi = 1\big].
% \ell(\vartheta_0,\vartheta_1)\big(\PP_{\vartheta_0}\big[{\mathcal A}^{c}\big]1_{\{\vartheta = \vartheta_0\}}+\PP_\vartheta\big[{\mathcal A}\big]1_{\{\vartheta = \vartheta_1\}}\big)\\
%& = \ell(\vartheta_0,\vartheta_1)\big(\PP_{\vartheta_0}\big[\varphi = 1\big]+\pi_{\vartheta_1}(\varphi)\big).
\end{align*}
Donc
$${\mathcal R}(\est,\vartheta_0) = \ell(\vartheta_1,\vartheta_0)\PP_{\vartheta_0}\big[\varphi = 1\big]$$
soit l'erreur de première espèce du test $\varphi$, et
$${\mathcal R}(\est,\vartheta_1) = \ell(\vartheta_0,\vartheta_1)\big(1-\pi(\varphi)\big),$$
soit l'erreur de seconde espèce du test. Construire un estimateur ayant un risque \og petit \fg{} en $\vartheta_0$ et $\vartheta_1$ est équivalent ici à construire un test ayant simultanément une erreur de première et de seconde espèce petite.

Le principe de Neyman au niveau $\alpha$ se traduit comme la recherche de $\varphi$ qui minimise $\pi_{\vartheta_1}(\varphi)$, sous la contrainte $\PP_{\vartheta_0}\big[\varphi = 1\big]\leq \alpha$.
%mais on voit que cela ne va pas forcément de soi du point de vue de l'estimation, c'est-à-dite si l'on cherche à rendre $\E_\vartheta\big[\ell(\est,\vartheta)\big]$ petit.

\subsection{Lemme de Neyman-Pearson} \label{test de neyman pearson}

Dans le cas d'une hypothèse simple contre une alternative simple, un test optimal $\varphi^\star$ existe\footnote{Pour des raisons de simplicité, on fera dans ce cours une restriction technique, mais le résultat est vrai en toute généralité.}, et on sait le construire explicitement à l'aide du Lemme de Neyman-Pearson.

La famille $\{\PP_{\vartheta_0}, \PP_{\vartheta_1}\}$ est dominée, par exemple par $\mu = \PP_{\vartheta_0}+\PP_{\vartheta_1}$. Notons
$$f(\vartheta, z) = \frac{d\PP_\vartheta}{d\mu}(z),\;\;z \in \mathfrak{Z},\;\vartheta = \vartheta_0,\vartheta_1$$
les densités associées. Si l'on veut estimer $\vartheta$ dans ce contexte, alors l'estimateur du maximum de vraisemblance s'écrit
$$\estMV = \vartheta_0 1_{\{f(\vartheta_1, Z) < f(\vartheta_0, Z)\}}+ \vartheta_1 1_{\{f(\vartheta_0, Z) < f(\vartheta_1, Z)\}}$$
et il est bien défini sur l'événement $\{f(\vartheta_0,Z) \neq f(\vartheta_1,Z)\}$, sinon, on ne peut pas dire grand-chose. La comparaison de $f(\vartheta_0,Z)$ et $f(\vartheta_1,Z)$ nous fournit donc une règle de décision naturelle. Mais on va un peu affiner cette règle de décision, pour pouvoir \og calibrer \fg{}  l'erreur de première espèce.
\index{rapport de vraisemblance, test du}
Soit $c = c(\alpha) >0$ à choisir. On décide alors de rejeter $H_0$ si
$$f(\vartheta_1,Z) > c f(\vartheta_0,Z),$$
et on considère la famille des tests de région critique
\begin{equation} \label{def region critique np}
{\mathcal R}_c = \big\{f(\vartheta_1,Z) > c f(\vartheta_0,Z)\big\}.
\end{equation}
Le choix de $c$ est réglé par le résultat suivant.
\begin{theoreme}[Lemme de Neyman-Pearson] \label{lemme de np}
Soit $\alpha \in [0,1]$. S'il existe $c = c(\alpha)$ solution de
\begin{equation} \label{equation neyman pearson}
\PP_{\vartheta_0}\big[f(\vartheta_1,Z) > c f(\vartheta_0,Z)\big] = \alpha,
\end{equation}
alors le test de région critique ${\mathcal R}^\star = {\mathcal R}_{c(\alpha)}$ est optimal.
\end{theoreme}
\begin{proof}Considérons un test simple de niveau $\alpha$ défini par la région critique ${\mathcal R}$. On a
\begin{align*}
\PP_{\vartheta_1}\big[Z \in {\mathcal R}^\star\big] - \PP_{\vartheta_1}\big[Z \in {\mathcal R}\big]
=\,& \int_{{\mathcal R}^\star} f(\vartheta_1,z)\mu(dz) - \int_{{\mathcal R}} f(\vartheta_1,z)\mu(dz)  \\
 = \,&  \int_{{\mathcal R}^\star\setminus {\mathcal R}} f(\vartheta_1,z)\mu(dz) - \int_{{\mathcal R} \setminus {\mathcal R}^\star} f(\vartheta_1,z)\mu(dz)
\end{align*}
car $f(\vartheta_1,z)\mu(dz) = \PP_{\vartheta_1}(dz)$ est une mesure de probabilité. Puisque
$${\mathcal R}^\star\setminus {\mathcal R} \subset {\mathcal R}^\star,$$
on a, sur cet ensemble
$$f(\vartheta_1,z) > c(\alpha) f(\vartheta_0, z).$$
De même, sur ${\mathcal R}\setminus {\mathcal R}^\star$,
$$f(\vartheta_1,z)\leq c(\alpha)f(\vartheta_0,z).$$
Il vient
\begin{align*}
 \PP_{\vartheta_1}\big[Z \in {\mathcal R}^\star\big] - \PP_{\vartheta_1}\big[Z \in {\mathcal R}\big]
 \geq \,&
c(\alpha) \Big(\int_{{\mathcal R}^\star\setminus {\mathcal R}} f(\vartheta_0,z)\mu(dz) - \int_{{\mathcal R} \setminus {\mathcal R}^\star} f(\vartheta_0,z)\mu(dz)  \Big) \\
=\,&  c(\alpha) \Big(\int_{{\mathcal R}^\star} f(\vartheta_0,z)\mu(dz) - \int_{{\mathcal R} } f(\vartheta_0,z)\mu(dz)  \Big) \\
=\,&  c(\alpha) \Big(\PP_{\vartheta_0}\big[Z \in {\mathcal R}^\star\big] - \PP_{\vartheta_0}\big[Z \in {\mathcal R}\big]\Big)
\end{align*}
où l'on a utilisé cette fois-ci le fait que $f(\vartheta_0,z)\mu(dz)$ est une mesure de probabilité. Finalement, cette dernière quantitté est positive car, d'une part, ${\mathcal R}^\star$ est de la forme ${\mathcal R}_{c(\alpha)}$ donné par \eqref{equation neyman pearson} et donc $\PP_{\vartheta_0}\big[Z \in {\mathcal R}^\star\big] =\alpha$ et d'autre part, puisque ${\mathcal R}$ est la zone de rejet d'un test de niveau $\alpha$, on a $\PP_{\vartheta_0}\big[Z \in {\mathcal R}\big] \leq \alpha$.
\end{proof}
\begin{definition}[Test simple de Neyman-Pearson]
Le test simple de l'hypothèse simple $H_0:\vartheta = \vartheta_0$ contre l'alternative simple $H_1:\vartheta = \vartheta_1$ défini\footnote{Cela suppose implicitement qu'une solution $c(\alpha)$ existe, ce qui sera vérifié dans la plupart de nos exemples.} par la région critique
${\mathcal R}^\star = {\mathcal R}_{c(\alpha)}$ du Théorème \ref{lemme de np} est appelé test de Neyman-Pearson.
\end{definition}
\begin{corollaire} \label{np sans biais}
Si $\varphi^\star$ est le test de Neyman-Pearson de niveau $\alpha$ de $H_0:\vartheta = \vartheta_0$ contre $H_1:\vartheta = \vartheta_1$, on a
$$\pi(\varphi^\star) \geq \alpha.$$
\end{corollaire}
\begin{proof}
Le test de Neyman-Pearson $\varphi^\star$ est plus puissant que tous les tests de niveau $\alpha$, en particulier, il est plus puissant que le test artificiel
$\varphi = 1_{u \leq \alpha}$, où $U$ est une variable aléatoire\footnote{Quitte à considérer une bonne extension de l'espace de probabilité sur lequel sont définis les $\PP_\vartheta$, on peut toujours faire \og exister \fg{} une telle variable aléatoire.}, indépendante de $Z$, de loi uniforme. En effet,
$$\PP_{\vartheta_0}\big[\varphi = 1\big] = \alpha.$$
Donc $\varphi$ est de niveau $\alpha$ et puisque $\varphi^\star$ est le test de Neyman-Pearson, on a
$$\pi(\varphi^\star) \geq \pi(\varphi) = \PP_{\vartheta_1}\big[\varphi = 1\big] = \alpha.$$
\end{proof}
\begin{remarque}
\emph{
Une condition suffisante pour que l'équation \eqref{equation neyman pearson} ait une solution est que la variable aléatoire $f(\vartheta_1,Z)/f(\vartheta_0,Z)$ soit bien définie et ait une densité par rapport à la mesure de Lebesgue sur $\R_+$ sous $\PP_{\vartheta_0}$.
}
\end{remarque}
\begin{exemple}
\emph{Soit $F$ la fonction de répartition d'une loi de probabilité donnée sur $\R$. On considère l'expérience statistique engendrée par un $n$-échantillon de loi $\PP_\vartheta$ de fonction de répartition $F(\cdot-\vartheta)$, où $\vartheta \in \Theta = \{0,\vartheta_0\}$ pour un point $\vartheta_0\neq 0$ de $\R$ . On teste $H_0:\vartheta = 0$ contre $H_1:\vartheta = \vartheta_0$. Si $X_1,\ldots, X_n$ désigne l'échantillon observé, on a la représentation pour $\vartheta\in \Theta$
$$X_i = \vartheta + \zeta_i,\;\;\;i=1,\ldots, n$$
où les $\zeta_i$ sont des variables aléatoires indépendantes, identiquement distribuées, de loi $F$ sous $\PP_\vartheta$. Le problème consiste donc à tester l'absence d'un facteur additif $\vartheta = \vartheta_0$ s'ajoutant aux variables $\zeta_i$ ou non.
Si l'on suppose que $F$ est absolument continue, de densité $f$ et que la variable aléatoire $f(X-\vartheta_0)/f(X)$ a une densité sous $\PP_\vartheta$ avec $\vartheta  \in \Theta$, alors \eqref{equation neyman pearson} a une solution et le test de Neyman-Pearson a pour zone de rejet
$${\mathcal R}_{n,\alpha} = \Big\{\prod_{i = 1}^n \frac{f(X_i-\vartheta_0)}{f(X_i)} > c(\alpha) \Big\},$$
où le choix de $c(\alpha)>0$ est réglé par la condition de niveau $\alpha$ du test :
$$\PP_{0}\Big[\sum_{i = 1}^n \log \frac{f(X_i-\vartheta_0)}{f(X_i)} > \log c(\alpha)\Big] = \alpha.$$
Lorsque $n$ est grand, on peut calculer une valeur approchée de $c_\alpha$ à l'aide du théorème central-limite.
}
\end{exemple}

\begin{exemple} \label{poisson neyman pearson}
\emph{
Considérons une seule observation $X$ de loi de Poisson de paramètre $\vartheta >0$. On teste $H_0:\vartheta = \vartheta_0$ contre $H_1: \vartheta_1$, avec $\vartheta_0 \neq \vartheta_1$. Ici, le test de Neyman-Pearson a pour zone de rejet
$${\mathcal R}_{n,\alpha} = \Big\{\exp\big(-(\vartheta_1-\vartheta_0)\big)(\vartheta_1\vartheta_0^{-1})^X \geq c(\alpha)\Big\},$$
où le choix de $c(\alpha)$ garantit que le test est de niveau $\alpha$. Ici,
$${\mathcal R}_{n,\alpha} = \Big\{X > \frac{\log c(\alpha) - (\vartheta_1-\vartheta_0)}{\log\vartheta_1-\log \vartheta_0}\Big\}.$$
Pour trouver $c(\alpha)$, on doit en principe résoudre
$$\PP_{\vartheta_0}\Big[X > \frac{\log c(\alpha) - (\vartheta_1-\vartheta_0)}{\log\vartheta_1-\log \vartheta_0}\Big] =\alpha,$$
mais la loi de $X$ n'est pas absolument continue, donc cette équation n'a pas de solution en général. On cherche alors le plus petit seuil $c(\alpha)>0$ de sorte que
$$\PP_{\vartheta_0}\Big[X > \frac{\log c(\alpha) - (\vartheta_1-\vartheta_0)}{\log\vartheta_1-\log \vartheta_0}\Big]  \leq \alpha.$$
En pratique, on procède de la manière suivante : par exemple, pour $\vartheta_0=5$ et $\alpha = 5\%$, on trouve
$$\PP_{\vartheta_0}\big[X > 9\big] = 0,032,\;\;\;\text{et}\;\;\;\PP_{\vartheta_0}\big[X > 8\big] = 0,068,$$
et on rejette l'hypothèse si $\{X>9\}$ et on l'accepte si $\{X \leq 9\}$. Ainsi, l'erreur de première espèce du test est plus petite que $\alpha = 5\%$, mais on ne peut plus garantir que le test est optimal au sens du Théorème \ref{lemme de np}.
}
\end{exemple}
\begin{remarque}
\emph{
Il existe une version plus sophistiquée du test de Neyman-Pearson, qui permet de traiter le cas où l'équation \eqref{equation neyman pearson} n'a pas de solution, comme dans l'exemple \ref{poisson neyman pearson}. Il faut alors considérer une classe plus large que les tests simples, la classe des tests randomisés (voir par exemple \cite{B}).
 }
\end{remarque}
\section{Tests d'hypothèses composites}
\subsection{Familles à rapport de vraisemblance monotone$^\star$} \label{rapport de vraisemblance monotone}
On fait la restriction -- importante ici -- $\Theta \subset \R$, et plus précisément $\Theta$ est un intervalle ouvert.
\index{monotone, rapport de vraisemblance}
On suppose la famille $\{\PP_\vartheta,\vartheta \in \Theta\}$ dominée, et on note $\mu$ une mesure dominante. Comme d'habitude, on définit la famille de densités
$$f(\vartheta, z) = \frac{d\PP_\vartheta}{d\mu}(z),\;\;z\in \mathfrak{Z},\;\;\vartheta \in \Theta.$$
L'hypothèse de travail dans toute cette section est
\begin{hypothese} \label{hyp de travail}
Pour tout $\vartheta \in \Theta$, on a $f(\vartheta, z) >0,\;\;\mu(dz)$-presque partout.
\end{hypothese}

Soit $\widetilde \vartheta \in \Theta$ un point arbitraire de l'ensemble des paramètres. On souhaite tester une hypothèse nulle de la forme
$$H_0:\;\;\;\vartheta \leq \widetilde \vartheta$$
contre l'alternative
$$H_1:\;\;\;\vartheta > \widetilde \vartheta.$$
Pour appliquer le résultat de Neyman-Pearson, il faut, d'une certaine manière, pouvoir traiter tous les tests de l'hypothèse simple
$H_0:\vartheta = \vartheta_0$ contre l'alternative $H_1: \vartheta = \vartheta_1$ simultanément pour tous les  $\vartheta_0 \leq \widetilde \vartheta$ et $\vartheta_1 \geq \widetilde \vartheta$.

%L'hypothèse suivante va permettre de nous ramener à cette situation :

\begin{definition} Sous l'Hypothèse \ref{hyp de travail}, la famille de densité $\{f(\vartheta, \cdot),\vartheta \in \Theta\}$,  avec $\Theta \subset \R$, est dite à rapport de vraisemblance monotone s'il existe une application $T:\mathfrak{Z}\rightarrow \R$ mesurable, de sorte que pour tous
$\vartheta_1 < \vartheta_2$,
$$\frac{f(\vartheta_2,Z)}{f(\vartheta_1,Z)}\;\;\;\text{
est une fonction monotone de}\;\;T(Z).$$
\end{definition}
\begin{remarque}
\emph{
Quitte à changer $T$ en $-T$, on peut toujours supposer que cette fonction est croissante.
}
\end{remarque}
\begin{theoreme}[Lehmann]
Soit $\alpha \in [0,1]$ un niveau de risque. On suppose que $\Theta \subset \R$ est un intervalle ouvert et que la famille $\{f(\vartheta,\cdot),\vartheta \in \Theta\}$ satisfait l'Hypothèse \ref{hyp de travail} et est à rapport de vraisemblance monotone. Si, pour $\widetilde \vartheta \in \Theta$, il existe une solution $\rho = \rho(\widetilde \vartheta, \alpha) >0$ à
$$
\PP_{\widetilde \vartheta}\big[T(Z)>\rho\big]=\alpha,
$$
alors le test de région de rejet
$${\mathcal R}^\star = \big\{T(Z)>\rho(\widetilde \vartheta,\alpha)\big\}$$
est de niveau $\alpha$ pour tester $H_0:\vartheta \leq \widetilde \vartheta$ contre $H_1:\vartheta> \widetilde \vartheta$, et de puissance maximale parmi tous les tests de niveau $\alpha$.
\end{theoreme}
%\begin{remarque}
%{\tt terminologie UPP}
%\end{remarque}
\begin{proof}
C'est une adaptation de la preuve du Lemme de Neyman-Pearson. L'hypothèse d'une famille à rapport de vraisemblance monotone se traduit par la propriété suivante : pour tous $ \vartheta > \widetilde \vartheta$, la condition
$$\frac{f(\vartheta,Z)}{f(\widetilde \vartheta,Z)} >c$$
est équivalente à
$$T(Z) \geq \kappa(\widetilde \vartheta, \vartheta, c)$$
pour une certaine fonction $\kappa$. Notons $\varphi^\star$ le test simple de région critique ${\mathcal R}^\star$ et soit $\vartheta' > \widetilde \vartheta$ un point arbitraire de l'alternative. Montrons que la puissance $\pi_{\vartheta'}(\varphi^\star)$ est maximale parmi tous les tests de niveau $\alpha$ pour tester $H_0$ contre $H_1$.

Si l'on considère le test de l'hypothèse simple $\vartheta = \widetilde \vartheta$ contre l'alternative simple $\vartheta = \vartheta'$, on sait que le test de Neyman-Pearson
$$\varphi^{\text{NP}} = 1_{\big\{\frac{f(\vartheta',Z)}{f(\widetilde \vartheta,Z)}> c(\alpha,\vartheta',\widetilde \vartheta)\big\}},$$
où $c(\alpha, \vartheta',\widetilde \vartheta)$ est la constante du Théorème \ref{lemme de np}, a la puissance maximale parmi tous les tests de niveau $\alpha$. D'après notre  remarque préliminaire, il s'écrit aussi sous la forme
$$\varphi^{\text{NP}}  = 1_{\big\{T(Z) \geq \kappa\big(\widetilde \vartheta, \vartheta, c(\alpha, \vartheta',\widetilde \vartheta)\big)\big\}},$$
et $c(\alpha, \vartheta',\widetilde \vartheta)$ est déterminée par la condition
$$\PP_{\widetilde \vartheta}\big[T(Z) \geq \kappa\big(\widetilde \vartheta, \vartheta, c(\alpha, \vartheta',\widetilde \vartheta)\big)\big] = \alpha,$$
s'il existe. C'est le cas, d'après les hypothèses,
%d'après l'hypothèse \ref{},
et on a aussi
$$\kappa\big(\widetilde \vartheta, \vartheta, c(\alpha, \vartheta',\widetilde \vartheta)\big) = \rho(\widetilde \vartheta, \alpha).$$
%c(\alpha, \vartheta',\widetilde \vartheta).$$
D'après le Lemme de Neyman-Pearson, on en déduit que $\varphi^\star$ a une erreur de seconde espèce maximale au point $\vartheta'$ parmi tous les tests de niveau $\alpha$, et donc uniformément sur l'alternative.

Il reste à montrer que $\varphi^\star$ est bien de niveau $\alpha$. Soit $\vartheta^{''} \leq \widetilde \vartheta$ un point arbitraire de l'hypothèse nulle. Posons
$$\alpha' = \PP_{\vartheta^{''}}\big[\varphi^\star = 1\big].$$
Alors $\alpha'$ est le niveau du test $\varphi^\star$ utilisé pour tester l'hypothèse nulle $\vartheta = \vartheta^{''}$ contre l'alternative $\vartheta  = \widetilde \vartheta$. Alors, comme précédemment, le Lemme de Neyman-Pearson entraîne que $\varphi^\star$ est optimal pour tester $\vartheta = \vartheta^{''}$ contre l'alternative $\vartheta  = \widetilde \vartheta$ au niveau $\alpha'$. Finalement, le Corollaire \ref{np sans biais} implique que la puissance de $\varphi^\star$ est plus grande que $\alpha'$, c'est-à-dire
$$\pi(\varphi^\star) \geq \PP_{\vartheta^{''}}\big[\varphi^\star=1\big] = 1-\PP_{\widetilde \vartheta}\big[\varphi^\star = 0\big] ,$$
soit
$$\PP_{\vartheta^{''}}\big[\varphi^\star=1\big]\leq \PP_{\widetilde \vartheta}\big[\varphi^\star = 0\big] = \alpha.$$
Comme $\vartheta^{''}$ est arbitraire, le théorème est démontré.
\end{proof}
\subsection{Exemples}
\begin{exemple}
\emph{
On observe $X_1,\ldots, X_n$ indépendantes, de loi ${\mathcal N}(\vartheta, \sigma^2)$, où $\sigma^2$ est connu, et $\vartheta \in \Theta =\R$.
On teste $H_0:\vartheta = \vartheta_0$ contre $H_1:\vartheta = \vartheta_1$, avec $\vartheta_0 < \vartheta_1$. On a $Z = (X_1,\ldots, X_n)$, et on prend pour mesure dominante $\mu$ la mesure de Lebesgue sur $\R^n$. Si $g(x) = (2\pi)^{-1/2} \exp(-x^2/2)$ désigne la densité de la loi gaussienne standard sur $\R$, on a
\begin{align*}
f(\vartheta,Z) =\,& \sum_{i=1}^n g(\vartheta - X_i) \\
=\,& \frac{1}{(2\pi \sigma^2)^{n/2}} \exp\big(-\frac{1}{2\sigma^2}\sum_{i = 1}^n (X_i-\vartheta)^2\big) \\
 =\,& \frac{1}{(2\pi \sigma^2)^{n/2}} \exp\big(-\frac{1}{2\sigma^2}\sum_{i = 1}^n X_i^2 + \frac{n\vartheta}{\sigma^2}\overline{X}_n-\frac{n\vartheta^2}{2\sigma^2}\big)
 \end{align*}
d'où
$$\frac{f(\vartheta_1,Z)}{f(\vartheta_0,Z)} =  \exp\big(\frac{n}{\sigma^2}(\vartheta_1-\vartheta_0)\overline{X}_n\big)\exp\big(-\frac{n}{2\sigma^2}(\vartheta_1^2-\vartheta_0^2)\big).$$
La zone de rejet du test de Neyman-Pearson s'écrit
\begin{align*}
\big\{f(\vartheta_1,Z) > cf(\vartheta_0,Z)\big\} \,&= \big\{\frac{n}{\sigma^2}(\vartheta_1-\vartheta_0) \overline{X}_n - \frac{n}{2\sigma^2}(\vartheta_1^2-\vartheta_0^2) >c\big\} \\
=\,& \big\{\overline{X}_n > \frac{\vartheta_0+\vartheta_1}{2}+\frac{\sigma^2\log c}{n(\vartheta_0-\vartheta_1)}\big\}.
\end{align*}
Le choix de $c$ est réglé par l'équation
\begin{equation} \label{choix du seuil}
\PP_{\vartheta_0}\big[\overline{X}_n > \frac{1}{2}(\vartheta_0+\vartheta_1)+\frac{\sigma^2\log c}{n(\vartheta_0-\vartheta_1)}\big] = \alpha.
\end{equation}
Sous $\PP_{\vartheta_0}$, les $X_i$ sont distribuées  comme des variables aléatoires gaussiennes indépendantes, de moyenne $\vartheta_0$ et de variance $\sigma^2$. Donc, sous $\PP_{\vartheta_0}$, on peut écrire
\begin{equation} \label{rep moy empirique}
\overline{X}_n = \vartheta_0+\frac{\sigma}{\sqrt{n}}\xi^{(\vartheta_0)},
\end{equation}
où la loi de $\xi^{(\vartheta_0)}$ -- sous $\PP_{\vartheta_0}$-- est la loi gaussienne standard ${\mathcal N}(0,1)$. Donc l'équation \eqref{choix du seuil} est équivalente  à
$$\PP_{\vartheta_0}\big[\xi^{(\vartheta_0)}>\frac{\sqrt{n}}{2\sigma}(\vartheta_1-\vartheta_0)+\frac{\sigma}{\sqrt{n}}\frac{\log c}{\vartheta_0-\vartheta_1}\big] = \alpha,$$
soit
$$\frac{\sqrt{n}}{2\sigma}(\vartheta_1-\vartheta_0)+\frac{1}{\sqrt{n}}\frac{\sigma\log c}{\vartheta_0-\vartheta_1} = \Phi^{-1}(1-\alpha)$$
où $\Phi(x)$ désigne la fonction de répartition de la loi ${\mathcal N}(0,1)$, d'où finalement
$$c = \exp\big(n\frac{(\vartheta_1-\vartheta_0)^2}{2\sigma^2}+\frac{\sqrt{n}}{\sigma}(\vartheta_0-\vartheta_1)\Phi^{-1}(1-\alpha)\big).$$
}
\end{exemple}
\begin{exemple} \label{rapp de vrais monotone}
\emph{
Dans le même contexte, on a bien, pour $\vartheta > \widetilde \vartheta$
$$\frac{f(\vartheta,Z)}{f(\widetilde \vartheta,Z)}  = \exp\Big(\frac{n(\vartheta-\widetilde\vartheta)}{\sigma^2}T(X_1,\ldots, X_n) - \frac{n}{2\sigma^2}(\vartheta^2-\widetilde \vartheta^2)\Big),$$
avec $T(X_1,\ldots, X_n) =\overline{X}_n$.  La famille $\{f(\vartheta, \cdot), \vartheta \in \R\}$ est à rapport de vraisemblance monotone, et un test optimal (uniformément plus puissant) de  $H_0:\vartheta \leq \widetilde \vartheta$ contre $H_1: \vartheta > \widetilde \vartheta$ est donné par la région critique
$${\mathcal R}  = \big\{\overline{X}_n > c\big\},$$
où $c = c(\widetilde \vartheta, \alpha)$ est calibré par l'équation
$$\PP_{\widetilde \vartheta}\big[\overline{X}_n > c\big] = \alpha,$$
soit, d'après \ref{rep moy empirique} en remplaçant $\vartheta_0$ par $\widetilde \vartheta$,
$$\PP_{\widetilde \vartheta}\Big[\xi^{(\widetilde \vartheta)} > \frac{\sqrt{n}}{\sigma}(c-\widetilde \vartheta)\Big] = \alpha,$$
où la loi de $\xi^{(\widetilde \vartheta)}$ sous $\PP_{\widetilde \vartheta}$ est la loi ${\mathcal N}(0,1)$. D'où
$$c = c(\widetilde \vartheta,\alpha) = \widetilde \vartheta + \frac{\sigma\Phi^{-1}(1-\alpha)}{\sqrt{n}}.$$
On peut expliciter sur cet exemple la puissance du test optimal
$$\varphi^\star = 1_{\big\{\overline{X}_n >  \widetilde \vartheta + \frac{\sigma\Phi^{-1}(1-\alpha)}{\sqrt{n}}\big\}}.$$
%{\tt more comments here}
On a, pour tout point de l'alternative $\vartheta > \widetilde \vartheta$, en utilisant une fois de plus la représentation $\overline{X}_n = \vartheta +\frac{\sigma}{\sqrt{n}}\xi^{\vartheta}$, où la loi de $\xi^{(\vartheta)}$ sous $\PP_\vartheta$ est la loi ${\mathcal N}(0,1)$,
\begin{align*}
\pi_\vartheta(\varphi^\star) = \,& \PP_\vartheta\big[\vartheta + \frac{\sigma}{\sqrt{n}}\xi^{(\vartheta)} > \widetilde \vartheta + \frac{\sigma\Phi^{-1}(1-\alpha)}{\sqrt{n}}\big] \\
 = \, & \PP_\vartheta\Big[\xi^{(\vartheta)} > \frac{\sqrt{n}}{\sigma}(\widetilde \vartheta - \vartheta)+\sigma \Phi^{-1}(1-\alpha)\Big] \\
= \, & 1- \Phi\Big(\frac{\sqrt{n}}{\sigma}(\widetilde \vartheta - \vartheta)+ \sigma\Phi^{-1}(1-\alpha)\Big) \\
= \, & \Phi\Big(\frac{\sqrt{n}}{\sigma}(\vartheta - \widetilde \vartheta)-\sigma\Phi^{-1}(1-\alpha)\Big)
\end{align*}
en utilisant l'identité $1-\Phi(x) = \Phi(-x)$ (qui traduit simplement le fait que la loi gaussienne standard est symétrique).
%more comments here}
}
\end{exemple}
%\subsection{Sur l'absence d'optimalité dans le cas général}
%\begin{center}
%{\tt INSERT HERE SUPPL. 45}
%\end{center}
\begin{remarque}
\emph{
Hormis quelques cas particuliers comme les familles à rapport de vraisemblance monotone\footnote{Et le cas des échantillons gaussiens étudiés plus loin dans le Section \ref{tests echantillons gaussiens}.}, on ne sait pas en général exhiber de tests optimaux au sens de Neyman lorsque l'hypothèse nulle ou l'alternative sont composites. Pour développer une théorie générale, nous nous placerons -- comme pour l'estimation -- dans un cadre asymptotique dès le Chapitre \ref{tests asymptotiques}.
}
\end{remarque}
\section{$p\,$--valeur} \label{p valeur}
\subsection{Notion de $p\,$--valeur}
\subsubsection{Introduction sur un exemple}
%Accepter ou rejeter l'hypothèse à partir d'un test, même optimal au sens de Neyman-Pearson n'a en fait que peu de signification scientifique.
Reprenons l'Exemple \ref{rapp de vrais monotone} avec $\widetilde \vartheta = 0$, où l'on teste au niveau $\alpha$ l'hypothèse nulle $H_0: \vartheta \leq 0$ contre l'alternative $H_1: \vartheta >0$. La règle de décision (optimale) prend la forme
$$\text{\og On rejette l'hypothèse}\;H_0\;\;\;\text{si}\;\;\; \overline{X}_n > \sigma\frac{\Phi^{-1}(1-\alpha)}{\sqrt{n}}\;\;\text{\fg{}}.$$
Si les observations $X_i$ sont indépendantes, ont un moment d'ordre 2, et si $n$ est grand, alors cette approche est plausible. Toutefois, on ne connaît pas $\sigma$ en général, mais on peut l'estimer par $\widehat \sigma_n$, de sorte qu'en pratique, on va rejeter l'hypothèse si
\begin{equation} \label{la regle}
\overline{X}_n >\widehat \sigma_n \frac{\Phi^{-1}(1-\alpha)}{\sqrt{n}}.
\end{equation}
On se donne sa valeur de $\alpha$ favorite, par exemple $5\%$, et on effectue le test : on accepte ou on rejette, en fonction du nombre de données $n$, des valeurs calculées à partir des observations $\Xbar$, $\widehat \sigma_n$, et de la valeur $\alpha$ choisie, selon la règle de décision \eqref{la regle}.

Imaginons que l'on rejette l'hypothèse. Qu'aurions-nous fait pour le choix de $\alpha = 1\%$ ? Ou bien $\alpha = 1/1000$, etc. ?
En prenant $\alpha$ de plus en plus petit, il y a fatalement un seuil $\alpha$ à partir duquel on va systématiquement accepter l'hypothèse : pour se garder contre l'erreur de première espèce, on est prêt à augmenter les faux positifs\footnote{Dans le cas limite $\alpha = 0$, on ne peut pas se permettre de rejeter l'hypothèse à tort, et ceci \og oblige\fg{} le test à accepter systématiquement l'hypothèse.}.
%\index{$p$--valeur}
\subsubsection{Définition de la $p\,$-valeur d'un test}

En pratique, accepter ou rejeter l'hypothèse n'a donc que peu de signification scientifique, surtout si $\alpha$ est proche du seuil limite où la décision va  basculer : en baissant $\alpha$, on accepte l'hypothèse (ou bien en augmentant $\alpha$ on rejette l'hypothèse). Par contre, le seuil de basculement  de la décision (qui dépend des observations) a une signification et une interprétation : c'est ce que l'on appelle la $p$-valeur du test.

\begin{definition}[$p\,$--valeur] Soit, pour tout $\alpha \in [0,1]$, une famille de tests simples $\varphi_\alpha$ de niveau $\alpha$ pour tester l'hypothèse $H_0$ contre l'alternative $H_1$.
On note ${\mathcal R}_\alpha$ la zone de rejet de $\varphi_\alpha$.
On appelle $p$-valeur du test la quantité
$$p-\mathrm{valeur}(Z) =  \inf\{\alpha,\; Z \in {\mathcal R}_\alpha\}.$$
\end{definition}
La $p$-valeur d'un test (de la famille de tests indicée par le niveau $\alpha$) est le plus petit niveau pour lequel on rejette $H_0$.

\subsubsection{Règle d'interprétation}
On est confiant vis-à-vis de la décision de ne pas rejeter $H_0$ lorsque la $p\,$-valeur du test est grande.
Voici quelques interprétations courantes qui sévissent dans les applications (extrait du livre de Wasserman \cite{W}) de l'interprétation des ordres de grandeur des $p\,$-valeurs :
\begin{center}
\begin{tabular}{llll}
$p\,$--valeur & \vline & suspicion de rejet \\
\hline
  $<0.01$ & \vline & suspicion très forte contre $H_0$\\
  $0.01 - 0.05$ & \vline & suspicion  forte contre $H_0$\\
  $0.05 - 0.1$ & \vline & suspicion faible contre $H_0$\\
 $> 0.1$ & \vline & peu ou pas de suspicion contre $H_0$\\
\end{tabular}
\end{center}

 \index{$p\,$-valeur}
Attention ! Une $p\,$-valeur grande n'est pas un indicateur en faveur de l'acceptation de l'hypothèse  $H_0$, mais plutôt en faveur du non-rejet (suggérant en pratique d'envisager d'autres tests plus précis ou plus coûteux). Une $p\,$-valeur peut être grande pour deux raisons :

\begin{itemize}

\item effectivement, l'hypothèse $H_0$ est vraie,

\item l'hypothèse $H_0$ n'est pas vraie, mais le test est très peu puissant (beaucoup de faux positifs) et son erreur de seconde espèce est grande.

\end{itemize}
 Concernant la seconde raison, prenons par exemple le test trivial $\varphi = 1_{\emptyset}$. Sa $p$-valeur vaut $1$ et prend donc la plus grande valeur possible. Mais son erreur de seconde espèce est maximale.
 %Néanmoins, {\tt more here}


\subsection{Propriétés de la $p\,$-valeur}
On peut préciser -- un peu -- le sens mathématique des remarques précédentes. On se restreint au cas  où l'hypothèse nulle est simple : on teste $H_0:\vartheta = \vartheta_0$ contre $H_1=\vartheta \neq \vartheta_0$.
\begin{proposition} \label{proprietes p valeur}
Soit $\{\varphi_\alpha, 0 \leq \alpha \leq 1\}$ une famille de tests exactement\footnote{Au sens où l'erreur de première espèce vaut exactement $\alpha$.} de niveau $\alpha$ dont la zone de rejet est de la forme
$${\mathcal R}_\alpha = \big\{T(Z) \geq c_\alpha\big\}$$
pour une certaine application $T:\mathfrak{Z}\rightarrow \R$ mesurable. Alors, si $\widetilde Z$ désigne une copie indépendante de $Z$, on a
$$p-\mathrm{valeur}(Z) = \PP_{\vartheta_0}\big[T(\widetilde Z) \geq T(Z)\,|\,Z\big].$$
De plus, si la loi de $T(Z)$ est absolument continue sous $\PP_{\vartheta_0}$, alors la loi de $p-\mathrm{valeur}(Z)$ est uniforme sous $\PP_{\vartheta_0}$.
%CHECK SI ABS CONT NEC
\end{proposition}
Le premier résultat de la Proposition \ref{proprietes p valeur} s'interprète de la façon suivante : la $p$-valeur est la probabilité sous $\PP_{\vartheta_0}$ qu'une observation $T(\widetilde Z)$ d'une expérience \og copie \fg{} soit supérieure à ce que l'on a observé, c'est-à-dire $T(Z)$.

%La seconde partie de la Proposition nous dit que, si l'on décide de rejeter l'hypothèse dès que la $p\,$-valeur du test est plus petite qu'un niveau $\alpha$ que l'on s'est fixé, alors on a une probabilité $\alpha$ de rejeter à tort.
\begin{proof}
L'application $c_\cdot : [0,1] \rightarrow \overline{\R}$ est décroissante et  $c_0 = +\infty$ et $c_1=-\infty$. On a l'identité
$$c_{p-\mathrm{valeur}(Z)} = T(Z).$$
Il vient
\begin{align*}
\PP_{\vartheta_0}\big[T(\widetilde Z) \geq T(Z)\,|\,Z\big] = &\,\PP_{\vartheta_0}\big[T(\widetilde Z) \geq c_{p-\mathrm{valeur}(Z)}\,|\,Z \big] \\
=&\, p-\mathrm{valeur}(Z)
\end{align*}
par définition de l'erreur de première espèce, en utilisant l'hypothèse que le test $\varphi_\alpha$ est exactement de niveau $\alpha$.
%{\tt pb de niveau ou exactement de niveau}.

La seconde partie de la proposition est standard. Si $F$ désigne la fonction de répartition de $T(\widetilde Z)$, posons
$$Y = \PP_{\vartheta_0}\big[T(\widetilde Z) \leq T(Z)\,|\,Z\big] = F\big(T(Z)\big).$$
Alors, pour tout réel $x$, on a
\begin{align*}
\PP_{\vartheta_0}\big[Y \leq x\big] = \,&\PP_{\vartheta_0}\big[F\big(T(Z)\big)\leq x\big] \\
=\;& \PP_{\vartheta_0}\big[T(Z)\leq F^{-1}(x)\big] \\
=\;& F\big(F^{-1}(x)\big) = x
\end{align*}
si $x \in [0,1]$, et où $F^{-1}(x) = \inf\{t \in \R, \,F(t)\geq x\}$ (Méléard \cite{M}, paragraphe 4.2.4 p. 78). Si $x \leq 0$, la probabilité ci-dessus vaut $0$ et si $x > 1$, elle vaut $1$. Donc la loi de $Y$ sous $\PP_{\vartheta_0}$ est uniforme sur $[0,1]$, ce qui achève la démonstration.
\end{proof}
%\section{Tests dans le modèle linéaire}
\section{Régions de confiance}
\index{confiance, intervalle de}
\index{confiance, région de}
Nous avons déjà construit des intervalles de confiance dans le contexte de la précision d'estimation pour le modèle d'échantillonnage général du Chapitre \ref{echantillonnage}. Nous formalisons -- un peu -- dans cette section la notion et le lien naturel avec les tests d'hypothèse, que nous avons déja utilisés au Chapitre \ref{echantillonnage}.
\subsubsection{Situation}
On considère l'expérience statistique engendrée par l'observation d'un $n$-échantillon $X_1,\ldots, X_n$ où la variable aléatoire réelle $X_i$ suit la loi $\PP_\vartheta$, avec $\Theta \subset \R^d$, $d \geq 1$. On peut immédiatement généraliser ce qui va suivre à une expérience statistique arbitraire, avec un simple coût notationnel.
\subsection{Région de confiance}
\begin{definition}
Soit $\alpha \in [0,1]$. Une région de confiance de niveau $1-\alpha$ pour le paramètre $\vartheta \in \Theta$ est un ensemble
$${\mathcal C} = {\mathcal C}_\alpha(X_1,\ldots, X_n) \subset \R^d,$$
tel que
\begin{equation} \label{covering}
\forall \vartheta \in \Theta,\;\;\;
\PP_\vartheta\big[\vartheta \in {\mathcal C}(X_1,\ldots, X_n)\big] \geq 1-\alpha.
\end{equation}
\end{definition}
\index{couverture, propriété de}
La propriété \eqref{covering} est appelée \og propriété de couverture \fg{} de la région ${\mathcal C}_\alpha(X_1,\ldots, X_n)$. Bien qu'en principe arbitraire, on construit en pratique des régions  de confiance très particulières. Si $\Theta \subset \R$, on utilise le plus souvent des intervalles. Construire un intervalle de confiance de niveau $1-\alpha$ revient alors à se donner deux statistiques $g_\alpha(X_1,\ldots, X_n)$ et $d_\alpha(X_1,\ldots, X_n)$  avec
$$g_\alpha(X_1,\ldots, X_n) \leq d_\alpha(X_1,\ldots, X_n)$$
telles que, pour tout $\vartheta \in \Theta$,
$$\PP_\vartheta\big[g_\alpha(X_1,\ldots, X_n) \leq \vartheta \leq d_\alpha(X_1,\ldots, X_n)\big] \geq 1-\alpha.$$
Posée comme cela, la construction des statistiques $g_\alpha(X_1,\ldots, X_n)$ et $d_\alpha(X_1,\ldots, X_n)$ n'a pas d'intérêt : n'importe quel intervalle contenant $\Theta$ conviendra. La qualité d'un intervalle de confiance de niveau $1-\alpha$ se mesurera à sa longueur (en générale aléatoire) que l'on cherche à rendre la plus petite possible, sous la contrainte de la propriété de couverture. Dans ce sens, la problématique des tests et des intervalles de confiance est similaire.

\subsection{Fonctions pivotales : le cas non-asymptotique}
\index{pivotale, statistique}
Dans le cas particulier où l'ensemble des paramètres $\Theta$ est de dimension 1, nous examinons une méthode  de construction de régions de confiance, très particulière, mais qui sera mise en œuvre de manière plus systématique dans le cadre asymptotique (voir \ref{les tests de wald}). Elle est fortement apparentée à la construction des tests.

Supposons que l'on dispose d'une variable aléatoire\footnote{Attention : $S(\vartheta, X_1,\ldots, X_n)$ dépend de $\vartheta$, elle n'est pas observable et ce n'est pas une statistique.} $S(\vartheta,X_1,\ldots, X_n)$ à valeurs dans $\R$ dont la loi sous $\PP_\vartheta$ ne dépende pas de $\vartheta$. En particulier, pour tout intervalle $I$ de $\R$, la probabilité
$$\PP_\vartheta\big[S(\vartheta,X_1,\ldots, X_n) \in I\big]$$
ne dépend pas de $\vartheta$.
%On a déja rencontré de telles situations {\tt more here}.
\begin{definition}
On appelle pivot toute variable aléatoire $S(\vartheta, X_1,\ldots, X_n)$ dont la loi ne dépend pas de $\vartheta$.
\end{definition}
\begin{exemple}
\emph{
\begin{enumerate}
\item
Si $X_1,\ldots, X_n$ sont indépendantes, de même loi ${\mathcal N}(\vartheta, \sigma^2)$, où $\sigma^2$ est connu et $\vartheta \in \Theta = \R$ est le paramètre inconnu, alors
$$S(\vartheta, X_1,\ldots, X_n) = \frac{\overline{X}_n-\vartheta}{\sigma}$$
est pivotale.
\item
Si $X_1,\ldots, X_n$ sont indépendantes, de même loi exponentielle de paramètre $\vartheta$, où $\vartheta \in \R_+\setminus \{0\}$ est le paramètre, alors
$S(\vartheta, X_1,\ldots, X_n) = \vartheta \overline{X}_n$ est pivotale. En effet, la loi de $X$ sous $\PP_\vartheta$ est exponentielle de paramètre $\vartheta$. Sa densité par rapport à la mesure de Lebesgue s'écrit
$\vartheta g(\vartheta \cdot)$, où $g(x) = \exp(-x)1_{\{x \in \R_+\}}$ est la densité de la loi exponentielle de paramètre $1$. De manière générale, si $X$ a pour densité $f$ par rapport à la mesure de Lebesgue, alors $\vartheta X$ a pour densité $\vartheta^{-1}f(\vartheta^{-1}\cdot)$ si $\vartheta \neq 0$. Donc $\vartheta X$ a pour densité $g(\cdot)$ qui ne dépend pas de $\vartheta$. Par suite, puisque
$$S(\vartheta,X_1,\ldots, X_n) = \frac{1}{n}\sum_{i = 1}^n \vartheta X_i,$$
et que les $X_i$ sont indépendantes, la loi de $S(\vartheta, X_1,\ldots, X_n)$ ne dépend pas de $\vartheta$.
\end{enumerate}
}
\end{exemple}
Une méthode de  construction de pivot est la suivante. Soit $\xi$ une variable aléatoire de même loi que le pivot. Pour $\alpha \in [0,1]$, on considère la classe des intervalles $I_\alpha \subset \R$ vérifiant
\begin{equation} \label{les pivots}
\PP_\vartheta\big[S(\vartheta , X_1,\ldots, X_n) \in I_\alpha\big] = \PP_\vartheta\big[\xi \in I_\alpha\big] \geq 1-\alpha.
\end{equation}
Alors la région
$${\mathcal I}_\alpha = \big\{\vartheta \in \Theta, S(\vartheta, X_1,\ldots, X_n) \in I_{\alpha}\big\}$$
est une région de confiance pour $\vartheta$ de niveau $1-\alpha$. On est alors ramené à choisir dans la classe des intervalles $I_\alpha$ satisfaisant \eqref{les pivots} de sorte que le diamètre de ${\mathcal I}_\alpha$ soit le plus petit possible.

%\begin{exemple}
%\emph{
%%{\tt modèle de Bernoulli}
%\begin{center}
%{\tt INSERT HERE SUPPL. 47}
%\end{center}
%}
%\end{exemple}
%\begin{exemple}
%\emph{
%%{\tt exemple Tsyb}
%\begin{center}
%{\tt INSERT HERE SUPPL. 48}
%\end{center}
%}
%\end{exemple}

\subsubsection{Méthode générique de construction d'un pivot}
Dans les deux exemples précédents,  les pivots se basent sur des estimateurs préliminai\-res du paramètre $\vartheta$. Si $\est$ est un estimateur de $\vartheta$, une méthode générique de construction d'un pivot est la suivante.

On note $x \leadsto \Gamma_\vartheta(x) = \PP_\vartheta\big[\est \leq x\big]$, la fonction de répartition de $\est$ au point $\vartheta$.
\begin{proposition}
%Soit $\Gamma_\vartheta(x) = \PP_\vartheta\big[\est \leq x\big]$  la fonction de répartition de $\est$ au point $\varetheta$
Si
\begin{itemize}
\item[(i)] $\vartheta \leadsto \Gamma_\vartheta(x)$ est monotone pour tout $x \in \R$,
\item[(ii)] $x \leadsto \Gamma_\vartheta(x)$ est continue pour tout $\vartheta \in \Theta$,
\end{itemize}
alors
$$S(\vartheta, X_1,\ldots, X_n) = \Gamma_\vartheta(\est)$$
est un pivot de loi uniforme sur $[0,1]$. En particulier, pour tout $\alpha \in [0,1]$
$$\PP_\vartheta\Big[\frac{\alpha}{2} \leq \Gamma_\vartheta(\est) \leq 1-\frac{\alpha}{2}\Big] = 1-\alpha$$
et
$${\mathcal I}_\alpha = \big[\Gamma^{-1}_{\alpha/2}, \Gamma^{-1}_{1-\alpha/2}\big]$$
est un intervalle de confiance pour $\vartheta$ de niveau $1-\alpha$.
\end{proposition}
\begin{remarque}
\emph{
De même, pour tout $\rho \in [0,1]$,
$${\mathcal I}_\alpha^{(\rho)} = \big[\Gamma^{-1}_{\rho\alpha}, \Gamma^{-1}_{(1-\rho)\alpha}\big]$$
et on peut chercher la valeur $\rho$ qui minimise $\Gamma^{-1}_{(1-\rho)\alpha}-\Gamma^{-1}_{\rho\alpha}$ pour trouver le meilleur intervalle de confiance parmi la classe des estimateurs donnés par le pivot.
%Voir à ce sujet l'Exercice \ref{optimal conf int}.
%mais {\tt dire qqch ici...}
%CHeCK HERE
}
\end{remarque}

\subsection{Dualité tests -- régions de confiance}
Il existe un lien naturel entre intervalles de confiances et tests que nous avons déjà mis en évidence au Chapitre \ref{echantillonnage}.
\subsubsection{Un exemple illustratif}
Considérons l'expérience statistique engendrée par l'observation de $X_1,\ldots, X_n$, indépendantes et de même loi ${\mathcal N}(\vartheta, \sigma^2)$, où $\sigma^2>0$ est connu et $\vartheta \in \Theta = \R$ est le paramètre inconnu. Soit $\alpha \in [0,1]$. Posons, pour $\vartheta_0 \in \Theta$,
$${\mathcal A}_\alpha(\vartheta_0) = \Big\{\big|\vartheta_0-\overline{X}_n\big| \leq \frac{\sigma}{\sqrt{n}}\Phi^{-1}\big(1-\frac{\alpha}{2}\big)\Big\}$$
et
$${\mathcal R}_\alpha(\vartheta_0) = \Big\{\big|\vartheta_0 - \overline{X}_n\big| > \frac{\sigma}{\sqrt{n}}\Phi^{-1}\big(1-\frac{\alpha}{2}\big)\Big\}.$$
Alors l'ensemble ${\mathcal R}_\alpha(\vartheta_0)$ s'interprète naturellement comme la zone de rejet d'un test de niveau $\alpha$ pour l'hypothèse
$$H_0: \vartheta = \vartheta_0,\;\;\;\;\text{contre}\;\;\;\;H_1:\vartheta \neq \vartheta_0.$$
De plus, ${\mathcal A}_\alpha(\vartheta_0) = {\mathcal R}_\alpha^c(\vartheta_0)$ correspond à la zone où l'on accepte l'hypothèse.
\begin{proposition}
 Si, pour tout $\vartheta_0 \in \Theta$, il existe un test de niveau $\alpha$ et de zone de rejet ${\mathcal R}_\alpha(\vartheta_0)$ de l'hypothèse nulle $H_0: \vartheta = \vartheta_0$ contre l'alternative $H_1:\vartheta \neq \vartheta_0$, alors, pour tout $\vartheta \in \Theta$
$${\mathcal C} = {\mathcal C}_\alpha(X_1,\ldots, X_n) = \Big\{\vartheta \in \Theta,\;(X_1,\ldots, X_n)\in {\mathcal R}_\alpha(\vartheta)^c\Big\}$$
est une région de confiance de niveau $1-\alpha$ pour $\vartheta$.

Réciproquement, si $ {\mathcal C}_\alpha(X_1,\ldots, X_n)$ est une région de confiance  de niveau $1-\alpha$ pour le paramètre $\vartheta \in \Theta$, alors, le test de l'hypothèse nulle $H_0:\vartheta = \vartheta_0$ contre l'alternative $\vartheta \neq \vartheta_0$ de région critique
$${\mathcal R}_\alpha(\vartheta_0) = \big\{\vartheta_0 \in {\mathcal C}_\alpha^c\big\}$$
est de niveau $\alpha$.
\end{proposition}
\begin{proof}
On a
\begin{align*}
\PP_\vartheta\big[\vartheta \in {\mathcal C}(X_1,\ldots, X_n)\big]  =\,& \PP_\vartheta\big[(X_1,\ldots, X_n) \in {\mathcal R}(\vartheta_0)^c\big] \\
=\, & 1 -\PP_\vartheta\big[(X_1,\ldots, X_n)\in {\mathcal R}(\vartheta_0)\big] \\
\geq \,& 1-\alpha.
\end{align*}
Réciproquement, il suffit de noter que pour tout $\vartheta_0 \in \Theta$, on a
\begin{align*}
\PP_{\vartheta_0}\big[(X_1,\ldots, X_n)\in {\mathcal R}(\vartheta_0)\big] =\,& 1- \PP_{\vartheta_0}\big[(X_1,\ldots, X_n)\in {\mathcal R}^c\big] \\
=\,&1-\PP_{\vartheta_0}\big[\vartheta_0\in {\mathcal C}\big] \\
\leq &\, \alpha.
\end{align*}
\end{proof}
\begin{remarque}
\emph{
Ce résultat, relativement immédiat, ne nous dit rien sur la puissance du test d'une part, ni sur la qualité (le diamètre) de la région de confiance d'autre part. Ces deux notions sont évidemment étroitement liées.
}
\end{remarque}
\section{Tests dans le modèle de régression linéaire}
\subsection{Echantillons gaussiens} \label{tests echantillons gaussiens}
\subsubsection{Situation}
Dans toute cette section, on considère l'expérience statistique engendrée par un $n$-échantillon de la loi ${\mathcal N}(\mu,\sigma^2)$, où $\vartheta = (\mu,\sigma^2) \in \Theta  = \R \times \R_+\subset \{0\}$. Il y a coïncidence dans ce cas très simple avec le modèle de régression linéaire à \og design \fg{} déterministe :  les observations sont  ${\bf Y} = (Y_1,\ldots, Y_n)$ et on a la représentation
\begin{equation}
{\bf Y} = \design \mu + \sigma \boldsymbol{\xi},
\end{equation}
où
$$\design = (1 \ldots 1)^T\;\;\text{($n$ fois)}\;\text{et}\;\;\;\boldsymbol{\xi} = (\xi_1 \ldots \xi_n)^T,$$
les $\xi_i$ étant sous $\PP_\vartheta$ des variables gaussiennes standard.
% Par habitude, on utilisera la représentation \eqref{rep modele lineaire} :
L'estimateur du maximum de vraisemblance est
\begin{align*}
\estMV =\,& \big(\widehat \mu_n^{\,{\tt mv}} , (\widehat \sigma_n^2)^{\,{\tt mv}}\big) \\
=\,&\Big( \overline{Y}_n, \tfrac{1}{n}\sum_{i = 1}^n (Y_i-\overline{Y}_n)^2\Big),
\end{align*}
voir Chapitre \ref{regression}, Proposition \ref{MC is MLE}. Une autre manière -- peut-être plus naturelle dans ce contexte -- est de maximiser directement
la log-vraisemblance
$$\ell_n\big((\mu,\sigma^2),Y_1,\ldots, Y_n\big) = -\frac{n}{2}\log(2\pi \sigma^2)-\frac{1}{2\sigma^2}\sum_{i = 1}^n (Y_i-\mu)^2.$$
On a
$$
\left\{
\begin{array}{lll}
\partial_\mu\ell_n \big((\mu,\sigma^2),Y_1,\ldots, Y_n\big)&  =\displaystyle  &\frac{1}{\sigma^2}\sum_{i = 1}^n (Y_i-\mu) \\ \\
\partial_{\sigma^2}\ell_n \big((\mu,\sigma^2),Y_1,\ldots, Y_n\big)&  = &\displaystyle -\frac{n}{2\sigma^2}+\frac{1}{2\sigma^4}\sum_{i = 1}^n (Y_i-\mu)^2,
\end{array}
\right.
$$
ce qui nous fournit le point critique
$$\est = \big(\overline{Y}_n,\frac{1}{n}\sum_{i = 1}^n(Y_i-\overline{Y}_n)^2\big).$$
On vérifie ensuite que le point critique est l'unique  maximum global et donc $\est = \estMV$.
%qui coïncident avec {\tt more sur methode empiriques}.
Un estimateur sans biais de $\sigma^2$ est
$$s_n^2 = \frac{1}{n-1}\sum_{i = 1}^n (Y_i-\overline{Y}_n)^2 = \frac{n}{n-1} (\widehat \sigma_n^2)^{\,{\tt mv}}.$$
%{\tt dire quelque chose ici}
Les propriétés des vecteurs gaussiens et des lois dérivées étudiées au Chapitre \ref{chapitre 1} nous donnent gratuitement la loi jointe de $(\overline{Y}_n,s_n^2)$.
\begin{lemme}
Sous $\PP_\vartheta$, les variables $\overline{Y}_n$ et $s_n^2$ sont indépendantes. De plus, $\overline{Y}_n$ suit la loi ${\mathcal N}\big(\mu,\frac{\sigma^2}{n}\big)$ et $(n-1)\frac{s_n^2}{\sigma^2}$ suit la loi du $\chi^2$ à $n-1$ degrés de liberté.
\end{lemme}
\begin{proof} C'est une application de la Proposition \ref{application cochran} qui repose sur la Proposition \ref{cochran} (Cochran) du Chapitre \ref{chapitre 1}.
\end{proof}
\subsubsection{Batterie de tests classiques}
Soit $\mu_0 \in \R$ et $\sigma_0^2 >0$ donnés.
\begin{enumerate}
\item On teste
$$H_0:\mu \leq \mu_0\;\;\;\;\text{ contre}\;\;\;\; H_1:\mu > \mu_0.$$
Un test de niveau $\alpha$
%optimal (au sens de la Définition \ref{}, c'est-à-dire Uniforméménet Plus Puissant)
est donné par la zone de rejet
$${\mathcal R}_\alpha = \big\{T({\bf Y}) > q_{1-\alpha, n-1}^{\mathfrak{T}}\big\},$$ où
$$T({\bf Y}) = \frac{\sqrt{n}(\overline{Y}_n-\mu_0)}{\big(\frac{1}{n-1}\sum_{i = 1}^n (Y_i - \overline{Y}_n)^2\big)^{1/2}},$$
où $q_{1-\alpha, n-1}^{\mathfrak{T}}$ est le quantile d'ordre $1-\alpha$ de la loi de Student à $n-1$ degrés de liberté.

Si l'on veut tester
$$H_0:\mu \geq \mu_0\;\;\;\;\text{ contre}\;\;\;\;H_1:\mu < \mu_0,$$
on prend la zone de rejet définie par
$${\mathcal R}_\alpha = \big\{T({\bf Y}) < q_{1-\alpha, n-1}^{\mathfrak{T}}\big\}.$$
%, mais on perd l'optimalité {\tt en dire plus ici...}.
\item On teste
$$H_0: \mu = \mu_0\;\;\;\;\text{ contre}\;\;\;\; H_1:\mu \neq \mu_0.$$
Un test de niveau $\alpha$ est par exemple le test défini par la zone de rejet
$${\mathcal R}_\alpha = \big\{\big|T({\bf Y})\big|>q_{1-\alpha/2, n-1}^{\mathfrak{T}}\big\}.$$
Il n'est pas optimal.
%Toutefois {\tt more here exo}
\item On teste
$$H_0: \sigma^2 \leq \sigma_0^2\;\;\;\; \text{contre}\;\;\;\;H_1:\sigma^2 > \sigma_0^2.$$
Un test de niveau $\alpha$ est défini par la zone de rejet
$${\mathcal R}_\alpha = \big\{V({\bf Y}) > q_{1-\alpha,n-1}^{\chi^2}\big\},$$
où
$$V({\bf Y}) = \frac{1}{\sigma_0^2}\sum_{i = 1}^n (Y_i - \overline{Y})^2$$
et $q_{1-\alpha,n-1}^{\chi^2}$ est le quantile d'ordre $1-\alpha$ de la loi du $\chi^2$ à $n-1$ degrés de liberté.
%Ce test est optimal (UPP).
Si l'on veut tester
$$H_0:\sigma^2 \geq \sigma_0^2\;\;\;\;\text{contre}\;\;\;\;H_1:\sigma^2 < \sigma_0^2,$$
on prend la zone de rejet définie par
$${\mathcal R}_\alpha = \big\{V({\bf Y}) < q_{1-\alpha, n-1}^{\chi^2}\big\},$$
% mais on perd l'optimalité {\tt en dire plus ici...}.
\item Finalement, si l'on teste
$$H_0: \sigma = \sigma_0\;\;\;\;\text{ contre}\;\;\;\;H_1:\sigma^2 \neq  \sigma_0^2,$$
on construit un test de niveau $\alpha$ en définissant le test de zone de rejet comme
$${\mathcal R}_\alpha = \big\{V({\bf Y}) < c_1(\alpha)\;\;\text{ou}\;\;V({\bf Y}) > c_2(\alpha)\big\},$$
où les constantes $c_i(\alpha), i=1,2$ sont définies par les conditions
$$\forall \mu\in \R,\;\;\PP_{(\mu, \varsigma_0)}\big[{\mathcal R}_\alpha\big] = \alpha$$
et
$$\forall \mu \in \R,\;\;\E_{\mu,\sigma_0}\big[V({\bf Y})1_{[c_1(\alpha), c_2(\alpha)]}\big(V({\bf Y})\big)\big] = (n-1)(1-\alpha).$$
\end{enumerate}
Un type de tests couramment rencontrés en pratique sont les tests relatifs à deux échantillons gaussiens. C'est l'objet de l'exercice \ref{deux echantillons gaussiens}.
\subsubsection{Sur l'optimalité des tests dans le cas gaussien}
Nous avons affirmé l'optimalité de certains des tests présentés dans le paragraphe précédent. Pour la démontrer, on prouve d'abord qu'un test optimal peut être construit par la statistique de test annoncée (la moyenne empirique, la variance empirique, la statistque $\mathfrak{T}$ de Student, et ainsi de suite), puis on optimise les paramètres de sorte de garantir le niveau voulu pour une erreur de seconde espèce minimale, et on retrouve ainsi les tests présentés ci-dessus.

Le premier point est délicat et utilise la notion de statistique exhaustive  définie au Chapitre \ref{theorie asymptotique} et le fait que les modèles gaussiens considérés appartiennent à une famille remarquable de modèles statistiques\footnote{Les modèles exponentiels, dont l'étude dépasse le cadre de ce cours.}.
%\begin{center}
%{\tt INSERT HERE SUPPL. 49}
%\end{center}
\subsection{Test d'appartenance à un sous-espace linéaire}
\index{sous-espace, test d'appartenance}
\index{sélection de variables, test de}
\subsubsection{Situation}
On se place dans le cadre du Chapitre \ref{regression}, sous l'Hypothèse de la Proposition \ref{emc multiple} et dans le cadre de la régression multiple gaussienne. On observe
$${\bf Y} = \mathbb{M}\, \vartheta + \boldsymbol{\xi},\;\;\vartheta \in \Theta = \R^d$$
et on suppose
$$\design^T\design >0.$$
On suppose de plus que $\boldsymbol{\xi}$ suit la loi normale sur $\R^n$ de matrice de variance-covariance $\sigma^2$ fois l'identité, c'est-à-dire les $\xi_i$ sont indépendantes, de loi ${\mathcal N}(0,\sigma^2)$.
\subsubsection{Un premier cas simple}
Soit $a \in \R$. On veut tester $H_0: \vartheta_j = a$ contre $H_1:\vartheta_j \neq a$, pour la composante $\vartheta_j$ du vecteur $\vartheta = (\vartheta_1,\ldots, \vartheta_d)^T$, où la direction $j$ est fixée à l'avance.

Un corollaire de la Proposition \ref{application cochran} du Chapitre \ref{regression} est le résultat suivant
\begin{lemme} \label{sigma connu}
On a, pour tout $\vartheta \in \Theta$, l'égalité en loi sous $\PP_\vartheta$
$$\frac{(\estMC)_j - \vartheta_j}{\sigma \sqrt{(\design^T\design)_{jj}^{-1}}} \stackrel{d}{=} {\mathcal N}(0,1),$$
où $(\design^T\design)_{jj}^{-1}$ désigne l'élément de la $j$-ième ligne et de la $j$-ième colonne de la matrice $(\design^T\design)^{-1}$.
\end{lemme}
\begin{proof} On a, d'après la Proposition \ref{regression},
$$\estMC - \vartheta_j  \stackrel{d}{=} \mathcal{N}\big(0,\sigma^2 (\design^T\design)^{-1}\big)$$
en loi sous $\PP_\vartheta$, donc, en posant $v_j = (0, \ldots, 0, 1, 0, \ldots, 0)$ où le terme non-nul est à la $j$-ième place, la variable aléatoire
$(\estMC)_j-\vartheta_j = (\estMC-\vartheta)^Tv_j$ est gaussienne, de moyenne
$$\E_\vartheta\big[(\estMC-\vartheta)^Tv_j\big] = 0$$
et de variance
\begin{align*}
\E_\vartheta\big[\big((\estMC-\vartheta)^Tv_j\big)^2\big] =\,& v_j^T\E_\vartheta\big[(\estMC-\vartheta)(\estMC-\vartheta)^T\big]v_j \\
=\,& \sigma^2 v_j^T (\design^T\design)^{-1}v_j\\
=\,& \sigma^2 (\design^T\design)_{jj}^{-1}.
\end{align*}
\end{proof}

Si $\sigma$ est inconnu, alors, en introduisant l'estimateur $s_n^2$, le Lemme \ref{sigma connu} devient
\begin{lemme}
On a, pour tout $\vartheta \in \Theta$, l'égalité en loi sous $\PP_\vartheta$,
$$\frac{(\estMC)_j - \vartheta_j}{s_n \sqrt{(\design^T\design)_{jj}^{-1}}} \stackrel{d}{=} \mathfrak{T}(n-d),$$
où $\mathfrak{T}(n-p)$ est la loi de Student de paramètre $n-d$.
 \end{lemme}
\begin{proof}
Posons $\eta = \sigma (\design^T\design)_{jj}^{-1}(\estMC_j-\vartheta_j)$ et
$$\mathfrak{K} = (n-d)\frac{s_n^2}{\sigma^2} = \frac{\|{\bf Y}-\design \estMC\|^2}{\sigma^2}$$
d'après la Proposition \ref{application cochran}. Alors sous $\PP_\vartheta$, la variable $\eta$ est gaussienne centrée réduite, et  $\mathfrak{K}$ suit la loi du $\chi^2$  à $n-d$ degrés de liberté d'après la Propostion \ref{cochran} (Cochran), et est indépendante de ${\bf Y}$ donc de $\eta$.
\end{proof}

En conséquence, le test défini par la région critique
$${\mathcal R}_\alpha = \left\{\Big|\frac{\big(\estMC\big)_j - a}{\widehat \sigma_n \sqrt{(\design^T\design)_{jj}^{-1}}}\Big| > q^{\mathfrak{T}}_{1-\alpha/2, n-d}\right\},$$
où $q^{\mathfrak{T}}_{1-\alpha/2, n-d}$ désigne le quantile d'ordre $1-\alpha$ de la loi de Student à $n-d$ degrés de liberté est de niveau $\alpha$ pour tester $H_0:\vartheta_j = a$ contre $H_1:\vartheta_j \neq a$.
\begin{remarque}
\emph{
Avec ce résultat, on n'a pas d'information sur l'erreur de seconde espèce (la puissance du test), que l'on doit étudier séparément.
}
\end{remarque}
\subsubsection{Une hypothèse plus générale}
Soit $(a_1,\ldots, a_m) \in \R^m$, avec $m < d$ et soit
$$1 \leq j_1 < j_2 < \ldots < j_m \leq d$$
une direction donnée. On souhaite tester
$$H_0:\vartheta_{j_1}=a_1,\ldots, \vartheta_{j_m}=a_m$$
contre l'alternative
$$H_1:\;\;\mathrm{il\;existe\; un \;indice}\;\;k \in \{1,\ldots, m\},\;\;\mathrm{tel\; que}\;\;\vartheta_{j_k}\neq a_k.$$

\subsubsection{Le cas le plus utile : la sélection de variables}
C'est un cas particulier de la situation précédente utile dans de nombreuses situations pratiques. On se place dans le modèle linéaire
$${\bf Y} = \design \, \vartheta +\boldsymbol{\xi},$$
où chaque observation $Y_i$ s'écrit
$$Y_i = \vartheta^T\bx_i +\xi_i= \sum_{i=1}^d\vartheta_i x_i+\xi_i,\;\;i=1,\ldots, n.$$
(On peut poser $x_1 = 1$ si l'on souhaite incorporer une \og ordonnée à l'origine \fg{}). Dans le cas de la sélection de variables, on teste si les $k$ premières variables influencent $Y$, les $d-k$ suivantes ne jouant pas de rôle, ce qui se traduit par l'hypothèse nulle
$$H_0: \vartheta_{k+\ell}=0,\;\;\ell=1,\ldots, \ell = d-k,$$
contre l'alternative
$$H_1: \text{il existe}\;\;1 \leq \ell\leq d-k,\;\;\vartheta_{k+\ell} \neq 0.$$
La sélection de variables est un problème vaste et très important en pratique. On présente quelques compléments sur ce sujet dans l'Exercice \ref{bonferroni}.
\subsubsection{Les F-tests}
C'est la cadre le plus général, qui inclut les situations décrites précédemment.

Soit $\mathbb{G}$ la matrice d'une application linéaire de
$\R^d$ dans $\R^m$, avec $m \leq d$, et soit ${\bf b} = (a_1,\ldots, a_m)^T$ un vecteur de $\R^m$ arbitraire. On veut tester l'hypothèse nulle
$$H_0:\mathbb{G}\vartheta = {\bf b}$$
contre l'alternative
$$H_1:\mathbb{G}\vartheta \neq {\bf b}.$$
On suppose que $\mathbb{G}$ est de la forme
$$
\mathbb{G} =
\left(
\begin{array}{llllll}
0 & \ldots & 0 & \;\;1 & \ldots & 0 \\
\vdots & \ddots &\vdots &\;\; \vdots & \ddots & \vdots \\
0 & \ldots & 0 &\;\; 0 & \ldots & 1
\end{array}
\right),
$$
où le premier bloc de $0$ a $m$ lignes et $d-m$ colonnes, alors que le second bloc est la matrice identité à $m$ lignes et $m$ colonnes.
\begin{proposition}
Sous l'hypothèse, c'est-à-dire sous $\PP_\vartheta$ avec $\mathbb{G}\vartheta = {\bf b}$, on a l'égalité en loi
$$\mathbb{G}\estMC \sim \mathcal{N}\big({\bf b}, \sigma^2 \mathbb{G}(\design^T\design)^{-1}\mathbb{G}^T\big).$$
\end{proposition}
\begin{proof}
C'est une application de la Proposition \ref{cochran} (Cochran).
%\begin{center}
%{\tt INSERT HERE SUPPL. 50}
%\end{center}
%{\tt more here}
\end{proof}
Notons qu'ici, la matrice de variance-covariance est de dimension $m$.
Donc, pour tout point de l'hypothèse $\vartheta$, c'est-à-dire vérifiant $\mathbb{G}\vartheta = {\bf b}$, le vecteur $m$-dimensionnel $\mathbb{G}\estMC$ est gaussien, de moyenne ${\bf b}$ et de matrice de variance-covariance
$${\bf U} = \sigma^2 \mathbb{G}(\design^T\design)^{-1}\mathbb{G}^T.$$
Notons que puisque $\design^T\design$ est inversible, la matrice ${\bf U}$ est définie positive. Posons
$$\eta = (\mathbb{G}\estMC-{\bf b})^T{\bf U}^{-1}(\mathbb{G}\estMC-{\bf b}).$$
Donc sous $\PP_\vartheta$ avec $\mathbb{G}\vartheta = {\bf b}$, la variable aléatoire $\eta$ suit la loi du $\chi^2$ à
$m$-degrés de libertés.
%more here ????????

On sait alors construire un test de niveau $\alpha$ lorsque $\sigma$ est connu.

Si $\sigma$ est inconnu, on peut l'estimer comme précédemment, mais dans le contexte modèle linéaire gaussien général, où $\vartheta$ est de dimension $d \geq 1$, voir Proposition \ref{application cochran} du Chapitre \ref{regression}. Alors
$$\widehat \sigma_n^2 = \frac{\|{\bf Y}-\design \,\estMC\|^2}{n-d},$$
et en posant
$$\widehat {\bf U} = \widehat \sigma_n^2 \mathbb{G}(\design^T\design)^{-1}\mathbb{G}^T,$$
la statistique
$$F({\bf Y}) = \frac{(\mathbb{G}\estMC-{\bf b})^T\widehat {\bf U}^{-1}(\mathbb{G}\estMC-{\bf b})}{m}$$
est pivotale sous $\PP_\vartheta$ avec $\mathbb{G}\vartheta = {\bf b}$ et  suit la loi de Fisher-Snedecor à $(m,n-d)$ degrés de liberté.
Un test de niveau $\alpha$ est alors fourni par la région de rejet
$${\mathcal R}_\alpha = \big\{F({\bf Y}) > q_{1-\alpha, m, n-d}^{{\tt FS}} \big\},$$
où $q_{1-\alpha, m, n-d}^{{\tt FS}}$ désigne le quantile d'ordre $1-\alpha$ de la loi de Fisher-Snedecor à $(m,n-d)$ degrés de liberté.
%{\tt puissance ?????}
Là encore, ceci ne nous fournit pas d'information sur l'erreur de seconde espèce du test que l'on doit étudier séparément.
%MORE HERE ???????????????????????
\section{Exercices}
%\begin{exercice} \label{test et estimation}
%\begin{center}
%{\tt INSERT HERE SUPPL. 52}
%\end{center}
%\end{exercice}
%\begin{exercice} \label{optimal conf int}
%\begin{center}
%{\tt INSERT HERE SUPPL. 53}
%\end{center}
%\end{exercice}
\begin{exercice} \label{deux echantillons gaussiens}
\emph{Soient $X_1,\ldots, X_m$ et $Y_1,\ldots, Y_n$ deux échantillons indépendants, de taille respective $m$ et $n$, de loi respective ${\mathcal N}(\mu_1,\sigma_1^2)$ et ${\mathcal N}(\mu_2,\sigma_2^2)$. On teste
$$H_0:\mu_1 = \mu_1\;\;\;\;\text{contre}\;\;\;\;H_1:\mu_1\neq \mu_2.$$
Construire un test basé sur la statistique
$$T_n = \frac{\overline{X}_m-\overline{Y}_n}{\sqrt{(s_m^{(1)})^2+(s_n^{(2)})^2}},$$
où $(s_m^{(1)})^2 = \tfrac{1}{m}\sum_{i = 1}^m (X_i-\overline{X}_m)^2$ et $(s_n^{(2)})^2 = \tfrac{1}{n}\sum_{i = 1}^n (Y_i-\overline{Y}_n)^2$, et étudier sa consistance.
}
\end{exercice}
\begin{exercice}[Règle de Bonferroni en test multiple] \label{bonferroni}
\emph{
On souhaite faire $m$ tests simultanément. On teste
$$H_{0,i}\;\;\;\text{contre}\;\;\;H_{1,i},\;\;\;\text{pour}\;\;i=1,\ldots, m$$
Etant donnés $m$ tests $\{\varphi_{\alpha}^{(i)},\;i=1,\ldots,m\}$
où $\varphi_{\alpha}^{(i)}$ est un test de niveau $\alpha$ pour l'hypothèse $H_{0,i}$ contre l'alternative $H_{1,i}$, on construit les $p$-valeurs associées
$$p-\text{valeur}(\varphi_{\cdot}^{(i)}),\;\;\;i=1,\ldots,m.$$
La règle de Bonferroni consiste à rejeter l'hypothèse $H_{0,i}$ si $p-\text{valeur}(\varphi_{\cdot}^{(i)})<\alpha/m$. Montrer que la probabilité de rejeter à tort une hypothèse nulle parmi les $m$ hypothèses nulles est inférieure à $\alpha$.
}
\end{exercice}
\chapter{Tests asymptotiques} \label{tests asymptotiques}
\index{test asymptotique}
On a vu dans le chapitre précédent que, mis à part des cas relativement particuliers, on n'a pas de méthode de construction de test systématique. Dans ce chapitre, on
se place dans le régime asymptotique $n \rightarrow \infty$, lorsque l'information de modèle est \og grande \fg. Dans ce cas, dès que le modèle est suffisamment régulier au sens du Chapitre \ref{theorie asymptotique} et que l'on dispose d'estimateurs \og raisonnables\fg{}, on sait construire des tests de façon un peu plus systématique.

Cependant, on ne pourra pas obtenir l'optimalité d'une suite de tests de niveau (asymptotique) donnée aussi facilement qu'au chapitre précédent ; on se contentera d'une notion plus faible : la convergence ou consistance de la suite de tests.
\section{Convergence d'une suite de tests}
\index{convergent, test}
\index{consistant, test}
On se place dans la problématique du Chapitre \ref{tests}. Etant donné une suite d'expériences statistiques ${\mathcal E}^n$ ayant pour ensemble de paramètres $\Theta \subset \R^d$ avec $d \geq 1$, on teste
$$H_0:\vartheta \in \Theta_0\;\;\;\text{contre}\;\;\;H_1:\vartheta \in \Theta_1,\;\;\;\text{avec}\;\;\;\Theta_0 \cap \Theta_1 = \emptyset.$$
On se donne un test ou plutôt une suite de tests \footnote{De la même manière que l'on parle d'estimateur pour une suite d'estimateurs, on utilisera le terme test pour désigner une suite de tests.}  simples $\varphi_n$ dans ${\mathcal E}^n$ de l'hypothèse nulle $H_0$ contre l'alternative $H_1$.
\begin{definition}[Niveau asymptotique d'une suite de tests]
Soit $\alpha \in [0,1]$. Le test $\varphi_n$ est asymptotiquement de niveau $\alpha$ si son erreur de première espèce est asymptotiquement plus petite que $\alpha$:
$$\forall \vartheta \in \Theta_0,\;\;\;\limsup_{n \rightarrow \infty}\PP_\vartheta\big[\varphi_n = 0\big] \leq \alpha.$$
\end{definition}
\begin{definition}
Le test $\varphi_n$ est convergent ou consistant si sa puissance asymptotique vaut 1, c'est-à-dire si son erreur de seconde espèce est asymptotiquement nulle :
$$\forall \vartheta \in \Theta_1,\;\;\;\lim_{n \rightarrow \infty}\PP_\vartheta\big[\varphi_n = 1\big] = 1 = 1- \lim_{n\rightarrow\infty}\PP_\vartheta\big[\varphi_n = 0\big].$$
\end{definition}
\section{Tests de Wald} \label{les tests de wald}
\subsection{Le cas d'une hypothèse nulle simple}
Traitons d'abord le cas du test d'une hypothèse nulle simple $H_0:\vartheta = \{\vartheta_0\}$ contre $H_1:\vartheta \neq \vartheta_0$. Plaçons-nous en dimension $d=1$ pour simplifier.
Supposons que l'on dispose d'un estimateur $\est$ asymptotiquement normal, c'est-à-dire pour lequel on a, pour tout $\vartheta \in \Theta$,
$$\sqrt{n}\big(\est -\vartheta\big)\stackrel{d}{\rightarrow} \mathcal{N}\big(0,v(\vartheta)\big),$$
où $v(\vartheta)>0$, la convergence ayant lieu en loi sous $\PP_\vartheta$. On suppose que la fonction $\vartheta \leadsto v(\vartheta)$ est régulière. Sous l'hypothèse, c'est-à-dire sous $\PP_{\vartheta_0}$, on a la convergence
$$
\sqrt{n}\frac{\est - \vartheta_0}{\sqrt{v(\vartheta_0)}}\stackrel{d}{\rightarrow} \mathcal{N}(0,1),
$$
en loi sous $\PP_{\vartheta_0}$, ou encore, en appliquant la Proposition \ref{slutsky} (Slutsky)
\begin{equation} \label{stat test wald simple}
T_n = \sqrt{n}\frac{\est - \vartheta_0}{\sqrt{v(\est)}}\stackrel{d}{\rightarrow} \mathcal{N}(0,1)
\end{equation}
en loi sous $\PP_{\vartheta_0}$. On en déduit \og presque immédiatement \fg{} la construction suivante
\begin{proposition} \label{wald simple}
Pour tout $\alpha \in (0,1)$, le test $\varphi_n$ défini par la zone de rejet
$${\mathcal R}_{n,\alpha} = \big\{\big|T_{n}\big|\geq \Phi^{-1}(1-\alpha/2)\big\},$$
où $\Phi^{-1}(1-\alpha)$ désigne le quantile d'ordre $1-\alpha$ de la loi normale standard, est asymptotiquement de niveau $\alpha$ et consistant.
\end{proposition}
\begin{proof}
Le contrôle du niveau asymptotique de $\varphi_n$ est une conséquence immédiate de la convergence \eqref{stat test wald simple} :
$$
\PP_{\vartheta_0}\big[\varphi_n = 1\big] = \PP_{\vartheta_0}\big[\big|T_n\big|\geq \Phi^{-1}(1-\alpha/2)\big] \\
 \rightarrow \alpha.
$$
Montrons la consistance. Soit $\vartheta \neq \vartheta_0$ un point de l'alternative. On écrit
\begin{equation} \label{decomp alternative}
T_n = \sqrt{n}\frac{\est - \vartheta}{\sqrt{v(\est)}} + \sqrt{n}\frac{\vartheta - \vartheta_0}{\sqrt{v(\est)}}.
\end{equation}
Le premier terme tend en loi sous $\PP_{\vartheta}$ vers la loi ${\mathcal N}(0,1)$, en appliquant la convergence \eqref{stat test wald simple} avec $\vartheta$ à la place de $\vartheta_0$. Le dénominateur du second terme converge en probabilité sous $\PP_{\vartheta}$ vers $v(\vartheta)$, et le numérateur diverge vers $\pm\infty$. Donc
$$|T_n| \stackrel{\PP_{\vartheta}}{\longrightarrow}+\infty$$
et donc $\varphi_n \stackrel{\PP_{\vartheta}}{\longrightarrow} 1$ pour tout $\vartheta \neq \vartheta_0$. On en déduit la consistance de $\varphi_n$ (par exemple par convergence dominée).
\end{proof}
\begin{remarque}
\emph{
Ici, le choix de la zone de rejet ne s'impose pas naturellement. Si ${\mathcal D}_\alpha \subset \R$ est tel que
\begin{equation} \label{condition de charge}
\PP\big[\xi \in {\mathcal D}_\alpha\big] = 1-\alpha
\end{equation}
où $\xi \sim {\mathcal N}(0,1)$, alors le test $\varphi_n({\mathcal D}_\alpha)$ défini par la zone de rejet
$${\mathcal R}_{n}({\mathcal D}_\alpha) = \big\{T_n \notin {\mathcal D}_\alpha\big\}$$
est asymptotiquement de niveau $\alpha$.
}
\end{remarque}
\begin{remarque}
\emph{
Pour construire le test $\varphi_n$ de la Proposition \ref{wald simple}, on a choisi la zone d'acceptation
$${\mathcal D}_\alpha = \big[-\Phi^{-1}(1-\alpha/2), \Phi^{-1}(1-\alpha/2)\big]$$
car elle est de longueur minimale parmi les zones ${\mathcal D}_\alpha$ satisfaisant \eqref{condition de charge} mais ce choix n'a pas d'importance si l'on n'étudie pas plus précisément la puissance du test. Si l'on se contente simplement de la consistance, il suffit d'imposer en plus que ${\mathcal D}_\alpha$ est borné. Dans ce cas, on a toujours $\varphi_n({\mathcal D}_\alpha) \stackrel{\PP_{\vartheta}}{\longrightarrow} 1$ pour tout point $\vartheta \neq \vartheta_0$ de l'alternative et $\varphi_n({\mathcal D}_\alpha)$ est consistant.
}
%Anderson ?????
\end{remarque}
\begin{remarque}
\emph{
Le test $\varphi_n$ basé sur la statistique $T_n$ dépend de $v(\vartheta)$. Intuitivement, il sera d'autant meilleur (d'autant plus puissant) que $v(\vartheta)$ sera petit.
Cela se voit immédiatement sur la décomposition \eqref{decomp alternative} : le terme de droite diverge \og d'autant mieux \fg{} que $v(\est)$ et donc asymptotiquement
$v(\vartheta)$ est petit, sans que cela affecte son erreur de première espèce.
\\
Si on est dans un modèle d'échantillonnage régulier, on aura donc intérêt à prendre l'estimateur de variance asymptotique minimale, c'est-à-dire l'estimateur du maximum de vraisemblance, qui fournit $v(\vartheta) = \IF(\vartheta)^{-1}$.
}
\end{remarque}
Dans la convergence \eqref{stat test wald simple}, on aurait pu, de manière équivalente, remplacer la statistique $T_n$ par son carré, et obtenir
$$T_n^2 = n\frac{(\est-\vartheta_0)^2}{v(\est)}\stackrel{d}{\longrightarrow} \chi^2(1)$$
en loi sous $\PP_\vartheta$, où $\chi^2(1)$ désigne la loi du $\chi^2$ à 1 degré de liberté. En construisant un test basé sur la statistique $T_n$ avec comme loi limite, on obtient la zone de rejet
$$\widetilde {\mathcal R}_{n,\alpha} = \Big\{T_n^2 \geq q_{1-\alpha,1}^{\chi^2}\Big\}$$
où $q_{1-\alpha,1}^{\chi^2}$ désigne le quantile d'ordre $1-\alpha$ de la loi du $\chi^2$ à 1 degré de liberté. Sans surprise,
$\widetilde {\mathcal R}_{n,\alpha} = {\mathcal R}_{n,\alpha}$ !
\subsection{Hypothèse nulle composite}
On se place dans le cadre général $\Theta \subset \R^d$, et on suppose que $\Theta_0$ peut s'écrire sous la forme
$$\Theta_0 = \big\{\vartheta \in \Theta,\;\;g(\vartheta) = 0\big\}$$
où l'application
$$g:\R^d \rightarrow \R^m$$
est régulière. Par exemple, l'hypothèse nulle simple $H_0:\vartheta = \vartheta_0$ pour un point $\vartheta_0 \in \Theta$ donné peut toujours se ramener à la condition $g(\vartheta) = 0$, avec $g(\vartheta) = \vartheta - \vartheta_0$.
%un exemple courant...
\begin{remarque}
\emph{
 En dimension $d=1$, l'hypothèse composite $H_0:\vartheta >\vartheta_0$ s'écrit bien sous la forme $g(\vartheta) = 0$ avec $g(\vartheta) = 1_{\{\vartheta \leq \vartheta_0\}}$, mais la fonction $\vartheta \leadsto g(\vartheta)$ n'est pas continue en $\vartheta_0$.
}
\end{remarque}
\subsubsection{Construction du test de Wald}
\index{Wald, test de}
%Plaçons nous en dimension $d=1$ pour simplifier et supposons que l'on dispose d'un estimateur $\est$ de $\vartheta$ asymptotiquement normal, c'est-à-dire vérifiant
%$$\sqrt{n} \big(\est-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,v(\vartheta)\big)$$
%lorsque $n \rightarrow \infty$, où $v(\vartheta) >0$. Alors, si $g$ est dérivable au point $\vartheta$ et si $g'(\vartheta)>0$ {\tt check}, on a aussi
%$$\sqrt{n} \big(g(\est)-g(\vartheta)\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,g'(\vartheta)^2v(\vartheta)\big)$$
%lorsque $n \rightarrow \infty$. Sous $H_0$, c'est-à-dire pour $\vartheta \in \Theta_0$, on a$g(\vartheta) = 0$ et donc
%$$\sqrt{n} \frac{g(\est)}{|g'(\vartheta)|\sqrt{v(\vartheta)}} \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,1\big)$$
%lorsque $n \rightarrow \infty$. Si de plus, les applications $\vartheta \leadsto g'(\vartheta)$ et $\vartheta \leadsto v(\vartheta)$ sont continues en tout point de $\Theta$, on a d'après la Proposition \ref{Slutsky}
%\begin{equation} \label{convergence stat de test}
%T_n = \sqrt{n} \frac{g(\est)}{|g'(\est)|\sqrt{v(\est)}} \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,1\big)
%\end{equation}
%lorsque $n \rightarrow \infty$, la convergence ayant lieu en loi sous $\PP_\vartheta$ pour tout $\vartheta \in \Theta_0$. La construction de $T_n$ fournit une statistique de test.
%\begin{proposition} Soit $\alpha \in [0,1]$. La suite de test $\varphi_n$ définis par la région critique
%$${\mathcal R}_\alpha = \big\{|T_n | \geq \Phi^{-1}(1-\alpha/2)\big\}$$
%où $\Phi$ désigne la fonction de répartition de la loi ${\mathcal N}(0,1)$ est asymptotiquement de niveau $\alpha$. De plus, la suite $\varphi_n$ est consistante :
%$$\forall \vartheta \in \Theta_1,\;\;\;\lim_{n \rightarrow} \PP_\vartheta\big[\varphi_n = 1\big]=1.$$
%\end{proposition}
%\begin{proof}
%La première partie de la proposition provient de la construction de $T_n$ et traduit la convergence \eqref{convergence stat de test}. Etudions la puissance asymptotique de $\varphi_n$. Pour tout point $\vartheta \in \Theta_1$, on a
%$$g(\est) \rightarrow g(\vartheta)\neq 0$$
%en probabilité sous $\PP_\vartheta$, lorsque $n \rightarrow \infty$, et $T_n$ s'écrit
%$$T_n = \sqrt{n} \frac{g(\est)}{|g'(\est)|\sqrt{v(\est)}} = T_{n,1}+T_{n,2},$$
%avec
%$$T_{n,1} = \sqrt{n}\frac{\big(g(\est)-g(\vartheta)\big)}{|g'(\est)|\sqrt{v(\est)}}+ \sqrt{n}\frac{g(\vartheta)}{|g'(\vartheta)|\sqrt{v(\est)}}.$$
%On a la convergence en loi sous $\PP_\vartheta$
%$$T_{n,1}\stackrel{d}{\longrightarrow}{\mathcal N}(0,1)$$
%(qui est vraie pour tout $\vartheta \in \Theta$, indépendamment du fait d'appartenir à $\Theta_0$ ou à $\Theta_1$). D'autre part
%$$T_{n,2} \longrightarrow \pm\infty$$
%en probabilité sous $\PP_\vartheta$ lorsque $n\rightarrow \infty$. En effet, le dénominateur converge en probabilité sous $\PP_\vartheta$ vers $|g'(\vartheta)|\sqrt{v(\vartheta)}>0$ et le numérateur est déterministe et diverge vers $\pm\infty$ en fonction du signe de $g(\vartheta)$.
%\end{proof}
%\subsection{Le test de Wald dans le cas général}
%On se place dans le cas général où $\Theta \subset \R^d$, avec $d \geq 1$ et  $g:\R^d \rightarrow \R^m$ est l'application qui définit l'hypothèse nulle
%$$H_0\;\;\;\vartheta \in \Theta_0 = \big\{\vartheta \in \Theta,\;\;g(\vartheta) = 0\}.$$
\begin{hypothese} \label{hyp wald} L'application $g:\R^d\rightarrow \R^m$ est continûment différentiable. De plus, sa différentielle, en tant qu'élément de ${\mathcal L}(\R^d,\R^m)$, est de rang maximal $m$ en tout point $\vartheta$ de (l'intérieur\footnote{En ne tenant pas compte de cette restriction quand $\Theta_0$ se réduit à un seul point.} de) $\Theta_0$.
\end{hypothese}
On notera $J_g(\vartheta)$ la matrice de la différentielle de $g$ au point $\vartheta$. On suppose qu'il existe un estimateur $\est$ de $\vartheta$ asymptotiquement normal, au sens suivant :
\begin{hypothese} \label{norm asympt multidim}
%\begin{equation} \label{conv stat test wald multidim}
$$
\sqrt{n}\big(\est-\vartheta\big)\stackrel{d}{\longrightarrow} \mathcal{N}\big(0,V(\vartheta)\big),
$$
en loi sous $\PP_\vartheta$, où $V(\vartheta)$ est définie positive, et $\vartheta
\leadsto V(\vartheta)$ est continue pour tout $\vartheta \in \Theta$.
\end{hypothese}
\begin{proposition} \label{conv preparatoire chi2}
Sous l'Hypothèse \ref{hyp wald}, en tout point $\vartheta \in \Theta_0$ de l'hypothèse, c'est-à-dire vérifiant
$g(\vartheta) = 0$, on a
$$\sqrt{n}g(\est)\stackrel{d}{\longrightarrow}\mathcal{N}\big(0, J_g(\vartheta)V(\vartheta)J_g(\vartheta)^T\big)$$
sous $\PP_\vartheta$ lorsque $n\rightarrow \infty$.
\end{proposition}
\begin{corollaire} \label{conv chi2}
Posons $\Sigma_g(\vartheta) = J_g(\vartheta)V(\vartheta)J_g(\vartheta)^T$ dans la proposition précédente. On a la convergence
\begin{equation} \label{def stat de test wald last}
T_n^2(g) = ng(\est)^T \Sigma_g(\est)^{-1}g(\est) \stackrel{d}{\longrightarrow} \chi^2(m)
\end{equation}
sous $\PP_\vartheta$, où $\chi^2(m)$ désigne la loi du $\chi^2$ à $m$ degrés de liberté. Pour tout $\alpha \in (0,1)$, le test défini par la région critique
\begin{equation} \label{def rejet wald}
{\mathcal R}_{n,\alpha} = \big\{T_n^2 \geq q_{1-\alpha, m}^{\chi^2}\big\},
\end{equation}
où $q_{1-\alpha, m}^{\chi^2}$ désigne le quantile d'ordre $1-\alpha$ de la loi du $\chi^2$ à $m$ degrés de liberté, est asymptotiquement de niveau $\alpha$ et consistant.
\end{corollaire}
\begin{definition}[Test de Wald] On appelle test de Wald de $H_0:g(\vartheta)=0$ contre $H_1:g(\vartheta)\neq 0$ associé à l'estimateur asymptotiquement normal $\est$ le test basé sur la statistique $T_n^2$ définie en \eqref{def stat de test wald last} de région critique ${\mathcal R}_{n,\alpha}$ défini en \eqref{def rejet wald}. La statistique $T_n^2$ s'appelle statistique de Wald (associée à l'estimateur $\est$).
\end{definition}
\begin{remarque}
\emph{
Le test de la Proposition \ref{stat test wald simple} est un test de Wald, dans la cas très particulier où $g(\vartheta) = \vartheta - \vartheta_0$ en dimension $1$. En particulier, $g'(\vartheta) = 1$ en tout point $\vartheta \in \Theta \subset \R$.
}
\end{remarque}
\begin{proof}[Démonstration de la Proposition \ref{conv preparatoire chi2} et de son Corollaire \ref{conv chi2}]
La proposition est simplement la version multidimensionnelle de la \og méthode delta \fg, (Proposition \ref{methode delta multidimensionnelle}) appliquée à $g(\est)$ d'après l'Hypothèse \ref{norm asympt multidim}, en utilisant le fait que sous l'hypothèse nulle, $g(\vartheta)=0$. Pour son corollaire, on en déduit d'abord la convergence
$$\sqrt{n} \Sigma_g(\vartheta)^{-1}g(\est) \stackrel{d}{\longrightarrow} \mathcal{N}(0,\text{Id}_m),$$
en loi sous $\PP_\vartheta$, puis, par la Proposition \ref{slutsky} (Slutsky), par continuité de $\vartheta \leadsto \Sigma_g(\vartheta)$
$$\sqrt{n} \Sigma_g(\est)^{-1}g(\est) \stackrel{d}{\longrightarrow} \mathcal{N}(0,\text{Id}_m).$$
En passant à la norme au carré
$$\|\sqrt{n} \Sigma_g(\est)^{-1}g(\est)\|^2 = ng(\est)^T\Sigma_g(\est)^{-1}g(\est) \stackrel{d}{\longrightarrow} \|\mathcal{N}(0,\text{Id}_m)\|^2 \sim \chi^2(m).$$
On en déduit que le test donné par la région de rejet ${\mathcal R}_{n,\alpha}$ est asymptotiquement de niveau $\alpha$.

Montrons qu'il est consistant. On raisonne comme en dimension 1 : si $\vartheta \in \Theta_1$ est un point de l'alternative, on a $g(\vartheta)\neq 0$, on force le terme $g(\vartheta)$ dans $T_n$ et on écrit
$$T_n^2 = T_{n,1}^2+T_{n,2}^2,$$
avec
 $$T_{n,1}^2 = n\big(g(\est)-g(\vartheta)\big)^T\Sigma_g(\est)^{-1}\big(g(\est)-g(\vartheta)\big),$$
 et un terme additionnel
 $$
 T_{n,2}^2  = U_n+V_n,$$
 qui se redécompose en
 $$U_n =  ng(\vartheta)^T\Sigma_g(\est)^{-1}g(\vartheta)$$
 et
 $$
 V_n =  n\big(g(\est)-g(\vartheta)\big)^T\Sigma_g(\est)^{-1}g(\vartheta)
 +ng(\vartheta)^T\Sigma_g(\est)^{-1}\big(g(\est)-g(\vartheta)\big).
 $$
Pour tout $\vartheta$, le terme $T_{n,1}$ converge en loi sous $\PP_\vartheta$ vers la loi du $\chi^2$ à $m$ degrés de liberté : c'est la \og méthode delta \fg{} appliquée à $g(\est)$ lorsque $g(\vartheta) \neq 0$. Il reste à démontrer que $T_{n,2}$ diverge. Par continuité, $V_g(\est)\stackrel{\PP_{\vartheta}}{\rightarrow}V_g(\vartheta)$, donc $U_n\stackrel{\PP_\vartheta}{\rightarrow}+\infty$. Le terme $V_n$ diverge de même, mais on ne peut pas contrôler son signe. Il reste à vérifier que $V_n$ est petit devant $U_n$. Pour cela, on écrit
$V_n  = \sqrt{n} \tilde V_n,$
avec
$$\tilde V_n = \sqrt{n}\big(g(\est)-g(\vartheta)\big)^T\Sigma_g(\est)^{-1}g(\vartheta)
 +\sqrt{n}g(\vartheta)^T\Sigma_g(\est)^{-1}\big(g(\est)-g(\vartheta)\big)$$
 et chacun des termes converge séparement en loi sous $\PP_\vartheta$ via la Proposition \ref{conv preparatoire chi2}. Donc
 $V_n/U_n\stackrel{\PP_{\vartheta}}{\rightarrow} 0$ et le corollaire est démontré.
\end{proof}
%\begin{exemple}
%\begin{center}
%{\tt INSERT HERE SUPPL. 56}
%\end{center}
%\end{exemple}
\section{Test \og sup sur sup\fg{}$^\star$} \label{test sup sur sup}
\subsubsection{Situation et notations}
On suppose pour simplifier que ${\mathcal E}^n$ est engendrée par un $n$-échantillon
$$X_1,\ldots, X_n$$
de variables aléatoires réelles, dont la loi appartient à la famille $\big\{\PP_\vartheta,\, \vartheta \in \Theta\big\}$, avec $\Theta \subset \R^d$, $d\geq 1$, dominée par une mesure $\sigma$-finie $\mu$ sur $\R$. On note
$\{f(\vartheta, \cdot),\,\vartheta \in \Theta\}$ la famille de densités associées. On teste $H_0:\vartheta \in \Theta_0$ contre $H_1:\vartheta \in \Theta_1$, avec $\Theta_0 \cap \Theta_1 = \emptyset$.
\subsubsection{La statistique \og sup sur sup \fg{}}
Si les deux hypothèses sont simples, c'est-à-dire  $\Theta_0 = \{\vartheta_0\}$ et $\Theta_1 =\{\vartheta_1\}$, avec $\vartheta_0 \neq \vartheta_1$, alors l'approche de Neyman-Pearson de la Section \ref{test de neyman pearson} du chapitre précédent suggère de considérer le rapport des vraisemblances
$$\frac{{\mathcal L}_n(\vartheta_1,X_1,\ldots, X_n)}{{\mathcal L}_n(\vartheta_0, X_1,\ldots, X_n)} = \frac{\prod_{i =1}^nf(\vartheta_1, X_i)}{\prod_{i = 1}^nf(\vartheta_0,X_i)},$$
ou son logarithme
$$\sum_{i = 1}^n \log f(\vartheta_1,X_i)-\sum_{i = 1}^n \log f(\vartheta_0, X_i),$$
et, suivant la règle de la construction du test du rapport de vraisemblance, on rejette l'hypothèse nulle $\vartheta = \vartheta_0$ si $\Lambda_n$ dépasse un seuil, calibré pour contrôler l'erreur de première espèce.

Lorsque $\Theta_0$ et $\Theta_1$ ne sont pas réduits à un point, une règle conservative consiste à remplacer la quantité ci-dessus par
$$\widetilde\Lambda_n(X_1,\ldots,X_n) = \sup_{\vartheta \in \Theta_1}\sum_{i = 1}^n \log f(\vartheta,X_i)-\sup_{\vartheta \in \Theta_0}\sum_{i = 1}^n \log f(\vartheta, X_i)$$
et donc de comparer la vraisemblance de \og la valeur la plus vraisemblable \fg{} sur $\Theta_0$  à \og la valeur la plus vraisemblable \fg{} sur $\Theta_1$.
%On peut réécrire
%$$\widetilde \Lambda_n = \log \frac{\sup_{\vartheta \in \Theta_1}{\mathcal L}(\vartheta_1,X_1,\ldots, X_n)}{\sup_{\vartheta \in \Theta_0}{\mathcal L}(\vartheta, X_1,\ldots, X_n)}.$$
Malheureusement, le calcul de la loi de cette quantité est difficile, même asymptotiquement. On remplace alors $\widetilde \Lambda_n$ par
\begin{align*}
\Lambda_n &=   \sup_{\vartheta \in \Theta}\sum_{i = 1}^n \log f(\vartheta,X_i)-\sup_{\vartheta \in \Theta_0}\sum_{i = 1}^n \log f(\vartheta_0, X_i) \\
&= \log \frac{\sup_{\vartheta \in \Theta}{\mathcal L}(\vartheta,X_1,\ldots, X_n)}{\sup_{\vartheta \in \Theta_0}{\mathcal L}(\vartheta, X_1,\ldots, X_n)},
\end{align*}
où le supremum au numérateur est évalué sur tout l'espace des paramètres. On peut se convaincre -- au moins heuristiquement -- que cette approche est raisonnable si le modèle est suffisamment régulier. Dans ce cas, si $\vartheta \in \Theta_1$, sous $\PP_\vartheta$, la quantité qui atteint le maximum pour le numérateur est l'estimateur du maximum de vraisemblance $\estMV$ qui converge vers $\vartheta \in \Theta_1$.
\begin{definition} \label{def stat rapport vrais max}
On appelle $\Lambda_n$ la \og statistique du rapport de vraisemblance maximal \fg{}.
\end{definition}
Un résultat remarquable est que sous l'hypothèse nulle, la loi de la statistique du rapport de vraisemblance maximal est asymptotiquement la loi du $\chi^2$ (à une constante multiplicative près) pour un nombre de degrés de liberté dépendant de la dimension de $\Theta_0$, et ceci conduit à une méthode systématique de construction de tests.
\subsection{Rapport de vraisemblance maximal asymptotique}
\index{rapport de vraisemblance maximal, test}
\index{ \og sup sur sup\fg, test}
On suppose le modèle régulier au sens du Chapitre \ref{theorie asymptotique}.
%, c'est-à-dire sous les Hypothèses \ref{} \ref{} et \ref{}
%pb de dimension
Notons $\estMV$ l'estimateur du maximum de vraisemblance du $\Theta$ et $\estMVc$ l'estimateur du maximum de vraisemblance restreint à $\Theta_0$ (c'est-à-dire obtenu lorsque l'on maximise la vraisemblance sur $\Theta_0$).

En appliquant la formule de Taylor à l'ordre 2 à $\vartheta \leadsto \ell(\vartheta, x) = \log f(\vartheta,\cdot)$, on réécrit $\Lambda_n$ comme
\begin{align*}
 &- \sum_{i = 1}^n \big(\ell(\estMVc, X_i) - \ell(\estMV, X_i)\big) \\
=\,&   -\Big(\sum_{i = 1}^n \nabla \ell(\estMV, X_i)\Big)^T(\estMVc-\estMV)-\tfrac{1}{2}(\estMV-\estMVc)^T\Big(\sum_{i = 1}^nH_{\ell(\cdot,X_i)}[\widetilde \vartheta_n]\Big)(\estMV-\estMVc) \\
=\,& -\tfrac{1}{2}(\estMV-\estMVc)^T\Big(\sum_{i = 1}^nH_{\ell(\cdot,X_i)}[\widetilde \vartheta_n]\Big)(\estMV-\estMVc),
\end{align*}
où $\widetilde \vartheta_n$ est un point entre $\estMVc$ et $\estMV$ et $H_{\ell(\cdot,X_i)}[\vartheta]$ désigne la matrice hessienne de la fonction $\vartheta \leadsto \ell(\vartheta, X_i)$ au point $\vartheta$. Le terme d'ordre 1 disparaît par définition du maximum de vraisemblance (dès que $\estMV \in \Theta$).
Sous les hypothèses de régularité sur le modèle $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$,
%MORE HERE ???????????? \ref{},
si $\vartheta \in \Theta_0$, on a les convergences
\begin{equation} \label{borne proba 1}
\sqrt{n}\big(\estMVc-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,\IF^{-1}(\vartheta)\big)\;\;\text{en loi sous}\;\;\PP_\vartheta,\;\vartheta \in \Theta_0,
\end{equation}
où $\IF^{-1}(\vartheta)$ désigne l'inverse de la matrice d'information de Fisher du modèle $\big\{\PP_\vartheta,\,\vartheta \in \Theta\big\}$, et on a toujours
\begin{equation} \label{borne proba 2}
\sqrt{n}\big(\estMV-\vartheta\big) \stackrel{d}{\longrightarrow} {\mathcal N}\big(0,\IF^{-1}(\vartheta)\big) \;\;\text{en loi sous}\;\;\PP_\vartheta.
\end{equation}
Donc la suite de vecteurs $\sqrt{n}(\estMV-\estMVc)$ est bornée en probabilité sous $\PP_\vartheta, \vartheta \in \Theta_0$. Par ailleurs, on a toujours la convergence
\begin{equation} \label{loi grands nombres approx}
-\frac{1}{n}\sum_{i = 1}^nH_{\ell(\cdot,X_i)}[\vartheta] \stackrel{\PP_\vartheta}{\longrightarrow} \IF(\vartheta),\;\;\vartheta \in \Theta_0
\end{equation}
(composante par composante) par la loi des grands nombres.
On en déduit le résultat suivant :
\begin{proposition} \label{equivalence sup sur sup}
Si l'expérience statistique est régulière au sens du Chapitre \ref{theorie asymptotique}, pour tout $\vartheta \in \Theta_0$ (c'est-à-dire en se plaçant sous l'hypothèse $H_0$), on a les approximations suivantes
$$\Lambda_n  = \tfrac{1}{2}\sqrt{n}\big(\estMVc-\vartheta\big)^T\IF(\vartheta)\sqrt{n}\big(\estMVc-\vartheta\big)^T+\varepsilon_n$$
et aussi
$$\Lambda_n  = \tfrac{1}{2}\sqrt{n}\big(\estMVc-\vartheta\big)^T\IF(\estMV)\sqrt{n}\big(\estMVc-\vartheta\big)^T+\varepsilon'_n$$
où $\varepsilon_n$ et $\varepsilon'_n$ sont deux suites qui tendent vers $0$ en probabilité sous $\PP_\vartheta$ pour tout $\vartheta \in \Theta_0$.
\end{proposition}
\begin{proof}
La première approximation est simplement une combinaison des estimations précédentes : on écrit
\begin{align*}
&-(\estMV-\estMVc)^T\Big(\sum_{i = 1}^nH_{\ell(\cdot,X_i)}[\widetilde \vartheta_n]\Big)(\estMV-\estMVc)\\
=&-\sqrt{n}(\estMV-\estMVc)^T\Big(\frac{1}{n}\sum_{i = 1}^nH_{\ell(\cdot,X_i)}[\widetilde \vartheta_n]\Big)\sqrt{n}(\estMV-\estMVc),
\end{align*}
et on utilise d'une part le fait que le terme du milieu converge en probabilité vers $\IF^{-1}(\vartheta)$ via \eqref{loi grands nombres approx} en utilisant le fait que $\widetilde \vartheta_n$ est proche de $\vartheta$ (nous omettons les détails), et d'autre part que la suite $\sqrt{n}(\estMV-\estMVc)$ est bornée en $\PP_\vartheta$ probabilité pour $\vartheta \in \Theta_0$ par \eqref{borne proba 1} et \eqref{borne proba 2}.

La seconde approximation est simplement une conséquence de la Proposition \ref{slutsky} (Slutsky).
\end{proof}
\begin{remarque}
\emph{Les estimateurs $\estMV$ et $\estMVc$ ne sont pas les mêmes en général. Un exemple classique -- rencontré aussi en régression -- est celui de l'expérience statistique engendrée par un $n$-échantilllon de loi ${\mathcal N}(\mu, \sigma^2)$, avec $\vartheta = (\mu,\sigma^2) \in \Theta = \R \times \R_+\setminus \{0\}$. Alors, si
$\Theta_0 = \{\vartheta \in \Theta,\;\mu=0\}$, on a
$$\estMVc = \big(0,\tfrac{1}{n}\sum_{i = 1}^n X_i^2\big),\;\;\;\text{alors que}\;\;\;\estMV = \big(\Xbar, \tfrac{1}{n}\sum_{i = 1}^nX_i^2-\overline{X}_n^2\big).$$
}
\end{remarque}
\subsection{Lien avec la statistique de Wald}
Plaçons-nous dans le cas d'une hypothèse nulle simple $\Theta_0 = \{\vartheta_0\}$ pour simplifier. La statistique $T_n^2$ du test de Wald définie dans le Corollaire \ref{conv chi2} par \eqref{def stat de test wald last} s'écrit à l'aide de la fonction $g(\vartheta) = \vartheta - \vartheta_0$, et $J_g = \mathrm{Id}_d$.

Si l'expérience sous-jacente est régulière, le choix de l'estimateur $\est = \estMV$ conduit à $V(\vartheta) = \IF(\vartheta)$, où $\IF(\vartheta)$ est l'information de Fisher du modèle. On a donc dans ce cas $\Sigma_g(\vartheta) = J_g(\vartheta)V(\vartheta)J_g(\vartheta)^T = \IF(\vartheta)$ et finalement,
$$T_n^2 =  \sqrt{n}\big(\estMV-\vartheta_0\big)^T\IF(\estMV)\sqrt{n}\big(\estMVc-\vartheta\big)^T.$$
Par ailleurs, puisque l'hypothèse nulle $H_0$ est simple, on a $\estMVc = \vartheta_0$. D'après la Proposition \ref{equivalence sup sur sup}, on déduit
\begin{equation} \label{equivalence pour wald}
T_n^2 = 2\Lambda_n+\varepsilon_n,
\end{equation}
où $\varepsilon_n$ tend vers $0$ en probabilité sous $\PP_{\vartheta_0}$.

En conclusion, dans le cas d'une hypothèse nulle simple, la statistique de Wald associée à l'estimateur du maximum de vraisemblance et la statistique du rapport de vraisemblance maximal sont asymptotiquement équivalentes.  On en déduit immédiate\-ment que -- pour une hypothèse nulle simple -- la statistique du rapport de vraisemblance maximale converge en loi vers la loi du $\chi^2$ à $d$ degrés de liberté.

\begin{remarque}
\emph{
Le lien que nous venons de montrer est très particulier. L'équivalence \eqref{equivalence pour wald} s'étend au-delà d'une hypothèse simple. Nous nous contenterons de ce résultat particulier dans ce cours.
}
\end{remarque}
\begin{remarque}
\emph{
Une autre statistique remarquable, la statistique du score (voir par exemple Wasserman, \cite{W}), se déduit de ces approximations.
%C'est le sujet de l'Exercice \ref{statistique du score}.
}
\end{remarque}

\subsection{Résultat général pour le rapport de vraisemblance maximal$^\star$}
Dans le cas d'une hypothèse nulle simple $\Theta_0 = \{\vartheta_0\}$, nous venons de voir -- par l'équivalence asymptotique avec la statistique de Wald associée à l'estimateur du maximum de vraisemblance -- que la statistique $2\Lambda_n$ suit asymptotiquement la loi du $\chi^2$ à $d$ degrés de liberté.
Ici, grâce à la Propostion \ref{conv chi2}, le degré $d$ doit être compris comme le rang de la dif\-féren\-tielle de $J_g(\vartheta)$, qui dans le cas trivial $g(\vartheta) = \vartheta - \vartheta_0$ est maximal.

Ce résultat se généralise.  On suppose que $\Theta_0$ peut s'écrire sous la forme
$$\Theta_0 = \big\{\vartheta \in \Theta,\;\;g(\vartheta) = 0\big\}$$
où l'application
$$g:\R^d \rightarrow \R^m$$ est régulière au sens de l'Hypothèse \ref{hyp wald}, c'est-à-dire continûment différentiable, sa dif\-férentiel\-le étant de rang maximal $m$ en tout point de (l'intérieur de) $\Theta_0$.
\begin{proposition}
Si l'expérience statistique est régulière au sens du Chapitre \ref{theorie asymptotique}, sous l'Hypothèse \ref{hyp wald}, pour tout point $\vartheta$  (dans l'intérieur) de $\Theta_0$ (ou si $\Theta_0$ est réduit à un point), c'est-à-dire tel que $g(\vartheta) = 0$, on a
$$2\Lambda_n \stackrel{d}{\longrightarrow} \chi^2(m).$$
\end{proposition}
Nous admettons ce résultat. On en déduit un test asymptotiquement de niveau $\alpha$ défini par la région critique
$${\mathcal R}_{n,\alpha} = \big\{2\Lambda_n \geq q_{1-\alpha,m}^{\chi^2}\big\},$$
où $q_{1-\alpha,m}^{\chi^2}$ est le quantile d'ordre $1-\alpha$ de la loi du $\chi^2$ à $m$ degrés de liberté.

\section{Tests du $\chi^2$}
\index{$\chi^2$, test du}
\index{adéquation, test du $\chi^2$ d'}
\subsubsection{Notation et préliminaire}
Si $X$ une variable qualitative pouvant prendre $d$ valeurs distinctes, on note $\{1,\ldots, d\}$ l'ensemble de ses valeurs pour simplifier.
En toute généralité, la loi de $X$ s'écrit
$$\PP\big[X = \ell\,\big] = p_\ell,\;\;\;\ell = 1,\ldots, d$$
avec $0 \leq p_\ell \leq 1$ et $\sum_{\ell=1}^d p_\ell=1$,
et le vecteur $\boldsymbol{p} = (p_1,\ldots, p_d)^T$ caractérise la loi de $X$. Désormais, nous identifions les lois de probabilités prenant $d$ valeurs avec les vecteurs $\boldsymbol{p}$ de l'ensemble
$${\mathcal M}_d = \Big\{\vp = (p_1,\ldots, p_d)^T,\;\;\;0\leq p_\ell \leq 1,\;\;\;\sum_{\ell = 1}^dp_\ell=1\Big\}.$$
\subsection{Test d'adéquation du $\chi^2$} \label{test chi2 simple}
On observe un $n$-échantillon
$$X_1,\ldots, X_n$$
de loi $\vp \in {\mathcal M}_d$ inconnue et on teste l'hypothèse
$$H_0:\vp = \vq,\;\;\;\text{contre}\;\;\;H_1:\vp \neq \vq$$
où $\vq \in {\mathcal M}_d$ est une loi donnée. L'expérience statistique associée à l'observation s'écrit
$${\mathcal E}^n = \Big(\{1,\ldots, d\}^n, {\mathcal P}(\{1,\ldots, d\}^n),\;\big\{\PP_{\vp}^n,\;\vp \in {\mathcal M}_d\big\}\Big),$$
où $\PP_{\vp}^n$ est la loi\footnote{Dans cette section, $\vp \in {\mathcal M}_d$ remplacera l'écriture habituelle $\vartheta \in \Theta$.
} d'un $n$-échantillon de loi $\vp$.

Pour construire un test, une idée immédiate est de comparer les fréquences empiriques
\begin{equation} \label{est freq empirique}
\widehat p_{n,\ell}=\frac{1}{n}\sum_{i = 1}^n 1_{X_i = \ell},\;\;\ell=1,\ldots, d
\end{equation}
avec $q_\ell$, $\ell = 1,\ldots, d$. En effet, la loi des grands nombres garantit la convergence
\begin{equation} \label{convergence chi2}
(\widehat p_{n,1},\ldots, \widehat p_{n,d}\big) \stackrel{\PP_{\vp}}{\longrightarrow} (p_1,\ldots, p_d) = \vp
\end{equation}
en probabilité sous $\PP_{\vp}$. L'étape suivante consiste à établir une vitesse de convergence dans \eqref{convergence chi2}.
En anticipant sur le théorème central-limite, on considère le vecteur
$$\boldsymbol{U}_n(\vp) = \sqrt{n}\left(\frac{\widehat p_{n,1}-p_{1}}{\sqrt{p_{1}}},\ldots, \frac{\widehat p_{n,d}-p_{d}}{\sqrt{p_{d}}}\right)^T$$
qui est bien défini si toutes les composantes de $\vp$ sont non nulles, ainsi que sa norme au carré
$$\|\boldsymbol{U}_n(\vp)\|^2 = n\sum_{\ell= 1}^d \frac{\big(\widehat p_{n,\ell}-p_{\ell}\big)^2}{p_{\ell}}.$$

Par le théorème central limite, chaque composante de $\boldsymbol{U}_n$ converge en loi vers une gaussienne centrée réduite, mais ceci ne permet pas d'en déduire la convergence en loi vectorielle (et donc pas non plus celle de $\|\boldsymbol{U}_n\|^2$, utile pour construire un test), puisque les variables aléatoires $\widehat p_{\ell,n}$ ne sont pas indépendantes. Le résultat suivant précise la convergence
\begin{proposition} \label{conv loi vecteur chi2}
Si les composantes de $\vp$ sont toutes non nulles, alors
\begin{equation} \label{premiere conv loi}
\boldsymbol{U}_n(\vp)\stackrel{d}{\rightarrow}{\mathcal N}\big(0,V(\vp)\big),
\end{equation}
où
% la matrice $d\times d$ de variance-covariance est donnée par
$V(\vp) = \mathrm{Id}_d-\sqrt{\vp}(\sqrt{\vp})^T,$
et $\sqrt{\vp} = (\sqrt{p_1},\ldots, \sqrt{p_d})^T$. De plus
\begin{equation} \label{seconde conv loi}
\|\boldsymbol{U}_n(\vp)\|^2 \stackrel{d}{\rightarrow} \chi^2(d-1),
\end{equation}
où $\chi^2(d-1)$ désigne la loi du $\chi^2$ à $d-1$ degrés de liberté.
\end{proposition}
\begin{proof}
Pour $i=1,\ldots, n$ et $1\leq \ell \leq d$, posons
$$Y_{\ell}^{i} = \frac{1}{\sqrt{p_\ell}}(1_{\{X_i=\ell\}} - p_\ell).$$
La suite de vecteurs $\boldsymbol{Y}_i = (Y_{1}^{i},\ldots, Y_{d}^{i})$ est indépendante et de même loi, car chaque terme $\bY_i$ ne fait intervenir que la variable $X_i$ et les $X_i$ sont indépendantes et de même loi. Notons que
$$\boldsymbol{U}_n(\vp) = \frac{1}{\sqrt{n}}\sum_{i = 1}^n \bY_i.$$
De plus,
$$\E\big[Y^i_\ell\big] = 0,\;\;\E\big[(Y_\ell^i)^2\big] = p_\ell^{-1}(p_\ell - 2p_\ell^2+p_\ell^2) = 1-p_\ell,$$
et pour $\ell \neq \ell'$,
$$\E\big[Y_\ell^iY_{\ell'}^i\big] = (p_\ell p_{\ell'})^{-1/2}(0 - 2p_\ell p_{\ell'}+p_\ell p_{\ell'}) = -(p_\ell p_{\ell'})^{1/2}.$$
On applique alors le théorème central limite vectoriel \ref{TCL vectoriel} du Chapitre \ref{chapitre 1}. On obtient la convergence \eqref{premiere conv loi}.

Pour la convergence \eqref{seconde conv loi}, par continuité du carré de la norme, on a
$$\|\boldsymbol{U}_n(\vp)\|^2 \stackrel{d}{\longrightarrow} \big\|\,{\mathcal N}\big(0, V(\vp)\big)\big\|^2 \;\sim\; \chi^2\Big(\mathrm{Rang}\big(V(\vp)\big)\Big),$$
la dernière égalité en loi étant une application de la Proposition \ref{cochran} (Cochran). En effet, la matrice $V(\vp) = \mathrm{Id}_d-\sqrt{\vp}\sqrt{\vp}$ est la matrice de la projection orthogonale sur l'orthogonal de l'espace vectoriel de dimension 1 engendré par le vecteur $\sqrt{\vp}$. On vérifie aussi que l'on a bien $\mathrm{Rang}\big(V(\vp)\big) = d-1$, d'où le résultat.
\end{proof}

\begin{definition}[distance du $\chi^2$] \label{Distance chi2}
Si $\vp, \vq \in {\mathcal M}_d$ et les coefficients $\vq$ sont tous non nuls, on appelle distance du $\chi^2$ entre les lois $\vp$ et $\vq$ la quantité
$$\chi^2(\vp,\vq) = \sum_{\ell=1}^d \frac{(p_\ell-q_\ell)^2}{q_\ell}.$$
\end{definition}

Notons $\widehat \vp_n = (\widehat p_{n,1},\ldots, \widehat p_{n,d})^T$. La Définition \ref{Distance chi2} est motivée par l'identité
$$\|\boldsymbol{U}_n(\vp)\|^2 = n \chi^2\big(\widehat \vp_n,\vp\big).$$
\begin{remarque}
\emph{
Le terme \og distance \fg{} est manifestement impropre, puisque qu'en général on  a $\chi^2(\vp,\vq) \neq \chi^2(\vq, \vp)$. Toutefois, on a la propriété essentielle
$$\chi^2(\vp,\vq) = 0 \Longleftrightarrow \vp = \vq.$$
}
\end{remarque}
Avec ces notations et la Proposition \ref{conv loi vecteur chi2}, on en déduit le test suivant, appelé test d'adéquation du $\chi^2$.
\begin{proposition} Soit $\vq \in {\mathcal M}_d$ une loi donnée dont les coefficients sont tous non nuls.

Pour tout $\alpha \in (0,1)$,
%a suite de tests de $H_0:\vp = \vq$ contre $H_1:\vp \neq \vq$
le test défini par la zone de rejet
$${\mathcal R}_{n,\alpha} = \Big\{n\chi^2\big(\widehat \vp_n,\vq\big) \geq q_{1-\alpha, d-1}^{\chi^2}\Big\},$$
où $q_{1-\alpha, d-1}^{\chi^2}$ est le quantile de la loi du $\chi^2$ à $d-1$ degrés de liberté, est asymptotiquement de niveau $\alpha$ et consistant.
\end{proposition}
\begin{proof}
La première partie de la Proposition découle de la Proposition \ref{conv loi vecteur chi2} : on a $\vp = \vq$ sous l'hypothèse, donc
\begin{align*}
\PP_{\vp}\big[(X_1,\ldots, X_n) \in {\mathcal R}_{n,\alpha}\big] = &  \PP_{\vq}\big[n\chi^2\big(\widehat \vp_n,\vq\big) \geq q_{1-\alpha, d-1}^{\chi^2}\big] \\
= & \PP_{\vq}\big[\|\boldsymbol{U}_n(\vq)\|^2 \geq q_{1-\alpha, d-1}^{\chi^2}\big] \\
 \rightarrow &\, \alpha.
\end{align*}
Pour montrer la consistance, plaçons-nous sous l'alternative $H_1$. Alors on a $\vp \neq \vq$ et $\chi^2(\vp, \vq) \neq 0$. On a aussi la convergence en probabilité sous $\PP_{\vp}$
$$\chi^2\big(\widehat \vp_n,\vq\big) \stackrel{\PP_{\vp}}{\longrightarrow} \chi^2(\vp, \vq) \neq 0.$$
Donc $n \chi^2\big(\widehat \vp_n, \vq\big)$ diverge vers $+\infty$ en probabilité sous $\PP_{\vp}$. La consistance de la suite de tests en découle (par exemple par convergence dominée).
\end{proof}
\begin{exemple}[Mendel]
\emph{Dans la célèbre expérience de Mendel à l'origine de la génétique, le croisement de pois donne lieu à quatre phénotypes identifiés (combinant couleur et forme). Selon la théorie de l'hérédité de Mendel, les phénotypes de type $I$, $II$, $III$ et $IV$ sont distribués selon une loi multinomiale (voir Section \ref{familles parametrees}, Chapitre \ref{estimation densite}) de paramètre
$${\boldsymbol q} = \Big(\frac{9}{16}, \frac{3}{16}, \frac{3}{16}, \frac{1}{16}\Big).$$
Mendel rapporte les résultats suivants : pour $n=556$ observations, la répartition observée entre les phénotypes de type $I$, $II$, $III$ et $IV$ est
$(315, 101, 108, 32)$. On teste $H_0: {\boldsymbol p} = {\boldsymbol q} $ contre $H_1: {\boldsymbol p} \neq {\boldsymbol q}$, où ${\boldsymbol p} \in {\mathcal M}_4$ qui est l'ensemble des lois dont les coefficients sont tous non-nuls. On a ici
\begin{align*}
n\chi^2\big(\widehat \vp_n,\vq\big) & = 556\Big(\frac{(\tfrac{315}{556}- \tfrac{9}{16})^2}{\tfrac{9}{16}}+\frac{(\tfrac{101}{556}- \tfrac{3}{16})^2}{\tfrac{3}{16}}+\frac{(\tfrac{108}{556}- \tfrac{3}{16})^2}{\tfrac{3}{16}}+\frac{(\tfrac{32}{556}- \tfrac{1}{16})^2}{\tfrac{1}{16}}\Big) \\
& = 0,47.
\end{align*}
Pour le niveau $\alpha = 5\%$, la valeur critique de rejet du test est $q_{1-\alpha,3}^{\chi^2} = 0,7815$ et puisque $0,47 < 0,7815$, on accepte $H_0$. On peut aussi calculer la $p$-valeur du test\footnote{Il s'agit alors ici d'une notion de $p$-valeur asymptotique, voir Section \ref{p valeur} du Chapitre \ref{tests}.}. Dans un cadre asymptotique, si $Z \sim \chi^2(3)$ est distribuée selon la loi du $\chi^2$ avec $3$ degrés de liberté, on a donc (voir Proposition \ref{proprietes p valeur})
$$p-\text{valeur} = \PP_{{\boldsymbol q}}\big[Z > 0,47\big] = 0,93,$$
ce qui ne nous incite pas à rejeter\footnote{Attention, rappelons que la signification de $0,93$ nous conduit à ne pas rejeter $H_0$, mais cela peut être aussi bien dû au fait que $H_0$ est vrai ou bien que la puissance du test est faible.}  $H_0$.
}
\end{exemple}
%\begin{center}
%{\tt INSERT HERE SUPPL. 57}
%\end{center}
%\end{exemple}

%\begin{exemple}
%\begin{center}
%{\tt INSERT HERE SUPPL. 58}
%\end{center}
%%garçons-filles
%\end{exemple}
\subsection{Test du $\chi^2$ d'indépendance$^\star$}
\index{indépendance, test du $\chi^2$ d'}
\subsubsection{Test du $\chi^2$ avec paramètres estimés}
\index{paramètres estimés, test du $\chi^2$}
On observe un $n$-échantillon
$$X_1,\ldots, X_n$$
de loi $\vp \in {\mathcal M}_d$ inconnue et on teste l'hypothèse nulle composite
$$H_0:\vp \in ({\mathcal M}_d)_0\;\;\;\text{contre}\;\;\;H_1:\vp \in {\mathcal M}_d \setminus ({\mathcal M}_d)_0,$$
où $({\mathcal M}_d)_0 \subset {\mathcal M}_d$. On suppose que $({\mathcal M}_d)_0$ se représente sous la forme
$$({\mathcal M}_d)_0 = \big\{\vp = \vp(\gamma),\;\;\gamma \in \Gamma\big\},$$
où $\Gamma \subset \R^d$ est un sous-ensemble régulier de $\R^d$ de dimension $m<d-1$ (une variété affine ou différentiable de dimension $k$).
La famille $\{\vp,\, \vp \in {\mathcal M}_d\}$ est régulière au sens du Chapitre \ref{theorie asymptotique}  et il en va de même pour
la famille $\{\vp,\, \vp \in ({\mathcal M}_d)_0 \}$ dès que $\gamma \leadsto \vp(\gamma)$  est suffisamment régulière (voir Exercice \ref{regularite}). Sans être plus précis pour le moment, cela signifie que les estimateurs du maximum de vraisemblance pour la famille $\{\vp,\, \vp \in {\mathcal M}_d\}$ et pour la famille restreinte $\{\vp,\,\vp \in ({\mathcal M}_d)_0\}$ sont bien définis et asymptotiquement normaux. On peut donc utiliser le test basé sur la statistique du rapport de vraisemblance maximal $\Lambda_n$ de la Section \ref{test sup sur sup}.

Nous avons d'abord besoin du résultat auxiliaire suivant :
\begin{lemme} \label{emv freq emp}
On a les estimateurs du maximum de vraisemblance suivants : pour la famille\footnote{Restreinte aux $\vp$ dont toutes les composantes sont non nulles.} $\{\vp, \vp \in {\mathcal M}_d\}$:
\begin{equation} \label{est mv freq empirique}
\widehat \vp_n^{\,\tt mv} = \big(\widehat p_{n,1},\ldots, \widehat p_{n,p}\big)^T
\end{equation}
où le vecteur $\big(\widehat p_{n,1},\ldots, \widehat p_{n,p}\big)^T$ est le vecteur des fréquences empiriques défini par \ref{est freq empirique} dans la Section \ref{test chi2 simple}, et pour la famille restreinte $\{\vp, \vp \in ({\mathcal M}_d)_0\}$:
$$\vp(\widehat \gamma^{\,{\tt mv}}_n) = \mathrm{arg} \max_{\gamma \in \Gamma}\sum_{\ell=1}^d n \widehat p_{n,\ell} \log p_\ell(\gamma).$$
\end{lemme}
\begin{proof}
Montrons d'abord \eqref{est mv freq empirique}. La loi de l'observation $X_1,\ldots, X_n$ est dominée par la mesure de comptage sur $\{1,\ldots d\}^n$. On a donc
$$\mathcal{L}_n({\vp},X_1,\ldots,X_n) = \prod_{i = 1}^n p_{X_i},\;\;\;\vp = (p_1,\ldots, p_d)^T,$$
mais cette formule n'est pas très exploitable. En notant $N_\ell = \sum_{i = 1}^n 1_{\{X_i = \ell\}}$, on a une correspondance univoque entre $(X_1,\ldots, X_n)$ (à une permutation près) et $(N_1,\ldots, N_d)$ puisque les $X_i$ ne prennent qu'un nombre fini de valeurs. Ceci permet de réécrire la loi du vecteur $(X_1,\ldots, X_n)$ à l'aide de $(N_1,\ldots, N_d)$.

Plus précisément, pour tous $x_1,\ldots, x_n \in \{1\ldots, d\}$, avec $\sum_{i = 1}^n x_i=n$ et en notant $n_\ell = \sum_{i = 1}^n 1_{\{x_i = \ell \}}$, on a
\begin{align*}
\PP_{\vp}\big[X_1=x_1,\ldots, X_n=x_n\big] & = \PP_{\vp}\big[N_1=n_1,\ldots, N_d=n_d\big] \\
& = \frac{n!}{n_1! \cdots n_d!} \prod_{\ell = 1}^d p_\ell^{n_i}.
\end{align*}
On en déduit que le logarithme de la vraisemblance est
\index{modèle multinomial}
%$$
\begin{equation} \label{rep log vraisemblance}
{\mathcal L}_n(\vp,X_1,\ldots, X_n) = c(X_1,\ldots, X_n)+\sum_{\ell = 1}^d N_\ell \log p_{\ell},
%$$
\end{equation}
où $c(X_1,\ldots, X_n)$ est une constante qui ne dépend pas de $\vp$. Donc maximiser la log-vraisemblance revient à chercher le maximum de
$$(p_1,\ldots, p_d)\leadsto \sum_{i = 1}^d N_i \log p_i,\;\;\text{sous la contrainte}\;\;\sum_{i = 1}^d p_i=1.$$
On peut diviser cette fonction par $n$ sans changer le problème. Alors, en notant $\mu$ la fonction de comptage sur $\{1,\ldots,d\}$ et
$f(x) = N_x/n$ pour $x\in \{1,\ldots, d$, on cherche à maximiser
$$g \leadsto \int f(x) \log g(x) \mu(dx)$$
avec $f$ et $g$ des densités par rapport à $\mu$. Le Lemme \ref{entropie} (inégalité d'entropie) donne la solution $g=f$, soit $p_\ell = N_\ell/n = \widehat p_{n,\ell}$. La deuxième partie du lemme découle de la représentation \eqref{rep log vraisemblance} de la log-vraisemblance.
\end{proof}
On a le résultat remarquable suivant
\begin{proposition}
Si $\Lambda_n$ désigne la statistique du rapport de vraisemblance maximal défini en \eqref{def stat rapport vrais max}, on a, pour tout point $\vp \in {\mathcal M}_d$
$$2\Lambda_n =n\chi^2\big(\widehat \vp_n^{\tt mv}, \vp(\widehat \gamma^{\,{\tt mv}}_n)\big)+\varepsilon_n,$$
où $\varepsilon_n$ tend vers $0$ en probabilité sous $\PP_{\vp}$ pour tout $\vp \in {\mathcal M}_0$.
\end{proposition}
\begin{proof} On reprend les notations de la preuve du Lemme \ref{emv freq emp}. On a
$$2\Lambda_n = \sum_{\ell=1}^d N_\ell \Big(\log(N_\ell/n)-\log p_\ell(\widehat \gamma_n^{\tt mv})\Big) = 2 \sum_{\ell = 1}^d N_\ell \log \frac{N_\ell}{n p_\ell(\widehat \gamma_n^{\tt mv})}.$$
Sous l'hypothèse nulle, c'est-à-dire si $\vp =\vp(\gamma)$ pour un $\gamma \in \Gamma$, on a simultanément
$$\frac{N_\ell}{n}\stackrel{\PP_{\vp}}{\rightarrow} \vp(\gamma),\;\;\;\text{et}\;\;\;\vp(\widehat \gamma^{\,{\tt mv}}_n)) \stackrel{\PP_{\vp}}{\rightarrow} \vp(\gamma).$$
En posant $\varepsilon_{n,\ell} = \frac{N_\ell}{n} - \vp(\widehat \gamma)$, on écrit le développement de Taylor du logarithme à l'ordre 2:
\begin{align*}
2 \Lambda_n  & =  2n \sum_{\ell=1}^d \big(\varepsilon_{n,\ell}+p_\ell(\widehat \gamma_n^{{\tt mv}})\big)\log\Big(1+\frac{\varepsilon_{n,\ell}}{p_\ell(\widehat \gamma_n^{{\tt mv}})}\Big) \\
 &=  2n \sum_{\ell=1}^d \big(\varepsilon_{n,\ell}+p_\ell(\widehat \gamma_n^{{\tt mv}})\big)
\left(\frac{\varepsilon_{n,\ell}}{p_\ell(\widehat \gamma_n^{{\tt mv}})}-\frac{1}{2}\left(\frac{\varepsilon_{n,\ell}}{p_\ell(\widehat \gamma_n^{{\tt mv}})}\right)^2\big(1+o_{\vp}(1)\big)\right) \\
& =  2n \sum_{\ell=1}^d \left(\varepsilon_{n,\ell}+\frac{1}{2}\frac{\varepsilon_{n,\ell}^2}{p_\ell(\widehat \gamma_n^{{\tt mv}})}\big(1+o_{\vp}(1)\big)-\frac{1}{2}\frac{\varepsilon_{n,\ell}^3}{p_\ell(\widehat \gamma_n^{{\tt mv}})^2}\big(1+o_{\vp}(1)\big)\right),
\end{align*}
où $o_{\vp}(1)$ désigne une suite de variables aléatoires qui tend vers $0$ en probabilité sous $\PP_{\vp}$.

Les $N_\ell/n$ et les $p_\ell(\widehat \gamma_n^{{\tt mv}})$ sont des fréquences empiriques, donc leur somme en $\ell$ vaut $1$ pour chacun d'où
$\sum_{\ell=1}^d \varepsilon_{n,\ell} = 0$. On en déduit
\begin{align*}
2\Lambda_n &=  n\sum_{\ell=1}^d \frac{\varepsilon_{n,\ell}^2}{p_\ell(\widehat \gamma_n^{{\tt mv}})} +\varepsilon_n\\
&=  n\sum_{\ell=1}^d  \frac{\big(N_\ell/n-p_\ell(\widehat \gamma_n^{{\tt mv}})\big)^2}{p_\ell(\widehat \gamma_n^{{\tt mv}})} +\varepsilon_n\\
&=  n\chi^2\big(\widehat \vp_n^{\,{\tt mv}}, \vp(\widehat \gamma^{\,{\tt mv}}_n)\big) +\varepsilon_n\vspace{3mm},
\end{align*}
où $\varepsilon_n$ est une suite de variables aléatoires qui tend vers $0$ en probabilité sous $\PP_{\vp}$.
\end{proof}
Ce développement asymptotique permet de construire le test suivant
\begin{proposition} \label{test chi2 estime}
Si $\gamma \leadsto \vp(\lambda)$ est régulière et $\Gamma$ de dimension $m$, on a pour tout point de l'hypothèse $\vp \in ({\mathcal M}_d)_0$,
$$n\chi^2\big(\widehat \vp_n^{\,{\tt mv}}, \vp(\widehat \gamma^{\,{\tt mv}}_n)\big) \stackrel{d}{\longrightarrow} \chi^2(d-m-1).$$
En particulier, le test défini par la zone de rejet
\begin{equation} \label{rejet chi2 estime}
{\mathcal R}_{n,\alpha} = \big\{n\chi^2\big(\widehat \vp_n^{\,{\tt mv}}, \vp(\widehat \gamma^{\,{\tt mv}}_n)\big) \geq q_{1-\alpha,d-m-1}^{\chi^2}\big\}
\end{equation}
où $q_{1-\alpha,d-m-1}^{\chi^2}$ désigne le quantile de la loi du $\chi^2$ à $d-m-1$ degrés de liberté est asymptotiquement de niveau $\alpha$ et consistant.
\end{proposition}
Nous admettons ce résultat. On pourra consulter van der Vaart \cite{VDW} ou Borovkov \cite{B} pour une preuve et des compléments.
\begin{definition}[Test du $\chi^2$ avec paramètres estimés]
On appelle test du $\chi^2$ avec paramètres estimés le test de zone de rejet définie par \eqref{rejet chi2 estime}.
\end{definition}
%\begin{proof}[Esquisse de démonstration]
%\begin{center}
%{\tt INSERT HERE SUPPL. 59}
%\end{center}
%%dire aussi un mot de la consistance
%\end{proof}
%\begin{remarque}
%\begin{center}
%{\tt INSERT HERE SUPPL. 60}
%\end{center}
%re-visiste du test simple, avec m=0
%\end{remarque}
%\begin{exemple}
%\end{exemple}
%NOte sur la consistance
\subsubsection{Application au test d'indépendance}
Un cas très classique du test du $\chi^2$ avec paramètres estimés est celui du test d'indépen\-dance. On observe un $n$-échantillon
\begin{equation} \label{echantillon couple}
(X_1,Y_1),\ldots, (X_n,Y_n)
\end{equation}
où les variables $X_i$ et $Y_i$ sont qualitatives, prenant respectivement à $d_1$ et $d_2$ valeurs possibles. La loi $\vp$ du couple $(X,Y)$ est à valeurs dans
$${\mathcal M}_{d_1,d_2} = \Big\{\vp = (p_{\ell,\ell'})_{1\leq \ell \leq d_1, 1\leq \ell' \leq d_2},\; 0 \leq p_{\ell,\ell'} \leq 1,\;\sum_{\ell,\ell'}p_{\ell,\ell'}=1\Big\}.$$
Notons les lois marginales du vecteur $(X,Y)^T$.
$$p_{\ell,\cdot} = \PP\big[X=\ell\big],\;\;\;\text{et}\;\;\;p_{\cdot,\ell'} = \PP\big[Y = \ell'\big]$$
pour $1\leq \ell \leq d_1,1\leq \ell'\leq d_2$, et où on a
$$p_{\ell,\cdot} = \sum_{\ell'=1}^{d_2}p_{\ell,\ell'},\;\;p_{\cdot,\ell'} = \sum_{\ell=1}^{d_1}p_{\ell,\ell'}.$$

On teste l'indépendance des variables $X$ et $Y$ à partir de l'observation du $n$-échantillon \eqref{echantillon couple}. Cela se traduit par l'hypothèse nulle:
$$H_0:\forall \ell,\ell'\;\;\;\;p_{\ell,\ell'} = p_{\ell,\cdot}p_{\cdot,\ell'}$$
contre l'alternative
$$H_1:\;\exists\, \ell,\ell',\;\;\;p_{\ell,\ell'} \neq p_{\ell,\cdot}p_{\cdot,\ell'}.$$
Ici, l'hypothèse nulle s'écrit
$$H_0: \vp \in ({\mathcal M}_{d_1,d_2})_0 = \Big\{\vp = (p_{\ell,\ell'}),\;p_{\ell,\ell'} = p_{\ell,\cdot}p_{\cdot,\ell'}\Big\}$$
et donc $({\mathcal M}_{d_1,d_2})_0 = \big\{\vp=\vp(\gamma),\;\gamma \in \Gamma\big\}$ où $\Gamma \subset \R^m$ avec $m=d_1+d_2-2$ et la paramétrisation est régulière. On applique alors les résultats de la section précédente avec $m = d_1+d_2-2 < d_1d_2 -1$. Il nous faut pour cela connaître l'estimateur du maximum de vraisemblance sur $({\mathcal M}_{d_1,d_2})_0$.
\begin{lemme}
Pour la famille $\big\{\vp,\,\vp\in ({\mathcal M}_{d_1,d_2})_0\big\}$, l'estimateur du maximum de vraisemblance $\widehat \vp_{n,0}^{\,{\tt mv}}$  s'écrit
$$\big(\widehat p_{n,0}^{\,\,{\tt mv}}\big)_{\ell,\ell'} = \widehat p_{n, (\ell,\cdot)}\,  \widehat p_{n, (\cdot,\ell')}$$
pour $1\leq \ell \leq d_1$, $1 \leq \ell' \leq d_2$, avec
$$ \widehat p_{n, (\ell,\cdot)} = \frac{1}{n}\sum_{i = 1}^n 1_{\{X_i = \ell \}}\;\;\;\text{et}\;\;\;
\widehat p_{n, (\cdot,\ell')} = \frac{1}{n}\sum_{i = 1}^n 1_{\{Y_i = \ell' \}}$$
les fréquences empiriques marginales, qui sont aussi les estimateurs de maximum de vraisemblance correspondants aux familles des lois marginales d'après le Lemme \ref{emv freq emp}.
\end{lemme}
\begin{proof} C'est essentiellement la même preuve que celle du Lemme \ref{emv freq emp}. Si $\vp \in ({\mathcal M}_{d_1,d_2})_0$, les variables aléatoires $X_i$ et $Y_i$ sont indépendantes, et la vraisemblance s'écrit
$${\mathcal L}_n\big(\vp, (X_1,Y_1),\ldots (X_n,Y_n)\big) = \prod_{i = 1}^n p_{X_i,\cdot}\,p_{\cdot,Y_i} = \big(\prod_{i = 1}^np_{X_i,\cdot}\big) \big(\prod_{i = 1}^np_{\cdot,Y_i}\big).$$
En notant $N^X_{\ell} = \sum_{i = 1}^\ell 1_{\{X_i = \ell\}}$ et $N_{\ell'} = \sum_{i = 1}^n 1_{\{Y_i = \ell'\}}$ et en passant au logarithme, on obtient
\begin{align*}
&\log {\mathcal L}_n\big(\vp, (X_1,Y_1),\ldots (X_n,Y_n)\big) \\
=\,&c(X_1,\ldots, X_n, Y_1,\ldots, Y_n)+\sum_{\ell=1}^{d_1}N_\ell^{X}\log p_{\ell, \cdot}  + \sum_{\ell'=1}^{d_2}N_\ell^{Y}\log p_{\cdot,\ell'},
\end{align*}
où $c(X_1,\ldots, X_n, Y_1,\ldots, Y_n)$ ne dépend pas de $\vp$, et on raisonne comme pour le Lemme \ref{emv freq emp} en remplaçant $\{1,\ldots, d\}$ par $\{1,\ldots, d_1+d_2\}$.
\end{proof}
Par ailleurs, le Lemme \ref{emv freq emp} donne l'estimateur du maximum de vraisemblance $\widehat \vp_n^{\,\tt mv}$ pour la famille globale $\big\{\vp,\,\vp \in {\mathcal M}_{d_1,d_2}\big\}$  qui est l'estimateur des fréquences empiriques
$$(\widehat \vp_n)_{\ell,\ell'} = \frac{1}{n}\sum_{i = 1}^{n}1_{\{(X_i,Y_i) = (\ell,\ell')\}}$$
pour $1\leq \ell \leq d_1$, $1 \leq \ell' \leq d_2$.

Alors, comme précédemment, sous l'hypothèse nulle, c'est-à-dire pour $\vp \in  ({\mathcal M}_{d_1,d_2})_0$ on a la convergence
$$n\chi^2\Big(\widehat \vp_n^{\,{\tt mv}},\, \widehat \vp_{n,0}^{\,{\tt mv}}\Big) \stackrel{d}{\longrightarrow} \chi^2\Big((d_1-1)(d_2-1)\Big)$$
en loi sous $\PP_{\vp}$. En particulier, la statistique de test s'écrit
$$n\chi^2\Big(\widehat \vp_n^{\,{\tt mv}},\, \widehat \vp_{n,0}^{\,{\tt mv}}\Big)  = n\sum_{\ell,\ell'}\frac{\Big((\widehat \vp_n)_{\ell,\ell'}- \widehat p_{n, (\ell,\cdot)} \widehat p_{n, (\cdot,\ell')} \Big)^2}{\widehat p_{n, (\ell,\cdot)} \widehat p_{n, (\cdot,\ell')}}.$$
\begin{proposition}[Test d'indépendance du $\chi^2$] Pour tout $\alpha \in (0,1)$, le test défini par la zone de rejet
$${\mathcal R}_{n,\alpha} = \Big\{n\chi^2\Big(\widehat \vp_n^{\,{\tt mv}},\, \widehat \vp_{n,0}^{\,{\tt mv}}\Big) \geq q_{1-\alpha, (d_1-1)(d_2-1)}^{\chi^2}\Big\},$$
où $q_{1-\alpha, (d_1-1)(d_2-1)}^{\chi^2}$ est le quantile d'ordre $\alpha$ de la loi du $\chi^2$ à $(d_1-1)(d_2-1)$ degrés de liberté est asymptotiquement de niveau $\alpha$ et consistant.
\end{proposition}
Nous admettons la démonstration de ce résultat qui est essentiellement une application de la Proposition \ref{test chi2 estime}.
\begin{exemple}
\emph{
On test l'indépendance entre le nombre d'enfants d'un ménage et son revenu\footnote{D'après \cite{B}, p. 354.} sur une population de $n=25263$ ménages en Suède au milieu du siècle passé. Les ménages sont classés en 4 catégories selon leur revenus : la catégorie $I$ correspond aux revenus les plus faibles et la catégorie $IV$ aux revenus les plus élevés. Les résultats obtenus sont les suivants :
\begin{center}
\begin{tabular}{ccccccccc}
%\hline
 nb. enfants & \vline & I & II & III & IV & \vline & pop. \\
\hline
 0 & \vline & 2161 & 3577 & 2184 & 1636 & \vline & 9558 \\
 1 & \vline & 2755 & 5081 & 2222 & 1052 & \vline & 11110 \\
 2 & \vline & 936 & 1753 & 640 & 306 & \vline & 3635 \\
 3 & \vline & 225 & 419 & 96 & 38 & \vline & 778 \\
 $\geq $ 4 & \vline & 39 & 98 & 31 & 14 & \vline & 182\\
 \hline
 pop. & \vline & 6116 & 10928 & 5173 & 3016 & \vline & 25263 \\
 %\hline
\end{tabular}
\end{center}
Sans préjuger de la pertinence de la modélisation, on met en place un test du $\chi^2$ d'indépendance pour la loi $\boldsymbol{p} \in {\mathcal M}_{4,5}$
de la variable (nombre d'enfants, revenu) à valeurs dans $\{0,1,2,3,\geq 4\}\times \{I, II, III, IV\}$ dont la distribution empirique est donnée par le tableau ci-dessus et dont les marginales empiriques se lisent sur la dernière colonne et la dernière ligne. On trouve
$$n\chi^2\Big(\widehat \vp_n^{\,{\tt mv}},\, \widehat \vp_{n,0}^{\,{\tt mv}}\Big) = 568,5$$
ce qui est significativement plus grand que le quantile d'ordre $1-\alpha$ pour une loi du $\chi^2$ à $(5-1)(4-1) = 12$ degrés de liberté, même pour des petites valeurs de $\alpha$. Dans ces conditions, on rejette l'hypothèse d'indépendance.
}
\end{exemple}


%\section{Exercices}
%\begin{exercice} \label{statistique du score}
%\begin{center}
%{\tt INSERT HERE SUPPL. 62}
%\end{center}
%\end{exercice}
%\begin{exercice} \label{regularite}
%\begin{center}
%{\tt INSERT HERE SUPPL. 63}
%\end{center}
%\end{exercice}


.



%\section{Dualité tests-régions de confiance : le cadre asymptotique}



\begin{thebibliography}{99}
\bibitem{B} Borovkov, A. A. {\it Mathematical statistics} (traduit du russe). Gordon and Breach science publishers, 1998.
\bibitem{GCP} Genon-Catalot, V., et Picard, D. {\it Éléments de statistique asymptotique}. Mathématiques \& Applications. Springer-Verlag, Paris, 1993.
\bibitem{IH} Ibragimov, I. A., et Hasminskii, R. Z. {\it Statistical Estimation, Asymptotic Theory}. New-York, Berlin, 1981.
\bibitem{JP} Jacod, J. et Protter, P. {\it Probability essentials}. Seconde édition. Universitext. Springer-Verlag, Berlin, 2003.
\bibitem{M} Méléard, S. {\it Aléatoire}. Polycopié de l'\'Ecole polytechnique.
\bibitem{Monfort} Monfort, A. {\it Statistique}. Polycopié de l'\'Ecole polytechnique (version éditée par O. Cappé).
\bibitem{Picard} Picard, D. {\it Statistique et Modèles Aléatoires}. Polycopié de l'Université Paris 7.
\bibitem{Tsyb} Tsybakov, A. {\it Statistique Appliquée}. Polycopié de l'Université de Pierre et Marie Curie.
\bibitem{Tsyb2} Tsybakov, A. {\it Apprentissage statistique et estimation non-paramétrique}. Polycopié de l'\'Ecole polytechnique.
\bibitem{VDW} van der Vaart, A. {\it Asymptotic statistics}. Cambridge Series in Statistical and Probabilistic Mathematics, 3. Cambridge University Press, Cambridge, 1998.
\bibitem{W} Wasserman, L. {\it All of statistics. A concise course in statistical inference}. Springer Texts in Statistics. Springer-Verlag, New York, 2004.

\end{thebibliography}


\printindex





\end{document} 